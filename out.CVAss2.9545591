Lmod has detected the following error: You can only have one PYTORCH  module
loaded at a time.
You already have pytorch/python2.7  loaded.
To correct the situation, please enter the following command:

  module swap pytorch/python2.7  pytorch/0.2.0_1


While processing the following module(s):

Module fullname  Module Filename
---------------  ---------------
pytorch/0.2.0_1  /share/apps/modulefiles/pytorch/0.2.0_1.lua
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
Train Epoch: 1 [0/35339 (0%)]	Loss: 3.867984
Train Epoch: 1 [640/35339 (2%)]	Loss: 3.765065
Train Epoch: 1 [1280/35339 (4%)]	Loss: 3.680074
Train Epoch: 1 [1920/35339 (5%)]	Loss: 3.562442
Train Epoch: 1 [2560/35339 (7%)]	Loss: 3.503582
Train Epoch: 1 [3200/35339 (9%)]	Loss: 3.361715
Train Epoch: 1 [3840/35339 (11%)]	Loss: 3.332720
Train Epoch: 1 [4480/35339 (13%)]	Loss: 3.379965
Train Epoch: 1 [5120/35339 (14%)]	Loss: 3.264769
Train Epoch: 1 [5760/35339 (16%)]	Loss: 3.241677
Train Epoch: 1 [6400/35339 (18%)]	Loss: 3.296263
Train Epoch: 1 [7040/35339 (20%)]	Loss: 3.160486
Train Epoch: 1 [7680/35339 (22%)]	Loss: 3.148553
Train Epoch: 1 [8320/35339 (24%)]	Loss: 2.955512
Train Epoch: 1 [8960/35339 (25%)]	Loss: 3.126864
Train Epoch: 1 [9600/35339 (27%)]	Loss: 2.984510
Train Epoch: 1 [10240/35339 (29%)]	Loss: 3.086588
Train Epoch: 1 [10880/35339 (31%)]	Loss: 2.907900
Train Epoch: 1 [11520/35339 (33%)]	Loss: 3.080449
Train Epoch: 1 [12160/35339 (34%)]	Loss: 2.957172
Train Epoch: 1 [12800/35339 (36%)]	Loss: 3.042843
Train Epoch: 1 [13440/35339 (38%)]	Loss: 2.833460
Train Epoch: 1 [14080/35339 (40%)]	Loss: 2.728953
Train Epoch: 1 [14720/35339 (42%)]	Loss: 2.886908
Train Epoch: 1 [15360/35339 (43%)]	Loss: 2.670933
Train Epoch: 1 [16000/35339 (45%)]	Loss: 2.665229
Train Epoch: 1 [16640/35339 (47%)]	Loss: 2.653918
Train Epoch: 1 [17280/35339 (49%)]	Loss: 2.567525
Train Epoch: 1 [17920/35339 (51%)]	Loss: 2.645045
Train Epoch: 1 [18560/35339 (52%)]	Loss: 2.388225
Train Epoch: 1 [19200/35339 (54%)]	Loss: 2.474954
Train Epoch: 1 [19840/35339 (56%)]	Loss: 2.321236
Train Epoch: 1 [20480/35339 (58%)]	Loss: 2.300092
Train Epoch: 1 [21120/35339 (60%)]	Loss: 2.475071
Train Epoch: 1 [21760/35339 (61%)]	Loss: 2.415255
Train Epoch: 1 [22400/35339 (63%)]	Loss: 2.226781
Train Epoch: 1 [23040/35339 (65%)]	Loss: 2.251833
Train Epoch: 1 [23680/35339 (67%)]	Loss: 2.322906
Train Epoch: 1 [24320/35339 (69%)]	Loss: 2.381157
Train Epoch: 1 [24960/35339 (71%)]	Loss: 2.280350
Train Epoch: 1 [25600/35339 (72%)]	Loss: 2.188241
Train Epoch: 1 [26240/35339 (74%)]	Loss: 2.174310
Train Epoch: 1 [26880/35339 (76%)]	Loss: 2.005730
Train Epoch: 1 [27520/35339 (78%)]	Loss: 2.103084
Train Epoch: 1 [28160/35339 (80%)]	Loss: 2.016675
Train Epoch: 1 [28800/35339 (81%)]	Loss: 2.067207
Train Epoch: 1 [29440/35339 (83%)]	Loss: 2.041020
Train Epoch: 1 [30080/35339 (85%)]	Loss: 1.907120
Train Epoch: 1 [30720/35339 (87%)]	Loss: 1.777737
Train Epoch: 1 [31360/35339 (89%)]	Loss: 2.118117
Train Epoch: 1 [32000/35339 (90%)]	Loss: 1.951103
Train Epoch: 1 [32640/35339 (92%)]	Loss: 1.899086
Train Epoch: 1 [33280/35339 (94%)]	Loss: 1.661811
Train Epoch: 1 [33920/35339 (96%)]	Loss: 1.906340
Train Epoch: 1 [34560/35339 (98%)]	Loss: 1.696023
Train Epoch: 1 [35200/35339 (99%)]	Loss: 1.916260

Validation set: Average loss: 3.8238, Accuracy: 547/3870 (14%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 2 [0/35339 (0%)]	Loss: 1.645363
Train Epoch: 2 [640/35339 (2%)]	Loss: 1.622084
Train Epoch: 2 [1280/35339 (4%)]	Loss: 1.900631
Train Epoch: 2 [1920/35339 (5%)]	Loss: 1.747418
Train Epoch: 2 [2560/35339 (7%)]	Loss: 1.564525
Train Epoch: 2 [3200/35339 (9%)]	Loss: 1.776422
Train Epoch: 2 [3840/35339 (11%)]	Loss: 1.747597
Train Epoch: 2 [4480/35339 (13%)]	Loss: 1.906896
Train Epoch: 2 [5120/35339 (14%)]	Loss: 1.513668
Train Epoch: 2 [5760/35339 (16%)]	Loss: 1.503319
Train Epoch: 2 [6400/35339 (18%)]	Loss: 1.665513
Train Epoch: 2 [7040/35339 (20%)]	Loss: 1.665275
Train Epoch: 2 [7680/35339 (22%)]	Loss: 1.411878
Train Epoch: 2 [8320/35339 (24%)]	Loss: 1.371066
Train Epoch: 2 [8960/35339 (25%)]	Loss: 1.285970
Train Epoch: 2 [9600/35339 (27%)]	Loss: 1.809893
Train Epoch: 2 [10240/35339 (29%)]	Loss: 1.534377
Train Epoch: 2 [10880/35339 (31%)]	Loss: 1.246563
Train Epoch: 2 [11520/35339 (33%)]	Loss: 1.361192
Train Epoch: 2 [12160/35339 (34%)]	Loss: 1.414502
Train Epoch: 2 [12800/35339 (36%)]	Loss: 1.344560
Train Epoch: 2 [13440/35339 (38%)]	Loss: 1.543358
Train Epoch: 2 [14080/35339 (40%)]	Loss: 1.417640
Train Epoch: 2 [14720/35339 (42%)]	Loss: 1.377943
Train Epoch: 2 [15360/35339 (43%)]	Loss: 1.415133
Train Epoch: 2 [16000/35339 (45%)]	Loss: 1.472300
Train Epoch: 2 [16640/35339 (47%)]	Loss: 1.269505
Train Epoch: 2 [17280/35339 (49%)]	Loss: 1.280712
Train Epoch: 2 [17920/35339 (51%)]	Loss: 1.354486
Train Epoch: 2 [18560/35339 (52%)]	Loss: 1.309445
Train Epoch: 2 [19200/35339 (54%)]	Loss: 1.328994
Train Epoch: 2 [19840/35339 (56%)]	Loss: 1.088230
Train Epoch: 2 [20480/35339 (58%)]	Loss: 1.169402
Train Epoch: 2 [21120/35339 (60%)]	Loss: 1.246212
Train Epoch: 2 [21760/35339 (61%)]	Loss: 1.249164
Train Epoch: 2 [22400/35339 (63%)]	Loss: 1.746873
Train Epoch: 2 [23040/35339 (65%)]	Loss: 1.111710
Train Epoch: 2 [23680/35339 (67%)]	Loss: 1.098320
Train Epoch: 2 [24320/35339 (69%)]	Loss: 1.472071
Train Epoch: 2 [24960/35339 (71%)]	Loss: 1.124109
Train Epoch: 2 [25600/35339 (72%)]	Loss: 1.208610
Train Epoch: 2 [26240/35339 (74%)]	Loss: 1.266511
Train Epoch: 2 [26880/35339 (76%)]	Loss: 1.196878
Train Epoch: 2 [27520/35339 (78%)]	Loss: 1.184855
Train Epoch: 2 [28160/35339 (80%)]	Loss: 1.153134
Train Epoch: 2 [28800/35339 (81%)]	Loss: 1.153236
Train Epoch: 2 [29440/35339 (83%)]	Loss: 1.244127
Train Epoch: 2 [30080/35339 (85%)]	Loss: 1.304500
Train Epoch: 2 [30720/35339 (87%)]	Loss: 1.245506
Train Epoch: 2 [31360/35339 (89%)]	Loss: 1.307669
Train Epoch: 2 [32000/35339 (90%)]	Loss: 1.047324
Train Epoch: 2 [32640/35339 (92%)]	Loss: 0.982083
Train Epoch: 2 [33280/35339 (94%)]	Loss: 1.045054
Train Epoch: 2 [33920/35339 (96%)]	Loss: 1.112068
Train Epoch: 2 [34560/35339 (98%)]	Loss: 1.035384
Train Epoch: 2 [35200/35339 (99%)]	Loss: 0.962448

Validation set: Average loss: 3.8714, Accuracy: 642/3870 (17%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 3 [0/35339 (0%)]	Loss: 0.933445
Train Epoch: 3 [640/35339 (2%)]	Loss: 1.135085
Train Epoch: 3 [1280/35339 (4%)]	Loss: 1.019803
Train Epoch: 3 [1920/35339 (5%)]	Loss: 0.962178
Train Epoch: 3 [2560/35339 (7%)]	Loss: 0.958937
Train Epoch: 3 [3200/35339 (9%)]	Loss: 0.967393
Train Epoch: 3 [3840/35339 (11%)]	Loss: 1.025842
Train Epoch: 3 [4480/35339 (13%)]	Loss: 1.098207
Train Epoch: 3 [5120/35339 (14%)]	Loss: 1.001032
Train Epoch: 3 [5760/35339 (16%)]	Loss: 1.087355
Train Epoch: 3 [6400/35339 (18%)]	Loss: 0.980785
Train Epoch: 3 [7040/35339 (20%)]	Loss: 0.861533
Train Epoch: 3 [7680/35339 (22%)]	Loss: 0.936110
Train Epoch: 3 [8320/35339 (24%)]	Loss: 1.164650
Train Epoch: 3 [8960/35339 (25%)]	Loss: 0.854216
Train Epoch: 3 [9600/35339 (27%)]	Loss: 0.851744
Train Epoch: 3 [10240/35339 (29%)]	Loss: 0.966605
Train Epoch: 3 [10880/35339 (31%)]	Loss: 0.968198
Train Epoch: 3 [11520/35339 (33%)]	Loss: 1.066562
Train Epoch: 3 [12160/35339 (34%)]	Loss: 1.048535
Train Epoch: 3 [12800/35339 (36%)]	Loss: 1.163574
Train Epoch: 3 [13440/35339 (38%)]	Loss: 0.888983
Train Epoch: 3 [14080/35339 (40%)]	Loss: 0.909671
Train Epoch: 3 [14720/35339 (42%)]	Loss: 0.784938
Train Epoch: 3 [15360/35339 (43%)]	Loss: 0.996761
Train Epoch: 3 [16000/35339 (45%)]	Loss: 0.885468
Train Epoch: 3 [16640/35339 (47%)]	Loss: 0.838592
Train Epoch: 3 [17280/35339 (49%)]	Loss: 1.009967
Train Epoch: 3 [17920/35339 (51%)]	Loss: 0.853069
Train Epoch: 3 [18560/35339 (52%)]	Loss: 0.903630
Train Epoch: 3 [19200/35339 (54%)]	Loss: 0.753283
Train Epoch: 3 [19840/35339 (56%)]	Loss: 0.806248
Train Epoch: 3 [20480/35339 (58%)]	Loss: 0.911684
Train Epoch: 3 [21120/35339 (60%)]	Loss: 0.708628
Train Epoch: 3 [21760/35339 (61%)]	Loss: 0.840502
Train Epoch: 3 [22400/35339 (63%)]	Loss: 0.890901
Train Epoch: 3 [23040/35339 (65%)]	Loss: 0.852238
Train Epoch: 3 [23680/35339 (67%)]	Loss: 0.952157
Train Epoch: 3 [24320/35339 (69%)]	Loss: 0.914979
Train Epoch: 3 [24960/35339 (71%)]	Loss: 0.717561
Train Epoch: 3 [25600/35339 (72%)]	Loss: 0.732201
Train Epoch: 3 [26240/35339 (74%)]	Loss: 0.753549
Train Epoch: 3 [26880/35339 (76%)]	Loss: 0.734942
Train Epoch: 3 [27520/35339 (78%)]	Loss: 0.973836
Train Epoch: 3 [28160/35339 (80%)]	Loss: 0.764830
Train Epoch: 3 [28800/35339 (81%)]	Loss: 0.760402
Train Epoch: 3 [29440/35339 (83%)]	Loss: 0.951382
Train Epoch: 3 [30080/35339 (85%)]	Loss: 0.917968
Train Epoch: 3 [30720/35339 (87%)]	Loss: 0.991715
Train Epoch: 3 [31360/35339 (89%)]	Loss: 0.793738
Train Epoch: 3 [32000/35339 (90%)]	Loss: 1.029831
Train Epoch: 3 [32640/35339 (92%)]	Loss: 0.665336
Train Epoch: 3 [33280/35339 (94%)]	Loss: 0.933727
Train Epoch: 3 [33920/35339 (96%)]	Loss: 0.832227
Train Epoch: 3 [34560/35339 (98%)]	Loss: 0.621812
Train Epoch: 3 [35200/35339 (99%)]	Loss: 0.854294

Validation set: Average loss: 3.7935, Accuracy: 606/3870 (16%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 4 [0/35339 (0%)]	Loss: 0.749674
Train Epoch: 4 [640/35339 (2%)]	Loss: 0.684168
Train Epoch: 4 [1280/35339 (4%)]	Loss: 0.668896
Train Epoch: 4 [1920/35339 (5%)]	Loss: 0.861308
Train Epoch: 4 [2560/35339 (7%)]	Loss: 0.892827
Train Epoch: 4 [3200/35339 (9%)]	Loss: 0.648117
Train Epoch: 4 [3840/35339 (11%)]	Loss: 0.731568
Train Epoch: 4 [4480/35339 (13%)]	Loss: 0.829387
Train Epoch: 4 [5120/35339 (14%)]	Loss: 0.871405
Train Epoch: 4 [5760/35339 (16%)]	Loss: 0.736899
Train Epoch: 4 [6400/35339 (18%)]	Loss: 0.982961
Train Epoch: 4 [7040/35339 (20%)]	Loss: 0.822300
Train Epoch: 4 [7680/35339 (22%)]	Loss: 0.999640
Train Epoch: 4 [8320/35339 (24%)]	Loss: 0.856797
Train Epoch: 4 [8960/35339 (25%)]	Loss: 0.882113
Train Epoch: 4 [9600/35339 (27%)]	Loss: 0.809573
Train Epoch: 4 [10240/35339 (29%)]	Loss: 0.655435
Train Epoch: 4 [10880/35339 (31%)]	Loss: 0.875427
Train Epoch: 4 [11520/35339 (33%)]	Loss: 0.730520
Train Epoch: 4 [12160/35339 (34%)]	Loss: 0.746568
Train Epoch: 4 [12800/35339 (36%)]	Loss: 0.763968
Train Epoch: 4 [13440/35339 (38%)]	Loss: 0.646206
Train Epoch: 4 [14080/35339 (40%)]	Loss: 0.913503
Train Epoch: 4 [14720/35339 (42%)]	Loss: 0.771698
Train Epoch: 4 [15360/35339 (43%)]	Loss: 0.661111
Train Epoch: 4 [16000/35339 (45%)]	Loss: 0.912537
Train Epoch: 4 [16640/35339 (47%)]	Loss: 0.665518
Train Epoch: 4 [17280/35339 (49%)]	Loss: 0.849674
Train Epoch: 4 [17920/35339 (51%)]	Loss: 0.706311
Train Epoch: 4 [18560/35339 (52%)]	Loss: 0.558435
Train Epoch: 4 [19200/35339 (54%)]	Loss: 0.814872
Train Epoch: 4 [19840/35339 (56%)]	Loss: 0.782447
Train Epoch: 4 [20480/35339 (58%)]	Loss: 0.704830
Train Epoch: 4 [21120/35339 (60%)]	Loss: 0.695875
Train Epoch: 4 [21760/35339 (61%)]	Loss: 0.716122
Train Epoch: 4 [22400/35339 (63%)]	Loss: 0.685174
Train Epoch: 4 [23040/35339 (65%)]	Loss: 0.767061
Train Epoch: 4 [23680/35339 (67%)]	Loss: 0.748638
Train Epoch: 4 [24320/35339 (69%)]	Loss: 0.730212
Train Epoch: 4 [24960/35339 (71%)]	Loss: 0.564383
Train Epoch: 4 [25600/35339 (72%)]	Loss: 0.697621
Train Epoch: 4 [26240/35339 (74%)]	Loss: 0.845233
Train Epoch: 4 [26880/35339 (76%)]	Loss: 0.570682
Train Epoch: 4 [27520/35339 (78%)]	Loss: 0.734606
Train Epoch: 4 [28160/35339 (80%)]	Loss: 0.756961
Train Epoch: 4 [28800/35339 (81%)]	Loss: 0.593961
Train Epoch: 4 [29440/35339 (83%)]	Loss: 0.602489
Train Epoch: 4 [30080/35339 (85%)]	Loss: 0.618517
Train Epoch: 4 [30720/35339 (87%)]	Loss: 0.609278
Train Epoch: 4 [31360/35339 (89%)]	Loss: 0.609433
Train Epoch: 4 [32000/35339 (90%)]	Loss: 0.655828
Train Epoch: 4 [32640/35339 (92%)]	Loss: 0.680502
Train Epoch: 4 [33280/35339 (94%)]	Loss: 0.754111
Train Epoch: 4 [33920/35339 (96%)]	Loss: 0.756490
Train Epoch: 4 [34560/35339 (98%)]	Loss: 0.683693
Train Epoch: 4 [35200/35339 (99%)]	Loss: 0.691646

Validation set: Average loss: 3.7156, Accuracy: 664/3870 (17%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 5 [0/35339 (0%)]	Loss: 0.749618
Train Epoch: 5 [640/35339 (2%)]	Loss: 0.780126
Train Epoch: 5 [1280/35339 (4%)]	Loss: 0.504784
Train Epoch: 5 [1920/35339 (5%)]	Loss: 0.924185
Train Epoch: 5 [2560/35339 (7%)]	Loss: 0.609807
Train Epoch: 5 [3200/35339 (9%)]	Loss: 0.738917
Train Epoch: 5 [3840/35339 (11%)]	Loss: 0.617860
Train Epoch: 5 [4480/35339 (13%)]	Loss: 0.457585
Train Epoch: 5 [5120/35339 (14%)]	Loss: 0.450460
Train Epoch: 5 [5760/35339 (16%)]	Loss: 0.881954
Train Epoch: 5 [6400/35339 (18%)]	Loss: 0.569764
Train Epoch: 5 [7040/35339 (20%)]	Loss: 0.836250
Train Epoch: 5 [7680/35339 (22%)]	Loss: 0.664716
Train Epoch: 5 [8320/35339 (24%)]	Loss: 0.796997
Train Epoch: 5 [8960/35339 (25%)]	Loss: 0.541805
Train Epoch: 5 [9600/35339 (27%)]	Loss: 0.534550
Train Epoch: 5 [10240/35339 (29%)]	Loss: 0.745985
Train Epoch: 5 [10880/35339 (31%)]	Loss: 0.941091
Train Epoch: 5 [11520/35339 (33%)]	Loss: 0.616944
Train Epoch: 5 [12160/35339 (34%)]	Loss: 0.697127
Train Epoch: 5 [12800/35339 (36%)]	Loss: 0.500039
Train Epoch: 5 [13440/35339 (38%)]	Loss: 0.567130
Train Epoch: 5 [14080/35339 (40%)]	Loss: 0.710564
Train Epoch: 5 [14720/35339 (42%)]	Loss: 0.722577
Train Epoch: 5 [15360/35339 (43%)]	Loss: 0.574927
Train Epoch: 5 [16000/35339 (45%)]	Loss: 0.690169
Train Epoch: 5 [16640/35339 (47%)]	Loss: 0.497308
Train Epoch: 5 [17280/35339 (49%)]	Loss: 0.586181
Train Epoch: 5 [17920/35339 (51%)]	Loss: 0.557399
Train Epoch: 5 [18560/35339 (52%)]	Loss: 0.549152
Train Epoch: 5 [19200/35339 (54%)]	Loss: 0.597044
Train Epoch: 5 [19840/35339 (56%)]	Loss: 0.636133
Train Epoch: 5 [20480/35339 (58%)]	Loss: 0.536498
Train Epoch: 5 [21120/35339 (60%)]	Loss: 0.479516
Train Epoch: 5 [21760/35339 (61%)]	Loss: 0.742126
Train Epoch: 5 [22400/35339 (63%)]	Loss: 0.627171
Train Epoch: 5 [23040/35339 (65%)]	Loss: 0.488715
Train Epoch: 5 [23680/35339 (67%)]	Loss: 0.470191
Train Epoch: 5 [24320/35339 (69%)]	Loss: 0.832631
Train Epoch: 5 [24960/35339 (71%)]	Loss: 0.629683
Train Epoch: 5 [25600/35339 (72%)]	Loss: 0.553108
Train Epoch: 5 [26240/35339 (74%)]	Loss: 0.563040
Train Epoch: 5 [26880/35339 (76%)]	Loss: 0.711143
Train Epoch: 5 [27520/35339 (78%)]	Loss: 0.558317
Train Epoch: 5 [28160/35339 (80%)]	Loss: 0.518077
Train Epoch: 5 [28800/35339 (81%)]	Loss: 0.511451
Train Epoch: 5 [29440/35339 (83%)]	Loss: 0.458851
Train Epoch: 5 [30080/35339 (85%)]	Loss: 0.780175
Train Epoch: 5 [30720/35339 (87%)]	Loss: 0.704743
Train Epoch: 5 [31360/35339 (89%)]	Loss: 0.580219
Train Epoch: 5 [32000/35339 (90%)]	Loss: 0.867251
Train Epoch: 5 [32640/35339 (92%)]	Loss: 0.502627
Train Epoch: 5 [33280/35339 (94%)]	Loss: 0.728671
Train Epoch: 5 [33920/35339 (96%)]	Loss: 0.527615
Train Epoch: 5 [34560/35339 (98%)]	Loss: 0.657591
Train Epoch: 5 [35200/35339 (99%)]	Loss: 0.663340

Validation set: Average loss: 3.6036, Accuracy: 756/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 6 [0/35339 (0%)]	Loss: 0.764958
Train Epoch: 6 [640/35339 (2%)]	Loss: 0.631056
Train Epoch: 6 [1280/35339 (4%)]	Loss: 0.600542
Train Epoch: 6 [1920/35339 (5%)]	Loss: 0.456026
Train Epoch: 6 [2560/35339 (7%)]	Loss: 0.768084
Train Epoch: 6 [3200/35339 (9%)]	Loss: 0.593137
Train Epoch: 6 [3840/35339 (11%)]	Loss: 0.640317
Train Epoch: 6 [4480/35339 (13%)]	Loss: 0.599138
Train Epoch: 6 [5120/35339 (14%)]	Loss: 0.607016
Train Epoch: 6 [5760/35339 (16%)]	Loss: 0.494119
Train Epoch: 6 [6400/35339 (18%)]	Loss: 0.380222
Train Epoch: 6 [7040/35339 (20%)]	Loss: 0.523780
Train Epoch: 6 [7680/35339 (22%)]	Loss: 0.523551
Train Epoch: 6 [8320/35339 (24%)]	Loss: 0.586560
Train Epoch: 6 [8960/35339 (25%)]	Loss: 0.441903
Train Epoch: 6 [9600/35339 (27%)]	Loss: 0.598167
Train Epoch: 6 [10240/35339 (29%)]	Loss: 0.640762
Train Epoch: 6 [10880/35339 (31%)]	Loss: 0.682685
Train Epoch: 6 [11520/35339 (33%)]	Loss: 0.508506
Train Epoch: 6 [12160/35339 (34%)]	Loss: 0.549561
Train Epoch: 6 [12800/35339 (36%)]	Loss: 0.535351
Train Epoch: 6 [13440/35339 (38%)]	Loss: 0.600277
Train Epoch: 6 [14080/35339 (40%)]	Loss: 0.456432
Train Epoch: 6 [14720/35339 (42%)]	Loss: 0.601961
Train Epoch: 6 [15360/35339 (43%)]	Loss: 0.572444
Train Epoch: 6 [16000/35339 (45%)]	Loss: 0.609955
Train Epoch: 6 [16640/35339 (47%)]	Loss: 0.444257
Train Epoch: 6 [17280/35339 (49%)]	Loss: 0.597593
Train Epoch: 6 [17920/35339 (51%)]	Loss: 0.638297
Train Epoch: 6 [18560/35339 (52%)]	Loss: 0.517066
Train Epoch: 6 [19200/35339 (54%)]	Loss: 0.509339
Train Epoch: 6 [19840/35339 (56%)]	Loss: 0.525928
Train Epoch: 6 [20480/35339 (58%)]	Loss: 0.600320
Train Epoch: 6 [21120/35339 (60%)]	Loss: 0.648538
Train Epoch: 6 [21760/35339 (61%)]	Loss: 0.331769
Train Epoch: 6 [22400/35339 (63%)]	Loss: 0.381008
Train Epoch: 6 [23040/35339 (65%)]	Loss: 0.583551
Train Epoch: 6 [23680/35339 (67%)]	Loss: 0.560083
Train Epoch: 6 [24320/35339 (69%)]	Loss: 0.601703
Train Epoch: 6 [24960/35339 (71%)]	Loss: 0.518566
Train Epoch: 6 [25600/35339 (72%)]	Loss: 0.779138
Train Epoch: 6 [26240/35339 (74%)]	Loss: 0.557624
Train Epoch: 6 [26880/35339 (76%)]	Loss: 0.639189
Train Epoch: 6 [27520/35339 (78%)]	Loss: 0.663489
Train Epoch: 6 [28160/35339 (80%)]	Loss: 0.394448
Train Epoch: 6 [28800/35339 (81%)]	Loss: 0.707926
Train Epoch: 6 [29440/35339 (83%)]	Loss: 0.545368
Train Epoch: 6 [30080/35339 (85%)]	Loss: 0.675762
Train Epoch: 6 [30720/35339 (87%)]	Loss: 0.566883
Train Epoch: 6 [31360/35339 (89%)]	Loss: 0.537554
Train Epoch: 6 [32000/35339 (90%)]	Loss: 0.470332
Train Epoch: 6 [32640/35339 (92%)]	Loss: 0.625392
Train Epoch: 6 [33280/35339 (94%)]	Loss: 0.529238
Train Epoch: 6 [33920/35339 (96%)]	Loss: 0.454922
Train Epoch: 6 [34560/35339 (98%)]	Loss: 0.635231
Train Epoch: 6 [35200/35339 (99%)]	Loss: 0.505948

Validation set: Average loss: 3.4965, Accuracy: 849/3870 (22%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 7 [0/35339 (0%)]	Loss: 0.633529
Train Epoch: 7 [640/35339 (2%)]	Loss: 0.687028
Train Epoch: 7 [1280/35339 (4%)]	Loss: 0.556316
Train Epoch: 7 [1920/35339 (5%)]	Loss: 0.557267
Train Epoch: 7 [2560/35339 (7%)]	Loss: 0.474676
Train Epoch: 7 [3200/35339 (9%)]	Loss: 0.558809
Train Epoch: 7 [3840/35339 (11%)]	Loss: 0.662224
Train Epoch: 7 [4480/35339 (13%)]	Loss: 0.567222
Train Epoch: 7 [5120/35339 (14%)]	Loss: 0.412054
Train Epoch: 7 [5760/35339 (16%)]	Loss: 0.648150
Train Epoch: 7 [6400/35339 (18%)]	Loss: 0.537177
Train Epoch: 7 [7040/35339 (20%)]	Loss: 0.724588
Train Epoch: 7 [7680/35339 (22%)]	Loss: 0.646395
Train Epoch: 7 [8320/35339 (24%)]	Loss: 0.588423
Train Epoch: 7 [8960/35339 (25%)]	Loss: 0.536606
Train Epoch: 7 [9600/35339 (27%)]	Loss: 0.576973
Train Epoch: 7 [10240/35339 (29%)]	Loss: 0.520312
Train Epoch: 7 [10880/35339 (31%)]	Loss: 0.395634
Train Epoch: 7 [11520/35339 (33%)]	Loss: 0.501274
Train Epoch: 7 [12160/35339 (34%)]	Loss: 0.467786
Train Epoch: 7 [12800/35339 (36%)]	Loss: 0.402955
Train Epoch: 7 [13440/35339 (38%)]	Loss: 0.533961
Train Epoch: 7 [14080/35339 (40%)]	Loss: 0.510254
Train Epoch: 7 [14720/35339 (42%)]	Loss: 0.625071
Train Epoch: 7 [15360/35339 (43%)]	Loss: 0.584452
Train Epoch: 7 [16000/35339 (45%)]	Loss: 0.541203
Train Epoch: 7 [16640/35339 (47%)]	Loss: 0.521574
Train Epoch: 7 [17280/35339 (49%)]	Loss: 0.385407
Train Epoch: 7 [17920/35339 (51%)]	Loss: 0.540743
Train Epoch: 7 [18560/35339 (52%)]	Loss: 0.502612
Train Epoch: 7 [19200/35339 (54%)]	Loss: 0.563969
Train Epoch: 7 [19840/35339 (56%)]	Loss: 0.600980
Train Epoch: 7 [20480/35339 (58%)]	Loss: 0.432221
Train Epoch: 7 [21120/35339 (60%)]	Loss: 0.580642
Train Epoch: 7 [21760/35339 (61%)]	Loss: 0.654254
Train Epoch: 7 [22400/35339 (63%)]	Loss: 0.400438
Train Epoch: 7 [23040/35339 (65%)]	Loss: 0.487118
Train Epoch: 7 [23680/35339 (67%)]	Loss: 0.392681
Train Epoch: 7 [24320/35339 (69%)]	Loss: 0.324969
Train Epoch: 7 [24960/35339 (71%)]	Loss: 0.660090
Train Epoch: 7 [25600/35339 (72%)]	Loss: 0.515930
Train Epoch: 7 [26240/35339 (74%)]	Loss: 0.433464
Train Epoch: 7 [26880/35339 (76%)]	Loss: 0.572270
Train Epoch: 7 [27520/35339 (78%)]	Loss: 0.586031
Train Epoch: 7 [28160/35339 (80%)]	Loss: 0.467158
Train Epoch: 7 [28800/35339 (81%)]	Loss: 0.319068
Train Epoch: 7 [29440/35339 (83%)]	Loss: 0.529362
Train Epoch: 7 [30080/35339 (85%)]	Loss: 0.518992
Train Epoch: 7 [30720/35339 (87%)]	Loss: 0.413519
Train Epoch: 7 [31360/35339 (89%)]	Loss: 0.345122
Train Epoch: 7 [32000/35339 (90%)]	Loss: 0.402089
Train Epoch: 7 [32640/35339 (92%)]	Loss: 0.414468
Train Epoch: 7 [33280/35339 (94%)]	Loss: 0.475665
Train Epoch: 7 [33920/35339 (96%)]	Loss: 0.531643
Train Epoch: 7 [34560/35339 (98%)]	Loss: 0.368228
Train Epoch: 7 [35200/35339 (99%)]	Loss: 0.415264

Validation set: Average loss: 3.2301, Accuracy: 1114/3870 (29%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 8 [0/35339 (0%)]	Loss: 0.442425
Train Epoch: 8 [640/35339 (2%)]	Loss: 0.490051
Train Epoch: 8 [1280/35339 (4%)]	Loss: 0.365803
Train Epoch: 8 [1920/35339 (5%)]	Loss: 0.408688
Train Epoch: 8 [2560/35339 (7%)]	Loss: 0.503120
Train Epoch: 8 [3200/35339 (9%)]	Loss: 0.374523
Train Epoch: 8 [3840/35339 (11%)]	Loss: 0.551449
Train Epoch: 8 [4480/35339 (13%)]	Loss: 0.413412
Train Epoch: 8 [5120/35339 (14%)]	Loss: 0.478745
Train Epoch: 8 [5760/35339 (16%)]	Loss: 0.345963
Train Epoch: 8 [6400/35339 (18%)]	Loss: 0.469822
Train Epoch: 8 [7040/35339 (20%)]	Loss: 0.418736
Train Epoch: 8 [7680/35339 (22%)]	Loss: 0.415906
Train Epoch: 8 [8320/35339 (24%)]	Loss: 0.414647
Train Epoch: 8 [8960/35339 (25%)]	Loss: 0.337444
Train Epoch: 8 [9600/35339 (27%)]	Loss: 0.409977
Train Epoch: 8 [10240/35339 (29%)]	Loss: 0.451810
Train Epoch: 8 [10880/35339 (31%)]	Loss: 0.350020
Train Epoch: 8 [11520/35339 (33%)]	Loss: 0.384016
Train Epoch: 8 [12160/35339 (34%)]	Loss: 0.602782
Train Epoch: 8 [12800/35339 (36%)]	Loss: 0.582429
Train Epoch: 8 [13440/35339 (38%)]	Loss: 0.518473
Train Epoch: 8 [14080/35339 (40%)]	Loss: 0.509237
Train Epoch: 8 [14720/35339 (42%)]	Loss: 0.495362
Train Epoch: 8 [15360/35339 (43%)]	Loss: 0.353274
Train Epoch: 8 [16000/35339 (45%)]	Loss: 0.417016
Train Epoch: 8 [16640/35339 (47%)]	Loss: 0.333587
Train Epoch: 8 [17280/35339 (49%)]	Loss: 0.396415
Train Epoch: 8 [17920/35339 (51%)]	Loss: 0.331287
Train Epoch: 8 [18560/35339 (52%)]	Loss: 0.519791
Train Epoch: 8 [19200/35339 (54%)]	Loss: 0.385515
Train Epoch: 8 [19840/35339 (56%)]	Loss: 0.432805
Train Epoch: 8 [20480/35339 (58%)]	Loss: 0.428180
Train Epoch: 8 [21120/35339 (60%)]	Loss: 0.417361
Train Epoch: 8 [21760/35339 (61%)]	Loss: 0.429302
Train Epoch: 8 [22400/35339 (63%)]	Loss: 0.482346
Train Epoch: 8 [23040/35339 (65%)]	Loss: 0.499162
Train Epoch: 8 [23680/35339 (67%)]	Loss: 0.438368
Train Epoch: 8 [24320/35339 (69%)]	Loss: 0.363330
Train Epoch: 8 [24960/35339 (71%)]	Loss: 0.340222
Train Epoch: 8 [25600/35339 (72%)]	Loss: 0.422844
Train Epoch: 8 [26240/35339 (74%)]	Loss: 0.390469
Train Epoch: 8 [26880/35339 (76%)]	Loss: 0.439736
Train Epoch: 8 [27520/35339 (78%)]	Loss: 0.385189
Train Epoch: 8 [28160/35339 (80%)]	Loss: 0.421349
Train Epoch: 8 [28800/35339 (81%)]	Loss: 0.393830
Train Epoch: 8 [29440/35339 (83%)]	Loss: 0.417189
Train Epoch: 8 [30080/35339 (85%)]	Loss: 0.331637
Train Epoch: 8 [30720/35339 (87%)]	Loss: 0.499773
Train Epoch: 8 [31360/35339 (89%)]	Loss: 0.453319
Train Epoch: 8 [32000/35339 (90%)]	Loss: 0.432661
Train Epoch: 8 [32640/35339 (92%)]	Loss: 0.342197
Train Epoch: 8 [33280/35339 (94%)]	Loss: 0.472878
Train Epoch: 8 [33920/35339 (96%)]	Loss: 0.394889
Train Epoch: 8 [34560/35339 (98%)]	Loss: 0.373146
Train Epoch: 8 [35200/35339 (99%)]	Loss: 0.583146

Validation set: Average loss: 3.1329, Accuracy: 1230/3870 (32%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 9 [0/35339 (0%)]	Loss: 0.598461
Train Epoch: 9 [640/35339 (2%)]	Loss: 0.400488
Train Epoch: 9 [1280/35339 (4%)]	Loss: 0.487008
Train Epoch: 9 [1920/35339 (5%)]	Loss: 0.362579
Train Epoch: 9 [2560/35339 (7%)]	Loss: 0.272992
Train Epoch: 9 [3200/35339 (9%)]	Loss: 0.368232
Train Epoch: 9 [3840/35339 (11%)]	Loss: 0.399355
Train Epoch: 9 [4480/35339 (13%)]	Loss: 0.490141
Train Epoch: 9 [5120/35339 (14%)]	Loss: 0.314693
Train Epoch: 9 [5760/35339 (16%)]	Loss: 0.352948
Train Epoch: 9 [6400/35339 (18%)]	Loss: 0.687512
Train Epoch: 9 [7040/35339 (20%)]	Loss: 0.443082
Train Epoch: 9 [7680/35339 (22%)]	Loss: 0.280080
Train Epoch: 9 [8320/35339 (24%)]	Loss: 0.329148
Train Epoch: 9 [8960/35339 (25%)]	Loss: 0.402103
Train Epoch: 9 [9600/35339 (27%)]	Loss: 0.464653
Train Epoch: 9 [10240/35339 (29%)]	Loss: 0.339487
Train Epoch: 9 [10880/35339 (31%)]	Loss: 0.413713
Train Epoch: 9 [11520/35339 (33%)]	Loss: 0.511962
Train Epoch: 9 [12160/35339 (34%)]	Loss: 0.445365
Train Epoch: 9 [12800/35339 (36%)]	Loss: 0.312911
Train Epoch: 9 [13440/35339 (38%)]	Loss: 0.507463
Train Epoch: 9 [14080/35339 (40%)]	Loss: 0.330115
Train Epoch: 9 [14720/35339 (42%)]	Loss: 0.271308
Train Epoch: 9 [15360/35339 (43%)]	Loss: 0.362650
Train Epoch: 9 [16000/35339 (45%)]	Loss: 0.367205
Train Epoch: 9 [16640/35339 (47%)]	Loss: 0.295608
Train Epoch: 9 [17280/35339 (49%)]	Loss: 0.250502
Train Epoch: 9 [17920/35339 (51%)]	Loss: 0.323187
Train Epoch: 9 [18560/35339 (52%)]	Loss: 0.249984
Train Epoch: 9 [19200/35339 (54%)]	Loss: 0.418099
Train Epoch: 9 [19840/35339 (56%)]	Loss: 0.323134
Train Epoch: 9 [20480/35339 (58%)]	Loss: 0.459369
Train Epoch: 9 [21120/35339 (60%)]	Loss: 0.286034
Train Epoch: 9 [21760/35339 (61%)]	Loss: 0.345164
Train Epoch: 9 [22400/35339 (63%)]	Loss: 0.387455
Train Epoch: 9 [23040/35339 (65%)]	Loss: 0.415229
Train Epoch: 9 [23680/35339 (67%)]	Loss: 0.349570
Train Epoch: 9 [24320/35339 (69%)]	Loss: 0.359703
Train Epoch: 9 [24960/35339 (71%)]	Loss: 0.338881
Train Epoch: 9 [25600/35339 (72%)]	Loss: 0.387658
Train Epoch: 9 [26240/35339 (74%)]	Loss: 0.268935
Train Epoch: 9 [26880/35339 (76%)]	Loss: 0.230560
Train Epoch: 9 [27520/35339 (78%)]	Loss: 0.433897
Train Epoch: 9 [28160/35339 (80%)]	Loss: 0.296016
Train Epoch: 9 [28800/35339 (81%)]	Loss: 0.369155
Train Epoch: 9 [29440/35339 (83%)]	Loss: 0.320878
Train Epoch: 9 [30080/35339 (85%)]	Loss: 0.299036
Train Epoch: 9 [30720/35339 (87%)]	Loss: 0.560322
Train Epoch: 9 [31360/35339 (89%)]	Loss: 0.365674
Train Epoch: 9 [32000/35339 (90%)]	Loss: 0.412586
Train Epoch: 9 [32640/35339 (92%)]	Loss: 0.308300
Train Epoch: 9 [33280/35339 (94%)]	Loss: 0.381609
Train Epoch: 9 [33920/35339 (96%)]	Loss: 0.374463
Train Epoch: 9 [34560/35339 (98%)]	Loss: 0.329334
Train Epoch: 9 [35200/35339 (99%)]	Loss: 0.220499

Validation set: Average loss: 3.0261, Accuracy: 1333/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 10 [0/35339 (0%)]	Loss: 0.269640
Train Epoch: 10 [640/35339 (2%)]	Loss: 0.305667
Train Epoch: 10 [1280/35339 (4%)]	Loss: 0.171850
Train Epoch: 10 [1920/35339 (5%)]	Loss: 0.394408
Train Epoch: 10 [2560/35339 (7%)]	Loss: 0.162804
Train Epoch: 10 [3200/35339 (9%)]	Loss: 0.413245
Train Epoch: 10 [3840/35339 (11%)]	Loss: 0.385030
Train Epoch: 10 [4480/35339 (13%)]	Loss: 0.327686
Train Epoch: 10 [5120/35339 (14%)]	Loss: 0.402213
Train Epoch: 10 [5760/35339 (16%)]	Loss: 0.285026
Train Epoch: 10 [6400/35339 (18%)]	Loss: 0.302266
Train Epoch: 10 [7040/35339 (20%)]	Loss: 0.277042
Train Epoch: 10 [7680/35339 (22%)]	Loss: 0.251473
Train Epoch: 10 [8320/35339 (24%)]	Loss: 0.399047
Train Epoch: 10 [8960/35339 (25%)]	Loss: 0.331668
Train Epoch: 10 [9600/35339 (27%)]	Loss: 0.330018
Train Epoch: 10 [10240/35339 (29%)]	Loss: 0.303068
Train Epoch: 10 [10880/35339 (31%)]	Loss: 0.215084
Train Epoch: 10 [11520/35339 (33%)]	Loss: 0.361154
Train Epoch: 10 [12160/35339 (34%)]	Loss: 0.239013
Train Epoch: 10 [12800/35339 (36%)]	Loss: 0.253413
Train Epoch: 10 [13440/35339 (38%)]	Loss: 0.291294
Train Epoch: 10 [14080/35339 (40%)]	Loss: 0.298475
Train Epoch: 10 [14720/35339 (42%)]	Loss: 0.308957
Train Epoch: 10 [15360/35339 (43%)]	Loss: 0.309765
Train Epoch: 10 [16000/35339 (45%)]	Loss: 0.353481
Train Epoch: 10 [16640/35339 (47%)]	Loss: 0.304551
Train Epoch: 10 [17280/35339 (49%)]	Loss: 0.264550
Train Epoch: 10 [17920/35339 (51%)]	Loss: 0.311997
Train Epoch: 10 [18560/35339 (52%)]	Loss: 0.442295
Train Epoch: 10 [19200/35339 (54%)]	Loss: 0.321080
Train Epoch: 10 [19840/35339 (56%)]	Loss: 0.274533
Train Epoch: 10 [20480/35339 (58%)]	Loss: 0.221806
Train Epoch: 10 [21120/35339 (60%)]	Loss: 0.212565
Train Epoch: 10 [21760/35339 (61%)]	Loss: 0.333594
Train Epoch: 10 [22400/35339 (63%)]	Loss: 0.427967
Train Epoch: 10 [23040/35339 (65%)]	Loss: 0.382895
Train Epoch: 10 [23680/35339 (67%)]	Loss: 0.248960
Train Epoch: 10 [24320/35339 (69%)]	Loss: 0.362059
Train Epoch: 10 [24960/35339 (71%)]	Loss: 0.312749
Train Epoch: 10 [25600/35339 (72%)]	Loss: 0.406353
Train Epoch: 10 [26240/35339 (74%)]	Loss: 0.328015
Train Epoch: 10 [26880/35339 (76%)]	Loss: 0.230794
Train Epoch: 10 [27520/35339 (78%)]	Loss: 0.241167
Train Epoch: 10 [28160/35339 (80%)]	Loss: 0.270010
Train Epoch: 10 [28800/35339 (81%)]	Loss: 0.243024
Train Epoch: 10 [29440/35339 (83%)]	Loss: 0.245824
Train Epoch: 10 [30080/35339 (85%)]	Loss: 0.366123
Train Epoch: 10 [30720/35339 (87%)]	Loss: 0.221435
Train Epoch: 10 [31360/35339 (89%)]	Loss: 0.283123
Train Epoch: 10 [32000/35339 (90%)]	Loss: 0.210569
Train Epoch: 10 [32640/35339 (92%)]	Loss: 0.255946
Train Epoch: 10 [33280/35339 (94%)]	Loss: 0.301453
Train Epoch: 10 [33920/35339 (96%)]	Loss: 0.266665
Train Epoch: 10 [34560/35339 (98%)]	Loss: 0.270522
Train Epoch: 10 [35200/35339 (99%)]	Loss: 0.247187

Validation set: Average loss: 3.1458, Accuracy: 1216/3870 (31%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 11 [0/35339 (0%)]	Loss: 0.383178
Train Epoch: 11 [640/35339 (2%)]	Loss: 0.244032
Train Epoch: 11 [1280/35339 (4%)]	Loss: 0.162731
Train Epoch: 11 [1920/35339 (5%)]	Loss: 0.212411
Train Epoch: 11 [2560/35339 (7%)]	Loss: 0.380268
Train Epoch: 11 [3200/35339 (9%)]	Loss: 0.247801
Train Epoch: 11 [3840/35339 (11%)]	Loss: 0.286242
Train Epoch: 11 [4480/35339 (13%)]	Loss: 0.306781
Train Epoch: 11 [5120/35339 (14%)]	Loss: 0.203922
Train Epoch: 11 [5760/35339 (16%)]	Loss: 0.156333
Train Epoch: 11 [6400/35339 (18%)]	Loss: 0.206508
Train Epoch: 11 [7040/35339 (20%)]	Loss: 0.259666
Train Epoch: 11 [7680/35339 (22%)]	Loss: 0.263670
Train Epoch: 11 [8320/35339 (24%)]	Loss: 0.220715
Train Epoch: 11 [8960/35339 (25%)]	Loss: 0.141752
Train Epoch: 11 [9600/35339 (27%)]	Loss: 0.230140
Train Epoch: 11 [10240/35339 (29%)]	Loss: 0.196689
Train Epoch: 11 [10880/35339 (31%)]	Loss: 0.348509
Train Epoch: 11 [11520/35339 (33%)]	Loss: 0.295474
Train Epoch: 11 [12160/35339 (34%)]	Loss: 0.237613
Train Epoch: 11 [12800/35339 (36%)]	Loss: 0.271149
Train Epoch: 11 [13440/35339 (38%)]	Loss: 0.287574
Train Epoch: 11 [14080/35339 (40%)]	Loss: 0.307190
Train Epoch: 11 [14720/35339 (42%)]	Loss: 0.177851
Train Epoch: 11 [15360/35339 (43%)]	Loss: 0.189562
Train Epoch: 11 [16000/35339 (45%)]	Loss: 0.238075
Train Epoch: 11 [16640/35339 (47%)]	Loss: 0.237889
Train Epoch: 11 [17280/35339 (49%)]	Loss: 0.163823
Train Epoch: 11 [17920/35339 (51%)]	Loss: 0.206893
Train Epoch: 11 [18560/35339 (52%)]	Loss: 0.256231
Train Epoch: 11 [19200/35339 (54%)]	Loss: 0.184223
Train Epoch: 11 [19840/35339 (56%)]	Loss: 0.268891
Train Epoch: 11 [20480/35339 (58%)]	Loss: 0.208930
Train Epoch: 11 [21120/35339 (60%)]	Loss: 0.395656
Train Epoch: 11 [21760/35339 (61%)]	Loss: 0.248455
Train Epoch: 11 [22400/35339 (63%)]	Loss: 0.303132
Train Epoch: 11 [23040/35339 (65%)]	Loss: 0.241921
Train Epoch: 11 [23680/35339 (67%)]	Loss: 0.195519
Train Epoch: 11 [24320/35339 (69%)]	Loss: 0.280446
Train Epoch: 11 [24960/35339 (71%)]	Loss: 0.187339
Train Epoch: 11 [25600/35339 (72%)]	Loss: 0.185378
Train Epoch: 11 [26240/35339 (74%)]	Loss: 0.327279
Train Epoch: 11 [26880/35339 (76%)]	Loss: 0.206572
Train Epoch: 11 [27520/35339 (78%)]	Loss: 0.291330
Train Epoch: 11 [28160/35339 (80%)]	Loss: 0.391954
Train Epoch: 11 [28800/35339 (81%)]	Loss: 0.231804
Train Epoch: 11 [29440/35339 (83%)]	Loss: 0.325525
Train Epoch: 11 [30080/35339 (85%)]	Loss: 0.241755
Train Epoch: 11 [30720/35339 (87%)]	Loss: 0.316147
Train Epoch: 11 [31360/35339 (89%)]	Loss: 0.230007
Train Epoch: 11 [32000/35339 (90%)]	Loss: 0.288135
Train Epoch: 11 [32640/35339 (92%)]	Loss: 0.142360
Train Epoch: 11 [33280/35339 (94%)]	Loss: 0.259670
Train Epoch: 11 [33920/35339 (96%)]	Loss: 0.182664
Train Epoch: 11 [34560/35339 (98%)]	Loss: 0.250215
Train Epoch: 11 [35200/35339 (99%)]	Loss: 0.356035

Validation set: Average loss: 3.0134, Accuracy: 1382/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 12 [0/35339 (0%)]	Loss: 0.136225
Train Epoch: 12 [640/35339 (2%)]	Loss: 0.207232
Train Epoch: 12 [1280/35339 (4%)]	Loss: 0.275850
Train Epoch: 12 [1920/35339 (5%)]	Loss: 0.239106
Train Epoch: 12 [2560/35339 (7%)]	Loss: 0.290263
Train Epoch: 12 [3200/35339 (9%)]	Loss: 0.260024
Train Epoch: 12 [3840/35339 (11%)]	Loss: 0.261025
Train Epoch: 12 [4480/35339 (13%)]	Loss: 0.159606
Train Epoch: 12 [5120/35339 (14%)]	Loss: 0.215430
Train Epoch: 12 [5760/35339 (16%)]	Loss: 0.214120
Train Epoch: 12 [6400/35339 (18%)]	Loss: 0.198167
Train Epoch: 12 [7040/35339 (20%)]	Loss: 0.171567
Train Epoch: 12 [7680/35339 (22%)]	Loss: 0.156449
Train Epoch: 12 [8320/35339 (24%)]	Loss: 0.150795
Train Epoch: 12 [8960/35339 (25%)]	Loss: 0.306810
Train Epoch: 12 [9600/35339 (27%)]	Loss: 0.250217
Train Epoch: 12 [10240/35339 (29%)]	Loss: 0.295330
Train Epoch: 12 [10880/35339 (31%)]	Loss: 0.234973
Train Epoch: 12 [11520/35339 (33%)]	Loss: 0.260363
Train Epoch: 12 [12160/35339 (34%)]	Loss: 0.220771
Train Epoch: 12 [12800/35339 (36%)]	Loss: 0.244542
Train Epoch: 12 [13440/35339 (38%)]	Loss: 0.230236
Train Epoch: 12 [14080/35339 (40%)]	Loss: 0.264920
Train Epoch: 12 [14720/35339 (42%)]	Loss: 0.246876
Train Epoch: 12 [15360/35339 (43%)]	Loss: 0.220588
Train Epoch: 12 [16000/35339 (45%)]	Loss: 0.210750
Train Epoch: 12 [16640/35339 (47%)]	Loss: 0.208541
Train Epoch: 12 [17280/35339 (49%)]	Loss: 0.263394
Train Epoch: 12 [17920/35339 (51%)]	Loss: 0.565184
Train Epoch: 12 [18560/35339 (52%)]	Loss: 0.235387
Train Epoch: 12 [19200/35339 (54%)]	Loss: 0.361723
Train Epoch: 12 [19840/35339 (56%)]	Loss: 0.208238
Train Epoch: 12 [20480/35339 (58%)]	Loss: 0.264887
Train Epoch: 12 [21120/35339 (60%)]	Loss: 0.162815
Train Epoch: 12 [21760/35339 (61%)]	Loss: 0.409127
Train Epoch: 12 [22400/35339 (63%)]	Loss: 0.332508
Train Epoch: 12 [23040/35339 (65%)]	Loss: 0.200632
Train Epoch: 12 [23680/35339 (67%)]	Loss: 0.165534
Train Epoch: 12 [24320/35339 (69%)]	Loss: 0.202577
Train Epoch: 12 [24960/35339 (71%)]	Loss: 0.371666
Train Epoch: 12 [25600/35339 (72%)]	Loss: 0.279013
Train Epoch: 12 [26240/35339 (74%)]	Loss: 0.226881
Train Epoch: 12 [26880/35339 (76%)]	Loss: 0.289483
Train Epoch: 12 [27520/35339 (78%)]	Loss: 0.239308
Train Epoch: 12 [28160/35339 (80%)]	Loss: 0.118243
Train Epoch: 12 [28800/35339 (81%)]	Loss: 0.341236
Train Epoch: 12 [29440/35339 (83%)]	Loss: 0.306913
Train Epoch: 12 [30080/35339 (85%)]	Loss: 0.180581
Train Epoch: 12 [30720/35339 (87%)]	Loss: 0.207012
Train Epoch: 12 [31360/35339 (89%)]	Loss: 0.209930
Train Epoch: 12 [32000/35339 (90%)]	Loss: 0.253829
Train Epoch: 12 [32640/35339 (92%)]	Loss: 0.180432
Train Epoch: 12 [33280/35339 (94%)]	Loss: 0.139511
Train Epoch: 12 [33920/35339 (96%)]	Loss: 0.191187
Train Epoch: 12 [34560/35339 (98%)]	Loss: 0.199960
Train Epoch: 12 [35200/35339 (99%)]	Loss: 0.241220

Validation set: Average loss: 2.9253, Accuracy: 1391/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 13 [0/35339 (0%)]	Loss: 0.177514
Train Epoch: 13 [640/35339 (2%)]	Loss: 0.252850
Train Epoch: 13 [1280/35339 (4%)]	Loss: 0.270183
Train Epoch: 13 [1920/35339 (5%)]	Loss: 0.136575
Train Epoch: 13 [2560/35339 (7%)]	Loss: 0.155335
Train Epoch: 13 [3200/35339 (9%)]	Loss: 0.196498
Train Epoch: 13 [3840/35339 (11%)]	Loss: 0.255002
Train Epoch: 13 [4480/35339 (13%)]	Loss: 0.163876
Train Epoch: 13 [5120/35339 (14%)]	Loss: 0.301650
Train Epoch: 13 [5760/35339 (16%)]	Loss: 0.412654
Train Epoch: 13 [6400/35339 (18%)]	Loss: 0.172404
Train Epoch: 13 [7040/35339 (20%)]	Loss: 0.251941
Train Epoch: 13 [7680/35339 (22%)]	Loss: 0.236023
Train Epoch: 13 [8320/35339 (24%)]	Loss: 0.207079
Train Epoch: 13 [8960/35339 (25%)]	Loss: 0.216120
Train Epoch: 13 [9600/35339 (27%)]	Loss: 0.144756
Train Epoch: 13 [10240/35339 (29%)]	Loss: 0.224721
Train Epoch: 13 [10880/35339 (31%)]	Loss: 0.214634
Train Epoch: 13 [11520/35339 (33%)]	Loss: 0.164605
Train Epoch: 13 [12160/35339 (34%)]	Loss: 0.121846
Train Epoch: 13 [12800/35339 (36%)]	Loss: 0.175314
Train Epoch: 13 [13440/35339 (38%)]	Loss: 0.340349
Train Epoch: 13 [14080/35339 (40%)]	Loss: 0.204719
Train Epoch: 13 [14720/35339 (42%)]	Loss: 0.178459
Train Epoch: 13 [15360/35339 (43%)]	Loss: 0.174964
Train Epoch: 13 [16000/35339 (45%)]	Loss: 0.216228
Train Epoch: 13 [16640/35339 (47%)]	Loss: 0.298643
Train Epoch: 13 [17280/35339 (49%)]	Loss: 0.266239
Train Epoch: 13 [17920/35339 (51%)]	Loss: 0.196209
Train Epoch: 13 [18560/35339 (52%)]	Loss: 0.251657
Train Epoch: 13 [19200/35339 (54%)]	Loss: 0.223737
Train Epoch: 13 [19840/35339 (56%)]	Loss: 0.150631
Train Epoch: 13 [20480/35339 (58%)]	Loss: 0.187615
Train Epoch: 13 [21120/35339 (60%)]	Loss: 0.205136
Train Epoch: 13 [21760/35339 (61%)]	Loss: 0.172650
Train Epoch: 13 [22400/35339 (63%)]	Loss: 0.247862
Train Epoch: 13 [23040/35339 (65%)]	Loss: 0.308318
Train Epoch: 13 [23680/35339 (67%)]	Loss: 0.173234
Train Epoch: 13 [24320/35339 (69%)]	Loss: 0.160670
Train Epoch: 13 [24960/35339 (71%)]	Loss: 0.222718
Train Epoch: 13 [25600/35339 (72%)]	Loss: 0.175875
Train Epoch: 13 [26240/35339 (74%)]	Loss: 0.229065
Train Epoch: 13 [26880/35339 (76%)]	Loss: 0.236641
Train Epoch: 13 [27520/35339 (78%)]	Loss: 0.171338
Train Epoch: 13 [28160/35339 (80%)]	Loss: 0.234484
Train Epoch: 13 [28800/35339 (81%)]	Loss: 0.291459
Train Epoch: 13 [29440/35339 (83%)]	Loss: 0.224577
Train Epoch: 13 [30080/35339 (85%)]	Loss: 0.158779
Train Epoch: 13 [30720/35339 (87%)]	Loss: 0.205312
Train Epoch: 13 [31360/35339 (89%)]	Loss: 0.185120
Train Epoch: 13 [32000/35339 (90%)]	Loss: 0.197352
Train Epoch: 13 [32640/35339 (92%)]	Loss: 0.246123
Train Epoch: 13 [33280/35339 (94%)]	Loss: 0.170189
Train Epoch: 13 [33920/35339 (96%)]	Loss: 0.174998
Train Epoch: 13 [34560/35339 (98%)]	Loss: 0.266664
Train Epoch: 13 [35200/35339 (99%)]	Loss: 0.287364

Validation set: Average loss: 2.9363, Accuracy: 1362/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 14 [0/35339 (0%)]	Loss: 0.293206
Train Epoch: 14 [640/35339 (2%)]	Loss: 0.144931
Train Epoch: 14 [1280/35339 (4%)]	Loss: 0.167280
Train Epoch: 14 [1920/35339 (5%)]	Loss: 0.171520
Train Epoch: 14 [2560/35339 (7%)]	Loss: 0.219416
Train Epoch: 14 [3200/35339 (9%)]	Loss: 0.178164
Train Epoch: 14 [3840/35339 (11%)]	Loss: 0.240700
Train Epoch: 14 [4480/35339 (13%)]	Loss: 0.171853
Train Epoch: 14 [5120/35339 (14%)]	Loss: 0.164785
Train Epoch: 14 [5760/35339 (16%)]	Loss: 0.145322
Train Epoch: 14 [6400/35339 (18%)]	Loss: 0.147675
Train Epoch: 14 [7040/35339 (20%)]	Loss: 0.227415
Train Epoch: 14 [7680/35339 (22%)]	Loss: 0.309900
Train Epoch: 14 [8320/35339 (24%)]	Loss: 0.190645
Train Epoch: 14 [8960/35339 (25%)]	Loss: 0.282127
Train Epoch: 14 [9600/35339 (27%)]	Loss: 0.198559
Train Epoch: 14 [10240/35339 (29%)]	Loss: 0.179776
Train Epoch: 14 [10880/35339 (31%)]	Loss: 0.086707
Train Epoch: 14 [11520/35339 (33%)]	Loss: 0.198732
Train Epoch: 14 [12160/35339 (34%)]	Loss: 0.166633
Train Epoch: 14 [12800/35339 (36%)]	Loss: 0.247386
Train Epoch: 14 [13440/35339 (38%)]	Loss: 0.213300
Train Epoch: 14 [14080/35339 (40%)]	Loss: 0.161841
Train Epoch: 14 [14720/35339 (42%)]	Loss: 0.171435
Train Epoch: 14 [15360/35339 (43%)]	Loss: 0.154213
Train Epoch: 14 [16000/35339 (45%)]	Loss: 0.200068
Train Epoch: 14 [16640/35339 (47%)]	Loss: 0.281483
Train Epoch: 14 [17280/35339 (49%)]	Loss: 0.249076
Train Epoch: 14 [17920/35339 (51%)]	Loss: 0.195819
Train Epoch: 14 [18560/35339 (52%)]	Loss: 0.181264
Train Epoch: 14 [19200/35339 (54%)]	Loss: 0.202276
Train Epoch: 14 [19840/35339 (56%)]	Loss: 0.292310
Train Epoch: 14 [20480/35339 (58%)]	Loss: 0.159737
Train Epoch: 14 [21120/35339 (60%)]	Loss: 0.127620
Train Epoch: 14 [21760/35339 (61%)]	Loss: 0.242222
Train Epoch: 14 [22400/35339 (63%)]	Loss: 0.197768
Train Epoch: 14 [23040/35339 (65%)]	Loss: 0.239919
Train Epoch: 14 [23680/35339 (67%)]	Loss: 0.188255
Train Epoch: 14 [24320/35339 (69%)]	Loss: 0.262767
Train Epoch: 14 [24960/35339 (71%)]	Loss: 0.144039
Train Epoch: 14 [25600/35339 (72%)]	Loss: 0.265624
Train Epoch: 14 [26240/35339 (74%)]	Loss: 0.261427
Train Epoch: 14 [26880/35339 (76%)]	Loss: 0.214178
Train Epoch: 14 [27520/35339 (78%)]	Loss: 0.197564
Train Epoch: 14 [28160/35339 (80%)]	Loss: 0.224236
Train Epoch: 14 [28800/35339 (81%)]	Loss: 0.249144
Train Epoch: 14 [29440/35339 (83%)]	Loss: 0.175438
Train Epoch: 14 [30080/35339 (85%)]	Loss: 0.128601
Train Epoch: 14 [30720/35339 (87%)]	Loss: 0.246541
Train Epoch: 14 [31360/35339 (89%)]	Loss: 0.122361
Train Epoch: 14 [32000/35339 (90%)]	Loss: 0.194111
Train Epoch: 14 [32640/35339 (92%)]	Loss: 0.359769
Train Epoch: 14 [33280/35339 (94%)]	Loss: 0.164974
Train Epoch: 14 [33920/35339 (96%)]	Loss: 0.130002
Train Epoch: 14 [34560/35339 (98%)]	Loss: 0.207290
Train Epoch: 14 [35200/35339 (99%)]	Loss: 0.186533

Validation set: Average loss: 2.9147, Accuracy: 1394/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 15 [0/35339 (0%)]	Loss: 0.205062
Train Epoch: 15 [640/35339 (2%)]	Loss: 0.264922
Train Epoch: 15 [1280/35339 (4%)]	Loss: 0.221771
Train Epoch: 15 [1920/35339 (5%)]	Loss: 0.212526
Train Epoch: 15 [2560/35339 (7%)]	Loss: 0.224495
Train Epoch: 15 [3200/35339 (9%)]	Loss: 0.173229
Train Epoch: 15 [3840/35339 (11%)]	Loss: 0.160477
Train Epoch: 15 [4480/35339 (13%)]	Loss: 0.189889
Train Epoch: 15 [5120/35339 (14%)]	Loss: 0.204811
Train Epoch: 15 [5760/35339 (16%)]	Loss: 0.271697
Train Epoch: 15 [6400/35339 (18%)]	Loss: 0.167398
Train Epoch: 15 [7040/35339 (20%)]	Loss: 0.196858
Train Epoch: 15 [7680/35339 (22%)]	Loss: 0.151543
Train Epoch: 15 [8320/35339 (24%)]	Loss: 0.260396
Train Epoch: 15 [8960/35339 (25%)]	Loss: 0.229683
Train Epoch: 15 [9600/35339 (27%)]	Loss: 0.213733
Train Epoch: 15 [10240/35339 (29%)]	Loss: 0.149205
Train Epoch: 15 [10880/35339 (31%)]	Loss: 0.127278
Train Epoch: 15 [11520/35339 (33%)]	Loss: 0.186173
Train Epoch: 15 [12160/35339 (34%)]	Loss: 0.181656
Train Epoch: 15 [12800/35339 (36%)]	Loss: 0.199749
Train Epoch: 15 [13440/35339 (38%)]	Loss: 0.210181
Train Epoch: 15 [14080/35339 (40%)]	Loss: 0.282812
Train Epoch: 15 [14720/35339 (42%)]	Loss: 0.138159
Train Epoch: 15 [15360/35339 (43%)]	Loss: 0.183386
Train Epoch: 15 [16000/35339 (45%)]	Loss: 0.246807
Train Epoch: 15 [16640/35339 (47%)]	Loss: 0.179688
Train Epoch: 15 [17280/35339 (49%)]	Loss: 0.147373
Train Epoch: 15 [17920/35339 (51%)]	Loss: 0.114962
Train Epoch: 15 [18560/35339 (52%)]	Loss: 0.263815
Train Epoch: 15 [19200/35339 (54%)]	Loss: 0.149791
Train Epoch: 15 [19840/35339 (56%)]	Loss: 0.202681
Train Epoch: 15 [20480/35339 (58%)]	Loss: 0.138754
Train Epoch: 15 [21120/35339 (60%)]	Loss: 0.208916
Train Epoch: 15 [21760/35339 (61%)]	Loss: 0.140561
Train Epoch: 15 [22400/35339 (63%)]	Loss: 0.462004
Train Epoch: 15 [23040/35339 (65%)]	Loss: 0.188309
Train Epoch: 15 [23680/35339 (67%)]	Loss: 0.134397
Train Epoch: 15 [24320/35339 (69%)]	Loss: 0.203681
Train Epoch: 15 [24960/35339 (71%)]	Loss: 0.208696
Train Epoch: 15 [25600/35339 (72%)]	Loss: 0.149681
Train Epoch: 15 [26240/35339 (74%)]	Loss: 0.327245
Train Epoch: 15 [26880/35339 (76%)]	Loss: 0.158130
Train Epoch: 15 [27520/35339 (78%)]	Loss: 0.237537
Train Epoch: 15 [28160/35339 (80%)]	Loss: 0.170466
Train Epoch: 15 [28800/35339 (81%)]	Loss: 0.144318
Train Epoch: 15 [29440/35339 (83%)]	Loss: 0.148552
Train Epoch: 15 [30080/35339 (85%)]	Loss: 0.210952
Train Epoch: 15 [30720/35339 (87%)]	Loss: 0.144670
Train Epoch: 15 [31360/35339 (89%)]	Loss: 0.150405
Train Epoch: 15 [32000/35339 (90%)]	Loss: 0.083966
Train Epoch: 15 [32640/35339 (92%)]	Loss: 0.361065
Train Epoch: 15 [33280/35339 (94%)]	Loss: 0.211717
Train Epoch: 15 [33920/35339 (96%)]	Loss: 0.259734
Train Epoch: 15 [34560/35339 (98%)]	Loss: 0.146940
Train Epoch: 15 [35200/35339 (99%)]	Loss: 0.166714

Validation set: Average loss: 2.9810, Accuracy: 1363/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 16 [0/35339 (0%)]	Loss: 0.269855
Train Epoch: 16 [640/35339 (2%)]	Loss: 0.272710
Train Epoch: 16 [1280/35339 (4%)]	Loss: 0.197776
Train Epoch: 16 [1920/35339 (5%)]	Loss: 0.242482
Train Epoch: 16 [2560/35339 (7%)]	Loss: 0.268518
Train Epoch: 16 [3200/35339 (9%)]	Loss: 0.176650
Train Epoch: 16 [3840/35339 (11%)]	Loss: 0.186729
Train Epoch: 16 [4480/35339 (13%)]	Loss: 0.109201
Train Epoch: 16 [5120/35339 (14%)]	Loss: 0.180400
Train Epoch: 16 [5760/35339 (16%)]	Loss: 0.183945
Train Epoch: 16 [6400/35339 (18%)]	Loss: 0.208533
Train Epoch: 16 [7040/35339 (20%)]	Loss: 0.140935
Train Epoch: 16 [7680/35339 (22%)]	Loss: 0.118390
Train Epoch: 16 [8320/35339 (24%)]	Loss: 0.188916
Train Epoch: 16 [8960/35339 (25%)]	Loss: 0.203640
Train Epoch: 16 [9600/35339 (27%)]	Loss: 0.204125
Train Epoch: 16 [10240/35339 (29%)]	Loss: 0.101736
Train Epoch: 16 [10880/35339 (31%)]	Loss: 0.220025
Train Epoch: 16 [11520/35339 (33%)]	Loss: 0.229648
Train Epoch: 16 [12160/35339 (34%)]	Loss: 0.150321
Train Epoch: 16 [12800/35339 (36%)]	Loss: 0.202732
Train Epoch: 16 [13440/35339 (38%)]	Loss: 0.219386
Train Epoch: 16 [14080/35339 (40%)]	Loss: 0.197677
Train Epoch: 16 [14720/35339 (42%)]	Loss: 0.476689
Train Epoch: 16 [15360/35339 (43%)]	Loss: 0.438413
Train Epoch: 16 [16000/35339 (45%)]	Loss: 0.205264
Train Epoch: 16 [16640/35339 (47%)]	Loss: 0.134098
Train Epoch: 16 [17280/35339 (49%)]	Loss: 0.211759
Train Epoch: 16 [17920/35339 (51%)]	Loss: 0.093200
Train Epoch: 16 [18560/35339 (52%)]	Loss: 0.159413
Train Epoch: 16 [19200/35339 (54%)]	Loss: 0.317537
Train Epoch: 16 [19840/35339 (56%)]	Loss: 0.166903
Train Epoch: 16 [20480/35339 (58%)]	Loss: 0.211613
Train Epoch: 16 [21120/35339 (60%)]	Loss: 0.164427
Train Epoch: 16 [21760/35339 (61%)]	Loss: 0.306187
Train Epoch: 16 [22400/35339 (63%)]	Loss: 0.304299
Train Epoch: 16 [23040/35339 (65%)]	Loss: 0.138062
Train Epoch: 16 [23680/35339 (67%)]	Loss: 0.131506
Train Epoch: 16 [24320/35339 (69%)]	Loss: 0.136358
Train Epoch: 16 [24960/35339 (71%)]	Loss: 0.121699
Train Epoch: 16 [25600/35339 (72%)]	Loss: 0.122648
Train Epoch: 16 [26240/35339 (74%)]	Loss: 0.172139
Train Epoch: 16 [26880/35339 (76%)]	Loss: 0.184357
Train Epoch: 16 [27520/35339 (78%)]	Loss: 0.257784
Train Epoch: 16 [28160/35339 (80%)]	Loss: 0.187881
Train Epoch: 16 [28800/35339 (81%)]	Loss: 0.179533
Train Epoch: 16 [29440/35339 (83%)]	Loss: 0.154359
Train Epoch: 16 [30080/35339 (85%)]	Loss: 0.173191
Train Epoch: 16 [30720/35339 (87%)]	Loss: 0.170432
Train Epoch: 16 [31360/35339 (89%)]	Loss: 0.263199
Train Epoch: 16 [32000/35339 (90%)]	Loss: 0.154499
Train Epoch: 16 [32640/35339 (92%)]	Loss: 0.196484
Train Epoch: 16 [33280/35339 (94%)]	Loss: 0.229610
Train Epoch: 16 [33920/35339 (96%)]	Loss: 0.197356
Train Epoch: 16 [34560/35339 (98%)]	Loss: 0.175917
Train Epoch: 16 [35200/35339 (99%)]	Loss: 0.254542

Validation set: Average loss: 2.9268, Accuracy: 1386/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 17 [0/35339 (0%)]	Loss: 0.138311
Train Epoch: 17 [640/35339 (2%)]	Loss: 0.144650
Train Epoch: 17 [1280/35339 (4%)]	Loss: 0.166281
Train Epoch: 17 [1920/35339 (5%)]	Loss: 0.134453
Train Epoch: 17 [2560/35339 (7%)]	Loss: 0.187459
Train Epoch: 17 [3200/35339 (9%)]	Loss: 0.132374
Train Epoch: 17 [3840/35339 (11%)]	Loss: 0.108001
Train Epoch: 17 [4480/35339 (13%)]	Loss: 0.251891
Train Epoch: 17 [5120/35339 (14%)]	Loss: 0.113778
Train Epoch: 17 [5760/35339 (16%)]	Loss: 0.144514
Train Epoch: 17 [6400/35339 (18%)]	Loss: 0.117591
Train Epoch: 17 [7040/35339 (20%)]	Loss: 0.154783
Train Epoch: 17 [7680/35339 (22%)]	Loss: 0.195545
Train Epoch: 17 [8320/35339 (24%)]	Loss: 0.188997
Train Epoch: 17 [8960/35339 (25%)]	Loss: 0.138698
Train Epoch: 17 [9600/35339 (27%)]	Loss: 0.177334
Train Epoch: 17 [10240/35339 (29%)]	Loss: 0.179651
Train Epoch: 17 [10880/35339 (31%)]	Loss: 0.108330
Train Epoch: 17 [11520/35339 (33%)]	Loss: 0.148017
Train Epoch: 17 [12160/35339 (34%)]	Loss: 0.216560
Train Epoch: 17 [12800/35339 (36%)]	Loss: 0.155849
Train Epoch: 17 [13440/35339 (38%)]	Loss: 0.265564
Train Epoch: 17 [14080/35339 (40%)]	Loss: 0.093733
Train Epoch: 17 [14720/35339 (42%)]	Loss: 0.114620
Train Epoch: 17 [15360/35339 (43%)]	Loss: 0.193645
Train Epoch: 17 [16000/35339 (45%)]	Loss: 0.114539
Train Epoch: 17 [16640/35339 (47%)]	Loss: 0.207710
Train Epoch: 17 [17280/35339 (49%)]	Loss: 0.161710
Train Epoch: 17 [17920/35339 (51%)]	Loss: 0.153016
Train Epoch: 17 [18560/35339 (52%)]	Loss: 0.150359
Train Epoch: 17 [19200/35339 (54%)]	Loss: 0.202965
Train Epoch: 17 [19840/35339 (56%)]	Loss: 0.155630
Train Epoch: 17 [20480/35339 (58%)]	Loss: 0.108458
Train Epoch: 17 [21120/35339 (60%)]	Loss: 0.158130
Train Epoch: 17 [21760/35339 (61%)]	Loss: 0.115955
Train Epoch: 17 [22400/35339 (63%)]	Loss: 0.258589
Train Epoch: 17 [23040/35339 (65%)]	Loss: 0.147865
Train Epoch: 17 [23680/35339 (67%)]	Loss: 0.125245
Train Epoch: 17 [24320/35339 (69%)]	Loss: 0.311856
Train Epoch: 17 [24960/35339 (71%)]	Loss: 0.156541
Train Epoch: 17 [25600/35339 (72%)]	Loss: 0.170690
Train Epoch: 17 [26240/35339 (74%)]	Loss: 0.124386
Train Epoch: 17 [26880/35339 (76%)]	Loss: 0.134338
Train Epoch: 17 [27520/35339 (78%)]	Loss: 0.136000
Train Epoch: 17 [28160/35339 (80%)]	Loss: 0.182565
Train Epoch: 17 [28800/35339 (81%)]	Loss: 0.149270
Train Epoch: 17 [29440/35339 (83%)]	Loss: 0.159733
Train Epoch: 17 [30080/35339 (85%)]	Loss: 0.192923
Train Epoch: 17 [30720/35339 (87%)]	Loss: 0.145162
Train Epoch: 17 [31360/35339 (89%)]	Loss: 0.153632
Train Epoch: 17 [32000/35339 (90%)]	Loss: 0.200449
Train Epoch: 17 [32640/35339 (92%)]	Loss: 0.216977
Train Epoch: 17 [33280/35339 (94%)]	Loss: 0.196497
Train Epoch: 17 [33920/35339 (96%)]	Loss: 0.148934
Train Epoch: 17 [34560/35339 (98%)]	Loss: 0.231739
Train Epoch: 17 [35200/35339 (99%)]	Loss: 0.203206

Validation set: Average loss: 3.1175, Accuracy: 1259/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 18 [0/35339 (0%)]	Loss: 0.085389
Train Epoch: 18 [640/35339 (2%)]	Loss: 0.197599
Train Epoch: 18 [1280/35339 (4%)]	Loss: 0.092217
Train Epoch: 18 [1920/35339 (5%)]	Loss: 0.174557
Train Epoch: 18 [2560/35339 (7%)]	Loss: 0.098788
Train Epoch: 18 [3200/35339 (9%)]	Loss: 0.120223
Train Epoch: 18 [3840/35339 (11%)]	Loss: 0.085593
Train Epoch: 18 [4480/35339 (13%)]	Loss: 0.211853
Train Epoch: 18 [5120/35339 (14%)]	Loss: 0.179475
Train Epoch: 18 [5760/35339 (16%)]	Loss: 0.156144
Train Epoch: 18 [6400/35339 (18%)]	Loss: 0.119771
Train Epoch: 18 [7040/35339 (20%)]	Loss: 0.122481
Train Epoch: 18 [7680/35339 (22%)]	Loss: 0.229544
Train Epoch: 18 [8320/35339 (24%)]	Loss: 0.177670
Train Epoch: 18 [8960/35339 (25%)]	Loss: 0.074616
Train Epoch: 18 [9600/35339 (27%)]	Loss: 0.170292
Train Epoch: 18 [10240/35339 (29%)]	Loss: 0.294437
Train Epoch: 18 [10880/35339 (31%)]	Loss: 0.214549
Train Epoch: 18 [11520/35339 (33%)]	Loss: 0.210547
Train Epoch: 18 [12160/35339 (34%)]	Loss: 0.128596
Train Epoch: 18 [12800/35339 (36%)]	Loss: 0.144959
Train Epoch: 18 [13440/35339 (38%)]	Loss: 0.115148
Train Epoch: 18 [14080/35339 (40%)]	Loss: 0.173931
Train Epoch: 18 [14720/35339 (42%)]	Loss: 0.204594
Train Epoch: 18 [15360/35339 (43%)]	Loss: 0.150467
Train Epoch: 18 [16000/35339 (45%)]	Loss: 0.152402
Train Epoch: 18 [16640/35339 (47%)]	Loss: 0.183263
Train Epoch: 18 [17280/35339 (49%)]	Loss: 0.206340
Train Epoch: 18 [17920/35339 (51%)]	Loss: 0.153449
Train Epoch: 18 [18560/35339 (52%)]	Loss: 0.219794
Train Epoch: 18 [19200/35339 (54%)]	Loss: 0.173002
Train Epoch: 18 [19840/35339 (56%)]	Loss: 0.152602
Train Epoch: 18 [20480/35339 (58%)]	Loss: 0.254999
Train Epoch: 18 [21120/35339 (60%)]	Loss: 0.118973
Train Epoch: 18 [21760/35339 (61%)]	Loss: 0.106089
Train Epoch: 18 [22400/35339 (63%)]	Loss: 0.143178
Train Epoch: 18 [23040/35339 (65%)]	Loss: 0.123410
Train Epoch: 18 [23680/35339 (67%)]	Loss: 0.185961
Train Epoch: 18 [24320/35339 (69%)]	Loss: 0.129481
Train Epoch: 18 [24960/35339 (71%)]	Loss: 0.157202
Train Epoch: 18 [25600/35339 (72%)]	Loss: 0.151606
Train Epoch: 18 [26240/35339 (74%)]	Loss: 0.376489
Train Epoch: 18 [26880/35339 (76%)]	Loss: 0.190753
Train Epoch: 18 [27520/35339 (78%)]	Loss: 0.135968
Train Epoch: 18 [28160/35339 (80%)]	Loss: 0.164863
Train Epoch: 18 [28800/35339 (81%)]	Loss: 0.281026
Train Epoch: 18 [29440/35339 (83%)]	Loss: 0.218801
Train Epoch: 18 [30080/35339 (85%)]	Loss: 0.151853
Train Epoch: 18 [30720/35339 (87%)]	Loss: 0.173013
Train Epoch: 18 [31360/35339 (89%)]	Loss: 0.261118
Train Epoch: 18 [32000/35339 (90%)]	Loss: 0.120808
Train Epoch: 18 [32640/35339 (92%)]	Loss: 0.266958
Train Epoch: 18 [33280/35339 (94%)]	Loss: 0.174072
Train Epoch: 18 [33920/35339 (96%)]	Loss: 0.135804
Train Epoch: 18 [34560/35339 (98%)]	Loss: 0.121288
Train Epoch: 18 [35200/35339 (99%)]	Loss: 0.127420

Validation set: Average loss: 2.9593, Accuracy: 1398/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 19 [0/35339 (0%)]	Loss: 0.264220
Train Epoch: 19 [640/35339 (2%)]	Loss: 0.295637
Train Epoch: 19 [1280/35339 (4%)]	Loss: 0.163483
Train Epoch: 19 [1920/35339 (5%)]	Loss: 0.110009
Train Epoch: 19 [2560/35339 (7%)]	Loss: 0.128928
Train Epoch: 19 [3200/35339 (9%)]	Loss: 0.142597
Train Epoch: 19 [3840/35339 (11%)]	Loss: 0.150364
Train Epoch: 19 [4480/35339 (13%)]	Loss: 0.124761
Train Epoch: 19 [5120/35339 (14%)]	Loss: 0.134457
Train Epoch: 19 [5760/35339 (16%)]	Loss: 0.150915
Train Epoch: 19 [6400/35339 (18%)]	Loss: 0.121494
Train Epoch: 19 [7040/35339 (20%)]	Loss: 0.171468
Train Epoch: 19 [7680/35339 (22%)]	Loss: 0.111914
Train Epoch: 19 [8320/35339 (24%)]	Loss: 0.172048
Train Epoch: 19 [8960/35339 (25%)]	Loss: 0.156806
Train Epoch: 19 [9600/35339 (27%)]	Loss: 0.117192
Train Epoch: 19 [10240/35339 (29%)]	Loss: 0.134487
Train Epoch: 19 [10880/35339 (31%)]	Loss: 0.191937
Train Epoch: 19 [11520/35339 (33%)]	Loss: 0.120100
Train Epoch: 19 [12160/35339 (34%)]	Loss: 0.164589
Train Epoch: 19 [12800/35339 (36%)]	Loss: 0.144666
Train Epoch: 19 [13440/35339 (38%)]	Loss: 0.239689
Train Epoch: 19 [14080/35339 (40%)]	Loss: 0.091230
Train Epoch: 19 [14720/35339 (42%)]	Loss: 0.237422
Train Epoch: 19 [15360/35339 (43%)]	Loss: 0.133999
Train Epoch: 19 [16000/35339 (45%)]	Loss: 0.174958
Train Epoch: 19 [16640/35339 (47%)]	Loss: 0.139460
Train Epoch: 19 [17280/35339 (49%)]	Loss: 0.187352
Train Epoch: 19 [17920/35339 (51%)]	Loss: 0.139462
Train Epoch: 19 [18560/35339 (52%)]	Loss: 0.160749
Train Epoch: 19 [19200/35339 (54%)]	Loss: 0.091873
Train Epoch: 19 [19840/35339 (56%)]	Loss: 0.521777
Train Epoch: 19 [20480/35339 (58%)]	Loss: 0.146353
Train Epoch: 19 [21120/35339 (60%)]	Loss: 0.154287
Train Epoch: 19 [21760/35339 (61%)]	Loss: 0.282371
Train Epoch: 19 [22400/35339 (63%)]	Loss: 0.204854
Train Epoch: 19 [23040/35339 (65%)]	Loss: 0.154595
Train Epoch: 19 [23680/35339 (67%)]	Loss: 0.147508
Train Epoch: 19 [24320/35339 (69%)]	Loss: 0.130039
Train Epoch: 19 [24960/35339 (71%)]	Loss: 0.145381
Train Epoch: 19 [25600/35339 (72%)]	Loss: 0.205078
Train Epoch: 19 [26240/35339 (74%)]	Loss: 0.168191
Train Epoch: 19 [26880/35339 (76%)]	Loss: 0.195611
Train Epoch: 19 [27520/35339 (78%)]	Loss: 0.201065
Train Epoch: 19 [28160/35339 (80%)]	Loss: 0.244103
Train Epoch: 19 [28800/35339 (81%)]	Loss: 0.136402
Train Epoch: 19 [29440/35339 (83%)]	Loss: 0.131164
Train Epoch: 19 [30080/35339 (85%)]	Loss: 0.097728
Train Epoch: 19 [30720/35339 (87%)]	Loss: 0.190274
Train Epoch: 19 [31360/35339 (89%)]	Loss: 0.348582
Train Epoch: 19 [32000/35339 (90%)]	Loss: 0.091984
Train Epoch: 19 [32640/35339 (92%)]	Loss: 0.137308
Train Epoch: 19 [33280/35339 (94%)]	Loss: 0.152884
Train Epoch: 19 [33920/35339 (96%)]	Loss: 0.072085
Train Epoch: 19 [34560/35339 (98%)]	Loss: 0.136238
Train Epoch: 19 [35200/35339 (99%)]	Loss: 0.070518

Validation set: Average loss: 3.0946, Accuracy: 1293/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 20 [0/35339 (0%)]	Loss: 0.201886
Train Epoch: 20 [640/35339 (2%)]	Loss: 0.135934
Train Epoch: 20 [1280/35339 (4%)]	Loss: 0.165519
Train Epoch: 20 [1920/35339 (5%)]	Loss: 0.085441
Train Epoch: 20 [2560/35339 (7%)]	Loss: 0.155148
Train Epoch: 20 [3200/35339 (9%)]	Loss: 0.167484
Train Epoch: 20 [3840/35339 (11%)]	Loss: 0.129463
Train Epoch: 20 [4480/35339 (13%)]	Loss: 0.080856
Train Epoch: 20 [5120/35339 (14%)]	Loss: 0.110819
Train Epoch: 20 [5760/35339 (16%)]	Loss: 0.118791
Train Epoch: 20 [6400/35339 (18%)]	Loss: 0.138905
Train Epoch: 20 [7040/35339 (20%)]	Loss: 0.260788
Train Epoch: 20 [7680/35339 (22%)]	Loss: 0.156356
Train Epoch: 20 [8320/35339 (24%)]	Loss: 0.143313
Train Epoch: 20 [8960/35339 (25%)]	Loss: 0.222532
Train Epoch: 20 [9600/35339 (27%)]	Loss: 0.255771
Train Epoch: 20 [10240/35339 (29%)]	Loss: 0.158820
Train Epoch: 20 [10880/35339 (31%)]	Loss: 0.091347
Train Epoch: 20 [11520/35339 (33%)]	Loss: 0.386669
Train Epoch: 20 [12160/35339 (34%)]	Loss: 0.112911
Train Epoch: 20 [12800/35339 (36%)]	Loss: 0.140824
Train Epoch: 20 [13440/35339 (38%)]	Loss: 0.124168
Train Epoch: 20 [14080/35339 (40%)]	Loss: 0.170254
Train Epoch: 20 [14720/35339 (42%)]	Loss: 0.223177
Train Epoch: 20 [15360/35339 (43%)]	Loss: 0.169082
Train Epoch: 20 [16000/35339 (45%)]	Loss: 0.087739
Train Epoch: 20 [16640/35339 (47%)]	Loss: 0.274592
Train Epoch: 20 [17280/35339 (49%)]	Loss: 0.152384
Train Epoch: 20 [17920/35339 (51%)]	Loss: 0.210943
Train Epoch: 20 [18560/35339 (52%)]	Loss: 0.164363
Train Epoch: 20 [19200/35339 (54%)]	Loss: 0.150406
Train Epoch: 20 [19840/35339 (56%)]	Loss: 0.221449
Train Epoch: 20 [20480/35339 (58%)]	Loss: 0.157325
Train Epoch: 20 [21120/35339 (60%)]	Loss: 0.137231
Train Epoch: 20 [21760/35339 (61%)]	Loss: 0.140320
Train Epoch: 20 [22400/35339 (63%)]	Loss: 0.102933
Train Epoch: 20 [23040/35339 (65%)]	Loss: 0.241288
Train Epoch: 20 [23680/35339 (67%)]	Loss: 0.141912
Train Epoch: 20 [24320/35339 (69%)]	Loss: 0.121914
Train Epoch: 20 [24960/35339 (71%)]	Loss: 0.171062
Train Epoch: 20 [25600/35339 (72%)]	Loss: 0.170853
Train Epoch: 20 [26240/35339 (74%)]	Loss: 0.148475
Train Epoch: 20 [26880/35339 (76%)]	Loss: 0.163332
Train Epoch: 20 [27520/35339 (78%)]	Loss: 0.162359
Train Epoch: 20 [28160/35339 (80%)]	Loss: 0.194404
Train Epoch: 20 [28800/35339 (81%)]	Loss: 0.196349
Train Epoch: 20 [29440/35339 (83%)]	Loss: 0.263059
Train Epoch: 20 [30080/35339 (85%)]	Loss: 0.259365
Train Epoch: 20 [30720/35339 (87%)]	Loss: 0.124999
Train Epoch: 20 [31360/35339 (89%)]	Loss: 0.115598
Train Epoch: 20 [32000/35339 (90%)]	Loss: 0.091052
Train Epoch: 20 [32640/35339 (92%)]	Loss: 0.114133
Train Epoch: 20 [33280/35339 (94%)]	Loss: 0.128181
Train Epoch: 20 [33920/35339 (96%)]	Loss: 0.115798
Train Epoch: 20 [34560/35339 (98%)]	Loss: 0.099668
Train Epoch: 20 [35200/35339 (99%)]	Loss: 0.134266

Validation set: Average loss: 3.2015, Accuracy: 1269/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 21 [0/35339 (0%)]	Loss: 0.136341
Train Epoch: 21 [640/35339 (2%)]	Loss: 0.102003
Train Epoch: 21 [1280/35339 (4%)]	Loss: 0.107832
Train Epoch: 21 [1920/35339 (5%)]	Loss: 0.178782
Train Epoch: 21 [2560/35339 (7%)]	Loss: 0.237800
Train Epoch: 21 [3200/35339 (9%)]	Loss: 0.194643
Train Epoch: 21 [3840/35339 (11%)]	Loss: 0.145444
Train Epoch: 21 [4480/35339 (13%)]	Loss: 0.199551
Train Epoch: 21 [5120/35339 (14%)]	Loss: 0.276004
Train Epoch: 21 [5760/35339 (16%)]	Loss: 0.132808
Train Epoch: 21 [6400/35339 (18%)]	Loss: 0.244091
Train Epoch: 21 [7040/35339 (20%)]	Loss: 0.104723
Train Epoch: 21 [7680/35339 (22%)]	Loss: 0.155157
Train Epoch: 21 [8320/35339 (24%)]	Loss: 0.084620
Train Epoch: 21 [8960/35339 (25%)]	Loss: 0.158809
Train Epoch: 21 [9600/35339 (27%)]	Loss: 0.188717
Train Epoch: 21 [10240/35339 (29%)]	Loss: 0.161523
Train Epoch: 21 [10880/35339 (31%)]	Loss: 0.123130
Train Epoch: 21 [11520/35339 (33%)]	Loss: 0.167586
Train Epoch: 21 [12160/35339 (34%)]	Loss: 0.162905
Train Epoch: 21 [12800/35339 (36%)]	Loss: 0.211065
Train Epoch: 21 [13440/35339 (38%)]	Loss: 0.106504
Train Epoch: 21 [14080/35339 (40%)]	Loss: 0.134896
Train Epoch: 21 [14720/35339 (42%)]	Loss: 0.169756
Train Epoch: 21 [15360/35339 (43%)]	Loss: 0.108034
Train Epoch: 21 [16000/35339 (45%)]	Loss: 0.101530
Train Epoch: 21 [16640/35339 (47%)]	Loss: 0.116577
Train Epoch: 21 [17280/35339 (49%)]	Loss: 0.100597
Train Epoch: 21 [17920/35339 (51%)]	Loss: 0.132093
Train Epoch: 21 [18560/35339 (52%)]	Loss: 0.147212
Train Epoch: 21 [19200/35339 (54%)]	Loss: 0.245453
Train Epoch: 21 [19840/35339 (56%)]	Loss: 0.170817
Train Epoch: 21 [20480/35339 (58%)]	Loss: 0.146785
Train Epoch: 21 [21120/35339 (60%)]	Loss: 0.137829
Train Epoch: 21 [21760/35339 (61%)]	Loss: 0.137410
Train Epoch: 21 [22400/35339 (63%)]	Loss: 0.169011
Train Epoch: 21 [23040/35339 (65%)]	Loss: 0.157566
Train Epoch: 21 [23680/35339 (67%)]	Loss: 0.125028
Train Epoch: 21 [24320/35339 (69%)]	Loss: 0.283760
Train Epoch: 21 [24960/35339 (71%)]	Loss: 0.154818
Train Epoch: 21 [25600/35339 (72%)]	Loss: 0.074164
Train Epoch: 21 [26240/35339 (74%)]	Loss: 0.090289
Train Epoch: 21 [26880/35339 (76%)]	Loss: 0.194892
Train Epoch: 21 [27520/35339 (78%)]	Loss: 0.144082
Train Epoch: 21 [28160/35339 (80%)]	Loss: 0.134592
Train Epoch: 21 [28800/35339 (81%)]	Loss: 0.096895
Train Epoch: 21 [29440/35339 (83%)]	Loss: 0.184265
Train Epoch: 21 [30080/35339 (85%)]	Loss: 0.122471
Train Epoch: 21 [30720/35339 (87%)]	Loss: 0.153188
Train Epoch: 21 [31360/35339 (89%)]	Loss: 0.140033
Train Epoch: 21 [32000/35339 (90%)]	Loss: 0.099705
Train Epoch: 21 [32640/35339 (92%)]	Loss: 0.157859
Train Epoch: 21 [33280/35339 (94%)]	Loss: 0.226065
Train Epoch: 21 [33920/35339 (96%)]	Loss: 0.091673
Train Epoch: 21 [34560/35339 (98%)]	Loss: 0.083963
Train Epoch: 21 [35200/35339 (99%)]	Loss: 0.181909

Validation set: Average loss: 2.9775, Accuracy: 1383/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 22 [0/35339 (0%)]	Loss: 0.104957
Train Epoch: 22 [640/35339 (2%)]	Loss: 0.155369
Train Epoch: 22 [1280/35339 (4%)]	Loss: 0.145180
Train Epoch: 22 [1920/35339 (5%)]	Loss: 0.170204
Train Epoch: 22 [2560/35339 (7%)]	Loss: 0.102582
Train Epoch: 22 [3200/35339 (9%)]	Loss: 0.169643
Train Epoch: 22 [3840/35339 (11%)]	Loss: 0.129382
Train Epoch: 22 [4480/35339 (13%)]	Loss: 0.147210
Train Epoch: 22 [5120/35339 (14%)]	Loss: 0.146590
Train Epoch: 22 [5760/35339 (16%)]	Loss: 0.186746
Train Epoch: 22 [6400/35339 (18%)]	Loss: 0.198422
Train Epoch: 22 [7040/35339 (20%)]	Loss: 0.172015
Train Epoch: 22 [7680/35339 (22%)]	Loss: 0.142165
Train Epoch: 22 [8320/35339 (24%)]	Loss: 0.092980
Train Epoch: 22 [8960/35339 (25%)]	Loss: 0.113145
Train Epoch: 22 [9600/35339 (27%)]	Loss: 0.111455
Train Epoch: 22 [10240/35339 (29%)]	Loss: 0.138539
Train Epoch: 22 [10880/35339 (31%)]	Loss: 0.164891
Train Epoch: 22 [11520/35339 (33%)]	Loss: 0.138769
Train Epoch: 22 [12160/35339 (34%)]	Loss: 0.128937
Train Epoch: 22 [12800/35339 (36%)]	Loss: 0.124524
Train Epoch: 22 [13440/35339 (38%)]	Loss: 0.179963
Train Epoch: 22 [14080/35339 (40%)]	Loss: 0.231330
Train Epoch: 22 [14720/35339 (42%)]	Loss: 0.079062
Train Epoch: 22 [15360/35339 (43%)]	Loss: 0.133365
Train Epoch: 22 [16000/35339 (45%)]	Loss: 0.138331
Train Epoch: 22 [16640/35339 (47%)]	Loss: 0.093944
Train Epoch: 22 [17280/35339 (49%)]	Loss: 0.139244
Train Epoch: 22 [17920/35339 (51%)]	Loss: 0.125951
Train Epoch: 22 [18560/35339 (52%)]	Loss: 0.119336
Train Epoch: 22 [19200/35339 (54%)]	Loss: 0.122847
Train Epoch: 22 [19840/35339 (56%)]	Loss: 0.142593
Train Epoch: 22 [20480/35339 (58%)]	Loss: 0.119232
Train Epoch: 22 [21120/35339 (60%)]	Loss: 0.090131
Train Epoch: 22 [21760/35339 (61%)]	Loss: 0.122712
Train Epoch: 22 [22400/35339 (63%)]	Loss: 0.095927
Train Epoch: 22 [23040/35339 (65%)]	Loss: 0.227122
Train Epoch: 22 [23680/35339 (67%)]	Loss: 0.093029
Train Epoch: 22 [24320/35339 (69%)]	Loss: 0.206557
Train Epoch: 22 [24960/35339 (71%)]	Loss: 0.107962
Train Epoch: 22 [25600/35339 (72%)]	Loss: 0.104592
Train Epoch: 22 [26240/35339 (74%)]	Loss: 0.104313
Train Epoch: 22 [26880/35339 (76%)]	Loss: 0.136143
Train Epoch: 22 [27520/35339 (78%)]	Loss: 0.156500
Train Epoch: 22 [28160/35339 (80%)]	Loss: 0.158125
Train Epoch: 22 [28800/35339 (81%)]	Loss: 0.261163
Train Epoch: 22 [29440/35339 (83%)]	Loss: 0.130455
Train Epoch: 22 [30080/35339 (85%)]	Loss: 0.198885
Train Epoch: 22 [30720/35339 (87%)]	Loss: 0.157335
Train Epoch: 22 [31360/35339 (89%)]	Loss: 0.127082
Train Epoch: 22 [32000/35339 (90%)]	Loss: 0.142052
Train Epoch: 22 [32640/35339 (92%)]	Loss: 0.143979
Train Epoch: 22 [33280/35339 (94%)]	Loss: 0.154538
Train Epoch: 22 [33920/35339 (96%)]	Loss: 0.142482
Train Epoch: 22 [34560/35339 (98%)]	Loss: 0.107210
Train Epoch: 22 [35200/35339 (99%)]	Loss: 0.098444

Validation set: Average loss: 3.1127, Accuracy: 1294/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 23 [0/35339 (0%)]	Loss: 0.101379
Train Epoch: 23 [640/35339 (2%)]	Loss: 0.128143
Train Epoch: 23 [1280/35339 (4%)]	Loss: 0.112273
Train Epoch: 23 [1920/35339 (5%)]	Loss: 0.111905
Train Epoch: 23 [2560/35339 (7%)]	Loss: 0.138303
Train Epoch: 23 [3200/35339 (9%)]	Loss: 0.156873
Train Epoch: 23 [3840/35339 (11%)]	Loss: 0.153701
Train Epoch: 23 [4480/35339 (13%)]	Loss: 0.100851
Train Epoch: 23 [5120/35339 (14%)]	Loss: 0.089877
Train Epoch: 23 [5760/35339 (16%)]	Loss: 0.150206
Train Epoch: 23 [6400/35339 (18%)]	Loss: 0.154067
Train Epoch: 23 [7040/35339 (20%)]	Loss: 0.127972
Train Epoch: 23 [7680/35339 (22%)]	Loss: 0.098048
Train Epoch: 23 [8320/35339 (24%)]	Loss: 0.190959
Train Epoch: 23 [8960/35339 (25%)]	Loss: 0.127360
Train Epoch: 23 [9600/35339 (27%)]	Loss: 0.080419
Train Epoch: 23 [10240/35339 (29%)]	Loss: 0.136553
Train Epoch: 23 [10880/35339 (31%)]	Loss: 0.069440
Train Epoch: 23 [11520/35339 (33%)]	Loss: 0.138270
Train Epoch: 23 [12160/35339 (34%)]	Loss: 0.149054
Train Epoch: 23 [12800/35339 (36%)]	Loss: 0.163699
Train Epoch: 23 [13440/35339 (38%)]	Loss: 0.124408
Train Epoch: 23 [14080/35339 (40%)]	Loss: 0.124862
Train Epoch: 23 [14720/35339 (42%)]	Loss: 0.114226
Train Epoch: 23 [15360/35339 (43%)]	Loss: 0.174492
Train Epoch: 23 [16000/35339 (45%)]	Loss: 0.205136
Train Epoch: 23 [16640/35339 (47%)]	Loss: 0.113803
Train Epoch: 23 [17280/35339 (49%)]	Loss: 0.154519
Train Epoch: 23 [17920/35339 (51%)]	Loss: 0.138833
Train Epoch: 23 [18560/35339 (52%)]	Loss: 0.094854
Train Epoch: 23 [19200/35339 (54%)]	Loss: 0.218823
Train Epoch: 23 [19840/35339 (56%)]	Loss: 0.124829
Train Epoch: 23 [20480/35339 (58%)]	Loss: 0.124139
Train Epoch: 23 [21120/35339 (60%)]	Loss: 0.128161
Train Epoch: 23 [21760/35339 (61%)]	Loss: 0.137246
Train Epoch: 23 [22400/35339 (63%)]	Loss: 0.093613
Train Epoch: 23 [23040/35339 (65%)]	Loss: 0.102967
Train Epoch: 23 [23680/35339 (67%)]	Loss: 0.200348
Train Epoch: 23 [24320/35339 (69%)]	Loss: 0.100864
Train Epoch: 23 [24960/35339 (71%)]	Loss: 0.133912
Train Epoch: 23 [25600/35339 (72%)]	Loss: 0.115848
Train Epoch: 23 [26240/35339 (74%)]	Loss: 0.160481
Train Epoch: 23 [26880/35339 (76%)]	Loss: 0.111621
Train Epoch: 23 [27520/35339 (78%)]	Loss: 0.105686
Train Epoch: 23 [28160/35339 (80%)]	Loss: 0.187103
Train Epoch: 23 [28800/35339 (81%)]	Loss: 0.161081
Train Epoch: 23 [29440/35339 (83%)]	Loss: 0.122145
Train Epoch: 23 [30080/35339 (85%)]	Loss: 0.199199
Train Epoch: 23 [30720/35339 (87%)]	Loss: 0.237205
Train Epoch: 23 [31360/35339 (89%)]	Loss: 0.086770
Train Epoch: 23 [32000/35339 (90%)]	Loss: 0.134816
Train Epoch: 23 [32640/35339 (92%)]	Loss: 0.153025
Train Epoch: 23 [33280/35339 (94%)]	Loss: 0.149041
Train Epoch: 23 [33920/35339 (96%)]	Loss: 0.091309
Train Epoch: 23 [34560/35339 (98%)]	Loss: 0.096441
Train Epoch: 23 [35200/35339 (99%)]	Loss: 0.065996

Validation set: Average loss: 3.1544, Accuracy: 1333/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 24 [0/35339 (0%)]	Loss: 0.166616
Train Epoch: 24 [640/35339 (2%)]	Loss: 0.177249
Train Epoch: 24 [1280/35339 (4%)]	Loss: 0.098342
Train Epoch: 24 [1920/35339 (5%)]	Loss: 0.190536
Train Epoch: 24 [2560/35339 (7%)]	Loss: 0.149820
Train Epoch: 24 [3200/35339 (9%)]	Loss: 0.134435
Train Epoch: 24 [3840/35339 (11%)]	Loss: 0.092882
Train Epoch: 24 [4480/35339 (13%)]	Loss: 0.093501
Train Epoch: 24 [5120/35339 (14%)]	Loss: 0.139914
Train Epoch: 24 [5760/35339 (16%)]	Loss: 0.074959
Train Epoch: 24 [6400/35339 (18%)]	Loss: 0.122824
Train Epoch: 24 [7040/35339 (20%)]	Loss: 0.110900
Train Epoch: 24 [7680/35339 (22%)]	Loss: 0.097763
Train Epoch: 24 [8320/35339 (24%)]	Loss: 0.120702
Train Epoch: 24 [8960/35339 (25%)]	Loss: 0.098738
Train Epoch: 24 [9600/35339 (27%)]	Loss: 0.118682
Train Epoch: 24 [10240/35339 (29%)]	Loss: 0.111073
Train Epoch: 24 [10880/35339 (31%)]	Loss: 0.133294
Train Epoch: 24 [11520/35339 (33%)]	Loss: 0.178231
Train Epoch: 24 [12160/35339 (34%)]	Loss: 0.130947
Train Epoch: 24 [12800/35339 (36%)]	Loss: 0.110673
Train Epoch: 24 [13440/35339 (38%)]	Loss: 0.222900
Train Epoch: 24 [14080/35339 (40%)]	Loss: 0.251717
Train Epoch: 24 [14720/35339 (42%)]	Loss: 0.103792
Train Epoch: 24 [15360/35339 (43%)]	Loss: 0.196717
Train Epoch: 24 [16000/35339 (45%)]	Loss: 0.116874
Train Epoch: 24 [16640/35339 (47%)]	Loss: 0.169636
Train Epoch: 24 [17280/35339 (49%)]	Loss: 0.098335
Train Epoch: 24 [17920/35339 (51%)]	Loss: 0.146651
Train Epoch: 24 [18560/35339 (52%)]	Loss: 0.190965
Train Epoch: 24 [19200/35339 (54%)]	Loss: 0.115913
Train Epoch: 24 [19840/35339 (56%)]	Loss: 0.137022
Train Epoch: 24 [20480/35339 (58%)]	Loss: 0.316963
Train Epoch: 24 [21120/35339 (60%)]	Loss: 0.125099
Train Epoch: 24 [21760/35339 (61%)]	Loss: 0.163771
Train Epoch: 24 [22400/35339 (63%)]	Loss: 0.128161
Train Epoch: 24 [23040/35339 (65%)]	Loss: 0.153447
Train Epoch: 24 [23680/35339 (67%)]	Loss: 0.138492
Train Epoch: 24 [24320/35339 (69%)]	Loss: 0.207098
Train Epoch: 24 [24960/35339 (71%)]	Loss: 0.122733
Train Epoch: 24 [25600/35339 (72%)]	Loss: 0.151927
Train Epoch: 24 [26240/35339 (74%)]	Loss: 0.082869
Train Epoch: 24 [26880/35339 (76%)]	Loss: 0.099011
Train Epoch: 24 [27520/35339 (78%)]	Loss: 0.361454
Train Epoch: 24 [28160/35339 (80%)]	Loss: 0.087616
Train Epoch: 24 [28800/35339 (81%)]	Loss: 0.168878
Train Epoch: 24 [29440/35339 (83%)]	Loss: 0.100194
Train Epoch: 24 [30080/35339 (85%)]	Loss: 0.115940
Train Epoch: 24 [30720/35339 (87%)]	Loss: 0.127237
Train Epoch: 24 [31360/35339 (89%)]	Loss: 0.088773
Train Epoch: 24 [32000/35339 (90%)]	Loss: 0.145837
Train Epoch: 24 [32640/35339 (92%)]	Loss: 0.175728
Train Epoch: 24 [33280/35339 (94%)]	Loss: 0.134298
Train Epoch: 24 [33920/35339 (96%)]	Loss: 0.125984
Train Epoch: 24 [34560/35339 (98%)]	Loss: 0.146077
Train Epoch: 24 [35200/35339 (99%)]	Loss: 0.123592

Validation set: Average loss: 3.2190, Accuracy: 1238/3870 (32%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 25 [0/35339 (0%)]	Loss: 0.076942
Train Epoch: 25 [640/35339 (2%)]	Loss: 0.101256
Train Epoch: 25 [1280/35339 (4%)]	Loss: 0.146232
Train Epoch: 25 [1920/35339 (5%)]	Loss: 0.101502
Train Epoch: 25 [2560/35339 (7%)]	Loss: 0.121765
Train Epoch: 25 [3200/35339 (9%)]	Loss: 0.173080
Train Epoch: 25 [3840/35339 (11%)]	Loss: 0.082436
Train Epoch: 25 [4480/35339 (13%)]	Loss: 0.103287
Train Epoch: 25 [5120/35339 (14%)]	Loss: 0.164414
Train Epoch: 25 [5760/35339 (16%)]	Loss: 0.220004
Train Epoch: 25 [6400/35339 (18%)]	Loss: 0.086944
Train Epoch: 25 [7040/35339 (20%)]	Loss: 0.088005
Train Epoch: 25 [7680/35339 (22%)]	Loss: 0.091411
Train Epoch: 25 [8320/35339 (24%)]	Loss: 0.159345
Train Epoch: 25 [8960/35339 (25%)]	Loss: 0.129708
Train Epoch: 25 [9600/35339 (27%)]	Loss: 0.117835
Train Epoch: 25 [10240/35339 (29%)]	Loss: 0.121339
Train Epoch: 25 [10880/35339 (31%)]	Loss: 0.198017
Train Epoch: 25 [11520/35339 (33%)]	Loss: 0.153181
Train Epoch: 25 [12160/35339 (34%)]	Loss: 0.177025
Train Epoch: 25 [12800/35339 (36%)]	Loss: 0.128876
Train Epoch: 25 [13440/35339 (38%)]	Loss: 0.144862
Train Epoch: 25 [14080/35339 (40%)]	Loss: 0.112871
Train Epoch: 25 [14720/35339 (42%)]	Loss: 0.153595
Train Epoch: 25 [15360/35339 (43%)]	Loss: 0.114185
Train Epoch: 25 [16000/35339 (45%)]	Loss: 0.196350
Train Epoch: 25 [16640/35339 (47%)]	Loss: 0.549798
Train Epoch: 25 [17280/35339 (49%)]	Loss: 0.153357
Train Epoch: 25 [17920/35339 (51%)]	Loss: 0.219602
Train Epoch: 25 [18560/35339 (52%)]	Loss: 0.177472
Train Epoch: 25 [19200/35339 (54%)]	Loss: 0.142379
Train Epoch: 25 [19840/35339 (56%)]	Loss: 0.099192
Train Epoch: 25 [20480/35339 (58%)]	Loss: 0.123876
Train Epoch: 25 [21120/35339 (60%)]	Loss: 0.117321
Train Epoch: 25 [21760/35339 (61%)]	Loss: 0.155487
Train Epoch: 25 [22400/35339 (63%)]	Loss: 0.132391
Train Epoch: 25 [23040/35339 (65%)]	Loss: 0.090261
Train Epoch: 25 [23680/35339 (67%)]	Loss: 0.196333
Train Epoch: 25 [24320/35339 (69%)]	Loss: 0.087542
Train Epoch: 25 [24960/35339 (71%)]	Loss: 0.108974
Train Epoch: 25 [25600/35339 (72%)]	Loss: 0.152235
Train Epoch: 25 [26240/35339 (74%)]	Loss: 0.158726
Train Epoch: 25 [26880/35339 (76%)]	Loss: 0.064412
Train Epoch: 25 [27520/35339 (78%)]	Loss: 0.257241
Train Epoch: 25 [28160/35339 (80%)]	Loss: 0.110940
Train Epoch: 25 [28800/35339 (81%)]	Loss: 0.108648
Train Epoch: 25 [29440/35339 (83%)]	Loss: 0.110625
Train Epoch: 25 [30080/35339 (85%)]	Loss: 0.167334
Train Epoch: 25 [30720/35339 (87%)]	Loss: 0.109442
Train Epoch: 25 [31360/35339 (89%)]	Loss: 0.187849
Train Epoch: 25 [32000/35339 (90%)]	Loss: 0.157430
Train Epoch: 25 [32640/35339 (92%)]	Loss: 0.092016
Train Epoch: 25 [33280/35339 (94%)]	Loss: 0.175178
Train Epoch: 25 [33920/35339 (96%)]	Loss: 0.108862
Train Epoch: 25 [34560/35339 (98%)]	Loss: 0.096703
Train Epoch: 25 [35200/35339 (99%)]	Loss: 0.079705

Validation set: Average loss: 3.2655, Accuracy: 1237/3870 (32%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 26 [0/35339 (0%)]	Loss: 0.168702
Train Epoch: 26 [640/35339 (2%)]	Loss: 0.152805
Train Epoch: 26 [1280/35339 (4%)]	Loss: 0.121378
Train Epoch: 26 [1920/35339 (5%)]	Loss: 0.095601
Train Epoch: 26 [2560/35339 (7%)]	Loss: 0.130235
Train Epoch: 26 [3200/35339 (9%)]	Loss: 0.141489
Train Epoch: 26 [3840/35339 (11%)]	Loss: 0.091786
Train Epoch: 26 [4480/35339 (13%)]	Loss: 0.231102
Train Epoch: 26 [5120/35339 (14%)]	Loss: 0.121442
Train Epoch: 26 [5760/35339 (16%)]	Loss: 0.097859
Train Epoch: 26 [6400/35339 (18%)]	Loss: 0.087781
Train Epoch: 26 [7040/35339 (20%)]	Loss: 0.168546
Train Epoch: 26 [7680/35339 (22%)]	Loss: 0.114357
Train Epoch: 26 [8320/35339 (24%)]	Loss: 0.207742
Train Epoch: 26 [8960/35339 (25%)]	Loss: 0.196403
Train Epoch: 26 [9600/35339 (27%)]	Loss: 0.100579
Train Epoch: 26 [10240/35339 (29%)]	Loss: 0.117595
Train Epoch: 26 [10880/35339 (31%)]	Loss: 0.172088
Train Epoch: 26 [11520/35339 (33%)]	Loss: 0.075797
Train Epoch: 26 [12160/35339 (34%)]	Loss: 0.141982
Train Epoch: 26 [12800/35339 (36%)]	Loss: 0.146469
Train Epoch: 26 [13440/35339 (38%)]	Loss: 0.095815
Train Epoch: 26 [14080/35339 (40%)]	Loss: 0.083580
Train Epoch: 26 [14720/35339 (42%)]	Loss: 0.129795
Train Epoch: 26 [15360/35339 (43%)]	Loss: 0.069437
Train Epoch: 26 [16000/35339 (45%)]	Loss: 0.075317
Train Epoch: 26 [16640/35339 (47%)]	Loss: 0.120491
Train Epoch: 26 [17280/35339 (49%)]	Loss: 0.175877
Train Epoch: 26 [17920/35339 (51%)]	Loss: 0.146426
Train Epoch: 26 [18560/35339 (52%)]	Loss: 0.142594
Train Epoch: 26 [19200/35339 (54%)]	Loss: 0.221078
Train Epoch: 26 [19840/35339 (56%)]	Loss: 0.125201
Train Epoch: 26 [20480/35339 (58%)]	Loss: 0.508893
Train Epoch: 26 [21120/35339 (60%)]	Loss: 0.279707
Train Epoch: 26 [21760/35339 (61%)]	Loss: 0.191586
Train Epoch: 26 [22400/35339 (63%)]	Loss: 0.147730
Train Epoch: 26 [23040/35339 (65%)]	Loss: 0.140964
Train Epoch: 26 [23680/35339 (67%)]	Loss: 0.133515
Train Epoch: 26 [24320/35339 (69%)]	Loss: 0.176416
Train Epoch: 26 [24960/35339 (71%)]	Loss: 0.143697
Train Epoch: 26 [25600/35339 (72%)]	Loss: 0.150484
Train Epoch: 26 [26240/35339 (74%)]	Loss: 0.094735
Train Epoch: 26 [26880/35339 (76%)]	Loss: 0.143224
Train Epoch: 26 [27520/35339 (78%)]	Loss: 0.137504
Train Epoch: 26 [28160/35339 (80%)]	Loss: 0.258913
Train Epoch: 26 [28800/35339 (81%)]	Loss: 0.279669
Train Epoch: 26 [29440/35339 (83%)]	Loss: 0.149690
Train Epoch: 26 [30080/35339 (85%)]	Loss: 0.134626
Train Epoch: 26 [30720/35339 (87%)]	Loss: 0.146787
Train Epoch: 26 [31360/35339 (89%)]	Loss: 0.124932
Train Epoch: 26 [32000/35339 (90%)]	Loss: 0.144590
Train Epoch: 26 [32640/35339 (92%)]	Loss: 0.131398
Train Epoch: 26 [33280/35339 (94%)]	Loss: 0.097465
Train Epoch: 26 [33920/35339 (96%)]	Loss: 0.118611
Train Epoch: 26 [34560/35339 (98%)]	Loss: 0.103487
Train Epoch: 26 [35200/35339 (99%)]	Loss: 0.093197

Validation set: Average loss: 3.0362, Accuracy: 1320/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 27 [0/35339 (0%)]	Loss: 0.125447
Train Epoch: 27 [640/35339 (2%)]	Loss: 0.091858
Train Epoch: 27 [1280/35339 (4%)]	Loss: 0.191067
Train Epoch: 27 [1920/35339 (5%)]	Loss: 0.108012
Train Epoch: 27 [2560/35339 (7%)]	Loss: 0.110842
Train Epoch: 27 [3200/35339 (9%)]	Loss: 0.136142
Train Epoch: 27 [3840/35339 (11%)]	Loss: 0.264133
Train Epoch: 27 [4480/35339 (13%)]	Loss: 0.106132
Train Epoch: 27 [5120/35339 (14%)]	Loss: 0.296603
Train Epoch: 27 [5760/35339 (16%)]	Loss: 0.118796
Train Epoch: 27 [6400/35339 (18%)]	Loss: 0.077665
Train Epoch: 27 [7040/35339 (20%)]	Loss: 0.136497
Train Epoch: 27 [7680/35339 (22%)]	Loss: 0.133633
Train Epoch: 27 [8320/35339 (24%)]	Loss: 0.157127
Train Epoch: 27 [8960/35339 (25%)]	Loss: 0.154578
Train Epoch: 27 [9600/35339 (27%)]	Loss: 0.086043
Train Epoch: 27 [10240/35339 (29%)]	Loss: 0.180370
Train Epoch: 27 [10880/35339 (31%)]	Loss: 0.107180
Train Epoch: 27 [11520/35339 (33%)]	Loss: 0.146580
Train Epoch: 27 [12160/35339 (34%)]	Loss: 0.096242
Train Epoch: 27 [12800/35339 (36%)]	Loss: 0.185882
Train Epoch: 27 [13440/35339 (38%)]	Loss: 0.143582
Train Epoch: 27 [14080/35339 (40%)]	Loss: 0.107966
Train Epoch: 27 [14720/35339 (42%)]	Loss: 0.125057
Train Epoch: 27 [15360/35339 (43%)]	Loss: 0.223120
Train Epoch: 27 [16000/35339 (45%)]	Loss: 0.099634
Train Epoch: 27 [16640/35339 (47%)]	Loss: 0.127455
Train Epoch: 27 [17280/35339 (49%)]	Loss: 0.124975
Train Epoch: 27 [17920/35339 (51%)]	Loss: 0.140233
Train Epoch: 27 [18560/35339 (52%)]	Loss: 0.097532
Train Epoch: 27 [19200/35339 (54%)]	Loss: 0.161589
Train Epoch: 27 [19840/35339 (56%)]	Loss: 0.084026
Train Epoch: 27 [20480/35339 (58%)]	Loss: 0.088461
Train Epoch: 27 [21120/35339 (60%)]	Loss: 0.129459
Train Epoch: 27 [21760/35339 (61%)]	Loss: 0.143706
Train Epoch: 27 [22400/35339 (63%)]	Loss: 0.147958
Train Epoch: 27 [23040/35339 (65%)]	Loss: 0.092209
Train Epoch: 27 [23680/35339 (67%)]	Loss: 0.175043
Train Epoch: 27 [24320/35339 (69%)]	Loss: 0.119526
Train Epoch: 27 [24960/35339 (71%)]	Loss: 0.109446
Train Epoch: 27 [25600/35339 (72%)]	Loss: 0.153440
Train Epoch: 27 [26240/35339 (74%)]	Loss: 0.172256
Train Epoch: 27 [26880/35339 (76%)]	Loss: 0.172118
Train Epoch: 27 [27520/35339 (78%)]	Loss: 0.098884
Train Epoch: 27 [28160/35339 (80%)]	Loss: 0.150179
Train Epoch: 27 [28800/35339 (81%)]	Loss: 0.135911
Train Epoch: 27 [29440/35339 (83%)]	Loss: 0.278510
Train Epoch: 27 [30080/35339 (85%)]	Loss: 0.079155
Train Epoch: 27 [30720/35339 (87%)]	Loss: 0.079403
Train Epoch: 27 [31360/35339 (89%)]	Loss: 0.137267
Train Epoch: 27 [32000/35339 (90%)]	Loss: 0.162167
Train Epoch: 27 [32640/35339 (92%)]	Loss: 0.162911
Train Epoch: 27 [33280/35339 (94%)]	Loss: 0.234052
Train Epoch: 27 [33920/35339 (96%)]	Loss: 0.092486
Train Epoch: 27 [34560/35339 (98%)]	Loss: 0.113604
Train Epoch: 27 [35200/35339 (99%)]	Loss: 0.147459

Validation set: Average loss: 3.1354, Accuracy: 1290/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 28 [0/35339 (0%)]	Loss: 0.227624
Train Epoch: 28 [640/35339 (2%)]	Loss: 0.150465
Train Epoch: 28 [1280/35339 (4%)]	Loss: 0.124765
Train Epoch: 28 [1920/35339 (5%)]	Loss: 0.123141
Train Epoch: 28 [2560/35339 (7%)]	Loss: 0.090970
Train Epoch: 28 [3200/35339 (9%)]	Loss: 0.303942
Train Epoch: 28 [3840/35339 (11%)]	Loss: 0.076095
Train Epoch: 28 [4480/35339 (13%)]	Loss: 0.090361
Train Epoch: 28 [5120/35339 (14%)]	Loss: 0.136608
Train Epoch: 28 [5760/35339 (16%)]	Loss: 0.166402
Train Epoch: 28 [6400/35339 (18%)]	Loss: 0.132721
Train Epoch: 28 [7040/35339 (20%)]	Loss: 0.079668
Train Epoch: 28 [7680/35339 (22%)]	Loss: 0.157674
Train Epoch: 28 [8320/35339 (24%)]	Loss: 0.457982
Train Epoch: 28 [8960/35339 (25%)]	Loss: 0.151901
Train Epoch: 28 [9600/35339 (27%)]	Loss: 0.093106
Train Epoch: 28 [10240/35339 (29%)]	Loss: 0.105509
Train Epoch: 28 [10880/35339 (31%)]	Loss: 0.319290
Train Epoch: 28 [11520/35339 (33%)]	Loss: 0.113081
Train Epoch: 28 [12160/35339 (34%)]	Loss: 0.099403
Train Epoch: 28 [12800/35339 (36%)]	Loss: 0.099853
Train Epoch: 28 [13440/35339 (38%)]	Loss: 0.114006
Train Epoch: 28 [14080/35339 (40%)]	Loss: 0.186275
Train Epoch: 28 [14720/35339 (42%)]	Loss: 0.136698
Train Epoch: 28 [15360/35339 (43%)]	Loss: 0.094854
Train Epoch: 28 [16000/35339 (45%)]	Loss: 0.153906
Train Epoch: 28 [16640/35339 (47%)]	Loss: 0.128523
Train Epoch: 28 [17280/35339 (49%)]	Loss: 0.115382
Train Epoch: 28 [17920/35339 (51%)]	Loss: 0.066214
Train Epoch: 28 [18560/35339 (52%)]	Loss: 0.142289
Train Epoch: 28 [19200/35339 (54%)]	Loss: 0.228639
Train Epoch: 28 [19840/35339 (56%)]	Loss: 0.157218
Train Epoch: 28 [20480/35339 (58%)]	Loss: 0.133540
Train Epoch: 28 [21120/35339 (60%)]	Loss: 0.116544
Train Epoch: 28 [21760/35339 (61%)]	Loss: 0.115917
Train Epoch: 28 [22400/35339 (63%)]	Loss: 0.103099
Train Epoch: 28 [23040/35339 (65%)]	Loss: 0.194188
Train Epoch: 28 [23680/35339 (67%)]	Loss: 0.104570
Train Epoch: 28 [24320/35339 (69%)]	Loss: 0.102555
Train Epoch: 28 [24960/35339 (71%)]	Loss: 0.310380
Train Epoch: 28 [25600/35339 (72%)]	Loss: 0.099857
Train Epoch: 28 [26240/35339 (74%)]	Loss: 0.336727
Train Epoch: 28 [26880/35339 (76%)]	Loss: 0.193811
Train Epoch: 28 [27520/35339 (78%)]	Loss: 0.088047
Train Epoch: 28 [28160/35339 (80%)]	Loss: 0.097723
Train Epoch: 28 [28800/35339 (81%)]	Loss: 0.204617
Train Epoch: 28 [29440/35339 (83%)]	Loss: 0.149518
Train Epoch: 28 [30080/35339 (85%)]	Loss: 0.141209
Train Epoch: 28 [30720/35339 (87%)]	Loss: 0.140504
Train Epoch: 28 [31360/35339 (89%)]	Loss: 0.274199
Train Epoch: 28 [32000/35339 (90%)]	Loss: 0.183389
Train Epoch: 28 [32640/35339 (92%)]	Loss: 0.142872
Train Epoch: 28 [33280/35339 (94%)]	Loss: 0.090375
Train Epoch: 28 [33920/35339 (96%)]	Loss: 0.127614
Train Epoch: 28 [34560/35339 (98%)]	Loss: 0.083008
Train Epoch: 28 [35200/35339 (99%)]	Loss: 0.094611

Validation set: Average loss: 3.1261, Accuracy: 1338/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 29 [0/35339 (0%)]	Loss: 0.187404
Train Epoch: 29 [640/35339 (2%)]	Loss: 0.191048
Train Epoch: 29 [1280/35339 (4%)]	Loss: 0.139961
Train Epoch: 29 [1920/35339 (5%)]	Loss: 0.111866
Train Epoch: 29 [2560/35339 (7%)]	Loss: 0.121069
Train Epoch: 29 [3200/35339 (9%)]	Loss: 0.295317
Train Epoch: 29 [3840/35339 (11%)]	Loss: 0.215625
Train Epoch: 29 [4480/35339 (13%)]	Loss: 0.108461
Train Epoch: 29 [5120/35339 (14%)]	Loss: 0.124220
Train Epoch: 29 [5760/35339 (16%)]	Loss: 0.093709
Train Epoch: 29 [6400/35339 (18%)]	Loss: 0.088101
Train Epoch: 29 [7040/35339 (20%)]	Loss: 0.217434
Train Epoch: 29 [7680/35339 (22%)]	Loss: 0.236443
Train Epoch: 29 [8320/35339 (24%)]	Loss: 0.128214
Train Epoch: 29 [8960/35339 (25%)]	Loss: 0.125011
Train Epoch: 29 [9600/35339 (27%)]	Loss: 0.127475
Train Epoch: 29 [10240/35339 (29%)]	Loss: 0.144175
Train Epoch: 29 [10880/35339 (31%)]	Loss: 0.143932
Train Epoch: 29 [11520/35339 (33%)]	Loss: 0.099340
Train Epoch: 29 [12160/35339 (34%)]	Loss: 0.156567
Train Epoch: 29 [12800/35339 (36%)]	Loss: 0.152505
Train Epoch: 29 [13440/35339 (38%)]	Loss: 0.201185
Train Epoch: 29 [14080/35339 (40%)]	Loss: 0.170993
Train Epoch: 29 [14720/35339 (42%)]	Loss: 0.107098
Train Epoch: 29 [15360/35339 (43%)]	Loss: 0.119802
Train Epoch: 29 [16000/35339 (45%)]	Loss: 0.138618
Train Epoch: 29 [16640/35339 (47%)]	Loss: 0.081527
Train Epoch: 29 [17280/35339 (49%)]	Loss: 0.074728
Train Epoch: 29 [17920/35339 (51%)]	Loss: 0.195709
Train Epoch: 29 [18560/35339 (52%)]	Loss: 0.143051
Train Epoch: 29 [19200/35339 (54%)]	Loss: 0.140076
Train Epoch: 29 [19840/35339 (56%)]	Loss: 0.114246
Train Epoch: 29 [20480/35339 (58%)]	Loss: 0.090910
Train Epoch: 29 [21120/35339 (60%)]	Loss: 0.166563
Train Epoch: 29 [21760/35339 (61%)]	Loss: 0.095674
Train Epoch: 29 [22400/35339 (63%)]	Loss: 0.176137
Train Epoch: 29 [23040/35339 (65%)]	Loss: 0.142936
Train Epoch: 29 [23680/35339 (67%)]	Loss: 0.104189
Train Epoch: 29 [24320/35339 (69%)]	Loss: 0.096339
Train Epoch: 29 [24960/35339 (71%)]	Loss: 0.164852
Train Epoch: 29 [25600/35339 (72%)]	Loss: 0.176878
Train Epoch: 29 [26240/35339 (74%)]	Loss: 0.078585
Train Epoch: 29 [26880/35339 (76%)]	Loss: 0.120101
Train Epoch: 29 [27520/35339 (78%)]	Loss: 0.119179
Train Epoch: 29 [28160/35339 (80%)]	Loss: 0.115434
Train Epoch: 29 [28800/35339 (81%)]	Loss: 0.211899
Train Epoch: 29 [29440/35339 (83%)]	Loss: 0.081273
Train Epoch: 29 [30080/35339 (85%)]	Loss: 0.178820
Train Epoch: 29 [30720/35339 (87%)]	Loss: 0.094254
Train Epoch: 29 [31360/35339 (89%)]	Loss: 0.120432
Train Epoch: 29 [32000/35339 (90%)]	Loss: 0.151843
Train Epoch: 29 [32640/35339 (92%)]	Loss: 0.147622
Train Epoch: 29 [33280/35339 (94%)]	Loss: 0.150843
Train Epoch: 29 [33920/35339 (96%)]	Loss: 0.210855
Train Epoch: 29 [34560/35339 (98%)]	Loss: 0.128414
Train Epoch: 29 [35200/35339 (99%)]	Loss: 0.184310

Validation set: Average loss: 3.0048, Accuracy: 1405/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 30 [0/35339 (0%)]	Loss: 0.141100
Train Epoch: 30 [640/35339 (2%)]	Loss: 0.155434
Train Epoch: 30 [1280/35339 (4%)]	Loss: 0.131711
Train Epoch: 30 [1920/35339 (5%)]	Loss: 0.115810
Train Epoch: 30 [2560/35339 (7%)]	Loss: 0.192400
Train Epoch: 30 [3200/35339 (9%)]	Loss: 0.116817
Train Epoch: 30 [3840/35339 (11%)]	Loss: 0.097673
Train Epoch: 30 [4480/35339 (13%)]	Loss: 0.145932
Train Epoch: 30 [5120/35339 (14%)]	Loss: 0.155354
Train Epoch: 30 [5760/35339 (16%)]	Loss: 0.141828
Train Epoch: 30 [6400/35339 (18%)]	Loss: 0.124242
Train Epoch: 30 [7040/35339 (20%)]	Loss: 0.103268
Train Epoch: 30 [7680/35339 (22%)]	Loss: 0.117585
Train Epoch: 30 [8320/35339 (24%)]	Loss: 0.147363
Train Epoch: 30 [8960/35339 (25%)]	Loss: 0.362946
Train Epoch: 30 [9600/35339 (27%)]	Loss: 0.093450
Train Epoch: 30 [10240/35339 (29%)]	Loss: 0.117412
Train Epoch: 30 [10880/35339 (31%)]	Loss: 0.240574
Train Epoch: 30 [11520/35339 (33%)]	Loss: 0.082533
Train Epoch: 30 [12160/35339 (34%)]	Loss: 0.132438
Train Epoch: 30 [12800/35339 (36%)]	Loss: 0.250021
Train Epoch: 30 [13440/35339 (38%)]	Loss: 0.132244
Train Epoch: 30 [14080/35339 (40%)]	Loss: 0.142291
Train Epoch: 30 [14720/35339 (42%)]	Loss: 0.199533
Train Epoch: 30 [15360/35339 (43%)]	Loss: 0.159456
Train Epoch: 30 [16000/35339 (45%)]	Loss: 0.095875
Train Epoch: 30 [16640/35339 (47%)]	Loss: 0.146117
Train Epoch: 30 [17280/35339 (49%)]	Loss: 0.175199
Train Epoch: 30 [17920/35339 (51%)]	Loss: 0.107532
Train Epoch: 30 [18560/35339 (52%)]	Loss: 0.070780
Train Epoch: 30 [19200/35339 (54%)]	Loss: 0.116984
Train Epoch: 30 [19840/35339 (56%)]	Loss: 0.136422
Train Epoch: 30 [20480/35339 (58%)]	Loss: 0.137104
Train Epoch: 30 [21120/35339 (60%)]	Loss: 0.145331
Train Epoch: 30 [21760/35339 (61%)]	Loss: 0.088344
Train Epoch: 30 [22400/35339 (63%)]	Loss: 0.079478
Train Epoch: 30 [23040/35339 (65%)]	Loss: 0.085551
Train Epoch: 30 [23680/35339 (67%)]	Loss: 0.087387
Train Epoch: 30 [24320/35339 (69%)]	Loss: 0.124229
Train Epoch: 30 [24960/35339 (71%)]	Loss: 0.161516
Train Epoch: 30 [25600/35339 (72%)]	Loss: 0.174270
Train Epoch: 30 [26240/35339 (74%)]	Loss: 0.131232
Train Epoch: 30 [26880/35339 (76%)]	Loss: 0.167165
Train Epoch: 30 [27520/35339 (78%)]	Loss: 0.171812
Train Epoch: 30 [28160/35339 (80%)]	Loss: 0.143134
Train Epoch: 30 [28800/35339 (81%)]	Loss: 0.213383
Train Epoch: 30 [29440/35339 (83%)]	Loss: 0.174017
Train Epoch: 30 [30080/35339 (85%)]	Loss: 0.078055
Train Epoch: 30 [30720/35339 (87%)]	Loss: 0.142325
Train Epoch: 30 [31360/35339 (89%)]	Loss: 0.198421
Train Epoch: 30 [32000/35339 (90%)]	Loss: 0.209513
Train Epoch: 30 [32640/35339 (92%)]	Loss: 0.201260
Train Epoch: 30 [33280/35339 (94%)]	Loss: 0.273064
Train Epoch: 30 [33920/35339 (96%)]	Loss: 0.118697
Train Epoch: 30 [34560/35339 (98%)]	Loss: 0.128550
Train Epoch: 30 [35200/35339 (99%)]	Loss: 0.192501

Validation set: Average loss: 2.7714, Accuracy: 1566/3870 (40%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 31 [0/35339 (0%)]	Loss: 0.149597
Train Epoch: 31 [640/35339 (2%)]	Loss: 0.124962
Train Epoch: 31 [1280/35339 (4%)]	Loss: 0.158213
Train Epoch: 31 [1920/35339 (5%)]	Loss: 0.119551
Train Epoch: 31 [2560/35339 (7%)]	Loss: 0.087851
Train Epoch: 31 [3200/35339 (9%)]	Loss: 0.113005
Train Epoch: 31 [3840/35339 (11%)]	Loss: 0.170437
Train Epoch: 31 [4480/35339 (13%)]	Loss: 0.144081
Train Epoch: 31 [5120/35339 (14%)]	Loss: 0.159119
Train Epoch: 31 [5760/35339 (16%)]	Loss: 0.193264
Train Epoch: 31 [6400/35339 (18%)]	Loss: 0.093896
Train Epoch: 31 [7040/35339 (20%)]	Loss: 0.129032
Train Epoch: 31 [7680/35339 (22%)]	Loss: 0.206347
Train Epoch: 31 [8320/35339 (24%)]	Loss: 0.102095
Train Epoch: 31 [8960/35339 (25%)]	Loss: 0.212778
Train Epoch: 31 [9600/35339 (27%)]	Loss: 0.239497
Train Epoch: 31 [10240/35339 (29%)]	Loss: 0.087105
Train Epoch: 31 [10880/35339 (31%)]	Loss: 0.115065
Train Epoch: 31 [11520/35339 (33%)]	Loss: 0.104925
Train Epoch: 31 [12160/35339 (34%)]	Loss: 0.104189
Train Epoch: 31 [12800/35339 (36%)]	Loss: 0.132773
Train Epoch: 31 [13440/35339 (38%)]	Loss: 0.115957
Train Epoch: 31 [14080/35339 (40%)]	Loss: 0.113617
Train Epoch: 31 [14720/35339 (42%)]	Loss: 0.132032
Train Epoch: 31 [15360/35339 (43%)]	Loss: 0.144830
Train Epoch: 31 [16000/35339 (45%)]	Loss: 0.089859
Train Epoch: 31 [16640/35339 (47%)]	Loss: 0.196991
Train Epoch: 31 [17280/35339 (49%)]	Loss: 0.135970
Train Epoch: 31 [17920/35339 (51%)]	Loss: 0.125022
Train Epoch: 31 [18560/35339 (52%)]	Loss: 0.162088
Train Epoch: 31 [19200/35339 (54%)]	Loss: 0.123814
Train Epoch: 31 [19840/35339 (56%)]	Loss: 0.077800
Train Epoch: 31 [20480/35339 (58%)]	Loss: 0.087042
Train Epoch: 31 [21120/35339 (60%)]	Loss: 0.063965
Train Epoch: 31 [21760/35339 (61%)]	Loss: 0.083157
Train Epoch: 31 [22400/35339 (63%)]	Loss: 0.107670
Train Epoch: 31 [23040/35339 (65%)]	Loss: 0.170361
Train Epoch: 31 [23680/35339 (67%)]	Loss: 0.158428
Train Epoch: 31 [24320/35339 (69%)]	Loss: 0.175572
Train Epoch: 31 [24960/35339 (71%)]	Loss: 0.118922
Train Epoch: 31 [25600/35339 (72%)]	Loss: 0.092109
Train Epoch: 31 [26240/35339 (74%)]	Loss: 0.164364
Train Epoch: 31 [26880/35339 (76%)]	Loss: 0.082993
Train Epoch: 31 [27520/35339 (78%)]	Loss: 0.104614
Train Epoch: 31 [28160/35339 (80%)]	Loss: 0.117254
Train Epoch: 31 [28800/35339 (81%)]	Loss: 0.290974
Train Epoch: 31 [29440/35339 (83%)]	Loss: 0.109564
Train Epoch: 31 [30080/35339 (85%)]	Loss: 0.118642
Train Epoch: 31 [30720/35339 (87%)]	Loss: 0.133717
Train Epoch: 31 [31360/35339 (89%)]	Loss: 0.143475
Train Epoch: 31 [32000/35339 (90%)]	Loss: 0.131555
Train Epoch: 31 [32640/35339 (92%)]	Loss: 0.156506
Train Epoch: 31 [33280/35339 (94%)]	Loss: 0.094003
Train Epoch: 31 [33920/35339 (96%)]	Loss: 0.144653
Train Epoch: 31 [34560/35339 (98%)]	Loss: 0.117136
Train Epoch: 31 [35200/35339 (99%)]	Loss: 0.141962

Validation set: Average loss: 3.0561, Accuracy: 1407/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 32 [0/35339 (0%)]	Loss: 0.128747
Train Epoch: 32 [640/35339 (2%)]	Loss: 0.200032
Train Epoch: 32 [1280/35339 (4%)]	Loss: 0.210422
Train Epoch: 32 [1920/35339 (5%)]	Loss: 0.167411
Train Epoch: 32 [2560/35339 (7%)]	Loss: 0.103540
Train Epoch: 32 [3200/35339 (9%)]	Loss: 0.089164
Train Epoch: 32 [3840/35339 (11%)]	Loss: 0.166189
Train Epoch: 32 [4480/35339 (13%)]	Loss: 0.138167
Train Epoch: 32 [5120/35339 (14%)]	Loss: 0.131644
Train Epoch: 32 [5760/35339 (16%)]	Loss: 0.162923
Train Epoch: 32 [6400/35339 (18%)]	Loss: 0.144071
Train Epoch: 32 [7040/35339 (20%)]	Loss: 0.157341
Train Epoch: 32 [7680/35339 (22%)]	Loss: 0.083864
Train Epoch: 32 [8320/35339 (24%)]	Loss: 0.104652
Train Epoch: 32 [8960/35339 (25%)]	Loss: 0.071965
Train Epoch: 32 [9600/35339 (27%)]	Loss: 0.146010
Train Epoch: 32 [10240/35339 (29%)]	Loss: 0.103295
Train Epoch: 32 [10880/35339 (31%)]	Loss: 0.134769
Train Epoch: 32 [11520/35339 (33%)]	Loss: 0.125144
Train Epoch: 32 [12160/35339 (34%)]	Loss: 0.135900
Train Epoch: 32 [12800/35339 (36%)]	Loss: 0.156625
Train Epoch: 32 [13440/35339 (38%)]	Loss: 0.103695
Train Epoch: 32 [14080/35339 (40%)]	Loss: 0.078417
Train Epoch: 32 [14720/35339 (42%)]	Loss: 0.070988
Train Epoch: 32 [15360/35339 (43%)]	Loss: 0.123919
Train Epoch: 32 [16000/35339 (45%)]	Loss: 0.141152
Train Epoch: 32 [16640/35339 (47%)]	Loss: 0.077171
Train Epoch: 32 [17280/35339 (49%)]	Loss: 0.105121
Train Epoch: 32 [17920/35339 (51%)]	Loss: 0.138087
Train Epoch: 32 [18560/35339 (52%)]	Loss: 0.118830
Train Epoch: 32 [19200/35339 (54%)]	Loss: 0.236349
Train Epoch: 32 [19840/35339 (56%)]	Loss: 0.211012
Train Epoch: 32 [20480/35339 (58%)]	Loss: 0.157306
Train Epoch: 32 [21120/35339 (60%)]	Loss: 0.116759
Train Epoch: 32 [21760/35339 (61%)]	Loss: 0.087211
Train Epoch: 32 [22400/35339 (63%)]	Loss: 0.125361
Train Epoch: 32 [23040/35339 (65%)]	Loss: 0.174277
Train Epoch: 32 [23680/35339 (67%)]	Loss: 0.158949
Train Epoch: 32 [24320/35339 (69%)]	Loss: 0.096121
Train Epoch: 32 [24960/35339 (71%)]	Loss: 0.121419
Train Epoch: 32 [25600/35339 (72%)]	Loss: 0.086773
Train Epoch: 32 [26240/35339 (74%)]	Loss: 0.106621
Train Epoch: 32 [26880/35339 (76%)]	Loss: 0.116372
Train Epoch: 32 [27520/35339 (78%)]	Loss: 0.121158
Train Epoch: 32 [28160/35339 (80%)]	Loss: 0.123658
Train Epoch: 32 [28800/35339 (81%)]	Loss: 0.099047
Train Epoch: 32 [29440/35339 (83%)]	Loss: 0.076069
Train Epoch: 32 [30080/35339 (85%)]	Loss: 0.091998
Train Epoch: 32 [30720/35339 (87%)]	Loss: 0.138722
Train Epoch: 32 [31360/35339 (89%)]	Loss: 0.091597
Train Epoch: 32 [32000/35339 (90%)]	Loss: 0.120473
Train Epoch: 32 [32640/35339 (92%)]	Loss: 0.361062
Train Epoch: 32 [33280/35339 (94%)]	Loss: 0.141019
Train Epoch: 32 [33920/35339 (96%)]	Loss: 0.119066
Train Epoch: 32 [34560/35339 (98%)]	Loss: 0.100372
Train Epoch: 32 [35200/35339 (99%)]	Loss: 0.107733

Validation set: Average loss: 3.0886, Accuracy: 1362/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 33 [0/35339 (0%)]	Loss: 0.147780
Train Epoch: 33 [640/35339 (2%)]	Loss: 0.296806
Train Epoch: 33 [1280/35339 (4%)]	Loss: 0.152630
Train Epoch: 33 [1920/35339 (5%)]	Loss: 0.157161
Train Epoch: 33 [2560/35339 (7%)]	Loss: 0.095449
Train Epoch: 33 [3200/35339 (9%)]	Loss: 0.132948
Train Epoch: 33 [3840/35339 (11%)]	Loss: 0.075804
Train Epoch: 33 [4480/35339 (13%)]	Loss: 0.121820
Train Epoch: 33 [5120/35339 (14%)]	Loss: 0.135363
Train Epoch: 33 [5760/35339 (16%)]	Loss: 0.113633
Train Epoch: 33 [6400/35339 (18%)]	Loss: 0.132583
Train Epoch: 33 [7040/35339 (20%)]	Loss: 0.165178
Train Epoch: 33 [7680/35339 (22%)]	Loss: 0.124853
Train Epoch: 33 [8320/35339 (24%)]	Loss: 0.208110
Train Epoch: 33 [8960/35339 (25%)]	Loss: 0.149105
Train Epoch: 33 [9600/35339 (27%)]	Loss: 0.122585
Train Epoch: 33 [10240/35339 (29%)]	Loss: 0.127060
Train Epoch: 33 [10880/35339 (31%)]	Loss: 0.150701
Train Epoch: 33 [11520/35339 (33%)]	Loss: 0.122756
Train Epoch: 33 [12160/35339 (34%)]	Loss: 0.102208
Train Epoch: 33 [12800/35339 (36%)]	Loss: 0.122093
Train Epoch: 33 [13440/35339 (38%)]	Loss: 0.173776
Train Epoch: 33 [14080/35339 (40%)]	Loss: 0.091600
Train Epoch: 33 [14720/35339 (42%)]	Loss: 0.116104
Train Epoch: 33 [15360/35339 (43%)]	Loss: 0.096968
Train Epoch: 33 [16000/35339 (45%)]	Loss: 0.130987
Train Epoch: 33 [16640/35339 (47%)]	Loss: 0.126723
Train Epoch: 33 [17280/35339 (49%)]	Loss: 0.168415
Train Epoch: 33 [17920/35339 (51%)]	Loss: 0.211745
Train Epoch: 33 [18560/35339 (52%)]	Loss: 0.161896
Train Epoch: 33 [19200/35339 (54%)]	Loss: 0.138323
Train Epoch: 33 [19840/35339 (56%)]	Loss: 0.125044
Train Epoch: 33 [20480/35339 (58%)]	Loss: 0.098487
Train Epoch: 33 [21120/35339 (60%)]	Loss: 0.089573
Train Epoch: 33 [21760/35339 (61%)]	Loss: 0.191950
Train Epoch: 33 [22400/35339 (63%)]	Loss: 0.120345
Train Epoch: 33 [23040/35339 (65%)]	Loss: 0.079137
Train Epoch: 33 [23680/35339 (67%)]	Loss: 0.109043
Train Epoch: 33 [24320/35339 (69%)]	Loss: 0.151597
Train Epoch: 33 [24960/35339 (71%)]	Loss: 0.098623
Train Epoch: 33 [25600/35339 (72%)]	Loss: 0.134460
Train Epoch: 33 [26240/35339 (74%)]	Loss: 0.080940
Train Epoch: 33 [26880/35339 (76%)]	Loss: 0.086983
Train Epoch: 33 [27520/35339 (78%)]	Loss: 0.106457
Train Epoch: 33 [28160/35339 (80%)]	Loss: 0.125831
Train Epoch: 33 [28800/35339 (81%)]	Loss: 0.077892
Train Epoch: 33 [29440/35339 (83%)]	Loss: 0.186430
Train Epoch: 33 [30080/35339 (85%)]	Loss: 0.070048
Train Epoch: 33 [30720/35339 (87%)]	Loss: 0.139438
Train Epoch: 33 [31360/35339 (89%)]	Loss: 0.102670
Train Epoch: 33 [32000/35339 (90%)]	Loss: 0.162480
Train Epoch: 33 [32640/35339 (92%)]	Loss: 0.098096
Train Epoch: 33 [33280/35339 (94%)]	Loss: 0.312899
Train Epoch: 33 [33920/35339 (96%)]	Loss: 0.274122
Train Epoch: 33 [34560/35339 (98%)]	Loss: 0.099976
Train Epoch: 33 [35200/35339 (99%)]	Loss: 0.085912

Validation set: Average loss: 3.0804, Accuracy: 1451/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 34 [0/35339 (0%)]	Loss: 0.109245
Train Epoch: 34 [640/35339 (2%)]	Loss: 0.065954
Train Epoch: 34 [1280/35339 (4%)]	Loss: 0.127671
Train Epoch: 34 [1920/35339 (5%)]	Loss: 0.307290
Train Epoch: 34 [2560/35339 (7%)]	Loss: 0.143734
Train Epoch: 34 [3200/35339 (9%)]	Loss: 0.107373
Train Epoch: 34 [3840/35339 (11%)]	Loss: 0.098425
Train Epoch: 34 [4480/35339 (13%)]	Loss: 0.099249
Train Epoch: 34 [5120/35339 (14%)]	Loss: 0.091542
Train Epoch: 34 [5760/35339 (16%)]	Loss: 0.280934
Train Epoch: 34 [6400/35339 (18%)]	Loss: 0.231953
Train Epoch: 34 [7040/35339 (20%)]	Loss: 0.154860
Train Epoch: 34 [7680/35339 (22%)]	Loss: 0.275054
Train Epoch: 34 [8320/35339 (24%)]	Loss: 0.119972
Train Epoch: 34 [8960/35339 (25%)]	Loss: 0.094051
Train Epoch: 34 [9600/35339 (27%)]	Loss: 0.147711
Train Epoch: 34 [10240/35339 (29%)]	Loss: 0.071823
Train Epoch: 34 [10880/35339 (31%)]	Loss: 0.084622
Train Epoch: 34 [11520/35339 (33%)]	Loss: 0.177330
Train Epoch: 34 [12160/35339 (34%)]	Loss: 0.216574
Train Epoch: 34 [12800/35339 (36%)]	Loss: 0.088817
Train Epoch: 34 [13440/35339 (38%)]	Loss: 0.096996
Train Epoch: 34 [14080/35339 (40%)]	Loss: 0.147388
Train Epoch: 34 [14720/35339 (42%)]	Loss: 0.090664
Train Epoch: 34 [15360/35339 (43%)]	Loss: 0.160961
Train Epoch: 34 [16000/35339 (45%)]	Loss: 0.118396
Train Epoch: 34 [16640/35339 (47%)]	Loss: 0.200108
Train Epoch: 34 [17280/35339 (49%)]	Loss: 0.164687
Train Epoch: 34 [17920/35339 (51%)]	Loss: 0.103741
Train Epoch: 34 [18560/35339 (52%)]	Loss: 0.117330
Train Epoch: 34 [19200/35339 (54%)]	Loss: 0.113173
Train Epoch: 34 [19840/35339 (56%)]	Loss: 0.114013
Train Epoch: 34 [20480/35339 (58%)]	Loss: 0.134334
Train Epoch: 34 [21120/35339 (60%)]	Loss: 0.119173
Train Epoch: 34 [21760/35339 (61%)]	Loss: 0.155193
Train Epoch: 34 [22400/35339 (63%)]	Loss: 0.075630
Train Epoch: 34 [23040/35339 (65%)]	Loss: 0.104706
Train Epoch: 34 [23680/35339 (67%)]	Loss: 0.132084
Train Epoch: 34 [24320/35339 (69%)]	Loss: 0.190262
Train Epoch: 34 [24960/35339 (71%)]	Loss: 0.132851
Train Epoch: 34 [25600/35339 (72%)]	Loss: 0.207705
Train Epoch: 34 [26240/35339 (74%)]	Loss: 0.241297
Train Epoch: 34 [26880/35339 (76%)]	Loss: 0.080440
Train Epoch: 34 [27520/35339 (78%)]	Loss: 0.168696
Train Epoch: 34 [28160/35339 (80%)]	Loss: 0.147046
Train Epoch: 34 [28800/35339 (81%)]	Loss: 0.076682
Train Epoch: 34 [29440/35339 (83%)]	Loss: 0.139777
Train Epoch: 34 [30080/35339 (85%)]	Loss: 0.181171
Train Epoch: 34 [30720/35339 (87%)]	Loss: 0.150231
Train Epoch: 34 [31360/35339 (89%)]	Loss: 0.077342
Train Epoch: 34 [32000/35339 (90%)]	Loss: 0.248564
Train Epoch: 34 [32640/35339 (92%)]	Loss: 0.099282
Train Epoch: 34 [33280/35339 (94%)]	Loss: 0.124532
Train Epoch: 34 [33920/35339 (96%)]	Loss: 0.105676
Train Epoch: 34 [34560/35339 (98%)]	Loss: 0.155098
Train Epoch: 34 [35200/35339 (99%)]	Loss: 0.107358

Validation set: Average loss: 2.9767, Accuracy: 1460/3870 (38%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 35 [0/35339 (0%)]	Loss: 0.097585
Train Epoch: 35 [640/35339 (2%)]	Loss: 0.116862
Train Epoch: 35 [1280/35339 (4%)]	Loss: 0.118208
Train Epoch: 35 [1920/35339 (5%)]	Loss: 0.089935
Train Epoch: 35 [2560/35339 (7%)]	Loss: 0.147005
Train Epoch: 35 [3200/35339 (9%)]	Loss: 0.105008
Train Epoch: 35 [3840/35339 (11%)]	Loss: 0.121342
Train Epoch: 35 [4480/35339 (13%)]	Loss: 0.119519
Train Epoch: 35 [5120/35339 (14%)]	Loss: 0.102898
Train Epoch: 35 [5760/35339 (16%)]	Loss: 0.209435
Train Epoch: 35 [6400/35339 (18%)]	Loss: 0.181511
Train Epoch: 35 [7040/35339 (20%)]	Loss: 0.264087
Train Epoch: 35 [7680/35339 (22%)]	Loss: 0.150252
Train Epoch: 35 [8320/35339 (24%)]	Loss: 0.104171
Train Epoch: 35 [8960/35339 (25%)]	Loss: 0.119284
Train Epoch: 35 [9600/35339 (27%)]	Loss: 0.102710
Train Epoch: 35 [10240/35339 (29%)]	Loss: 0.094645
Train Epoch: 35 [10880/35339 (31%)]	Loss: 0.104691
Train Epoch: 35 [11520/35339 (33%)]	Loss: 0.225004
Train Epoch: 35 [12160/35339 (34%)]	Loss: 0.210845
Train Epoch: 35 [12800/35339 (36%)]	Loss: 0.145939
Train Epoch: 35 [13440/35339 (38%)]	Loss: 0.126346
Train Epoch: 35 [14080/35339 (40%)]	Loss: 0.123470
Train Epoch: 35 [14720/35339 (42%)]	Loss: 0.287708
Train Epoch: 35 [15360/35339 (43%)]	Loss: 0.120915
Train Epoch: 35 [16000/35339 (45%)]	Loss: 0.128724
Train Epoch: 35 [16640/35339 (47%)]	Loss: 0.347711
Train Epoch: 35 [17280/35339 (49%)]	Loss: 0.104406
Train Epoch: 35 [17920/35339 (51%)]	Loss: 0.195498
Train Epoch: 35 [18560/35339 (52%)]	Loss: 0.173559
Train Epoch: 35 [19200/35339 (54%)]	Loss: 0.149667
Train Epoch: 35 [19840/35339 (56%)]	Loss: 0.083060
Train Epoch: 35 [20480/35339 (58%)]	Loss: 0.175768
Train Epoch: 35 [21120/35339 (60%)]	Loss: 0.110700
Train Epoch: 35 [21760/35339 (61%)]	Loss: 0.154066
Train Epoch: 35 [22400/35339 (63%)]	Loss: 0.174330
Train Epoch: 35 [23040/35339 (65%)]	Loss: 0.178641
Train Epoch: 35 [23680/35339 (67%)]	Loss: 0.110713
Train Epoch: 35 [24320/35339 (69%)]	Loss: 0.139237
Train Epoch: 35 [24960/35339 (71%)]	Loss: 0.144412
Train Epoch: 35 [25600/35339 (72%)]	Loss: 0.116879
Train Epoch: 35 [26240/35339 (74%)]	Loss: 0.111850
Train Epoch: 35 [26880/35339 (76%)]	Loss: 0.147035
Train Epoch: 35 [27520/35339 (78%)]	Loss: 0.127765
Train Epoch: 35 [28160/35339 (80%)]	Loss: 0.244210
Train Epoch: 35 [28800/35339 (81%)]	Loss: 0.159402
Train Epoch: 35 [29440/35339 (83%)]	Loss: 0.086810
Train Epoch: 35 [30080/35339 (85%)]	Loss: 0.086919
Train Epoch: 35 [30720/35339 (87%)]	Loss: 0.139610
Train Epoch: 35 [31360/35339 (89%)]	Loss: 0.116719
Train Epoch: 35 [32000/35339 (90%)]	Loss: 0.160409
Train Epoch: 35 [32640/35339 (92%)]	Loss: 0.142022
Train Epoch: 35 [33280/35339 (94%)]	Loss: 0.135386
Train Epoch: 35 [33920/35339 (96%)]	Loss: 0.132543
Train Epoch: 35 [34560/35339 (98%)]	Loss: 0.104581
Train Epoch: 35 [35200/35339 (99%)]	Loss: 0.090210

Validation set: Average loss: 3.1091, Accuracy: 1379/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 36 [0/35339 (0%)]	Loss: 0.250492
Train Epoch: 36 [640/35339 (2%)]	Loss: 0.119885
Train Epoch: 36 [1280/35339 (4%)]	Loss: 0.105982
Train Epoch: 36 [1920/35339 (5%)]	Loss: 0.120578
Train Epoch: 36 [2560/35339 (7%)]	Loss: 0.185549
Train Epoch: 36 [3200/35339 (9%)]	Loss: 0.113757
Train Epoch: 36 [3840/35339 (11%)]	Loss: 0.129658
Train Epoch: 36 [4480/35339 (13%)]	Loss: 0.140552
Train Epoch: 36 [5120/35339 (14%)]	Loss: 0.109191
Train Epoch: 36 [5760/35339 (16%)]	Loss: 0.145355
Train Epoch: 36 [6400/35339 (18%)]	Loss: 0.159012
Train Epoch: 36 [7040/35339 (20%)]	Loss: 0.097341
Train Epoch: 36 [7680/35339 (22%)]	Loss: 0.116511
Train Epoch: 36 [8320/35339 (24%)]	Loss: 0.179117
Train Epoch: 36 [8960/35339 (25%)]	Loss: 0.098477
Train Epoch: 36 [9600/35339 (27%)]	Loss: 0.174470
Train Epoch: 36 [10240/35339 (29%)]	Loss: 0.062046
Train Epoch: 36 [10880/35339 (31%)]	Loss: 0.178855
Train Epoch: 36 [11520/35339 (33%)]	Loss: 0.121193
Train Epoch: 36 [12160/35339 (34%)]	Loss: 0.096006
Train Epoch: 36 [12800/35339 (36%)]	Loss: 0.140702
Train Epoch: 36 [13440/35339 (38%)]	Loss: 0.113713
Train Epoch: 36 [14080/35339 (40%)]	Loss: 0.124937
Train Epoch: 36 [14720/35339 (42%)]	Loss: 0.151335
Train Epoch: 36 [15360/35339 (43%)]	Loss: 0.080783
Train Epoch: 36 [16000/35339 (45%)]	Loss: 0.067388
Train Epoch: 36 [16640/35339 (47%)]	Loss: 0.082889
Train Epoch: 36 [17280/35339 (49%)]	Loss: 0.110476
Train Epoch: 36 [17920/35339 (51%)]	Loss: 0.082519
Train Epoch: 36 [18560/35339 (52%)]	Loss: 0.219372
Train Epoch: 36 [19200/35339 (54%)]	Loss: 0.077726
Train Epoch: 36 [19840/35339 (56%)]	Loss: 0.141065
Train Epoch: 36 [20480/35339 (58%)]	Loss: 0.111318
Train Epoch: 36 [21120/35339 (60%)]	Loss: 0.105113
Train Epoch: 36 [21760/35339 (61%)]	Loss: 0.153581
Train Epoch: 36 [22400/35339 (63%)]	Loss: 0.180427
Train Epoch: 36 [23040/35339 (65%)]	Loss: 0.190884
Train Epoch: 36 [23680/35339 (67%)]	Loss: 0.072904
Train Epoch: 36 [24320/35339 (69%)]	Loss: 0.081807
Train Epoch: 36 [24960/35339 (71%)]	Loss: 0.249147
Train Epoch: 36 [25600/35339 (72%)]	Loss: 0.106394
Train Epoch: 36 [26240/35339 (74%)]	Loss: 0.192861
Train Epoch: 36 [26880/35339 (76%)]	Loss: 0.137499
Train Epoch: 36 [27520/35339 (78%)]	Loss: 0.098366
Train Epoch: 36 [28160/35339 (80%)]	Loss: 0.087068
Train Epoch: 36 [28800/35339 (81%)]	Loss: 0.164922
Train Epoch: 36 [29440/35339 (83%)]	Loss: 0.081959
Train Epoch: 36 [30080/35339 (85%)]	Loss: 0.108453
Train Epoch: 36 [30720/35339 (87%)]	Loss: 0.261035
Train Epoch: 36 [31360/35339 (89%)]	Loss: 0.124812
Train Epoch: 36 [32000/35339 (90%)]	Loss: 0.121861
Train Epoch: 36 [32640/35339 (92%)]	Loss: 0.144796
Train Epoch: 36 [33280/35339 (94%)]	Loss: 0.139739
Train Epoch: 36 [33920/35339 (96%)]	Loss: 0.219067
Train Epoch: 36 [34560/35339 (98%)]	Loss: 0.128329
Train Epoch: 36 [35200/35339 (99%)]	Loss: 0.104681

Validation set: Average loss: 2.9024, Accuracy: 1522/3870 (39%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 37 [0/35339 (0%)]	Loss: 0.147348
Train Epoch: 37 [640/35339 (2%)]	Loss: 0.102648
Train Epoch: 37 [1280/35339 (4%)]	Loss: 0.084613
Train Epoch: 37 [1920/35339 (5%)]	Loss: 0.113427
Train Epoch: 37 [2560/35339 (7%)]	Loss: 0.136073
Train Epoch: 37 [3200/35339 (9%)]	Loss: 0.113313
Train Epoch: 37 [3840/35339 (11%)]	Loss: 0.113325
Train Epoch: 37 [4480/35339 (13%)]	Loss: 0.202826
Train Epoch: 37 [5120/35339 (14%)]	Loss: 0.096676
Train Epoch: 37 [5760/35339 (16%)]	Loss: 0.080359
Train Epoch: 37 [6400/35339 (18%)]	Loss: 0.167997
Train Epoch: 37 [7040/35339 (20%)]	Loss: 0.157226
Train Epoch: 37 [7680/35339 (22%)]	Loss: 0.114412
Train Epoch: 37 [8320/35339 (24%)]	Loss: 0.119998
Train Epoch: 37 [8960/35339 (25%)]	Loss: 0.109983
Train Epoch: 37 [9600/35339 (27%)]	Loss: 0.096328
Train Epoch: 37 [10240/35339 (29%)]	Loss: 0.087646
Train Epoch: 37 [10880/35339 (31%)]	Loss: 0.104423
Train Epoch: 37 [11520/35339 (33%)]	Loss: 0.123139
Train Epoch: 37 [12160/35339 (34%)]	Loss: 0.166375
Train Epoch: 37 [12800/35339 (36%)]	Loss: 0.114889
Train Epoch: 37 [13440/35339 (38%)]	Loss: 0.186157
Train Epoch: 37 [14080/35339 (40%)]	Loss: 0.119647
Train Epoch: 37 [14720/35339 (42%)]	Loss: 0.114203
Train Epoch: 37 [15360/35339 (43%)]	Loss: 0.121837
Train Epoch: 37 [16000/35339 (45%)]	Loss: 0.074151
Train Epoch: 37 [16640/35339 (47%)]	Loss: 0.103482
Train Epoch: 37 [17280/35339 (49%)]	Loss: 0.117857
Train Epoch: 37 [17920/35339 (51%)]	Loss: 0.132477
Train Epoch: 37 [18560/35339 (52%)]	Loss: 0.206031
Train Epoch: 37 [19200/35339 (54%)]	Loss: 0.077855
Train Epoch: 37 [19840/35339 (56%)]	Loss: 0.081929
Train Epoch: 37 [20480/35339 (58%)]	Loss: 0.115517
Train Epoch: 37 [21120/35339 (60%)]	Loss: 0.155352
Train Epoch: 37 [21760/35339 (61%)]	Loss: 0.128371
Train Epoch: 37 [22400/35339 (63%)]	Loss: 0.161646
Train Epoch: 37 [23040/35339 (65%)]	Loss: 0.169176
Train Epoch: 37 [23680/35339 (67%)]	Loss: 0.129426
Train Epoch: 37 [24320/35339 (69%)]	Loss: 0.132027
Train Epoch: 37 [24960/35339 (71%)]	Loss: 0.199251
Train Epoch: 37 [25600/35339 (72%)]	Loss: 0.123132
Train Epoch: 37 [26240/35339 (74%)]	Loss: 0.108129
Train Epoch: 37 [26880/35339 (76%)]	Loss: 0.073199
Train Epoch: 37 [27520/35339 (78%)]	Loss: 0.156627
Train Epoch: 37 [28160/35339 (80%)]	Loss: 0.107986
Train Epoch: 37 [28800/35339 (81%)]	Loss: 0.127939
Train Epoch: 37 [29440/35339 (83%)]	Loss: 0.100852
Train Epoch: 37 [30080/35339 (85%)]	Loss: 0.079189
Train Epoch: 37 [30720/35339 (87%)]	Loss: 0.115369
Train Epoch: 37 [31360/35339 (89%)]	Loss: 0.119079
Train Epoch: 37 [32000/35339 (90%)]	Loss: 0.156855
Train Epoch: 37 [32640/35339 (92%)]	Loss: 0.087791
Train Epoch: 37 [33280/35339 (94%)]	Loss: 0.064318
Train Epoch: 37 [33920/35339 (96%)]	Loss: 0.087841
Train Epoch: 37 [34560/35339 (98%)]	Loss: 0.159642
Train Epoch: 37 [35200/35339 (99%)]	Loss: 0.146206

Validation set: Average loss: 3.1045, Accuracy: 1433/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 38 [0/35339 (0%)]	Loss: 0.123360
Train Epoch: 38 [640/35339 (2%)]	Loss: 0.070718
Train Epoch: 38 [1280/35339 (4%)]	Loss: 0.072641
Train Epoch: 38 [1920/35339 (5%)]	Loss: 0.085038
Train Epoch: 38 [2560/35339 (7%)]	Loss: 0.071029
Train Epoch: 38 [3200/35339 (9%)]	Loss: 0.082371
Train Epoch: 38 [3840/35339 (11%)]	Loss: 0.070952
Train Epoch: 38 [4480/35339 (13%)]	Loss: 0.100159
Train Epoch: 38 [5120/35339 (14%)]	Loss: 0.118769
Train Epoch: 38 [5760/35339 (16%)]	Loss: 0.111685
Train Epoch: 38 [6400/35339 (18%)]	Loss: 0.248361
Train Epoch: 38 [7040/35339 (20%)]	Loss: 0.085606
Train Epoch: 38 [7680/35339 (22%)]	Loss: 0.124689
Train Epoch: 38 [8320/35339 (24%)]	Loss: 0.093822
Train Epoch: 38 [8960/35339 (25%)]	Loss: 0.092866
Train Epoch: 38 [9600/35339 (27%)]	Loss: 0.126237
Train Epoch: 38 [10240/35339 (29%)]	Loss: 0.116599
Train Epoch: 38 [10880/35339 (31%)]	Loss: 0.085998
Train Epoch: 38 [11520/35339 (33%)]	Loss: 0.144669
Train Epoch: 38 [12160/35339 (34%)]	Loss: 0.078911
Train Epoch: 38 [12800/35339 (36%)]	Loss: 0.108129
Train Epoch: 38 [13440/35339 (38%)]	Loss: 0.106031
Train Epoch: 38 [14080/35339 (40%)]	Loss: 0.119222
Train Epoch: 38 [14720/35339 (42%)]	Loss: 0.105413
Train Epoch: 38 [15360/35339 (43%)]	Loss: 0.098669
Train Epoch: 38 [16000/35339 (45%)]	Loss: 0.141526
Train Epoch: 38 [16640/35339 (47%)]	Loss: 0.122737
Train Epoch: 38 [17280/35339 (49%)]	Loss: 0.138138
Train Epoch: 38 [17920/35339 (51%)]	Loss: 0.063566
Train Epoch: 38 [18560/35339 (52%)]	Loss: 0.109848
Train Epoch: 38 [19200/35339 (54%)]	Loss: 0.157897
Train Epoch: 38 [19840/35339 (56%)]	Loss: 0.156769
Train Epoch: 38 [20480/35339 (58%)]	Loss: 0.111714
Train Epoch: 38 [21120/35339 (60%)]	Loss: 0.094388
Train Epoch: 38 [21760/35339 (61%)]	Loss: 0.062504
Train Epoch: 38 [22400/35339 (63%)]	Loss: 0.177143
Train Epoch: 38 [23040/35339 (65%)]	Loss: 0.465511
Train Epoch: 38 [23680/35339 (67%)]	Loss: 0.116543
Train Epoch: 38 [24320/35339 (69%)]	Loss: 0.181092
Train Epoch: 38 [24960/35339 (71%)]	Loss: 0.070491
Train Epoch: 38 [25600/35339 (72%)]	Loss: 0.104858
Train Epoch: 38 [26240/35339 (74%)]	Loss: 0.097295
Train Epoch: 38 [26880/35339 (76%)]	Loss: 0.136719
Train Epoch: 38 [27520/35339 (78%)]	Loss: 0.145571
Train Epoch: 38 [28160/35339 (80%)]	Loss: 0.194012
Train Epoch: 38 [28800/35339 (81%)]	Loss: 0.128637
Train Epoch: 38 [29440/35339 (83%)]	Loss: 0.223805
Train Epoch: 38 [30080/35339 (85%)]	Loss: 0.183737
Train Epoch: 38 [30720/35339 (87%)]	Loss: 0.075818
Train Epoch: 38 [31360/35339 (89%)]	Loss: 0.201915
Train Epoch: 38 [32000/35339 (90%)]	Loss: 0.142066
Train Epoch: 38 [32640/35339 (92%)]	Loss: 0.122388
Train Epoch: 38 [33280/35339 (94%)]	Loss: 0.102708
Train Epoch: 38 [33920/35339 (96%)]	Loss: 0.129156
Train Epoch: 38 [34560/35339 (98%)]	Loss: 0.115947
Train Epoch: 38 [35200/35339 (99%)]	Loss: 0.103843

Validation set: Average loss: 3.2284, Accuracy: 1257/3870 (32%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 39 [0/35339 (0%)]	Loss: 0.122378
Train Epoch: 39 [640/35339 (2%)]	Loss: 0.101664
Train Epoch: 39 [1280/35339 (4%)]	Loss: 0.135685
Train Epoch: 39 [1920/35339 (5%)]	Loss: 0.118542
Train Epoch: 39 [2560/35339 (7%)]	Loss: 0.245155
Train Epoch: 39 [3200/35339 (9%)]	Loss: 0.198513
Train Epoch: 39 [3840/35339 (11%)]	Loss: 0.091403
Train Epoch: 39 [4480/35339 (13%)]	Loss: 0.103517
Train Epoch: 39 [5120/35339 (14%)]	Loss: 0.142893
Train Epoch: 39 [5760/35339 (16%)]	Loss: 0.258143
Train Epoch: 39 [6400/35339 (18%)]	Loss: 0.208798
Train Epoch: 39 [7040/35339 (20%)]	Loss: 0.064318
Train Epoch: 39 [7680/35339 (22%)]	Loss: 0.155122
Train Epoch: 39 [8320/35339 (24%)]	Loss: 0.111721
Train Epoch: 39 [8960/35339 (25%)]	Loss: 0.167856
Train Epoch: 39 [9600/35339 (27%)]	Loss: 0.080457
Train Epoch: 39 [10240/35339 (29%)]	Loss: 0.170230
Train Epoch: 39 [10880/35339 (31%)]	Loss: 0.162423
Train Epoch: 39 [11520/35339 (33%)]	Loss: 0.115608
Train Epoch: 39 [12160/35339 (34%)]	Loss: 0.072467
Train Epoch: 39 [12800/35339 (36%)]	Loss: 0.275149
Train Epoch: 39 [13440/35339 (38%)]	Loss: 0.101828
Train Epoch: 39 [14080/35339 (40%)]	Loss: 0.096714
Train Epoch: 39 [14720/35339 (42%)]	Loss: 0.105169
Train Epoch: 39 [15360/35339 (43%)]	Loss: 0.105371
Train Epoch: 39 [16000/35339 (45%)]	Loss: 0.096359
Train Epoch: 39 [16640/35339 (47%)]	Loss: 0.102611
Train Epoch: 39 [17280/35339 (49%)]	Loss: 0.144279
Train Epoch: 39 [17920/35339 (51%)]	Loss: 0.138060
Train Epoch: 39 [18560/35339 (52%)]	Loss: 0.123565
Train Epoch: 39 [19200/35339 (54%)]	Loss: 0.086408
Train Epoch: 39 [19840/35339 (56%)]	Loss: 0.107614
Train Epoch: 39 [20480/35339 (58%)]	Loss: 0.125722
Train Epoch: 39 [21120/35339 (60%)]	Loss: 0.130810
Train Epoch: 39 [21760/35339 (61%)]	Loss: 0.077605
Train Epoch: 39 [22400/35339 (63%)]	Loss: 0.182323
Train Epoch: 39 [23040/35339 (65%)]	Loss: 0.123808
Train Epoch: 39 [23680/35339 (67%)]	Loss: 0.133168
Train Epoch: 39 [24320/35339 (69%)]	Loss: 0.081924
Train Epoch: 39 [24960/35339 (71%)]	Loss: 0.073797
Train Epoch: 39 [25600/35339 (72%)]	Loss: 0.103912
Train Epoch: 39 [26240/35339 (74%)]	Loss: 0.115178
Train Epoch: 39 [26880/35339 (76%)]	Loss: 0.222986
Train Epoch: 39 [27520/35339 (78%)]	Loss: 0.137566
Train Epoch: 39 [28160/35339 (80%)]	Loss: 0.090797
Train Epoch: 39 [28800/35339 (81%)]	Loss: 0.138736
Train Epoch: 39 [29440/35339 (83%)]	Loss: 0.089958
Train Epoch: 39 [30080/35339 (85%)]	Loss: 0.119409
Train Epoch: 39 [30720/35339 (87%)]	Loss: 0.104953
Train Epoch: 39 [31360/35339 (89%)]	Loss: 0.115587
Train Epoch: 39 [32000/35339 (90%)]	Loss: 0.083989
Train Epoch: 39 [32640/35339 (92%)]	Loss: 0.091232
Train Epoch: 39 [33280/35339 (94%)]	Loss: 0.087410
Train Epoch: 39 [33920/35339 (96%)]	Loss: 0.109932
Train Epoch: 39 [34560/35339 (98%)]	Loss: 0.097830
Train Epoch: 39 [35200/35339 (99%)]	Loss: 0.069553

Validation set: Average loss: 3.1759, Accuracy: 1344/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 40 [0/35339 (0%)]	Loss: 0.112396
Train Epoch: 40 [640/35339 (2%)]	Loss: 0.174006
Train Epoch: 40 [1280/35339 (4%)]	Loss: 0.130122
Train Epoch: 40 [1920/35339 (5%)]	Loss: 0.275002
Train Epoch: 40 [2560/35339 (7%)]	Loss: 0.113306
Train Epoch: 40 [3200/35339 (9%)]	Loss: 0.075373
Train Epoch: 40 [3840/35339 (11%)]	Loss: 0.125547
Train Epoch: 40 [4480/35339 (13%)]	Loss: 0.274697
Train Epoch: 40 [5120/35339 (14%)]	Loss: 0.191286
Train Epoch: 40 [5760/35339 (16%)]	Loss: 0.119124
Train Epoch: 40 [6400/35339 (18%)]	Loss: 0.102784
Train Epoch: 40 [7040/35339 (20%)]	Loss: 0.242225
Train Epoch: 40 [7680/35339 (22%)]	Loss: 0.108375
Train Epoch: 40 [8320/35339 (24%)]	Loss: 0.096444
Train Epoch: 40 [8960/35339 (25%)]	Loss: 0.099368
Train Epoch: 40 [9600/35339 (27%)]	Loss: 0.148909
Train Epoch: 40 [10240/35339 (29%)]	Loss: 0.079604
Train Epoch: 40 [10880/35339 (31%)]	Loss: 0.112239
Train Epoch: 40 [11520/35339 (33%)]	Loss: 0.077097
Train Epoch: 40 [12160/35339 (34%)]	Loss: 0.085351
Train Epoch: 40 [12800/35339 (36%)]	Loss: 0.126331
Train Epoch: 40 [13440/35339 (38%)]	Loss: 0.065786
Train Epoch: 40 [14080/35339 (40%)]	Loss: 0.103326
Train Epoch: 40 [14720/35339 (42%)]	Loss: 0.126887
Train Epoch: 40 [15360/35339 (43%)]	Loss: 0.139919
Train Epoch: 40 [16000/35339 (45%)]	Loss: 0.233739
Train Epoch: 40 [16640/35339 (47%)]	Loss: 0.069765
Train Epoch: 40 [17280/35339 (49%)]	Loss: 0.103804
Train Epoch: 40 [17920/35339 (51%)]	Loss: 0.134936
Train Epoch: 40 [18560/35339 (52%)]	Loss: 0.073723
Train Epoch: 40 [19200/35339 (54%)]	Loss: 0.095607
Train Epoch: 40 [19840/35339 (56%)]	Loss: 0.085550
Train Epoch: 40 [20480/35339 (58%)]	Loss: 0.097254
Train Epoch: 40 [21120/35339 (60%)]	Loss: 0.128790
Train Epoch: 40 [21760/35339 (61%)]	Loss: 0.086684
Train Epoch: 40 [22400/35339 (63%)]	Loss: 0.262458
Train Epoch: 40 [23040/35339 (65%)]	Loss: 0.151355
Train Epoch: 40 [23680/35339 (67%)]	Loss: 0.102182
Train Epoch: 40 [24320/35339 (69%)]	Loss: 0.088469
Train Epoch: 40 [24960/35339 (71%)]	Loss: 0.192512
Train Epoch: 40 [25600/35339 (72%)]	Loss: 0.069425
Train Epoch: 40 [26240/35339 (74%)]	Loss: 0.112556
Train Epoch: 40 [26880/35339 (76%)]	Loss: 0.111511
Train Epoch: 40 [27520/35339 (78%)]	Loss: 0.057199
Train Epoch: 40 [28160/35339 (80%)]	Loss: 0.070102
Train Epoch: 40 [28800/35339 (81%)]	Loss: 0.138429
Train Epoch: 40 [29440/35339 (83%)]	Loss: 0.119240
Train Epoch: 40 [30080/35339 (85%)]	Loss: 0.068351
Train Epoch: 40 [30720/35339 (87%)]	Loss: 0.068668
Train Epoch: 40 [31360/35339 (89%)]	Loss: 0.072045
Train Epoch: 40 [32000/35339 (90%)]	Loss: 0.193962
Train Epoch: 40 [32640/35339 (92%)]	Loss: 0.092047
Train Epoch: 40 [33280/35339 (94%)]	Loss: 0.100274
Train Epoch: 40 [33920/35339 (96%)]	Loss: 0.106928
Train Epoch: 40 [34560/35339 (98%)]	Loss: 0.084063
Train Epoch: 40 [35200/35339 (99%)]	Loss: 0.084007

Validation set: Average loss: 3.2050, Accuracy: 1307/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 41 [0/35339 (0%)]	Loss: 0.082161
Train Epoch: 41 [640/35339 (2%)]	Loss: 0.182654
Train Epoch: 41 [1280/35339 (4%)]	Loss: 0.179437
Train Epoch: 41 [1920/35339 (5%)]	Loss: 0.069711
Train Epoch: 41 [2560/35339 (7%)]	Loss: 0.077941
Train Epoch: 41 [3200/35339 (9%)]	Loss: 0.074707
Train Epoch: 41 [3840/35339 (11%)]	Loss: 0.121442
Train Epoch: 41 [4480/35339 (13%)]	Loss: 0.098254
Train Epoch: 41 [5120/35339 (14%)]	Loss: 0.074869
Train Epoch: 41 [5760/35339 (16%)]	Loss: 0.119815
Train Epoch: 41 [6400/35339 (18%)]	Loss: 0.114774
Train Epoch: 41 [7040/35339 (20%)]	Loss: 0.085417
Train Epoch: 41 [7680/35339 (22%)]	Loss: 0.090644
Train Epoch: 41 [8320/35339 (24%)]	Loss: 0.097426
Train Epoch: 41 [8960/35339 (25%)]	Loss: 0.107185
Train Epoch: 41 [9600/35339 (27%)]	Loss: 0.097576
Train Epoch: 41 [10240/35339 (29%)]	Loss: 0.142876
Train Epoch: 41 [10880/35339 (31%)]	Loss: 0.162930
Train Epoch: 41 [11520/35339 (33%)]	Loss: 0.078476
Train Epoch: 41 [12160/35339 (34%)]	Loss: 0.126259
Train Epoch: 41 [12800/35339 (36%)]	Loss: 0.073545
Train Epoch: 41 [13440/35339 (38%)]	Loss: 0.090848
Train Epoch: 41 [14080/35339 (40%)]	Loss: 0.098069
Train Epoch: 41 [14720/35339 (42%)]	Loss: 0.083279
Train Epoch: 41 [15360/35339 (43%)]	Loss: 0.078322
Train Epoch: 41 [16000/35339 (45%)]	Loss: 0.082837
Train Epoch: 41 [16640/35339 (47%)]	Loss: 0.109358
Train Epoch: 41 [17280/35339 (49%)]	Loss: 0.129111
Train Epoch: 41 [17920/35339 (51%)]	Loss: 0.103632
Train Epoch: 41 [18560/35339 (52%)]	Loss: 0.129650
Train Epoch: 41 [19200/35339 (54%)]	Loss: 0.114133
Train Epoch: 41 [19840/35339 (56%)]	Loss: 0.131204
Train Epoch: 41 [20480/35339 (58%)]	Loss: 0.079108
Train Epoch: 41 [21120/35339 (60%)]	Loss: 0.101956
Train Epoch: 41 [21760/35339 (61%)]	Loss: 0.096535
Train Epoch: 41 [22400/35339 (63%)]	Loss: 0.116258
Train Epoch: 41 [23040/35339 (65%)]	Loss: 0.179992
Train Epoch: 41 [23680/35339 (67%)]	Loss: 0.279719
Train Epoch: 41 [24320/35339 (69%)]	Loss: 0.078104
Train Epoch: 41 [24960/35339 (71%)]	Loss: 0.183602
Train Epoch: 41 [25600/35339 (72%)]	Loss: 0.121168
Train Epoch: 41 [26240/35339 (74%)]	Loss: 0.089088
Train Epoch: 41 [26880/35339 (76%)]	Loss: 0.092608
Train Epoch: 41 [27520/35339 (78%)]	Loss: 0.135650
Train Epoch: 41 [28160/35339 (80%)]	Loss: 0.112383
Train Epoch: 41 [28800/35339 (81%)]	Loss: 0.114307
Train Epoch: 41 [29440/35339 (83%)]	Loss: 0.110516
Train Epoch: 41 [30080/35339 (85%)]	Loss: 0.170772
Train Epoch: 41 [30720/35339 (87%)]	Loss: 0.160206
Train Epoch: 41 [31360/35339 (89%)]	Loss: 0.152087
Train Epoch: 41 [32000/35339 (90%)]	Loss: 0.070841
Train Epoch: 41 [32640/35339 (92%)]	Loss: 0.184299
Train Epoch: 41 [33280/35339 (94%)]	Loss: 0.103754
Train Epoch: 41 [33920/35339 (96%)]	Loss: 0.164723
Train Epoch: 41 [34560/35339 (98%)]	Loss: 0.148570
Train Epoch: 41 [35200/35339 (99%)]	Loss: 0.162147

Validation set: Average loss: 3.2034, Accuracy: 1293/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 42 [0/35339 (0%)]	Loss: 0.104660
Train Epoch: 42 [640/35339 (2%)]	Loss: 0.072870
Train Epoch: 42 [1280/35339 (4%)]	Loss: 0.159524
Train Epoch: 42 [1920/35339 (5%)]	Loss: 0.117634
Train Epoch: 42 [2560/35339 (7%)]	Loss: 0.071355
Train Epoch: 42 [3200/35339 (9%)]	Loss: 0.075986
Train Epoch: 42 [3840/35339 (11%)]	Loss: 0.093566
Train Epoch: 42 [4480/35339 (13%)]	Loss: 0.126537
Train Epoch: 42 [5120/35339 (14%)]	Loss: 0.121782
Train Epoch: 42 [5760/35339 (16%)]	Loss: 0.086163
Train Epoch: 42 [6400/35339 (18%)]	Loss: 0.079232
Train Epoch: 42 [7040/35339 (20%)]	Loss: 0.127767
Train Epoch: 42 [7680/35339 (22%)]	Loss: 0.071811
Train Epoch: 42 [8320/35339 (24%)]	Loss: 0.090834
Train Epoch: 42 [8960/35339 (25%)]	Loss: 0.074721
Train Epoch: 42 [9600/35339 (27%)]	Loss: 0.127478
Train Epoch: 42 [10240/35339 (29%)]	Loss: 0.072149
Train Epoch: 42 [10880/35339 (31%)]	Loss: 0.075674
Train Epoch: 42 [11520/35339 (33%)]	Loss: 0.069602
Train Epoch: 42 [12160/35339 (34%)]	Loss: 0.069190
Train Epoch: 42 [12800/35339 (36%)]	Loss: 0.110271
Train Epoch: 42 [13440/35339 (38%)]	Loss: 0.237982
Train Epoch: 42 [14080/35339 (40%)]	Loss: 0.106872
Train Epoch: 42 [14720/35339 (42%)]	Loss: 0.147592
Train Epoch: 42 [15360/35339 (43%)]	Loss: 0.176319
Train Epoch: 42 [16000/35339 (45%)]	Loss: 0.152007
Train Epoch: 42 [16640/35339 (47%)]	Loss: 0.159479
Train Epoch: 42 [17280/35339 (49%)]	Loss: 0.172164
Train Epoch: 42 [17920/35339 (51%)]	Loss: 0.077564
Train Epoch: 42 [18560/35339 (52%)]	Loss: 0.137173
Train Epoch: 42 [19200/35339 (54%)]	Loss: 0.084978
Train Epoch: 42 [19840/35339 (56%)]	Loss: 0.112954
Train Epoch: 42 [20480/35339 (58%)]	Loss: 0.087031
Train Epoch: 42 [21120/35339 (60%)]	Loss: 0.159604
Train Epoch: 42 [21760/35339 (61%)]	Loss: 0.133615
Train Epoch: 42 [22400/35339 (63%)]	Loss: 0.091616
Train Epoch: 42 [23040/35339 (65%)]	Loss: 0.099919
Train Epoch: 42 [23680/35339 (67%)]	Loss: 0.068296
Train Epoch: 42 [24320/35339 (69%)]	Loss: 0.079963
Train Epoch: 42 [24960/35339 (71%)]	Loss: 0.167462
Train Epoch: 42 [25600/35339 (72%)]	Loss: 0.068449
Train Epoch: 42 [26240/35339 (74%)]	Loss: 0.091493
Train Epoch: 42 [26880/35339 (76%)]	Loss: 0.137950
Train Epoch: 42 [27520/35339 (78%)]	Loss: 0.113478
Train Epoch: 42 [28160/35339 (80%)]	Loss: 0.151850
Train Epoch: 42 [28800/35339 (81%)]	Loss: 0.105377
Train Epoch: 42 [29440/35339 (83%)]	Loss: 0.093658
Train Epoch: 42 [30080/35339 (85%)]	Loss: 0.220745
Train Epoch: 42 [30720/35339 (87%)]	Loss: 0.092760
Train Epoch: 42 [31360/35339 (89%)]	Loss: 0.103272
Train Epoch: 42 [32000/35339 (90%)]	Loss: 0.062961
Train Epoch: 42 [32640/35339 (92%)]	Loss: 0.118522
Train Epoch: 42 [33280/35339 (94%)]	Loss: 0.112422
Train Epoch: 42 [33920/35339 (96%)]	Loss: 0.075938
Train Epoch: 42 [34560/35339 (98%)]	Loss: 0.089063
Train Epoch: 42 [35200/35339 (99%)]	Loss: 0.136384

Validation set: Average loss: 3.0554, Accuracy: 1418/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 43 [0/35339 (0%)]	Loss: 0.418775
Train Epoch: 43 [640/35339 (2%)]	Loss: 0.069175
Train Epoch: 43 [1280/35339 (4%)]	Loss: 0.128722
Train Epoch: 43 [1920/35339 (5%)]	Loss: 0.180794
Train Epoch: 43 [2560/35339 (7%)]	Loss: 0.120043
Train Epoch: 43 [3200/35339 (9%)]	Loss: 0.069839
Train Epoch: 43 [3840/35339 (11%)]	Loss: 0.111889
Train Epoch: 43 [4480/35339 (13%)]	Loss: 0.129259
Train Epoch: 43 [5120/35339 (14%)]	Loss: 0.133575
Train Epoch: 43 [5760/35339 (16%)]	Loss: 0.111542
Train Epoch: 43 [6400/35339 (18%)]	Loss: 0.129569
Train Epoch: 43 [7040/35339 (20%)]	Loss: 0.097192
Train Epoch: 43 [7680/35339 (22%)]	Loss: 0.153348
Train Epoch: 43 [8320/35339 (24%)]	Loss: 0.061248
Train Epoch: 43 [8960/35339 (25%)]	Loss: 0.067037
Train Epoch: 43 [9600/35339 (27%)]	Loss: 0.084067
Train Epoch: 43 [10240/35339 (29%)]	Loss: 0.084905
Train Epoch: 43 [10880/35339 (31%)]	Loss: 0.148215
Train Epoch: 43 [11520/35339 (33%)]	Loss: 0.084417
Train Epoch: 43 [12160/35339 (34%)]	Loss: 0.116027
Train Epoch: 43 [12800/35339 (36%)]	Loss: 0.082386
Train Epoch: 43 [13440/35339 (38%)]	Loss: 0.160614
Train Epoch: 43 [14080/35339 (40%)]	Loss: 0.114601
Train Epoch: 43 [14720/35339 (42%)]	Loss: 0.086522
Train Epoch: 43 [15360/35339 (43%)]	Loss: 0.120782
Train Epoch: 43 [16000/35339 (45%)]	Loss: 0.187144
Train Epoch: 43 [16640/35339 (47%)]	Loss: 0.116512
Train Epoch: 43 [17280/35339 (49%)]	Loss: 0.182977
Train Epoch: 43 [17920/35339 (51%)]	Loss: 0.067873
Train Epoch: 43 [18560/35339 (52%)]	Loss: 0.146553
Train Epoch: 43 [19200/35339 (54%)]	Loss: 0.111750
Train Epoch: 43 [19840/35339 (56%)]	Loss: 0.124563
Train Epoch: 43 [20480/35339 (58%)]	Loss: 0.115260
Train Epoch: 43 [21120/35339 (60%)]	Loss: 0.105992
Train Epoch: 43 [21760/35339 (61%)]	Loss: 0.164733
Train Epoch: 43 [22400/35339 (63%)]	Loss: 0.152937
Train Epoch: 43 [23040/35339 (65%)]	Loss: 0.110980
Train Epoch: 43 [23680/35339 (67%)]	Loss: 0.080231
Train Epoch: 43 [24320/35339 (69%)]	Loss: 0.250784
Train Epoch: 43 [24960/35339 (71%)]	Loss: 0.151561
Train Epoch: 43 [25600/35339 (72%)]	Loss: 0.122932
Train Epoch: 43 [26240/35339 (74%)]	Loss: 0.076219
Train Epoch: 43 [26880/35339 (76%)]	Loss: 0.076705
Train Epoch: 43 [27520/35339 (78%)]	Loss: 0.071340
Train Epoch: 43 [28160/35339 (80%)]	Loss: 0.133404
Train Epoch: 43 [28800/35339 (81%)]	Loss: 0.108852
Train Epoch: 43 [29440/35339 (83%)]	Loss: 0.109540
Train Epoch: 43 [30080/35339 (85%)]	Loss: 0.201282
Train Epoch: 43 [30720/35339 (87%)]	Loss: 0.112451
Train Epoch: 43 [31360/35339 (89%)]	Loss: 0.141572
Train Epoch: 43 [32000/35339 (90%)]	Loss: 0.172820
Train Epoch: 43 [32640/35339 (92%)]	Loss: 0.098534
Train Epoch: 43 [33280/35339 (94%)]	Loss: 0.064287
Train Epoch: 43 [33920/35339 (96%)]	Loss: 0.071356
Train Epoch: 43 [34560/35339 (98%)]	Loss: 0.239381
Train Epoch: 43 [35200/35339 (99%)]	Loss: 0.087944

Validation set: Average loss: 3.1050, Accuracy: 1402/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 44 [0/35339 (0%)]	Loss: 0.100240
Train Epoch: 44 [640/35339 (2%)]	Loss: 0.127311
Train Epoch: 44 [1280/35339 (4%)]	Loss: 0.201405
Train Epoch: 44 [1920/35339 (5%)]	Loss: 0.087384
Train Epoch: 44 [2560/35339 (7%)]	Loss: 0.122369
Train Epoch: 44 [3200/35339 (9%)]	Loss: 0.132443
Train Epoch: 44 [3840/35339 (11%)]	Loss: 0.094534
Train Epoch: 44 [4480/35339 (13%)]	Loss: 0.144942
Train Epoch: 44 [5120/35339 (14%)]	Loss: 0.111136
Train Epoch: 44 [5760/35339 (16%)]	Loss: 0.080704
Train Epoch: 44 [6400/35339 (18%)]	Loss: 0.079914
Train Epoch: 44 [7040/35339 (20%)]	Loss: 0.084575
Train Epoch: 44 [7680/35339 (22%)]	Loss: 0.135017
Train Epoch: 44 [8320/35339 (24%)]	Loss: 0.062315
Train Epoch: 44 [8960/35339 (25%)]	Loss: 0.122772
Train Epoch: 44 [9600/35339 (27%)]	Loss: 0.132122
Train Epoch: 44 [10240/35339 (29%)]	Loss: 0.073955
Train Epoch: 44 [10880/35339 (31%)]	Loss: 0.124014
Train Epoch: 44 [11520/35339 (33%)]	Loss: 0.097943
Train Epoch: 44 [12160/35339 (34%)]	Loss: 0.171794
Train Epoch: 44 [12800/35339 (36%)]	Loss: 0.237220
Train Epoch: 44 [13440/35339 (38%)]	Loss: 0.143810
Train Epoch: 44 [14080/35339 (40%)]	Loss: 0.176007
Train Epoch: 44 [14720/35339 (42%)]	Loss: 0.095934
Train Epoch: 44 [15360/35339 (43%)]	Loss: 0.118039
Train Epoch: 44 [16000/35339 (45%)]	Loss: 0.104048
Train Epoch: 44 [16640/35339 (47%)]	Loss: 0.096371
Train Epoch: 44 [17280/35339 (49%)]	Loss: 0.202410
Train Epoch: 44 [17920/35339 (51%)]	Loss: 0.114674
Train Epoch: 44 [18560/35339 (52%)]	Loss: 0.083308
Train Epoch: 44 [19200/35339 (54%)]	Loss: 0.076956
Train Epoch: 44 [19840/35339 (56%)]	Loss: 0.121990
Train Epoch: 44 [20480/35339 (58%)]	Loss: 0.075781
Train Epoch: 44 [21120/35339 (60%)]	Loss: 0.096286
Train Epoch: 44 [21760/35339 (61%)]	Loss: 0.138009
Train Epoch: 44 [22400/35339 (63%)]	Loss: 0.125074
Train Epoch: 44 [23040/35339 (65%)]	Loss: 0.180817
Train Epoch: 44 [23680/35339 (67%)]	Loss: 0.219660
Train Epoch: 44 [24320/35339 (69%)]	Loss: 0.126753
Train Epoch: 44 [24960/35339 (71%)]	Loss: 0.128761
Train Epoch: 44 [25600/35339 (72%)]	Loss: 0.098691
Train Epoch: 44 [26240/35339 (74%)]	Loss: 0.073377
Train Epoch: 44 [26880/35339 (76%)]	Loss: 0.121519
Train Epoch: 44 [27520/35339 (78%)]	Loss: 0.072949
Train Epoch: 44 [28160/35339 (80%)]	Loss: 0.172163
Train Epoch: 44 [28800/35339 (81%)]	Loss: 0.109729
Train Epoch: 44 [29440/35339 (83%)]	Loss: 0.269167
Train Epoch: 44 [30080/35339 (85%)]	Loss: 0.143293
Train Epoch: 44 [30720/35339 (87%)]	Loss: 0.065761
Train Epoch: 44 [31360/35339 (89%)]	Loss: 0.105543
Train Epoch: 44 [32000/35339 (90%)]	Loss: 0.101197
Train Epoch: 44 [32640/35339 (92%)]	Loss: 0.078295
Train Epoch: 44 [33280/35339 (94%)]	Loss: 0.077917
Train Epoch: 44 [33920/35339 (96%)]	Loss: 0.111572
Train Epoch: 44 [34560/35339 (98%)]	Loss: 0.075690
Train Epoch: 44 [35200/35339 (99%)]	Loss: 0.084204

Validation set: Average loss: 3.2266, Accuracy: 1283/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 45 [0/35339 (0%)]	Loss: 0.075820
Train Epoch: 45 [640/35339 (2%)]	Loss: 0.078462
Train Epoch: 45 [1280/35339 (4%)]	Loss: 0.374886
Train Epoch: 45 [1920/35339 (5%)]	Loss: 0.108412
Train Epoch: 45 [2560/35339 (7%)]	Loss: 0.129456
Train Epoch: 45 [3200/35339 (9%)]	Loss: 0.066061
Train Epoch: 45 [3840/35339 (11%)]	Loss: 0.127899
Train Epoch: 45 [4480/35339 (13%)]	Loss: 0.100175
Train Epoch: 45 [5120/35339 (14%)]	Loss: 0.073100
Train Epoch: 45 [5760/35339 (16%)]	Loss: 0.081204
Train Epoch: 45 [6400/35339 (18%)]	Loss: 0.120151
Train Epoch: 45 [7040/35339 (20%)]	Loss: 0.231847
Train Epoch: 45 [7680/35339 (22%)]	Loss: 0.127043
Train Epoch: 45 [8320/35339 (24%)]	Loss: 0.122497
Train Epoch: 45 [8960/35339 (25%)]	Loss: 0.117143
Train Epoch: 45 [9600/35339 (27%)]	Loss: 0.081884
Train Epoch: 45 [10240/35339 (29%)]	Loss: 0.178472
Train Epoch: 45 [10880/35339 (31%)]	Loss: 0.072356
Train Epoch: 45 [11520/35339 (33%)]	Loss: 0.091601
Train Epoch: 45 [12160/35339 (34%)]	Loss: 0.075956
Train Epoch: 45 [12800/35339 (36%)]	Loss: 0.076363
Train Epoch: 45 [13440/35339 (38%)]	Loss: 0.057669
Train Epoch: 45 [14080/35339 (40%)]	Loss: 0.083997
Train Epoch: 45 [14720/35339 (42%)]	Loss: 0.097421
Train Epoch: 45 [15360/35339 (43%)]	Loss: 0.081766
Train Epoch: 45 [16000/35339 (45%)]	Loss: 0.073019
Train Epoch: 45 [16640/35339 (47%)]	Loss: 0.132106
Train Epoch: 45 [17280/35339 (49%)]	Loss: 0.079987
Train Epoch: 45 [17920/35339 (51%)]	Loss: 0.067284
Train Epoch: 45 [18560/35339 (52%)]	Loss: 0.101547
Train Epoch: 45 [19200/35339 (54%)]	Loss: 0.137282
Train Epoch: 45 [19840/35339 (56%)]	Loss: 0.107946
Train Epoch: 45 [20480/35339 (58%)]	Loss: 0.101709
Train Epoch: 45 [21120/35339 (60%)]	Loss: 0.128572
Train Epoch: 45 [21760/35339 (61%)]	Loss: 0.145708
Train Epoch: 45 [22400/35339 (63%)]	Loss: 0.092269
Train Epoch: 45 [23040/35339 (65%)]	Loss: 0.122089
Train Epoch: 45 [23680/35339 (67%)]	Loss: 0.063530
Train Epoch: 45 [24320/35339 (69%)]	Loss: 0.113656
Train Epoch: 45 [24960/35339 (71%)]	Loss: 0.077753
Train Epoch: 45 [25600/35339 (72%)]	Loss: 0.116485
Train Epoch: 45 [26240/35339 (74%)]	Loss: 0.089915
Train Epoch: 45 [26880/35339 (76%)]	Loss: 0.140738
Train Epoch: 45 [27520/35339 (78%)]	Loss: 0.143733
Train Epoch: 45 [28160/35339 (80%)]	Loss: 0.072967
Train Epoch: 45 [28800/35339 (81%)]	Loss: 0.134534
Train Epoch: 45 [29440/35339 (83%)]	Loss: 0.120019
Train Epoch: 45 [30080/35339 (85%)]	Loss: 0.142521
Train Epoch: 45 [30720/35339 (87%)]	Loss: 0.142067
Train Epoch: 45 [31360/35339 (89%)]	Loss: 0.105905
Train Epoch: 45 [32000/35339 (90%)]	Loss: 0.082531
Train Epoch: 45 [32640/35339 (92%)]	Loss: 0.113379
Train Epoch: 45 [33280/35339 (94%)]	Loss: 0.095358
Train Epoch: 45 [33920/35339 (96%)]	Loss: 0.076788
Train Epoch: 45 [34560/35339 (98%)]	Loss: 0.126403
Train Epoch: 45 [35200/35339 (99%)]	Loss: 0.064596

Validation set: Average loss: 3.1479, Accuracy: 1326/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 46 [0/35339 (0%)]	Loss: 0.126478
Train Epoch: 46 [640/35339 (2%)]	Loss: 0.122611
Train Epoch: 46 [1280/35339 (4%)]	Loss: 0.183417
Train Epoch: 46 [1920/35339 (5%)]	Loss: 0.097164
Train Epoch: 46 [2560/35339 (7%)]	Loss: 0.111972
Train Epoch: 46 [3200/35339 (9%)]	Loss: 0.273280
Train Epoch: 46 [3840/35339 (11%)]	Loss: 0.161499
Train Epoch: 46 [4480/35339 (13%)]	Loss: 0.131553
Train Epoch: 46 [5120/35339 (14%)]	Loss: 0.177814
Train Epoch: 46 [5760/35339 (16%)]	Loss: 0.075823
Train Epoch: 46 [6400/35339 (18%)]	Loss: 0.140575
Train Epoch: 46 [7040/35339 (20%)]	Loss: 0.125148
Train Epoch: 46 [7680/35339 (22%)]	Loss: 0.070869
Train Epoch: 46 [8320/35339 (24%)]	Loss: 0.092724
Train Epoch: 46 [8960/35339 (25%)]	Loss: 0.074414
Train Epoch: 46 [9600/35339 (27%)]	Loss: 0.065029
Train Epoch: 46 [10240/35339 (29%)]	Loss: 0.138804
Train Epoch: 46 [10880/35339 (31%)]	Loss: 0.108502
Train Epoch: 46 [11520/35339 (33%)]	Loss: 0.078239
Train Epoch: 46 [12160/35339 (34%)]	Loss: 0.084299
Train Epoch: 46 [12800/35339 (36%)]	Loss: 0.106242
Train Epoch: 46 [13440/35339 (38%)]	Loss: 0.082552
Train Epoch: 46 [14080/35339 (40%)]	Loss: 0.110653
Train Epoch: 46 [14720/35339 (42%)]	Loss: 0.123353
Train Epoch: 46 [15360/35339 (43%)]	Loss: 0.125142
Train Epoch: 46 [16000/35339 (45%)]	Loss: 0.087923
Train Epoch: 46 [16640/35339 (47%)]	Loss: 0.097843
Train Epoch: 46 [17280/35339 (49%)]	Loss: 0.121237
Train Epoch: 46 [17920/35339 (51%)]	Loss: 0.073677
Train Epoch: 46 [18560/35339 (52%)]	Loss: 0.310618
Train Epoch: 46 [19200/35339 (54%)]	Loss: 0.101768
Train Epoch: 46 [19840/35339 (56%)]	Loss: 0.089454
Train Epoch: 46 [20480/35339 (58%)]	Loss: 0.151678
Train Epoch: 46 [21120/35339 (60%)]	Loss: 0.080995
Train Epoch: 46 [21760/35339 (61%)]	Loss: 0.121019
Train Epoch: 46 [22400/35339 (63%)]	Loss: 0.111457
Train Epoch: 46 [23040/35339 (65%)]	Loss: 0.123940
Train Epoch: 46 [23680/35339 (67%)]	Loss: 0.111169
Train Epoch: 46 [24320/35339 (69%)]	Loss: 0.159247
Train Epoch: 46 [24960/35339 (71%)]	Loss: 0.088534
Train Epoch: 46 [25600/35339 (72%)]	Loss: 0.121647
Train Epoch: 46 [26240/35339 (74%)]	Loss: 0.130286
Train Epoch: 46 [26880/35339 (76%)]	Loss: 0.122298
Train Epoch: 46 [27520/35339 (78%)]	Loss: 0.138295
Train Epoch: 46 [28160/35339 (80%)]	Loss: 0.069024
Train Epoch: 46 [28800/35339 (81%)]	Loss: 0.220646
Train Epoch: 46 [29440/35339 (83%)]	Loss: 0.070051
Train Epoch: 46 [30080/35339 (85%)]	Loss: 0.086740
Train Epoch: 46 [30720/35339 (87%)]	Loss: 0.076215
Train Epoch: 46 [31360/35339 (89%)]	Loss: 0.134970
Train Epoch: 46 [32000/35339 (90%)]	Loss: 0.105252
Train Epoch: 46 [32640/35339 (92%)]	Loss: 0.117677
Train Epoch: 46 [33280/35339 (94%)]	Loss: 0.372241
Train Epoch: 46 [33920/35339 (96%)]	Loss: 0.091085
Train Epoch: 46 [34560/35339 (98%)]	Loss: 0.109639
Train Epoch: 46 [35200/35339 (99%)]	Loss: 0.125924

Validation set: Average loss: 3.0027, Accuracy: 1506/3870 (39%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 47 [0/35339 (0%)]	Loss: 0.147291
Train Epoch: 47 [640/35339 (2%)]	Loss: 0.117318
Train Epoch: 47 [1280/35339 (4%)]	Loss: 0.126885
Train Epoch: 47 [1920/35339 (5%)]	Loss: 0.069530
Train Epoch: 47 [2560/35339 (7%)]	Loss: 0.087576
Train Epoch: 47 [3200/35339 (9%)]	Loss: 0.151295
Train Epoch: 47 [3840/35339 (11%)]	Loss: 0.094886
Train Epoch: 47 [4480/35339 (13%)]	Loss: 0.123299
Train Epoch: 47 [5120/35339 (14%)]	Loss: 0.127354
Train Epoch: 47 [5760/35339 (16%)]	Loss: 0.155996
Train Epoch: 47 [6400/35339 (18%)]	Loss: 0.133673
Train Epoch: 47 [7040/35339 (20%)]	Loss: 0.062870
Train Epoch: 47 [7680/35339 (22%)]	Loss: 0.095011
Train Epoch: 47 [8320/35339 (24%)]	Loss: 0.099268
Train Epoch: 47 [8960/35339 (25%)]	Loss: 0.177943
Train Epoch: 47 [9600/35339 (27%)]	Loss: 0.088006
Train Epoch: 47 [10240/35339 (29%)]	Loss: 0.080434
Train Epoch: 47 [10880/35339 (31%)]	Loss: 0.120194
Train Epoch: 47 [11520/35339 (33%)]	Loss: 0.312034
Train Epoch: 47 [12160/35339 (34%)]	Loss: 0.071199
Train Epoch: 47 [12800/35339 (36%)]	Loss: 0.075418
Train Epoch: 47 [13440/35339 (38%)]	Loss: 0.134989
Train Epoch: 47 [14080/35339 (40%)]	Loss: 0.177228
Train Epoch: 47 [14720/35339 (42%)]	Loss: 0.100409
Train Epoch: 47 [15360/35339 (43%)]	Loss: 0.152534
Train Epoch: 47 [16000/35339 (45%)]	Loss: 0.135923
Train Epoch: 47 [16640/35339 (47%)]	Loss: 0.268240
Train Epoch: 47 [17280/35339 (49%)]	Loss: 0.075690
Train Epoch: 47 [17920/35339 (51%)]	Loss: 0.155999
Train Epoch: 47 [18560/35339 (52%)]	Loss: 0.194126
Train Epoch: 47 [19200/35339 (54%)]	Loss: 0.138503
Train Epoch: 47 [19840/35339 (56%)]	Loss: 0.068254
Train Epoch: 47 [20480/35339 (58%)]	Loss: 0.098189
Train Epoch: 47 [21120/35339 (60%)]	Loss: 0.142652
Train Epoch: 47 [21760/35339 (61%)]	Loss: 0.143435
Train Epoch: 47 [22400/35339 (63%)]	Loss: 0.166284
Train Epoch: 47 [23040/35339 (65%)]	Loss: 0.090992
Train Epoch: 47 [23680/35339 (67%)]	Loss: 0.116754
Train Epoch: 47 [24320/35339 (69%)]	Loss: 0.241284
Train Epoch: 47 [24960/35339 (71%)]	Loss: 0.104266
Train Epoch: 47 [25600/35339 (72%)]	Loss: 0.114670
Train Epoch: 47 [26240/35339 (74%)]	Loss: 0.108055
Train Epoch: 47 [26880/35339 (76%)]	Loss: 0.113540
Train Epoch: 47 [27520/35339 (78%)]	Loss: 0.079805
Train Epoch: 47 [28160/35339 (80%)]	Loss: 0.156473
Train Epoch: 47 [28800/35339 (81%)]	Loss: 0.118243
Train Epoch: 47 [29440/35339 (83%)]	Loss: 0.166158
Train Epoch: 47 [30080/35339 (85%)]	Loss: 0.079611
Train Epoch: 47 [30720/35339 (87%)]	Loss: 0.128070
Train Epoch: 47 [31360/35339 (89%)]	Loss: 0.102887
Train Epoch: 47 [32000/35339 (90%)]	Loss: 0.085230
Train Epoch: 47 [32640/35339 (92%)]	Loss: 0.093117
Train Epoch: 47 [33280/35339 (94%)]	Loss: 0.226791
Train Epoch: 47 [33920/35339 (96%)]	Loss: 0.161445
Train Epoch: 47 [34560/35339 (98%)]	Loss: 0.115775
Train Epoch: 47 [35200/35339 (99%)]	Loss: 0.123056

Validation set: Average loss: 3.0035, Accuracy: 1452/3870 (38%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 48 [0/35339 (0%)]	Loss: 0.164009
Train Epoch: 48 [640/35339 (2%)]	Loss: 0.131480
Train Epoch: 48 [1280/35339 (4%)]	Loss: 0.085944
Train Epoch: 48 [1920/35339 (5%)]	Loss: 0.137518
Train Epoch: 48 [2560/35339 (7%)]	Loss: 0.134643
Train Epoch: 48 [3200/35339 (9%)]	Loss: 0.105006
Train Epoch: 48 [3840/35339 (11%)]	Loss: 0.184929
Train Epoch: 48 [4480/35339 (13%)]	Loss: 0.120483
Train Epoch: 48 [5120/35339 (14%)]	Loss: 0.101085
Train Epoch: 48 [5760/35339 (16%)]	Loss: 0.105658
Train Epoch: 48 [6400/35339 (18%)]	Loss: 0.088149
Train Epoch: 48 [7040/35339 (20%)]	Loss: 0.095485
Train Epoch: 48 [7680/35339 (22%)]	Loss: 0.110094
Train Epoch: 48 [8320/35339 (24%)]	Loss: 0.106812
Train Epoch: 48 [8960/35339 (25%)]	Loss: 0.112495
Train Epoch: 48 [9600/35339 (27%)]	Loss: 0.064470
Train Epoch: 48 [10240/35339 (29%)]	Loss: 0.073288
Train Epoch: 48 [10880/35339 (31%)]	Loss: 0.135237
Train Epoch: 48 [11520/35339 (33%)]	Loss: 0.091894
Train Epoch: 48 [12160/35339 (34%)]	Loss: 0.092229
Train Epoch: 48 [12800/35339 (36%)]	Loss: 0.109981
Train Epoch: 48 [13440/35339 (38%)]	Loss: 0.095495
Train Epoch: 48 [14080/35339 (40%)]	Loss: 0.195825
Train Epoch: 48 [14720/35339 (42%)]	Loss: 0.115986
Train Epoch: 48 [15360/35339 (43%)]	Loss: 0.143458
Train Epoch: 48 [16000/35339 (45%)]	Loss: 0.203003
Train Epoch: 48 [16640/35339 (47%)]	Loss: 0.097253
Train Epoch: 48 [17280/35339 (49%)]	Loss: 0.119998
Train Epoch: 48 [17920/35339 (51%)]	Loss: 0.129511
Train Epoch: 48 [18560/35339 (52%)]	Loss: 0.107334
Train Epoch: 48 [19200/35339 (54%)]	Loss: 0.109598
Train Epoch: 48 [19840/35339 (56%)]	Loss: 0.100690
Train Epoch: 48 [20480/35339 (58%)]	Loss: 0.094071
Train Epoch: 48 [21120/35339 (60%)]	Loss: 0.093449
Train Epoch: 48 [21760/35339 (61%)]	Loss: 0.068897
Train Epoch: 48 [22400/35339 (63%)]	Loss: 0.074502
Train Epoch: 48 [23040/35339 (65%)]	Loss: 0.098824
Train Epoch: 48 [23680/35339 (67%)]	Loss: 0.095252
Train Epoch: 48 [24320/35339 (69%)]	Loss: 0.089817
Train Epoch: 48 [24960/35339 (71%)]	Loss: 0.122169
Train Epoch: 48 [25600/35339 (72%)]	Loss: 0.068197
Train Epoch: 48 [26240/35339 (74%)]	Loss: 0.078785
Train Epoch: 48 [26880/35339 (76%)]	Loss: 0.083357
Train Epoch: 48 [27520/35339 (78%)]	Loss: 0.086814
Train Epoch: 48 [28160/35339 (80%)]	Loss: 0.182714
Train Epoch: 48 [28800/35339 (81%)]	Loss: 0.087768
Train Epoch: 48 [29440/35339 (83%)]	Loss: 0.122666
Train Epoch: 48 [30080/35339 (85%)]	Loss: 0.113308
Train Epoch: 48 [30720/35339 (87%)]	Loss: 0.068734
Train Epoch: 48 [31360/35339 (89%)]	Loss: 0.079059
Train Epoch: 48 [32000/35339 (90%)]	Loss: 0.078497
Train Epoch: 48 [32640/35339 (92%)]	Loss: 0.119457
Train Epoch: 48 [33280/35339 (94%)]	Loss: 0.155022
Train Epoch: 48 [33920/35339 (96%)]	Loss: 0.116018
Train Epoch: 48 [34560/35339 (98%)]	Loss: 0.121200
Train Epoch: 48 [35200/35339 (99%)]	Loss: 0.117419

Validation set: Average loss: 3.1385, Accuracy: 1378/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 49 [0/35339 (0%)]	Loss: 0.065717
Train Epoch: 49 [640/35339 (2%)]	Loss: 0.102331
Train Epoch: 49 [1280/35339 (4%)]	Loss: 0.096884
Train Epoch: 49 [1920/35339 (5%)]	Loss: 0.080146
Train Epoch: 49 [2560/35339 (7%)]	Loss: 0.108681
Train Epoch: 49 [3200/35339 (9%)]	Loss: 0.104345
Train Epoch: 49 [3840/35339 (11%)]	Loss: 0.125514
Train Epoch: 49 [4480/35339 (13%)]	Loss: 0.098267
Train Epoch: 49 [5120/35339 (14%)]	Loss: 0.084814
Train Epoch: 49 [5760/35339 (16%)]	Loss: 0.118990
Train Epoch: 49 [6400/35339 (18%)]	Loss: 0.131472
Train Epoch: 49 [7040/35339 (20%)]	Loss: 0.094021
Train Epoch: 49 [7680/35339 (22%)]	Loss: 0.091369
Train Epoch: 49 [8320/35339 (24%)]	Loss: 0.124833
Train Epoch: 49 [8960/35339 (25%)]	Loss: 0.110470
Train Epoch: 49 [9600/35339 (27%)]	Loss: 0.102743
Train Epoch: 49 [10240/35339 (29%)]	Loss: 0.121760
Train Epoch: 49 [10880/35339 (31%)]	Loss: 0.099197
Train Epoch: 49 [11520/35339 (33%)]	Loss: 0.055778
Train Epoch: 49 [12160/35339 (34%)]	Loss: 0.107304
Train Epoch: 49 [12800/35339 (36%)]	Loss: 0.110858
Train Epoch: 49 [13440/35339 (38%)]	Loss: 0.154770
Train Epoch: 49 [14080/35339 (40%)]	Loss: 0.171277
Train Epoch: 49 [14720/35339 (42%)]	Loss: 0.202331
Train Epoch: 49 [15360/35339 (43%)]	Loss: 0.070877
Train Epoch: 49 [16000/35339 (45%)]	Loss: 0.086773
Train Epoch: 49 [16640/35339 (47%)]	Loss: 0.208459
Train Epoch: 49 [17280/35339 (49%)]	Loss: 0.066008
Train Epoch: 49 [17920/35339 (51%)]	Loss: 0.140226
Train Epoch: 49 [18560/35339 (52%)]	Loss: 0.068772
Train Epoch: 49 [19200/35339 (54%)]	Loss: 0.121673
Train Epoch: 49 [19840/35339 (56%)]	Loss: 0.068584
Train Epoch: 49 [20480/35339 (58%)]	Loss: 0.117319
Train Epoch: 49 [21120/35339 (60%)]	Loss: 0.119994
Train Epoch: 49 [21760/35339 (61%)]	Loss: 0.082912
Train Epoch: 49 [22400/35339 (63%)]	Loss: 0.056642
Train Epoch: 49 [23040/35339 (65%)]	Loss: 0.096372
Train Epoch: 49 [23680/35339 (67%)]	Loss: 0.079649
Train Epoch: 49 [24320/35339 (69%)]	Loss: 0.076382
Train Epoch: 49 [24960/35339 (71%)]	Loss: 0.147077
Train Epoch: 49 [25600/35339 (72%)]	Loss: 0.136988
Train Epoch: 49 [26240/35339 (74%)]	Loss: 0.112674
Train Epoch: 49 [26880/35339 (76%)]	Loss: 0.080329
Train Epoch: 49 [27520/35339 (78%)]	Loss: 0.060737
Train Epoch: 49 [28160/35339 (80%)]	Loss: 0.125785
Train Epoch: 49 [28800/35339 (81%)]	Loss: 0.109808
Train Epoch: 49 [29440/35339 (83%)]	Loss: 0.114838
Train Epoch: 49 [30080/35339 (85%)]	Loss: 0.074389
Train Epoch: 49 [30720/35339 (87%)]	Loss: 0.115790
Train Epoch: 49 [31360/35339 (89%)]	Loss: 0.083308
Train Epoch: 49 [32000/35339 (90%)]	Loss: 0.060548
Train Epoch: 49 [32640/35339 (92%)]	Loss: 0.099902
Train Epoch: 49 [33280/35339 (94%)]	Loss: 0.082742
Train Epoch: 49 [33920/35339 (96%)]	Loss: 0.068485
Train Epoch: 49 [34560/35339 (98%)]	Loss: 0.147310
Train Epoch: 49 [35200/35339 (99%)]	Loss: 0.082471

Validation set: Average loss: 3.1926, Accuracy: 1281/3870 (33%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 50 [0/35339 (0%)]	Loss: 0.097378
Train Epoch: 50 [640/35339 (2%)]	Loss: 0.098120
Train Epoch: 50 [1280/35339 (4%)]	Loss: 0.210965
Train Epoch: 50 [1920/35339 (5%)]	Loss: 0.117419
Train Epoch: 50 [2560/35339 (7%)]	Loss: 0.133437
Train Epoch: 50 [3200/35339 (9%)]	Loss: 0.189176
Train Epoch: 50 [3840/35339 (11%)]	Loss: 0.071373
Train Epoch: 50 [4480/35339 (13%)]	Loss: 0.087654
Train Epoch: 50 [5120/35339 (14%)]	Loss: 0.087871
Train Epoch: 50 [5760/35339 (16%)]	Loss: 0.089731
Train Epoch: 50 [6400/35339 (18%)]	Loss: 0.065216
Train Epoch: 50 [7040/35339 (20%)]	Loss: 0.064019
Train Epoch: 50 [7680/35339 (22%)]	Loss: 0.071686
Train Epoch: 50 [8320/35339 (24%)]	Loss: 0.079110
Train Epoch: 50 [8960/35339 (25%)]	Loss: 0.111061
Train Epoch: 50 [9600/35339 (27%)]	Loss: 0.073989
Train Epoch: 50 [10240/35339 (29%)]	Loss: 0.129954
Train Epoch: 50 [10880/35339 (31%)]	Loss: 0.067419
Train Epoch: 50 [11520/35339 (33%)]	Loss: 0.105799
Train Epoch: 50 [12160/35339 (34%)]	Loss: 0.100681
Train Epoch: 50 [12800/35339 (36%)]	Loss: 0.063968
Train Epoch: 50 [13440/35339 (38%)]	Loss: 0.115599
Train Epoch: 50 [14080/35339 (40%)]	Loss: 0.107056
Train Epoch: 50 [14720/35339 (42%)]	Loss: 0.159678
Train Epoch: 50 [15360/35339 (43%)]	Loss: 0.125429
Train Epoch: 50 [16000/35339 (45%)]	Loss: 0.117130
Train Epoch: 50 [16640/35339 (47%)]	Loss: 0.068140
Train Epoch: 50 [17280/35339 (49%)]	Loss: 0.093771
Train Epoch: 50 [17920/35339 (51%)]	Loss: 0.081983
Train Epoch: 50 [18560/35339 (52%)]	Loss: 0.097786
Train Epoch: 50 [19200/35339 (54%)]	Loss: 0.097422
Train Epoch: 50 [19840/35339 (56%)]	Loss: 0.104378
Train Epoch: 50 [20480/35339 (58%)]	Loss: 0.088896
Train Epoch: 50 [21120/35339 (60%)]	Loss: 0.200273
Train Epoch: 50 [21760/35339 (61%)]	Loss: 0.114595
Train Epoch: 50 [22400/35339 (63%)]	Loss: 0.113361
Train Epoch: 50 [23040/35339 (65%)]	Loss: 0.108048
Train Epoch: 50 [23680/35339 (67%)]	Loss: 0.113863
Train Epoch: 50 [24320/35339 (69%)]	Loss: 0.099364
Train Epoch: 50 [24960/35339 (71%)]	Loss: 0.127255
Train Epoch: 50 [25600/35339 (72%)]	Loss: 0.066409
Train Epoch: 50 [26240/35339 (74%)]	Loss: 0.076744
Train Epoch: 50 [26880/35339 (76%)]	Loss: 0.074064
Train Epoch: 50 [27520/35339 (78%)]	Loss: 0.120673
Train Epoch: 50 [28160/35339 (80%)]	Loss: 0.064046
Train Epoch: 50 [28800/35339 (81%)]	Loss: 0.092607
Train Epoch: 50 [29440/35339 (83%)]	Loss: 0.134212
Train Epoch: 50 [30080/35339 (85%)]	Loss: 0.093958
Train Epoch: 50 [30720/35339 (87%)]	Loss: 0.107651
Train Epoch: 50 [31360/35339 (89%)]	Loss: 0.148299
Train Epoch: 50 [32000/35339 (90%)]	Loss: 0.122538
Train Epoch: 50 [32640/35339 (92%)]	Loss: 0.112566
Train Epoch: 50 [33280/35339 (94%)]	Loss: 0.061534
Train Epoch: 50 [33920/35339 (96%)]	Loss: 0.066364
Train Epoch: 50 [34560/35339 (98%)]	Loss: 0.100333
Train Epoch: 50 [35200/35339 (99%)]	Loss: 0.078177

Validation set: Average loss: 3.1116, Accuracy: 1379/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 51 [0/35339 (0%)]	Loss: 0.088703
Train Epoch: 51 [640/35339 (2%)]	Loss: 0.092581
Train Epoch: 51 [1280/35339 (4%)]	Loss: 0.129490
Train Epoch: 51 [1920/35339 (5%)]	Loss: 0.108859
Train Epoch: 51 [2560/35339 (7%)]	Loss: 0.075019
Train Epoch: 51 [3200/35339 (9%)]	Loss: 0.134203
Train Epoch: 51 [3840/35339 (11%)]	Loss: 0.116430
Train Epoch: 51 [4480/35339 (13%)]	Loss: 0.076337
Train Epoch: 51 [5120/35339 (14%)]	Loss: 0.159199
Train Epoch: 51 [5760/35339 (16%)]	Loss: 0.071847
Train Epoch: 51 [6400/35339 (18%)]	Loss: 0.106081
Train Epoch: 51 [7040/35339 (20%)]	Loss: 0.065608
Train Epoch: 51 [7680/35339 (22%)]	Loss: 0.107932
Train Epoch: 51 [8320/35339 (24%)]	Loss: 0.087263
Train Epoch: 51 [8960/35339 (25%)]	Loss: 0.091402
Train Epoch: 51 [9600/35339 (27%)]	Loss: 0.100460
Train Epoch: 51 [10240/35339 (29%)]	Loss: 0.134067
Train Epoch: 51 [10880/35339 (31%)]	Loss: 0.085199
Train Epoch: 51 [11520/35339 (33%)]	Loss: 0.118436
Train Epoch: 51 [12160/35339 (34%)]	Loss: 0.073484
Train Epoch: 51 [12800/35339 (36%)]	Loss: 0.066454
Train Epoch: 51 [13440/35339 (38%)]	Loss: 0.077136
Train Epoch: 51 [14080/35339 (40%)]	Loss: 0.099167
Train Epoch: 51 [14720/35339 (42%)]	Loss: 0.065245
Train Epoch: 51 [15360/35339 (43%)]	Loss: 0.121955
Train Epoch: 51 [16000/35339 (45%)]	Loss: 0.123722
Train Epoch: 51 [16640/35339 (47%)]	Loss: 0.113749
Train Epoch: 51 [17280/35339 (49%)]	Loss: 0.108065
Train Epoch: 51 [17920/35339 (51%)]	Loss: 0.143914
Train Epoch: 51 [18560/35339 (52%)]	Loss: 0.089208
Train Epoch: 51 [19200/35339 (54%)]	Loss: 0.066023
Train Epoch: 51 [19840/35339 (56%)]	Loss: 0.089255
Train Epoch: 51 [20480/35339 (58%)]	Loss: 0.071870
Train Epoch: 51 [21120/35339 (60%)]	Loss: 0.122302
Train Epoch: 51 [21760/35339 (61%)]	Loss: 0.090391
Train Epoch: 51 [22400/35339 (63%)]	Loss: 0.111780
Train Epoch: 51 [23040/35339 (65%)]	Loss: 0.134394
Train Epoch: 51 [23680/35339 (67%)]	Loss: 0.096220
Train Epoch: 51 [24320/35339 (69%)]	Loss: 0.115945
Train Epoch: 51 [24960/35339 (71%)]	Loss: 0.124346
Train Epoch: 51 [25600/35339 (72%)]	Loss: 0.083634
Train Epoch: 51 [26240/35339 (74%)]	Loss: 0.068518
Train Epoch: 51 [26880/35339 (76%)]	Loss: 0.078458
Train Epoch: 51 [27520/35339 (78%)]	Loss: 0.092279
Train Epoch: 51 [28160/35339 (80%)]	Loss: 0.113303
Train Epoch: 51 [28800/35339 (81%)]	Loss: 0.130468
Train Epoch: 51 [29440/35339 (83%)]	Loss: 0.078622
Train Epoch: 51 [30080/35339 (85%)]	Loss: 0.085114
Train Epoch: 51 [30720/35339 (87%)]	Loss: 0.080414
Train Epoch: 51 [31360/35339 (89%)]	Loss: 0.111789
Train Epoch: 51 [32000/35339 (90%)]	Loss: 0.106458
Train Epoch: 51 [32640/35339 (92%)]	Loss: 0.084620
Train Epoch: 51 [33280/35339 (94%)]	Loss: 0.077415
Train Epoch: 51 [33920/35339 (96%)]	Loss: 0.068423
Train Epoch: 51 [34560/35339 (98%)]	Loss: 0.099634
Train Epoch: 51 [35200/35339 (99%)]	Loss: 0.081615

Validation set: Average loss: 3.1466, Accuracy: 1340/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 52 [0/35339 (0%)]	Loss: 0.088190
Train Epoch: 52 [640/35339 (2%)]	Loss: 0.100917
Train Epoch: 52 [1280/35339 (4%)]	Loss: 0.077607
Train Epoch: 52 [1920/35339 (5%)]	Loss: 0.104491
Train Epoch: 52 [2560/35339 (7%)]	Loss: 0.075335
Train Epoch: 52 [3200/35339 (9%)]	Loss: 0.093320
Train Epoch: 52 [3840/35339 (11%)]	Loss: 0.071383
Train Epoch: 52 [4480/35339 (13%)]	Loss: 0.100486
Train Epoch: 52 [5120/35339 (14%)]	Loss: 0.098046
Train Epoch: 52 [5760/35339 (16%)]	Loss: 0.069196
Train Epoch: 52 [6400/35339 (18%)]	Loss: 0.069058
Train Epoch: 52 [7040/35339 (20%)]	Loss: 0.137635
Train Epoch: 52 [7680/35339 (22%)]	Loss: 0.065620
Train Epoch: 52 [8320/35339 (24%)]	Loss: 0.119772
Train Epoch: 52 [8960/35339 (25%)]	Loss: 0.075803
Train Epoch: 52 [9600/35339 (27%)]	Loss: 0.128288
Train Epoch: 52 [10240/35339 (29%)]	Loss: 0.129191
Train Epoch: 52 [10880/35339 (31%)]	Loss: 0.124426
Train Epoch: 52 [11520/35339 (33%)]	Loss: 0.070909
Train Epoch: 52 [12160/35339 (34%)]	Loss: 0.069046
Train Epoch: 52 [12800/35339 (36%)]	Loss: 0.089426
Train Epoch: 52 [13440/35339 (38%)]	Loss: 0.071700
Train Epoch: 52 [14080/35339 (40%)]	Loss: 0.090320
Train Epoch: 52 [14720/35339 (42%)]	Loss: 0.163855
Train Epoch: 52 [15360/35339 (43%)]	Loss: 0.113464
Train Epoch: 52 [16000/35339 (45%)]	Loss: 0.141136
Train Epoch: 52 [16640/35339 (47%)]	Loss: 0.088619
Train Epoch: 52 [17280/35339 (49%)]	Loss: 0.076297
Train Epoch: 52 [17920/35339 (51%)]	Loss: 0.089132
Train Epoch: 52 [18560/35339 (52%)]	Loss: 0.105537
Train Epoch: 52 [19200/35339 (54%)]	Loss: 0.107326
Train Epoch: 52 [19840/35339 (56%)]	Loss: 0.121828
Train Epoch: 52 [20480/35339 (58%)]	Loss: 0.090020
Train Epoch: 52 [21120/35339 (60%)]	Loss: 0.088313
Train Epoch: 52 [21760/35339 (61%)]	Loss: 0.072612
Train Epoch: 52 [22400/35339 (63%)]	Loss: 0.087756
Train Epoch: 52 [23040/35339 (65%)]	Loss: 0.074234
Train Epoch: 52 [23680/35339 (67%)]	Loss: 0.131986
Train Epoch: 52 [24320/35339 (69%)]	Loss: 0.092909
Train Epoch: 52 [24960/35339 (71%)]	Loss: 0.109830
Train Epoch: 52 [25600/35339 (72%)]	Loss: 0.096626
Train Epoch: 52 [26240/35339 (74%)]	Loss: 0.075443
Train Epoch: 52 [26880/35339 (76%)]	Loss: 0.069513
Train Epoch: 52 [27520/35339 (78%)]	Loss: 0.094190
Train Epoch: 52 [28160/35339 (80%)]	Loss: 0.090989
Train Epoch: 52 [28800/35339 (81%)]	Loss: 0.128184
Train Epoch: 52 [29440/35339 (83%)]	Loss: 0.101737
Train Epoch: 52 [30080/35339 (85%)]	Loss: 0.090643
Train Epoch: 52 [30720/35339 (87%)]	Loss: 0.122691
Train Epoch: 52 [31360/35339 (89%)]	Loss: 0.065477
Train Epoch: 52 [32000/35339 (90%)]	Loss: 0.069852
Train Epoch: 52 [32640/35339 (92%)]	Loss: 0.157813
Train Epoch: 52 [33280/35339 (94%)]	Loss: 0.101825
Train Epoch: 52 [33920/35339 (96%)]	Loss: 0.073048
Train Epoch: 52 [34560/35339 (98%)]	Loss: 0.077466
Train Epoch: 52 [35200/35339 (99%)]	Loss: 0.157028

Validation set: Average loss: 3.1440, Accuracy: 1395/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 53 [0/35339 (0%)]	Loss: 0.107220
Train Epoch: 53 [640/35339 (2%)]	Loss: 0.105459
Train Epoch: 53 [1280/35339 (4%)]	Loss: 0.063052
Train Epoch: 53 [1920/35339 (5%)]	Loss: 0.072610
Train Epoch: 53 [2560/35339 (7%)]	Loss: 0.083770
Train Epoch: 53 [3200/35339 (9%)]	Loss: 0.191661
Train Epoch: 53 [3840/35339 (11%)]	Loss: 0.127075
Train Epoch: 53 [4480/35339 (13%)]	Loss: 0.116107
Train Epoch: 53 [5120/35339 (14%)]	Loss: 0.097417
Train Epoch: 53 [5760/35339 (16%)]	Loss: 0.077322
Train Epoch: 53 [6400/35339 (18%)]	Loss: 0.193807
Train Epoch: 53 [7040/35339 (20%)]	Loss: 0.094946
Train Epoch: 53 [7680/35339 (22%)]	Loss: 0.066417
Train Epoch: 53 [8320/35339 (24%)]	Loss: 0.097597
Train Epoch: 53 [8960/35339 (25%)]	Loss: 0.078368
Train Epoch: 53 [9600/35339 (27%)]	Loss: 0.071954
Train Epoch: 53 [10240/35339 (29%)]	Loss: 0.099557
Train Epoch: 53 [10880/35339 (31%)]	Loss: 0.073603
Train Epoch: 53 [11520/35339 (33%)]	Loss: 0.065370
Train Epoch: 53 [12160/35339 (34%)]	Loss: 0.063968
Train Epoch: 53 [12800/35339 (36%)]	Loss: 0.148928
Train Epoch: 53 [13440/35339 (38%)]	Loss: 0.215622
Train Epoch: 53 [14080/35339 (40%)]	Loss: 0.104087
Train Epoch: 53 [14720/35339 (42%)]	Loss: 0.062714
Train Epoch: 53 [15360/35339 (43%)]	Loss: 0.076630
Train Epoch: 53 [16000/35339 (45%)]	Loss: 0.288818
Train Epoch: 53 [16640/35339 (47%)]	Loss: 0.083703
Train Epoch: 53 [17280/35339 (49%)]	Loss: 0.117292
Train Epoch: 53 [17920/35339 (51%)]	Loss: 0.067640
Train Epoch: 53 [18560/35339 (52%)]	Loss: 0.116154
Train Epoch: 53 [19200/35339 (54%)]	Loss: 0.131635
Train Epoch: 53 [19840/35339 (56%)]	Loss: 0.120628
Train Epoch: 53 [20480/35339 (58%)]	Loss: 0.310849
Train Epoch: 53 [21120/35339 (60%)]	Loss: 0.080820
Train Epoch: 53 [21760/35339 (61%)]	Loss: 0.078734
Train Epoch: 53 [22400/35339 (63%)]	Loss: 0.123406
Train Epoch: 53 [23040/35339 (65%)]	Loss: 0.064190
Train Epoch: 53 [23680/35339 (67%)]	Loss: 0.074205
Train Epoch: 53 [24320/35339 (69%)]	Loss: 0.112189
Train Epoch: 53 [24960/35339 (71%)]	Loss: 0.201486
Train Epoch: 53 [25600/35339 (72%)]	Loss: 0.076229
Train Epoch: 53 [26240/35339 (74%)]	Loss: 0.095558
Train Epoch: 53 [26880/35339 (76%)]	Loss: 0.138381
Train Epoch: 53 [27520/35339 (78%)]	Loss: 0.160353
Train Epoch: 53 [28160/35339 (80%)]	Loss: 0.063976
Train Epoch: 53 [28800/35339 (81%)]	Loss: 0.135262
Train Epoch: 53 [29440/35339 (83%)]	Loss: 0.065199
Train Epoch: 53 [30080/35339 (85%)]	Loss: 0.166310
Train Epoch: 53 [30720/35339 (87%)]	Loss: 0.107743
Train Epoch: 53 [31360/35339 (89%)]	Loss: 0.080031
Train Epoch: 53 [32000/35339 (90%)]	Loss: 0.093868
Train Epoch: 53 [32640/35339 (92%)]	Loss: 0.093642
Train Epoch: 53 [33280/35339 (94%)]	Loss: 0.062874
Train Epoch: 53 [33920/35339 (96%)]	Loss: 0.072421
Train Epoch: 53 [34560/35339 (98%)]	Loss: 0.103647
Train Epoch: 53 [35200/35339 (99%)]	Loss: 0.125396

Validation set: Average loss: 3.1219, Accuracy: 1376/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 54 [0/35339 (0%)]	Loss: 0.066847
Train Epoch: 54 [640/35339 (2%)]	Loss: 0.078518
Train Epoch: 54 [1280/35339 (4%)]	Loss: 0.103599
Train Epoch: 54 [1920/35339 (5%)]	Loss: 0.094935
Train Epoch: 54 [2560/35339 (7%)]	Loss: 0.082317
Train Epoch: 54 [3200/35339 (9%)]	Loss: 0.109864
Train Epoch: 54 [3840/35339 (11%)]	Loss: 0.058075
Train Epoch: 54 [4480/35339 (13%)]	Loss: 0.061603
Train Epoch: 54 [5120/35339 (14%)]	Loss: 0.078905
Train Epoch: 54 [5760/35339 (16%)]	Loss: 0.061108
Train Epoch: 54 [6400/35339 (18%)]	Loss: 0.116339
Train Epoch: 54 [7040/35339 (20%)]	Loss: 0.059822
Train Epoch: 54 [7680/35339 (22%)]	Loss: 0.129929
Train Epoch: 54 [8320/35339 (24%)]	Loss: 0.105755
Train Epoch: 54 [8960/35339 (25%)]	Loss: 0.195527
Train Epoch: 54 [9600/35339 (27%)]	Loss: 0.065954
Train Epoch: 54 [10240/35339 (29%)]	Loss: 0.089287
Train Epoch: 54 [10880/35339 (31%)]	Loss: 0.166311
Train Epoch: 54 [11520/35339 (33%)]	Loss: 0.124603
Train Epoch: 54 [12160/35339 (34%)]	Loss: 0.159245
Train Epoch: 54 [12800/35339 (36%)]	Loss: 0.116163
Train Epoch: 54 [13440/35339 (38%)]	Loss: 0.119111
Train Epoch: 54 [14080/35339 (40%)]	Loss: 0.114852
Train Epoch: 54 [14720/35339 (42%)]	Loss: 0.171958
Train Epoch: 54 [15360/35339 (43%)]	Loss: 0.116324
Train Epoch: 54 [16000/35339 (45%)]	Loss: 0.121086
Train Epoch: 54 [16640/35339 (47%)]	Loss: 0.112959
Train Epoch: 54 [17280/35339 (49%)]	Loss: 0.086284
Train Epoch: 54 [17920/35339 (51%)]	Loss: 0.181800
Train Epoch: 54 [18560/35339 (52%)]	Loss: 0.153451
Train Epoch: 54 [19200/35339 (54%)]	Loss: 0.112788
Train Epoch: 54 [19840/35339 (56%)]	Loss: 0.099051
Train Epoch: 54 [20480/35339 (58%)]	Loss: 0.081054
Train Epoch: 54 [21120/35339 (60%)]	Loss: 0.087098
Train Epoch: 54 [21760/35339 (61%)]	Loss: 0.067784
Train Epoch: 54 [22400/35339 (63%)]	Loss: 0.256066
Train Epoch: 54 [23040/35339 (65%)]	Loss: 0.104388
Train Epoch: 54 [23680/35339 (67%)]	Loss: 0.083822
Train Epoch: 54 [24320/35339 (69%)]	Loss: 0.129962
Train Epoch: 54 [24960/35339 (71%)]	Loss: 0.132978
Train Epoch: 54 [25600/35339 (72%)]	Loss: 0.247176
Train Epoch: 54 [26240/35339 (74%)]	Loss: 0.064806
Train Epoch: 54 [26880/35339 (76%)]	Loss: 0.252228
Train Epoch: 54 [27520/35339 (78%)]	Loss: 0.126771
Train Epoch: 54 [28160/35339 (80%)]	Loss: 0.084079
Train Epoch: 54 [28800/35339 (81%)]	Loss: 0.102429
Train Epoch: 54 [29440/35339 (83%)]	Loss: 0.061453
Train Epoch: 54 [30080/35339 (85%)]	Loss: 0.122594
Train Epoch: 54 [30720/35339 (87%)]	Loss: 0.073606
Train Epoch: 54 [31360/35339 (89%)]	Loss: 0.093812
Train Epoch: 54 [32000/35339 (90%)]	Loss: 0.156640
Train Epoch: 54 [32640/35339 (92%)]	Loss: 0.105475
Train Epoch: 54 [33280/35339 (94%)]	Loss: 0.084407
Train Epoch: 54 [33920/35339 (96%)]	Loss: 0.090477
Train Epoch: 54 [34560/35339 (98%)]	Loss: 0.065034
Train Epoch: 54 [35200/35339 (99%)]	Loss: 0.156085

Validation set: Average loss: 3.2180, Accuracy: 1365/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 55 [0/35339 (0%)]	Loss: 0.080126
Train Epoch: 55 [640/35339 (2%)]	Loss: 0.132706
Train Epoch: 55 [1280/35339 (4%)]	Loss: 0.074701
Train Epoch: 55 [1920/35339 (5%)]	Loss: 0.070205
Train Epoch: 55 [2560/35339 (7%)]	Loss: 0.120514
Train Epoch: 55 [3200/35339 (9%)]	Loss: 0.110415
Train Epoch: 55 [3840/35339 (11%)]	Loss: 0.140302
Train Epoch: 55 [4480/35339 (13%)]	Loss: 0.073840
Train Epoch: 55 [5120/35339 (14%)]	Loss: 0.094454
Train Epoch: 55 [5760/35339 (16%)]	Loss: 0.125965
Train Epoch: 55 [6400/35339 (18%)]	Loss: 0.139029
Train Epoch: 55 [7040/35339 (20%)]	Loss: 0.235752
Train Epoch: 55 [7680/35339 (22%)]	Loss: 0.120892
Train Epoch: 55 [8320/35339 (24%)]	Loss: 0.099590
Train Epoch: 55 [8960/35339 (25%)]	Loss: 0.163125
Train Epoch: 55 [9600/35339 (27%)]	Loss: 0.177215
Train Epoch: 55 [10240/35339 (29%)]	Loss: 0.126170
Train Epoch: 55 [10880/35339 (31%)]	Loss: 0.105639
Train Epoch: 55 [11520/35339 (33%)]	Loss: 0.076941
Train Epoch: 55 [12160/35339 (34%)]	Loss: 0.100078
Train Epoch: 55 [12800/35339 (36%)]	Loss: 0.223944
Train Epoch: 55 [13440/35339 (38%)]	Loss: 0.066294
Train Epoch: 55 [14080/35339 (40%)]	Loss: 0.065554
Train Epoch: 55 [14720/35339 (42%)]	Loss: 0.338830
Train Epoch: 55 [15360/35339 (43%)]	Loss: 0.062090
Train Epoch: 55 [16000/35339 (45%)]	Loss: 0.070334
Train Epoch: 55 [16640/35339 (47%)]	Loss: 0.096721
Train Epoch: 55 [17280/35339 (49%)]	Loss: 0.106566
Train Epoch: 55 [17920/35339 (51%)]	Loss: 0.080265
Train Epoch: 55 [18560/35339 (52%)]	Loss: 0.076470
Train Epoch: 55 [19200/35339 (54%)]	Loss: 0.138287
Train Epoch: 55 [19840/35339 (56%)]	Loss: 0.122058
Train Epoch: 55 [20480/35339 (58%)]	Loss: 0.103248
Train Epoch: 55 [21120/35339 (60%)]	Loss: 0.065229
Train Epoch: 55 [21760/35339 (61%)]	Loss: 0.074335
Train Epoch: 55 [22400/35339 (63%)]	Loss: 0.074059
Train Epoch: 55 [23040/35339 (65%)]	Loss: 0.079624
Train Epoch: 55 [23680/35339 (67%)]	Loss: 0.072574
Train Epoch: 55 [24320/35339 (69%)]	Loss: 0.198827
Train Epoch: 55 [24960/35339 (71%)]	Loss: 0.063909
Train Epoch: 55 [25600/35339 (72%)]	Loss: 0.155193
Train Epoch: 55 [26240/35339 (74%)]	Loss: 0.093086
Train Epoch: 55 [26880/35339 (76%)]	Loss: 0.118958
Train Epoch: 55 [27520/35339 (78%)]	Loss: 0.138384
Train Epoch: 55 [28160/35339 (80%)]	Loss: 0.107949
Train Epoch: 55 [28800/35339 (81%)]	Loss: 0.099909
Train Epoch: 55 [29440/35339 (83%)]	Loss: 0.207814
Train Epoch: 55 [30080/35339 (85%)]	Loss: 0.066130
Train Epoch: 55 [30720/35339 (87%)]	Loss: 0.179187
Train Epoch: 55 [31360/35339 (89%)]	Loss: 0.061642
Train Epoch: 55 [32000/35339 (90%)]	Loss: 0.125957
Train Epoch: 55 [32640/35339 (92%)]	Loss: 0.108115
Train Epoch: 55 [33280/35339 (94%)]	Loss: 0.065721
Train Epoch: 55 [33920/35339 (96%)]	Loss: 0.086244
Train Epoch: 55 [34560/35339 (98%)]	Loss: 0.092759
Train Epoch: 55 [35200/35339 (99%)]	Loss: 0.082274

Validation set: Average loss: 3.1814, Accuracy: 1356/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 56 [0/35339 (0%)]	Loss: 0.073129
Train Epoch: 56 [640/35339 (2%)]	Loss: 0.084411
Train Epoch: 56 [1280/35339 (4%)]	Loss: 0.290881
Train Epoch: 56 [1920/35339 (5%)]	Loss: 0.068755
Train Epoch: 56 [2560/35339 (7%)]	Loss: 0.155755
Train Epoch: 56 [3200/35339 (9%)]	Loss: 0.107093
Train Epoch: 56 [3840/35339 (11%)]	Loss: 0.077156
Train Epoch: 56 [4480/35339 (13%)]	Loss: 0.072725
Train Epoch: 56 [5120/35339 (14%)]	Loss: 0.130291
Train Epoch: 56 [5760/35339 (16%)]	Loss: 0.075645
Train Epoch: 56 [6400/35339 (18%)]	Loss: 0.089911
Train Epoch: 56 [7040/35339 (20%)]	Loss: 0.073800
Train Epoch: 56 [7680/35339 (22%)]	Loss: 0.087106
Train Epoch: 56 [8320/35339 (24%)]	Loss: 0.246143
Train Epoch: 56 [8960/35339 (25%)]	Loss: 0.113124
Train Epoch: 56 [9600/35339 (27%)]	Loss: 0.102029
Train Epoch: 56 [10240/35339 (29%)]	Loss: 0.063635
Train Epoch: 56 [10880/35339 (31%)]	Loss: 0.064591
Train Epoch: 56 [11520/35339 (33%)]	Loss: 0.126157
Train Epoch: 56 [12160/35339 (34%)]	Loss: 0.101373
Train Epoch: 56 [12800/35339 (36%)]	Loss: 0.095777
Train Epoch: 56 [13440/35339 (38%)]	Loss: 0.077227
Train Epoch: 56 [14080/35339 (40%)]	Loss: 0.089750
Train Epoch: 56 [14720/35339 (42%)]	Loss: 0.069111
Train Epoch: 56 [15360/35339 (43%)]	Loss: 0.417664
Train Epoch: 56 [16000/35339 (45%)]	Loss: 0.114422
Train Epoch: 56 [16640/35339 (47%)]	Loss: 0.086821
Train Epoch: 56 [17280/35339 (49%)]	Loss: 0.064697
Train Epoch: 56 [17920/35339 (51%)]	Loss: 0.056973
Train Epoch: 56 [18560/35339 (52%)]	Loss: 0.076282
Train Epoch: 56 [19200/35339 (54%)]	Loss: 0.113953
Train Epoch: 56 [19840/35339 (56%)]	Loss: 0.124876
Train Epoch: 56 [20480/35339 (58%)]	Loss: 0.095334
Train Epoch: 56 [21120/35339 (60%)]	Loss: 0.063057
Train Epoch: 56 [21760/35339 (61%)]	Loss: 0.065092
Train Epoch: 56 [22400/35339 (63%)]	Loss: 0.069273
Train Epoch: 56 [23040/35339 (65%)]	Loss: 0.087736
Train Epoch: 56 [23680/35339 (67%)]	Loss: 0.108851
Train Epoch: 56 [24320/35339 (69%)]	Loss: 0.110340
Train Epoch: 56 [24960/35339 (71%)]	Loss: 0.088252
Train Epoch: 56 [25600/35339 (72%)]	Loss: 0.118475
Train Epoch: 56 [26240/35339 (74%)]	Loss: 0.069856
Train Epoch: 56 [26880/35339 (76%)]	Loss: 0.108417
Train Epoch: 56 [27520/35339 (78%)]	Loss: 0.134957
Train Epoch: 56 [28160/35339 (80%)]	Loss: 0.084241
Train Epoch: 56 [28800/35339 (81%)]	Loss: 0.084021
Train Epoch: 56 [29440/35339 (83%)]	Loss: 0.128407
Train Epoch: 56 [30080/35339 (85%)]	Loss: 0.083397
Train Epoch: 56 [30720/35339 (87%)]	Loss: 0.084237
Train Epoch: 56 [31360/35339 (89%)]	Loss: 0.323269
Train Epoch: 56 [32000/35339 (90%)]	Loss: 0.133750
Train Epoch: 56 [32640/35339 (92%)]	Loss: 0.417561
Train Epoch: 56 [33280/35339 (94%)]	Loss: 0.148770
Train Epoch: 56 [33920/35339 (96%)]	Loss: 0.158956
Train Epoch: 56 [34560/35339 (98%)]	Loss: 0.115318
Train Epoch: 56 [35200/35339 (99%)]	Loss: 0.115738

Validation set: Average loss: 3.1212, Accuracy: 1395/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 57 [0/35339 (0%)]	Loss: 0.151746
Train Epoch: 57 [640/35339 (2%)]	Loss: 0.118436
Train Epoch: 57 [1280/35339 (4%)]	Loss: 0.122353
Train Epoch: 57 [1920/35339 (5%)]	Loss: 0.149812
Train Epoch: 57 [2560/35339 (7%)]	Loss: 0.153025
Train Epoch: 57 [3200/35339 (9%)]	Loss: 0.131423
Train Epoch: 57 [3840/35339 (11%)]	Loss: 0.082121
Train Epoch: 57 [4480/35339 (13%)]	Loss: 0.102926
Train Epoch: 57 [5120/35339 (14%)]	Loss: 0.058980
Train Epoch: 57 [5760/35339 (16%)]	Loss: 0.119852
Train Epoch: 57 [6400/35339 (18%)]	Loss: 0.069721
Train Epoch: 57 [7040/35339 (20%)]	Loss: 0.100127
Train Epoch: 57 [7680/35339 (22%)]	Loss: 0.077359
Train Epoch: 57 [8320/35339 (24%)]	Loss: 0.099559
Train Epoch: 57 [8960/35339 (25%)]	Loss: 0.068907
Train Epoch: 57 [9600/35339 (27%)]	Loss: 0.071276
Train Epoch: 57 [10240/35339 (29%)]	Loss: 0.126941
Train Epoch: 57 [10880/35339 (31%)]	Loss: 0.132013
Train Epoch: 57 [11520/35339 (33%)]	Loss: 0.176537
Train Epoch: 57 [12160/35339 (34%)]	Loss: 0.239671
Train Epoch: 57 [12800/35339 (36%)]	Loss: 0.086715
Train Epoch: 57 [13440/35339 (38%)]	Loss: 0.060507
Train Epoch: 57 [14080/35339 (40%)]	Loss: 0.066634
Train Epoch: 57 [14720/35339 (42%)]	Loss: 0.061797
Train Epoch: 57 [15360/35339 (43%)]	Loss: 0.105498
Train Epoch: 57 [16000/35339 (45%)]	Loss: 0.079194
Train Epoch: 57 [16640/35339 (47%)]	Loss: 0.112146
Train Epoch: 57 [17280/35339 (49%)]	Loss: 0.085230
Train Epoch: 57 [17920/35339 (51%)]	Loss: 0.061526
Train Epoch: 57 [18560/35339 (52%)]	Loss: 0.114116
Train Epoch: 57 [19200/35339 (54%)]	Loss: 0.104778
Train Epoch: 57 [19840/35339 (56%)]	Loss: 0.064719
Train Epoch: 57 [20480/35339 (58%)]	Loss: 0.129511
Train Epoch: 57 [21120/35339 (60%)]	Loss: 0.062205
Train Epoch: 57 [21760/35339 (61%)]	Loss: 0.059605
Train Epoch: 57 [22400/35339 (63%)]	Loss: 0.146882
Train Epoch: 57 [23040/35339 (65%)]	Loss: 0.094604
Train Epoch: 57 [23680/35339 (67%)]	Loss: 0.061536
Train Epoch: 57 [24320/35339 (69%)]	Loss: 0.140260
Train Epoch: 57 [24960/35339 (71%)]	Loss: 0.102538
Train Epoch: 57 [25600/35339 (72%)]	Loss: 0.079141
Train Epoch: 57 [26240/35339 (74%)]	Loss: 0.072677
Train Epoch: 57 [26880/35339 (76%)]	Loss: 0.095116
Train Epoch: 57 [27520/35339 (78%)]	Loss: 0.086744
Train Epoch: 57 [28160/35339 (80%)]	Loss: 0.237064
Train Epoch: 57 [28800/35339 (81%)]	Loss: 0.081984
Train Epoch: 57 [29440/35339 (83%)]	Loss: 0.090034
Train Epoch: 57 [30080/35339 (85%)]	Loss: 0.066538
Train Epoch: 57 [30720/35339 (87%)]	Loss: 0.118220
Train Epoch: 57 [31360/35339 (89%)]	Loss: 0.114103
Train Epoch: 57 [32000/35339 (90%)]	Loss: 0.143957
Train Epoch: 57 [32640/35339 (92%)]	Loss: 0.114921
Train Epoch: 57 [33280/35339 (94%)]	Loss: 0.072057
Train Epoch: 57 [33920/35339 (96%)]	Loss: 0.094301
Train Epoch: 57 [34560/35339 (98%)]	Loss: 0.085731
Train Epoch: 57 [35200/35339 (99%)]	Loss: 0.073938

Validation set: Average loss: 3.1799, Accuracy: 1337/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 58 [0/35339 (0%)]	Loss: 0.070707
Train Epoch: 58 [640/35339 (2%)]	Loss: 0.120667
Train Epoch: 58 [1280/35339 (4%)]	Loss: 0.084036
Train Epoch: 58 [1920/35339 (5%)]	Loss: 0.099625
Train Epoch: 58 [2560/35339 (7%)]	Loss: 0.058408
Train Epoch: 58 [3200/35339 (9%)]	Loss: 0.126866
Train Epoch: 58 [3840/35339 (11%)]	Loss: 0.060288
Train Epoch: 58 [4480/35339 (13%)]	Loss: 0.060117
Train Epoch: 58 [5120/35339 (14%)]	Loss: 0.121769
Train Epoch: 58 [5760/35339 (16%)]	Loss: 0.063279
Train Epoch: 58 [6400/35339 (18%)]	Loss: 0.153193
Train Epoch: 58 [7040/35339 (20%)]	Loss: 0.061146
Train Epoch: 58 [7680/35339 (22%)]	Loss: 0.068030
Train Epoch: 58 [8320/35339 (24%)]	Loss: 0.133979
Train Epoch: 58 [8960/35339 (25%)]	Loss: 0.139882
Train Epoch: 58 [9600/35339 (27%)]	Loss: 0.087869
Train Epoch: 58 [10240/35339 (29%)]	Loss: 0.124815
Train Epoch: 58 [10880/35339 (31%)]	Loss: 0.077866
Train Epoch: 58 [11520/35339 (33%)]	Loss: 0.118522
Train Epoch: 58 [12160/35339 (34%)]	Loss: 0.067138
Train Epoch: 58 [12800/35339 (36%)]	Loss: 0.128559
Train Epoch: 58 [13440/35339 (38%)]	Loss: 0.069925
Train Epoch: 58 [14080/35339 (40%)]	Loss: 0.063004
Train Epoch: 58 [14720/35339 (42%)]	Loss: 0.119927
Train Epoch: 58 [15360/35339 (43%)]	Loss: 0.072849
Train Epoch: 58 [16000/35339 (45%)]	Loss: 0.063172
Train Epoch: 58 [16640/35339 (47%)]	Loss: 0.077297
Train Epoch: 58 [17280/35339 (49%)]	Loss: 0.097058
Train Epoch: 58 [17920/35339 (51%)]	Loss: 0.106039
Train Epoch: 58 [18560/35339 (52%)]	Loss: 0.095226
Train Epoch: 58 [19200/35339 (54%)]	Loss: 0.096520
Train Epoch: 58 [19840/35339 (56%)]	Loss: 0.157448
Train Epoch: 58 [20480/35339 (58%)]	Loss: 0.103135
Train Epoch: 58 [21120/35339 (60%)]	Loss: 0.110117
Train Epoch: 58 [21760/35339 (61%)]	Loss: 0.061238
Train Epoch: 58 [22400/35339 (63%)]	Loss: 0.113573
Train Epoch: 58 [23040/35339 (65%)]	Loss: 0.067703
Train Epoch: 58 [23680/35339 (67%)]	Loss: 0.077647
Train Epoch: 58 [24320/35339 (69%)]	Loss: 0.123692
Train Epoch: 58 [24960/35339 (71%)]	Loss: 0.084730
Train Epoch: 58 [25600/35339 (72%)]	Loss: 0.122131
Train Epoch: 58 [26240/35339 (74%)]	Loss: 0.084114
Train Epoch: 58 [26880/35339 (76%)]	Loss: 0.160467
Train Epoch: 58 [27520/35339 (78%)]	Loss: 0.122940
Train Epoch: 58 [28160/35339 (80%)]	Loss: 0.063695
Train Epoch: 58 [28800/35339 (81%)]	Loss: 0.062264
Train Epoch: 58 [29440/35339 (83%)]	Loss: 0.220825
Train Epoch: 58 [30080/35339 (85%)]	Loss: 0.121889
Train Epoch: 58 [30720/35339 (87%)]	Loss: 0.103832
Train Epoch: 58 [31360/35339 (89%)]	Loss: 0.065669
Train Epoch: 58 [32000/35339 (90%)]	Loss: 0.067553
Train Epoch: 58 [32640/35339 (92%)]	Loss: 0.065490
Train Epoch: 58 [33280/35339 (94%)]	Loss: 0.125738
Train Epoch: 58 [33920/35339 (96%)]	Loss: 0.086522
Train Epoch: 58 [34560/35339 (98%)]	Loss: 0.071531
Train Epoch: 58 [35200/35339 (99%)]	Loss: 0.090933

Validation set: Average loss: 3.2242, Accuracy: 1388/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 59 [0/35339 (0%)]	Loss: 0.104327
Train Epoch: 59 [640/35339 (2%)]	Loss: 0.061939
Train Epoch: 59 [1280/35339 (4%)]	Loss: 0.179929
Train Epoch: 59 [1920/35339 (5%)]	Loss: 0.076976
Train Epoch: 59 [2560/35339 (7%)]	Loss: 0.109803
Train Epoch: 59 [3200/35339 (9%)]	Loss: 0.067971
Train Epoch: 59 [3840/35339 (11%)]	Loss: 0.062604
Train Epoch: 59 [4480/35339 (13%)]	Loss: 0.064053
Train Epoch: 59 [5120/35339 (14%)]	Loss: 0.102623
Train Epoch: 59 [5760/35339 (16%)]	Loss: 0.092507
Train Epoch: 59 [6400/35339 (18%)]	Loss: 0.126395
Train Epoch: 59 [7040/35339 (20%)]	Loss: 0.133129
Train Epoch: 59 [7680/35339 (22%)]	Loss: 0.067141
Train Epoch: 59 [8320/35339 (24%)]	Loss: 0.142521
Train Epoch: 59 [8960/35339 (25%)]	Loss: 0.135257
Train Epoch: 59 [9600/35339 (27%)]	Loss: 0.097974
Train Epoch: 59 [10240/35339 (29%)]	Loss: 0.119187
Train Epoch: 59 [10880/35339 (31%)]	Loss: 0.191424
Train Epoch: 59 [11520/35339 (33%)]	Loss: 0.087084
Train Epoch: 59 [12160/35339 (34%)]	Loss: 0.113909
Train Epoch: 59 [12800/35339 (36%)]	Loss: 0.097590
Train Epoch: 59 [13440/35339 (38%)]	Loss: 0.068869
Train Epoch: 59 [14080/35339 (40%)]	Loss: 0.105765
Train Epoch: 59 [14720/35339 (42%)]	Loss: 0.100492
Train Epoch: 59 [15360/35339 (43%)]	Loss: 0.084745
Train Epoch: 59 [16000/35339 (45%)]	Loss: 0.099951
Train Epoch: 59 [16640/35339 (47%)]	Loss: 0.073529
Train Epoch: 59 [17280/35339 (49%)]	Loss: 0.089798
Train Epoch: 59 [17920/35339 (51%)]	Loss: 0.110642
Train Epoch: 59 [18560/35339 (52%)]	Loss: 0.073853
Train Epoch: 59 [19200/35339 (54%)]	Loss: 0.114076
Train Epoch: 59 [19840/35339 (56%)]	Loss: 0.108674
Train Epoch: 59 [20480/35339 (58%)]	Loss: 0.072702
Train Epoch: 59 [21120/35339 (60%)]	Loss: 0.062962
Train Epoch: 59 [21760/35339 (61%)]	Loss: 0.097570
Train Epoch: 59 [22400/35339 (63%)]	Loss: 0.066596
Train Epoch: 59 [23040/35339 (65%)]	Loss: 0.156883
Train Epoch: 59 [23680/35339 (67%)]	Loss: 0.092147
Train Epoch: 59 [24320/35339 (69%)]	Loss: 0.091167
Train Epoch: 59 [24960/35339 (71%)]	Loss: 0.107167
Train Epoch: 59 [25600/35339 (72%)]	Loss: 0.065991
Train Epoch: 59 [26240/35339 (74%)]	Loss: 0.128377
Train Epoch: 59 [26880/35339 (76%)]	Loss: 0.096903
Train Epoch: 59 [27520/35339 (78%)]	Loss: 0.072411
Train Epoch: 59 [28160/35339 (80%)]	Loss: 0.101145
Train Epoch: 59 [28800/35339 (81%)]	Loss: 0.264211
Train Epoch: 59 [29440/35339 (83%)]	Loss: 0.306156
Train Epoch: 59 [30080/35339 (85%)]	Loss: 0.099095
Train Epoch: 59 [30720/35339 (87%)]	Loss: 0.389887
Train Epoch: 59 [31360/35339 (89%)]	Loss: 0.069858
Train Epoch: 59 [32000/35339 (90%)]	Loss: 0.076829
Train Epoch: 59 [32640/35339 (92%)]	Loss: 0.075167
Train Epoch: 59 [33280/35339 (94%)]	Loss: 0.095972
Train Epoch: 59 [33920/35339 (96%)]	Loss: 0.082865
Train Epoch: 59 [34560/35339 (98%)]	Loss: 0.158774
Train Epoch: 59 [35200/35339 (99%)]	Loss: 0.191190

Validation set: Average loss: 3.1473, Accuracy: 1386/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 60 [0/35339 (0%)]	Loss: 0.253928
Train Epoch: 60 [640/35339 (2%)]	Loss: 0.059824
Train Epoch: 60 [1280/35339 (4%)]	Loss: 0.104332
Train Epoch: 60 [1920/35339 (5%)]	Loss: 0.064544
Train Epoch: 60 [2560/35339 (7%)]	Loss: 0.116818
Train Epoch: 60 [3200/35339 (9%)]	Loss: 0.085795
Train Epoch: 60 [3840/35339 (11%)]	Loss: 0.070850
Train Epoch: 60 [4480/35339 (13%)]	Loss: 0.257179
Train Epoch: 60 [5120/35339 (14%)]	Loss: 0.098878
Train Epoch: 60 [5760/35339 (16%)]	Loss: 0.079591
Train Epoch: 60 [6400/35339 (18%)]	Loss: 0.114083
Train Epoch: 60 [7040/35339 (20%)]	Loss: 0.094988
Train Epoch: 60 [7680/35339 (22%)]	Loss: 0.063504
Train Epoch: 60 [8320/35339 (24%)]	Loss: 0.084968
Train Epoch: 60 [8960/35339 (25%)]	Loss: 0.109254
Train Epoch: 60 [9600/35339 (27%)]	Loss: 0.094739
Train Epoch: 60 [10240/35339 (29%)]	Loss: 0.083353
Train Epoch: 60 [10880/35339 (31%)]	Loss: 0.071793
Train Epoch: 60 [11520/35339 (33%)]	Loss: 0.251618
Train Epoch: 60 [12160/35339 (34%)]	Loss: 0.077596
Train Epoch: 60 [12800/35339 (36%)]	Loss: 0.093645
Train Epoch: 60 [13440/35339 (38%)]	Loss: 0.065447
Train Epoch: 60 [14080/35339 (40%)]	Loss: 0.087483
Train Epoch: 60 [14720/35339 (42%)]	Loss: 0.069095
Train Epoch: 60 [15360/35339 (43%)]	Loss: 0.080190
Train Epoch: 60 [16000/35339 (45%)]	Loss: 0.089542
Train Epoch: 60 [16640/35339 (47%)]	Loss: 0.081381
Train Epoch: 60 [17280/35339 (49%)]	Loss: 0.166635
Train Epoch: 60 [17920/35339 (51%)]	Loss: 0.090402
Train Epoch: 60 [18560/35339 (52%)]	Loss: 0.115042
Train Epoch: 60 [19200/35339 (54%)]	Loss: 0.079938
Train Epoch: 60 [19840/35339 (56%)]	Loss: 0.061986
Train Epoch: 60 [20480/35339 (58%)]	Loss: 0.057170
Train Epoch: 60 [21120/35339 (60%)]	Loss: 0.107932
Train Epoch: 60 [21760/35339 (61%)]	Loss: 0.066330
Train Epoch: 60 [22400/35339 (63%)]	Loss: 0.082540
Train Epoch: 60 [23040/35339 (65%)]	Loss: 0.080862
Train Epoch: 60 [23680/35339 (67%)]	Loss: 0.117645
Train Epoch: 60 [24320/35339 (69%)]	Loss: 0.105721
Train Epoch: 60 [24960/35339 (71%)]	Loss: 0.107538
Train Epoch: 60 [25600/35339 (72%)]	Loss: 0.101745
Train Epoch: 60 [26240/35339 (74%)]	Loss: 0.109027
Train Epoch: 60 [26880/35339 (76%)]	Loss: 0.110734
Train Epoch: 60 [27520/35339 (78%)]	Loss: 0.116766
Train Epoch: 60 [28160/35339 (80%)]	Loss: 0.071070
Train Epoch: 60 [28800/35339 (81%)]	Loss: 0.105588
Train Epoch: 60 [29440/35339 (83%)]	Loss: 0.160803
Train Epoch: 60 [30080/35339 (85%)]	Loss: 0.098276
Train Epoch: 60 [30720/35339 (87%)]	Loss: 0.093580
Train Epoch: 60 [31360/35339 (89%)]	Loss: 0.075216
Train Epoch: 60 [32000/35339 (90%)]	Loss: 0.082143
Train Epoch: 60 [32640/35339 (92%)]	Loss: 0.109298
Train Epoch: 60 [33280/35339 (94%)]	Loss: 0.074707
Train Epoch: 60 [33920/35339 (96%)]	Loss: 0.123518
Train Epoch: 60 [34560/35339 (98%)]	Loss: 0.081517
Train Epoch: 60 [35200/35339 (99%)]	Loss: 0.078007

Validation set: Average loss: 3.2184, Accuracy: 1364/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 61 [0/35339 (0%)]	Loss: 0.072173
Train Epoch: 61 [640/35339 (2%)]	Loss: 0.067881
Train Epoch: 61 [1280/35339 (4%)]	Loss: 0.068260
Train Epoch: 61 [1920/35339 (5%)]	Loss: 0.104884
Train Epoch: 61 [2560/35339 (7%)]	Loss: 0.121796
Train Epoch: 61 [3200/35339 (9%)]	Loss: 0.096769
Train Epoch: 61 [3840/35339 (11%)]	Loss: 0.100475
Train Epoch: 61 [4480/35339 (13%)]	Loss: 0.195140
Train Epoch: 61 [5120/35339 (14%)]	Loss: 0.120132
Train Epoch: 61 [5760/35339 (16%)]	Loss: 0.056507
Train Epoch: 61 [6400/35339 (18%)]	Loss: 0.062010
Train Epoch: 61 [7040/35339 (20%)]	Loss: 0.117506
Train Epoch: 61 [7680/35339 (22%)]	Loss: 0.179382
Train Epoch: 61 [8320/35339 (24%)]	Loss: 0.116198
Train Epoch: 61 [8960/35339 (25%)]	Loss: 0.086123
Train Epoch: 61 [9600/35339 (27%)]	Loss: 0.103874
Train Epoch: 61 [10240/35339 (29%)]	Loss: 0.079770
Train Epoch: 61 [10880/35339 (31%)]	Loss: 0.083171
Train Epoch: 61 [11520/35339 (33%)]	Loss: 0.106402
Train Epoch: 61 [12160/35339 (34%)]	Loss: 0.082459
Train Epoch: 61 [12800/35339 (36%)]	Loss: 0.094772
Train Epoch: 61 [13440/35339 (38%)]	Loss: 0.074164
Train Epoch: 61 [14080/35339 (40%)]	Loss: 0.150786
Train Epoch: 61 [14720/35339 (42%)]	Loss: 0.096699
Train Epoch: 61 [15360/35339 (43%)]	Loss: 0.111636
Train Epoch: 61 [16000/35339 (45%)]	Loss: 0.063727
Train Epoch: 61 [16640/35339 (47%)]	Loss: 0.088891
Train Epoch: 61 [17280/35339 (49%)]	Loss: 0.111476
Train Epoch: 61 [17920/35339 (51%)]	Loss: 0.070850
Train Epoch: 61 [18560/35339 (52%)]	Loss: 0.061593
Train Epoch: 61 [19200/35339 (54%)]	Loss: 0.178623
Train Epoch: 61 [19840/35339 (56%)]	Loss: 0.091905
Train Epoch: 61 [20480/35339 (58%)]	Loss: 0.098095
Train Epoch: 61 [21120/35339 (60%)]	Loss: 0.096183
Train Epoch: 61 [21760/35339 (61%)]	Loss: 0.086716
Train Epoch: 61 [22400/35339 (63%)]	Loss: 0.101569
Train Epoch: 61 [23040/35339 (65%)]	Loss: 0.109086
Train Epoch: 61 [23680/35339 (67%)]	Loss: 0.131619
Train Epoch: 61 [24320/35339 (69%)]	Loss: 0.264451
Train Epoch: 61 [24960/35339 (71%)]	Loss: 0.066840
Train Epoch: 61 [25600/35339 (72%)]	Loss: 0.142301
Train Epoch: 61 [26240/35339 (74%)]	Loss: 0.070211
Train Epoch: 61 [26880/35339 (76%)]	Loss: 0.063358
Train Epoch: 61 [27520/35339 (78%)]	Loss: 0.121032
Train Epoch: 61 [28160/35339 (80%)]	Loss: 0.089091
Train Epoch: 61 [28800/35339 (81%)]	Loss: 0.110484
Train Epoch: 61 [29440/35339 (83%)]	Loss: 0.083510
Train Epoch: 61 [30080/35339 (85%)]	Loss: 0.084676
Train Epoch: 61 [30720/35339 (87%)]	Loss: 0.193901
Train Epoch: 61 [31360/35339 (89%)]	Loss: 0.347773
Train Epoch: 61 [32000/35339 (90%)]	Loss: 0.075687
Train Epoch: 61 [32640/35339 (92%)]	Loss: 0.117927
Train Epoch: 61 [33280/35339 (94%)]	Loss: 0.151987
Train Epoch: 61 [33920/35339 (96%)]	Loss: 0.094788
Train Epoch: 61 [34560/35339 (98%)]	Loss: 0.215165
Train Epoch: 61 [35200/35339 (99%)]	Loss: 0.139069

Validation set: Average loss: 3.2258, Accuracy: 1316/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 62 [0/35339 (0%)]	Loss: 0.079873
Train Epoch: 62 [640/35339 (2%)]	Loss: 0.081339
Train Epoch: 62 [1280/35339 (4%)]	Loss: 0.101411
Train Epoch: 62 [1920/35339 (5%)]	Loss: 0.111107
Train Epoch: 62 [2560/35339 (7%)]	Loss: 0.113666
Train Epoch: 62 [3200/35339 (9%)]	Loss: 0.076338
Train Epoch: 62 [3840/35339 (11%)]	Loss: 0.114541
Train Epoch: 62 [4480/35339 (13%)]	Loss: 0.069483
Train Epoch: 62 [5120/35339 (14%)]	Loss: 0.086597
Train Epoch: 62 [5760/35339 (16%)]	Loss: 0.126494
Train Epoch: 62 [6400/35339 (18%)]	Loss: 0.107688
Train Epoch: 62 [7040/35339 (20%)]	Loss: 0.081653
Train Epoch: 62 [7680/35339 (22%)]	Loss: 0.283000
Train Epoch: 62 [8320/35339 (24%)]	Loss: 0.094822
Train Epoch: 62 [8960/35339 (25%)]	Loss: 0.120367
Train Epoch: 62 [9600/35339 (27%)]	Loss: 0.063559
Train Epoch: 62 [10240/35339 (29%)]	Loss: 0.104777
Train Epoch: 62 [10880/35339 (31%)]	Loss: 0.064647
Train Epoch: 62 [11520/35339 (33%)]	Loss: 0.062800
Train Epoch: 62 [12160/35339 (34%)]	Loss: 0.114498
Train Epoch: 62 [12800/35339 (36%)]	Loss: 0.261818
Train Epoch: 62 [13440/35339 (38%)]	Loss: 0.287693
Train Epoch: 62 [14080/35339 (40%)]	Loss: 0.075750
Train Epoch: 62 [14720/35339 (42%)]	Loss: 0.066209
Train Epoch: 62 [15360/35339 (43%)]	Loss: 0.172194
Train Epoch: 62 [16000/35339 (45%)]	Loss: 0.145690
Train Epoch: 62 [16640/35339 (47%)]	Loss: 0.073999
Train Epoch: 62 [17280/35339 (49%)]	Loss: 0.129914
Train Epoch: 62 [17920/35339 (51%)]	Loss: 0.070589
Train Epoch: 62 [18560/35339 (52%)]	Loss: 0.088223
Train Epoch: 62 [19200/35339 (54%)]	Loss: 0.118926
Train Epoch: 62 [19840/35339 (56%)]	Loss: 0.079723
Train Epoch: 62 [20480/35339 (58%)]	Loss: 0.065835
Train Epoch: 62 [21120/35339 (60%)]	Loss: 0.061265
Train Epoch: 62 [21760/35339 (61%)]	Loss: 0.060971
Train Epoch: 62 [22400/35339 (63%)]	Loss: 0.111747
Train Epoch: 62 [23040/35339 (65%)]	Loss: 0.173194
Train Epoch: 62 [23680/35339 (67%)]	Loss: 0.123880
Train Epoch: 62 [24320/35339 (69%)]	Loss: 0.094220
Train Epoch: 62 [24960/35339 (71%)]	Loss: 0.112928
Train Epoch: 62 [25600/35339 (72%)]	Loss: 0.167378
Train Epoch: 62 [26240/35339 (74%)]	Loss: 0.131461
Train Epoch: 62 [26880/35339 (76%)]	Loss: 0.098819
Train Epoch: 62 [27520/35339 (78%)]	Loss: 0.175605
Train Epoch: 62 [28160/35339 (80%)]	Loss: 0.083765
Train Epoch: 62 [28800/35339 (81%)]	Loss: 0.137203
Train Epoch: 62 [29440/35339 (83%)]	Loss: 0.078941
Train Epoch: 62 [30080/35339 (85%)]	Loss: 0.127121
Train Epoch: 62 [30720/35339 (87%)]	Loss: 0.116838
Train Epoch: 62 [31360/35339 (89%)]	Loss: 0.092577
Train Epoch: 62 [32000/35339 (90%)]	Loss: 0.068055
Train Epoch: 62 [32640/35339 (92%)]	Loss: 0.072005
Train Epoch: 62 [33280/35339 (94%)]	Loss: 0.100037
Train Epoch: 62 [33920/35339 (96%)]	Loss: 0.061165
Train Epoch: 62 [34560/35339 (98%)]	Loss: 0.073443
Train Epoch: 62 [35200/35339 (99%)]	Loss: 0.063888

Validation set: Average loss: 3.0736, Accuracy: 1426/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 63 [0/35339 (0%)]	Loss: 0.077970
Train Epoch: 63 [640/35339 (2%)]	Loss: 0.145355
Train Epoch: 63 [1280/35339 (4%)]	Loss: 0.106081
Train Epoch: 63 [1920/35339 (5%)]	Loss: 0.113652
Train Epoch: 63 [2560/35339 (7%)]	Loss: 0.109839
Train Epoch: 63 [3200/35339 (9%)]	Loss: 0.133442
Train Epoch: 63 [3840/35339 (11%)]	Loss: 0.114760
Train Epoch: 63 [4480/35339 (13%)]	Loss: 0.078389
Train Epoch: 63 [5120/35339 (14%)]	Loss: 0.069278
Train Epoch: 63 [5760/35339 (16%)]	Loss: 0.287938
Train Epoch: 63 [6400/35339 (18%)]	Loss: 0.093054
Train Epoch: 63 [7040/35339 (20%)]	Loss: 0.128347
Train Epoch: 63 [7680/35339 (22%)]	Loss: 0.105143
Train Epoch: 63 [8320/35339 (24%)]	Loss: 0.102974
Train Epoch: 63 [8960/35339 (25%)]	Loss: 0.104035
Train Epoch: 63 [9600/35339 (27%)]	Loss: 0.145124
Train Epoch: 63 [10240/35339 (29%)]	Loss: 0.072040
Train Epoch: 63 [10880/35339 (31%)]	Loss: 0.080478
Train Epoch: 63 [11520/35339 (33%)]	Loss: 0.107907
Train Epoch: 63 [12160/35339 (34%)]	Loss: 0.083760
Train Epoch: 63 [12800/35339 (36%)]	Loss: 0.077968
Train Epoch: 63 [13440/35339 (38%)]	Loss: 0.230425
Train Epoch: 63 [14080/35339 (40%)]	Loss: 0.107677
Train Epoch: 63 [14720/35339 (42%)]	Loss: 0.088706
Train Epoch: 63 [15360/35339 (43%)]	Loss: 0.084402
Train Epoch: 63 [16000/35339 (45%)]	Loss: 0.105369
Train Epoch: 63 [16640/35339 (47%)]	Loss: 0.087091
Train Epoch: 63 [17280/35339 (49%)]	Loss: 0.063578
Train Epoch: 63 [17920/35339 (51%)]	Loss: 0.069379
Train Epoch: 63 [18560/35339 (52%)]	Loss: 0.075430
Train Epoch: 63 [19200/35339 (54%)]	Loss: 0.060927
Train Epoch: 63 [19840/35339 (56%)]	Loss: 0.074673
Train Epoch: 63 [20480/35339 (58%)]	Loss: 0.104704
Train Epoch: 63 [21120/35339 (60%)]	Loss: 0.104014
Train Epoch: 63 [21760/35339 (61%)]	Loss: 0.151599
Train Epoch: 63 [22400/35339 (63%)]	Loss: 0.088209
Train Epoch: 63 [23040/35339 (65%)]	Loss: 0.107365
Train Epoch: 63 [23680/35339 (67%)]	Loss: 0.087433
Train Epoch: 63 [24320/35339 (69%)]	Loss: 0.090604
Train Epoch: 63 [24960/35339 (71%)]	Loss: 0.103739
Train Epoch: 63 [25600/35339 (72%)]	Loss: 0.116236
Train Epoch: 63 [26240/35339 (74%)]	Loss: 0.113688
Train Epoch: 63 [26880/35339 (76%)]	Loss: 0.068404
Train Epoch: 63 [27520/35339 (78%)]	Loss: 0.066834
Train Epoch: 63 [28160/35339 (80%)]	Loss: 0.066678
Train Epoch: 63 [28800/35339 (81%)]	Loss: 0.101446
Train Epoch: 63 [29440/35339 (83%)]	Loss: 0.063501
Train Epoch: 63 [30080/35339 (85%)]	Loss: 0.062475
Train Epoch: 63 [30720/35339 (87%)]	Loss: 0.073296
Train Epoch: 63 [31360/35339 (89%)]	Loss: 0.062119
Train Epoch: 63 [32000/35339 (90%)]	Loss: 0.113340
Train Epoch: 63 [32640/35339 (92%)]	Loss: 0.138951
Train Epoch: 63 [33280/35339 (94%)]	Loss: 0.102696
Train Epoch: 63 [33920/35339 (96%)]	Loss: 0.086525
Train Epoch: 63 [34560/35339 (98%)]	Loss: 0.083785
Train Epoch: 63 [35200/35339 (99%)]	Loss: 0.074528

Validation set: Average loss: 3.2219, Accuracy: 1332/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 64 [0/35339 (0%)]	Loss: 0.066803
Train Epoch: 64 [640/35339 (2%)]	Loss: 0.066833
Train Epoch: 64 [1280/35339 (4%)]	Loss: 0.129583
Train Epoch: 64 [1920/35339 (5%)]	Loss: 0.147353
Train Epoch: 64 [2560/35339 (7%)]	Loss: 0.067087
Train Epoch: 64 [3200/35339 (9%)]	Loss: 0.131849
Train Epoch: 64 [3840/35339 (11%)]	Loss: 0.093820
Train Epoch: 64 [4480/35339 (13%)]	Loss: 0.076302
Train Epoch: 64 [5120/35339 (14%)]	Loss: 0.067939
Train Epoch: 64 [5760/35339 (16%)]	Loss: 0.063951
Train Epoch: 64 [6400/35339 (18%)]	Loss: 0.077150
Train Epoch: 64 [7040/35339 (20%)]	Loss: 0.091029
Train Epoch: 64 [7680/35339 (22%)]	Loss: 0.064419
Train Epoch: 64 [8320/35339 (24%)]	Loss: 0.071070
Train Epoch: 64 [8960/35339 (25%)]	Loss: 0.094609
Train Epoch: 64 [9600/35339 (27%)]	Loss: 0.098723
Train Epoch: 64 [10240/35339 (29%)]	Loss: 0.074070
Train Epoch: 64 [10880/35339 (31%)]	Loss: 0.071234
Train Epoch: 64 [11520/35339 (33%)]	Loss: 0.087990
Train Epoch: 64 [12160/35339 (34%)]	Loss: 0.075044
Train Epoch: 64 [12800/35339 (36%)]	Loss: 0.145200
Train Epoch: 64 [13440/35339 (38%)]	Loss: 0.099240
Train Epoch: 64 [14080/35339 (40%)]	Loss: 0.081431
Train Epoch: 64 [14720/35339 (42%)]	Loss: 0.071912
Train Epoch: 64 [15360/35339 (43%)]	Loss: 0.074147
Train Epoch: 64 [16000/35339 (45%)]	Loss: 0.142723
Train Epoch: 64 [16640/35339 (47%)]	Loss: 0.072020
Train Epoch: 64 [17280/35339 (49%)]	Loss: 0.092122
Train Epoch: 64 [17920/35339 (51%)]	Loss: 0.127512
Train Epoch: 64 [18560/35339 (52%)]	Loss: 0.086874
Train Epoch: 64 [19200/35339 (54%)]	Loss: 0.127752
Train Epoch: 64 [19840/35339 (56%)]	Loss: 0.149582
Train Epoch: 64 [20480/35339 (58%)]	Loss: 0.097492
Train Epoch: 64 [21120/35339 (60%)]	Loss: 0.062217
Train Epoch: 64 [21760/35339 (61%)]	Loss: 0.099126
Train Epoch: 64 [22400/35339 (63%)]	Loss: 0.157539
Train Epoch: 64 [23040/35339 (65%)]	Loss: 0.073926
Train Epoch: 64 [23680/35339 (67%)]	Loss: 0.083591
Train Epoch: 64 [24320/35339 (69%)]	Loss: 0.218536
Train Epoch: 64 [24960/35339 (71%)]	Loss: 0.148935
Train Epoch: 64 [25600/35339 (72%)]	Loss: 0.072186
Train Epoch: 64 [26240/35339 (74%)]	Loss: 0.078844
Train Epoch: 64 [26880/35339 (76%)]	Loss: 0.106614
Train Epoch: 64 [27520/35339 (78%)]	Loss: 0.126548
Train Epoch: 64 [28160/35339 (80%)]	Loss: 0.058124
Train Epoch: 64 [28800/35339 (81%)]	Loss: 0.149414
Train Epoch: 64 [29440/35339 (83%)]	Loss: 0.068979
Train Epoch: 64 [30080/35339 (85%)]	Loss: 0.082181
Train Epoch: 64 [30720/35339 (87%)]	Loss: 0.087785
Train Epoch: 64 [31360/35339 (89%)]	Loss: 0.072781
Train Epoch: 64 [32000/35339 (90%)]	Loss: 0.089831
Train Epoch: 64 [32640/35339 (92%)]	Loss: 0.077668
Train Epoch: 64 [33280/35339 (94%)]	Loss: 0.073284
Train Epoch: 64 [33920/35339 (96%)]	Loss: 0.070588
Train Epoch: 64 [34560/35339 (98%)]	Loss: 0.096171
Train Epoch: 64 [35200/35339 (99%)]	Loss: 0.095179

Validation set: Average loss: 3.1268, Accuracy: 1386/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 65 [0/35339 (0%)]	Loss: 0.078338
Train Epoch: 65 [640/35339 (2%)]	Loss: 0.134310
Train Epoch: 65 [1280/35339 (4%)]	Loss: 0.079724
Train Epoch: 65 [1920/35339 (5%)]	Loss: 0.076723
Train Epoch: 65 [2560/35339 (7%)]	Loss: 0.059784
Train Epoch: 65 [3200/35339 (9%)]	Loss: 0.089421
Train Epoch: 65 [3840/35339 (11%)]	Loss: 0.095059
Train Epoch: 65 [4480/35339 (13%)]	Loss: 0.126958
Train Epoch: 65 [5120/35339 (14%)]	Loss: 0.061429
Train Epoch: 65 [5760/35339 (16%)]	Loss: 0.157777
Train Epoch: 65 [6400/35339 (18%)]	Loss: 0.095188
Train Epoch: 65 [7040/35339 (20%)]	Loss: 0.074286
Train Epoch: 65 [7680/35339 (22%)]	Loss: 0.115908
Train Epoch: 65 [8320/35339 (24%)]	Loss: 0.059384
Train Epoch: 65 [8960/35339 (25%)]	Loss: 0.096675
Train Epoch: 65 [9600/35339 (27%)]	Loss: 0.082387
Train Epoch: 65 [10240/35339 (29%)]	Loss: 0.067601
Train Epoch: 65 [10880/35339 (31%)]	Loss: 0.117457
Train Epoch: 65 [11520/35339 (33%)]	Loss: 0.075879
Train Epoch: 65 [12160/35339 (34%)]	Loss: 0.094066
Train Epoch: 65 [12800/35339 (36%)]	Loss: 0.090442
Train Epoch: 65 [13440/35339 (38%)]	Loss: 0.104534
Train Epoch: 65 [14080/35339 (40%)]	Loss: 0.115717
Train Epoch: 65 [14720/35339 (42%)]	Loss: 0.076110
Train Epoch: 65 [15360/35339 (43%)]	Loss: 0.110994
Train Epoch: 65 [16000/35339 (45%)]	Loss: 0.066472
Train Epoch: 65 [16640/35339 (47%)]	Loss: 0.090570
Train Epoch: 65 [17280/35339 (49%)]	Loss: 0.120913
Train Epoch: 65 [17920/35339 (51%)]	Loss: 0.096169
Train Epoch: 65 [18560/35339 (52%)]	Loss: 0.072368
Train Epoch: 65 [19200/35339 (54%)]	Loss: 0.176972
Train Epoch: 65 [19840/35339 (56%)]	Loss: 0.122110
Train Epoch: 65 [20480/35339 (58%)]	Loss: 0.072551
Train Epoch: 65 [21120/35339 (60%)]	Loss: 0.068705
Train Epoch: 65 [21760/35339 (61%)]	Loss: 0.134051
Train Epoch: 65 [22400/35339 (63%)]	Loss: 0.162281
Train Epoch: 65 [23040/35339 (65%)]	Loss: 0.106888
Train Epoch: 65 [23680/35339 (67%)]	Loss: 0.155543
Train Epoch: 65 [24320/35339 (69%)]	Loss: 0.068909
Train Epoch: 65 [24960/35339 (71%)]	Loss: 0.065103
Train Epoch: 65 [25600/35339 (72%)]	Loss: 0.075536
Train Epoch: 65 [26240/35339 (74%)]	Loss: 0.264059
Train Epoch: 65 [26880/35339 (76%)]	Loss: 0.134896
Train Epoch: 65 [27520/35339 (78%)]	Loss: 0.058294
Train Epoch: 65 [28160/35339 (80%)]	Loss: 0.066581
Train Epoch: 65 [28800/35339 (81%)]	Loss: 0.088497
Train Epoch: 65 [29440/35339 (83%)]	Loss: 0.195901
Train Epoch: 65 [30080/35339 (85%)]	Loss: 0.077336
Train Epoch: 65 [30720/35339 (87%)]	Loss: 0.107803
Train Epoch: 65 [31360/35339 (89%)]	Loss: 0.135073
Train Epoch: 65 [32000/35339 (90%)]	Loss: 0.091432
Train Epoch: 65 [32640/35339 (92%)]	Loss: 0.108772
Train Epoch: 65 [33280/35339 (94%)]	Loss: 0.108975
Train Epoch: 65 [33920/35339 (96%)]	Loss: 0.067509
Train Epoch: 65 [34560/35339 (98%)]	Loss: 0.181093
Train Epoch: 65 [35200/35339 (99%)]	Loss: 0.130868

Validation set: Average loss: 3.1334, Accuracy: 1407/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 66 [0/35339 (0%)]	Loss: 0.126001
Train Epoch: 66 [640/35339 (2%)]	Loss: 0.071865
Train Epoch: 66 [1280/35339 (4%)]	Loss: 0.126292
Train Epoch: 66 [1920/35339 (5%)]	Loss: 0.149532
Train Epoch: 66 [2560/35339 (7%)]	Loss: 0.083115
Train Epoch: 66 [3200/35339 (9%)]	Loss: 0.100079
Train Epoch: 66 [3840/35339 (11%)]	Loss: 0.096681
Train Epoch: 66 [4480/35339 (13%)]	Loss: 0.104463
Train Epoch: 66 [5120/35339 (14%)]	Loss: 0.119148
Train Epoch: 66 [5760/35339 (16%)]	Loss: 0.165302
Train Epoch: 66 [6400/35339 (18%)]	Loss: 0.159476
Train Epoch: 66 [7040/35339 (20%)]	Loss: 0.190560
Train Epoch: 66 [7680/35339 (22%)]	Loss: 0.123473
Train Epoch: 66 [8320/35339 (24%)]	Loss: 0.113039
Train Epoch: 66 [8960/35339 (25%)]	Loss: 0.067881
Train Epoch: 66 [9600/35339 (27%)]	Loss: 0.072655
Train Epoch: 66 [10240/35339 (29%)]	Loss: 0.077400
Train Epoch: 66 [10880/35339 (31%)]	Loss: 0.060297
Train Epoch: 66 [11520/35339 (33%)]	Loss: 0.137183
Train Epoch: 66 [12160/35339 (34%)]	Loss: 0.078920
Train Epoch: 66 [12800/35339 (36%)]	Loss: 0.100990
Train Epoch: 66 [13440/35339 (38%)]	Loss: 0.137491
Train Epoch: 66 [14080/35339 (40%)]	Loss: 0.105346
Train Epoch: 66 [14720/35339 (42%)]	Loss: 0.100682
Train Epoch: 66 [15360/35339 (43%)]	Loss: 0.103331
Train Epoch: 66 [16000/35339 (45%)]	Loss: 0.102658
Train Epoch: 66 [16640/35339 (47%)]	Loss: 0.075197
Train Epoch: 66 [17280/35339 (49%)]	Loss: 0.061080
Train Epoch: 66 [17920/35339 (51%)]	Loss: 0.115154
Train Epoch: 66 [18560/35339 (52%)]	Loss: 0.073475
Train Epoch: 66 [19200/35339 (54%)]	Loss: 0.128776
Train Epoch: 66 [19840/35339 (56%)]	Loss: 0.059666
Train Epoch: 66 [20480/35339 (58%)]	Loss: 0.076392
Train Epoch: 66 [21120/35339 (60%)]	Loss: 0.172874
Train Epoch: 66 [21760/35339 (61%)]	Loss: 0.062374
Train Epoch: 66 [22400/35339 (63%)]	Loss: 0.114502
Train Epoch: 66 [23040/35339 (65%)]	Loss: 0.076625
Train Epoch: 66 [23680/35339 (67%)]	Loss: 0.090277
Train Epoch: 66 [24320/35339 (69%)]	Loss: 0.088715
Train Epoch: 66 [24960/35339 (71%)]	Loss: 0.067113
Train Epoch: 66 [25600/35339 (72%)]	Loss: 0.091694
Train Epoch: 66 [26240/35339 (74%)]	Loss: 0.110229
Train Epoch: 66 [26880/35339 (76%)]	Loss: 0.125035
Train Epoch: 66 [27520/35339 (78%)]	Loss: 0.086606
Train Epoch: 66 [28160/35339 (80%)]	Loss: 0.155932
Train Epoch: 66 [28800/35339 (81%)]	Loss: 0.126581
Train Epoch: 66 [29440/35339 (83%)]	Loss: 0.085117
Train Epoch: 66 [30080/35339 (85%)]	Loss: 0.069982
Train Epoch: 66 [30720/35339 (87%)]	Loss: 0.086420
Train Epoch: 66 [31360/35339 (89%)]	Loss: 0.085699
Train Epoch: 66 [32000/35339 (90%)]	Loss: 0.073063
Train Epoch: 66 [32640/35339 (92%)]	Loss: 0.071191
Train Epoch: 66 [33280/35339 (94%)]	Loss: 0.077283
Train Epoch: 66 [33920/35339 (96%)]	Loss: 0.163378
Train Epoch: 66 [34560/35339 (98%)]	Loss: 0.081747
Train Epoch: 66 [35200/35339 (99%)]	Loss: 0.103204

Validation set: Average loss: 3.2678, Accuracy: 1319/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 67 [0/35339 (0%)]	Loss: 0.099254
Train Epoch: 67 [640/35339 (2%)]	Loss: 0.104070
Train Epoch: 67 [1280/35339 (4%)]	Loss: 0.098118
Train Epoch: 67 [1920/35339 (5%)]	Loss: 0.070007
Train Epoch: 67 [2560/35339 (7%)]	Loss: 0.067324
Train Epoch: 67 [3200/35339 (9%)]	Loss: 0.152029
Train Epoch: 67 [3840/35339 (11%)]	Loss: 0.137230
Train Epoch: 67 [4480/35339 (13%)]	Loss: 0.191155
Train Epoch: 67 [5120/35339 (14%)]	Loss: 0.082178
Train Epoch: 67 [5760/35339 (16%)]	Loss: 0.073896
Train Epoch: 67 [6400/35339 (18%)]	Loss: 0.113794
Train Epoch: 67 [7040/35339 (20%)]	Loss: 0.069185
Train Epoch: 67 [7680/35339 (22%)]	Loss: 0.094900
Train Epoch: 67 [8320/35339 (24%)]	Loss: 0.139671
Train Epoch: 67 [8960/35339 (25%)]	Loss: 0.096620
Train Epoch: 67 [9600/35339 (27%)]	Loss: 0.087621
Train Epoch: 67 [10240/35339 (29%)]	Loss: 0.065743
Train Epoch: 67 [10880/35339 (31%)]	Loss: 0.057918
Train Epoch: 67 [11520/35339 (33%)]	Loss: 0.104867
Train Epoch: 67 [12160/35339 (34%)]	Loss: 0.092941
Train Epoch: 67 [12800/35339 (36%)]	Loss: 0.101525
Train Epoch: 67 [13440/35339 (38%)]	Loss: 0.090011
Train Epoch: 67 [14080/35339 (40%)]	Loss: 0.067181
Train Epoch: 67 [14720/35339 (42%)]	Loss: 0.076914
Train Epoch: 67 [15360/35339 (43%)]	Loss: 0.112589
Train Epoch: 67 [16000/35339 (45%)]	Loss: 0.118251
Train Epoch: 67 [16640/35339 (47%)]	Loss: 0.088782
Train Epoch: 67 [17280/35339 (49%)]	Loss: 0.085038
Train Epoch: 67 [17920/35339 (51%)]	Loss: 0.062291
Train Epoch: 67 [18560/35339 (52%)]	Loss: 0.061924
Train Epoch: 67 [19200/35339 (54%)]	Loss: 0.099390
Train Epoch: 67 [19840/35339 (56%)]	Loss: 0.154389
Train Epoch: 67 [20480/35339 (58%)]	Loss: 0.072658
Train Epoch: 67 [21120/35339 (60%)]	Loss: 0.063471
Train Epoch: 67 [21760/35339 (61%)]	Loss: 0.094977
Train Epoch: 67 [22400/35339 (63%)]	Loss: 0.093918
Train Epoch: 67 [23040/35339 (65%)]	Loss: 0.118307
Train Epoch: 67 [23680/35339 (67%)]	Loss: 0.122539
Train Epoch: 67 [24320/35339 (69%)]	Loss: 0.152641
Train Epoch: 67 [24960/35339 (71%)]	Loss: 0.069827
Train Epoch: 67 [25600/35339 (72%)]	Loss: 0.068998
Train Epoch: 67 [26240/35339 (74%)]	Loss: 0.088702
Train Epoch: 67 [26880/35339 (76%)]	Loss: 0.067885
Train Epoch: 67 [27520/35339 (78%)]	Loss: 0.065253
Train Epoch: 67 [28160/35339 (80%)]	Loss: 0.068625
Train Epoch: 67 [28800/35339 (81%)]	Loss: 0.412148
Train Epoch: 67 [29440/35339 (83%)]	Loss: 0.073723
Train Epoch: 67 [30080/35339 (85%)]	Loss: 0.187151
Train Epoch: 67 [30720/35339 (87%)]	Loss: 0.078406
Train Epoch: 67 [31360/35339 (89%)]	Loss: 0.075881
Train Epoch: 67 [32000/35339 (90%)]	Loss: 0.061249
Train Epoch: 67 [32640/35339 (92%)]	Loss: 0.083562
Train Epoch: 67 [33280/35339 (94%)]	Loss: 0.098844
Train Epoch: 67 [33920/35339 (96%)]	Loss: 0.070771
Train Epoch: 67 [34560/35339 (98%)]	Loss: 0.062437
Train Epoch: 67 [35200/35339 (99%)]	Loss: 0.327470

Validation set: Average loss: 3.2599, Accuracy: 1319/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 68 [0/35339 (0%)]	Loss: 0.119777
Train Epoch: 68 [640/35339 (2%)]	Loss: 0.087022
Train Epoch: 68 [1280/35339 (4%)]	Loss: 0.061243
Train Epoch: 68 [1920/35339 (5%)]	Loss: 0.101562
Train Epoch: 68 [2560/35339 (7%)]	Loss: 0.064245
Train Epoch: 68 [3200/35339 (9%)]	Loss: 0.069863
Train Epoch: 68 [3840/35339 (11%)]	Loss: 0.093964
Train Epoch: 68 [4480/35339 (13%)]	Loss: 0.101603
Train Epoch: 68 [5120/35339 (14%)]	Loss: 0.070388
Train Epoch: 68 [5760/35339 (16%)]	Loss: 0.063976
Train Epoch: 68 [6400/35339 (18%)]	Loss: 0.098124
Train Epoch: 68 [7040/35339 (20%)]	Loss: 0.065261
Train Epoch: 68 [7680/35339 (22%)]	Loss: 0.067344
Train Epoch: 68 [8320/35339 (24%)]	Loss: 0.134574
Train Epoch: 68 [8960/35339 (25%)]	Loss: 0.099378
Train Epoch: 68 [9600/35339 (27%)]	Loss: 0.240998
Train Epoch: 68 [10240/35339 (29%)]	Loss: 0.231500
Train Epoch: 68 [10880/35339 (31%)]	Loss: 0.099568
Train Epoch: 68 [11520/35339 (33%)]	Loss: 0.076852
Train Epoch: 68 [12160/35339 (34%)]	Loss: 0.071894
Train Epoch: 68 [12800/35339 (36%)]	Loss: 0.121532
Train Epoch: 68 [13440/35339 (38%)]	Loss: 0.123787
Train Epoch: 68 [14080/35339 (40%)]	Loss: 0.079676
Train Epoch: 68 [14720/35339 (42%)]	Loss: 0.061361
Train Epoch: 68 [15360/35339 (43%)]	Loss: 0.210624
Train Epoch: 68 [16000/35339 (45%)]	Loss: 0.268215
Train Epoch: 68 [16640/35339 (47%)]	Loss: 0.062978
Train Epoch: 68 [17280/35339 (49%)]	Loss: 0.081399
Train Epoch: 68 [17920/35339 (51%)]	Loss: 0.128267
Train Epoch: 68 [18560/35339 (52%)]	Loss: 0.116990
Train Epoch: 68 [19200/35339 (54%)]	Loss: 0.062775
Train Epoch: 68 [19840/35339 (56%)]	Loss: 0.112568
Train Epoch: 68 [20480/35339 (58%)]	Loss: 0.071564
Train Epoch: 68 [21120/35339 (60%)]	Loss: 0.056610
Train Epoch: 68 [21760/35339 (61%)]	Loss: 0.085110
Train Epoch: 68 [22400/35339 (63%)]	Loss: 0.060764
Train Epoch: 68 [23040/35339 (65%)]	Loss: 0.142434
Train Epoch: 68 [23680/35339 (67%)]	Loss: 0.086886
Train Epoch: 68 [24320/35339 (69%)]	Loss: 0.083226
Train Epoch: 68 [24960/35339 (71%)]	Loss: 0.100745
Train Epoch: 68 [25600/35339 (72%)]	Loss: 0.122803
Train Epoch: 68 [26240/35339 (74%)]	Loss: 0.113245
Train Epoch: 68 [26880/35339 (76%)]	Loss: 0.106410
Train Epoch: 68 [27520/35339 (78%)]	Loss: 0.083960
Train Epoch: 68 [28160/35339 (80%)]	Loss: 0.079113
Train Epoch: 68 [28800/35339 (81%)]	Loss: 0.067237
Train Epoch: 68 [29440/35339 (83%)]	Loss: 0.087687
Train Epoch: 68 [30080/35339 (85%)]	Loss: 0.061423
Train Epoch: 68 [30720/35339 (87%)]	Loss: 0.117697
Train Epoch: 68 [31360/35339 (89%)]	Loss: 0.078952
Train Epoch: 68 [32000/35339 (90%)]	Loss: 0.150078
Train Epoch: 68 [32640/35339 (92%)]	Loss: 0.084867
Train Epoch: 68 [33280/35339 (94%)]	Loss: 0.105069
Train Epoch: 68 [33920/35339 (96%)]	Loss: 0.080428
Train Epoch: 68 [34560/35339 (98%)]	Loss: 0.088481
Train Epoch: 68 [35200/35339 (99%)]	Loss: 0.101012

Validation set: Average loss: 3.1261, Accuracy: 1392/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 69 [0/35339 (0%)]	Loss: 0.065426
Train Epoch: 69 [640/35339 (2%)]	Loss: 0.093018
Train Epoch: 69 [1280/35339 (4%)]	Loss: 0.116795
Train Epoch: 69 [1920/35339 (5%)]	Loss: 0.100065
Train Epoch: 69 [2560/35339 (7%)]	Loss: 0.087268
Train Epoch: 69 [3200/35339 (9%)]	Loss: 0.099282
Train Epoch: 69 [3840/35339 (11%)]	Loss: 0.125362
Train Epoch: 69 [4480/35339 (13%)]	Loss: 0.077274
Train Epoch: 69 [5120/35339 (14%)]	Loss: 0.084913
Train Epoch: 69 [5760/35339 (16%)]	Loss: 0.066518
Train Epoch: 69 [6400/35339 (18%)]	Loss: 0.087686
Train Epoch: 69 [7040/35339 (20%)]	Loss: 0.061863
Train Epoch: 69 [7680/35339 (22%)]	Loss: 0.100605
Train Epoch: 69 [8320/35339 (24%)]	Loss: 0.247428
Train Epoch: 69 [8960/35339 (25%)]	Loss: 0.114342
Train Epoch: 69 [9600/35339 (27%)]	Loss: 0.063848
Train Epoch: 69 [10240/35339 (29%)]	Loss: 0.082815
Train Epoch: 69 [10880/35339 (31%)]	Loss: 0.064004
Train Epoch: 69 [11520/35339 (33%)]	Loss: 0.066414
Train Epoch: 69 [12160/35339 (34%)]	Loss: 0.125204
Train Epoch: 69 [12800/35339 (36%)]	Loss: 0.113964
Train Epoch: 69 [13440/35339 (38%)]	Loss: 0.094550
Train Epoch: 69 [14080/35339 (40%)]	Loss: 0.134277
Train Epoch: 69 [14720/35339 (42%)]	Loss: 0.108860
Train Epoch: 69 [15360/35339 (43%)]	Loss: 0.112265
Train Epoch: 69 [16000/35339 (45%)]	Loss: 0.079681
Train Epoch: 69 [16640/35339 (47%)]	Loss: 0.059113
Train Epoch: 69 [17280/35339 (49%)]	Loss: 0.173797
Train Epoch: 69 [17920/35339 (51%)]	Loss: 0.088880
Train Epoch: 69 [18560/35339 (52%)]	Loss: 0.082881
Train Epoch: 69 [19200/35339 (54%)]	Loss: 0.149252
Train Epoch: 69 [19840/35339 (56%)]	Loss: 0.128890
Train Epoch: 69 [20480/35339 (58%)]	Loss: 0.157454
Train Epoch: 69 [21120/35339 (60%)]	Loss: 0.076408
Train Epoch: 69 [21760/35339 (61%)]	Loss: 0.103190
Train Epoch: 69 [22400/35339 (63%)]	Loss: 0.094518
Train Epoch: 69 [23040/35339 (65%)]	Loss: 0.083640
Train Epoch: 69 [23680/35339 (67%)]	Loss: 0.079505
Train Epoch: 69 [24320/35339 (69%)]	Loss: 0.101758
Train Epoch: 69 [24960/35339 (71%)]	Loss: 0.142947
Train Epoch: 69 [25600/35339 (72%)]	Loss: 0.061807
Train Epoch: 69 [26240/35339 (74%)]	Loss: 0.203367
Train Epoch: 69 [26880/35339 (76%)]	Loss: 0.131757
Train Epoch: 69 [27520/35339 (78%)]	Loss: 0.121994
Train Epoch: 69 [28160/35339 (80%)]	Loss: 0.137355
Train Epoch: 69 [28800/35339 (81%)]	Loss: 0.078925
Train Epoch: 69 [29440/35339 (83%)]	Loss: 0.096083
Train Epoch: 69 [30080/35339 (85%)]	Loss: 0.068077
Train Epoch: 69 [30720/35339 (87%)]	Loss: 0.164439
Train Epoch: 69 [31360/35339 (89%)]	Loss: 0.077933
Train Epoch: 69 [32000/35339 (90%)]	Loss: 0.115337
Train Epoch: 69 [32640/35339 (92%)]	Loss: 0.091253
Train Epoch: 69 [33280/35339 (94%)]	Loss: 0.080871
Train Epoch: 69 [33920/35339 (96%)]	Loss: 0.151124
Train Epoch: 69 [34560/35339 (98%)]	Loss: 0.141875
Train Epoch: 69 [35200/35339 (99%)]	Loss: 0.063199

Validation set: Average loss: 3.1082, Accuracy: 1412/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 70 [0/35339 (0%)]	Loss: 0.134428
Train Epoch: 70 [640/35339 (2%)]	Loss: 0.118159
Train Epoch: 70 [1280/35339 (4%)]	Loss: 0.083329
Train Epoch: 70 [1920/35339 (5%)]	Loss: 0.071780
Train Epoch: 70 [2560/35339 (7%)]	Loss: 0.101240
Train Epoch: 70 [3200/35339 (9%)]	Loss: 0.170768
Train Epoch: 70 [3840/35339 (11%)]	Loss: 0.060423
Train Epoch: 70 [4480/35339 (13%)]	Loss: 0.128949
Train Epoch: 70 [5120/35339 (14%)]	Loss: 0.081149
Train Epoch: 70 [5760/35339 (16%)]	Loss: 0.074479
Train Epoch: 70 [6400/35339 (18%)]	Loss: 0.070617
Train Epoch: 70 [7040/35339 (20%)]	Loss: 0.067552
Train Epoch: 70 [7680/35339 (22%)]	Loss: 0.059720
Train Epoch: 70 [8320/35339 (24%)]	Loss: 0.105804
Train Epoch: 70 [8960/35339 (25%)]	Loss: 0.071843
Train Epoch: 70 [9600/35339 (27%)]	Loss: 0.060141
Train Epoch: 70 [10240/35339 (29%)]	Loss: 0.149584
Train Epoch: 70 [10880/35339 (31%)]	Loss: 0.100850
Train Epoch: 70 [11520/35339 (33%)]	Loss: 0.065011
Train Epoch: 70 [12160/35339 (34%)]	Loss: 0.062894
Train Epoch: 70 [12800/35339 (36%)]	Loss: 0.262670
Train Epoch: 70 [13440/35339 (38%)]	Loss: 0.081875
Train Epoch: 70 [14080/35339 (40%)]	Loss: 0.098370
Train Epoch: 70 [14720/35339 (42%)]	Loss: 0.196691
Train Epoch: 70 [15360/35339 (43%)]	Loss: 0.079852
Train Epoch: 70 [16000/35339 (45%)]	Loss: 0.114034
Train Epoch: 70 [16640/35339 (47%)]	Loss: 0.071626
Train Epoch: 70 [17280/35339 (49%)]	Loss: 0.126730
Train Epoch: 70 [17920/35339 (51%)]	Loss: 0.122456
Train Epoch: 70 [18560/35339 (52%)]	Loss: 0.061042
Train Epoch: 70 [19200/35339 (54%)]	Loss: 0.113571
Train Epoch: 70 [19840/35339 (56%)]	Loss: 0.079875
Train Epoch: 70 [20480/35339 (58%)]	Loss: 0.099982
Train Epoch: 70 [21120/35339 (60%)]	Loss: 0.069253
Train Epoch: 70 [21760/35339 (61%)]	Loss: 0.122849
Train Epoch: 70 [22400/35339 (63%)]	Loss: 0.074134
Train Epoch: 70 [23040/35339 (65%)]	Loss: 0.123988
Train Epoch: 70 [23680/35339 (67%)]	Loss: 0.065334
Train Epoch: 70 [24320/35339 (69%)]	Loss: 0.076174
Train Epoch: 70 [24960/35339 (71%)]	Loss: 0.062567
Train Epoch: 70 [25600/35339 (72%)]	Loss: 0.094451
Train Epoch: 70 [26240/35339 (74%)]	Loss: 0.066335
Train Epoch: 70 [26880/35339 (76%)]	Loss: 0.103020
Train Epoch: 70 [27520/35339 (78%)]	Loss: 0.071682
Train Epoch: 70 [28160/35339 (80%)]	Loss: 0.095361
Train Epoch: 70 [28800/35339 (81%)]	Loss: 0.212271
Train Epoch: 70 [29440/35339 (83%)]	Loss: 0.136550
Train Epoch: 70 [30080/35339 (85%)]	Loss: 0.107750
Train Epoch: 70 [30720/35339 (87%)]	Loss: 0.079925
Train Epoch: 70 [31360/35339 (89%)]	Loss: 0.062405
Train Epoch: 70 [32000/35339 (90%)]	Loss: 0.232978
Train Epoch: 70 [32640/35339 (92%)]	Loss: 0.092409
Train Epoch: 70 [33280/35339 (94%)]	Loss: 0.067971
Train Epoch: 70 [33920/35339 (96%)]	Loss: 0.133813
Train Epoch: 70 [34560/35339 (98%)]	Loss: 0.138563
Train Epoch: 70 [35200/35339 (99%)]	Loss: 0.087799

Validation set: Average loss: 3.1798, Accuracy: 1373/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 71 [0/35339 (0%)]	Loss: 0.130467
Train Epoch: 71 [640/35339 (2%)]	Loss: 0.077905
Train Epoch: 71 [1280/35339 (4%)]	Loss: 0.107114
Train Epoch: 71 [1920/35339 (5%)]	Loss: 0.252623
Train Epoch: 71 [2560/35339 (7%)]	Loss: 0.102560
Train Epoch: 71 [3200/35339 (9%)]	Loss: 0.108120
Train Epoch: 71 [3840/35339 (11%)]	Loss: 0.069820
Train Epoch: 71 [4480/35339 (13%)]	Loss: 0.065639
Train Epoch: 71 [5120/35339 (14%)]	Loss: 0.060196
Train Epoch: 71 [5760/35339 (16%)]	Loss: 0.110888
Train Epoch: 71 [6400/35339 (18%)]	Loss: 0.081151
Train Epoch: 71 [7040/35339 (20%)]	Loss: 0.183033
Train Epoch: 71 [7680/35339 (22%)]	Loss: 0.071501
Train Epoch: 71 [8320/35339 (24%)]	Loss: 0.077489
Train Epoch: 71 [8960/35339 (25%)]	Loss: 0.097319
Train Epoch: 71 [9600/35339 (27%)]	Loss: 0.093111
Train Epoch: 71 [10240/35339 (29%)]	Loss: 0.105624
Train Epoch: 71 [10880/35339 (31%)]	Loss: 0.065893
Train Epoch: 71 [11520/35339 (33%)]	Loss: 0.112229
Train Epoch: 71 [12160/35339 (34%)]	Loss: 0.108640
Train Epoch: 71 [12800/35339 (36%)]	Loss: 0.071810
Train Epoch: 71 [13440/35339 (38%)]	Loss: 0.099675
Train Epoch: 71 [14080/35339 (40%)]	Loss: 0.123019
Train Epoch: 71 [14720/35339 (42%)]	Loss: 0.119041
Train Epoch: 71 [15360/35339 (43%)]	Loss: 0.074360
Train Epoch: 71 [16000/35339 (45%)]	Loss: 0.062782
Train Epoch: 71 [16640/35339 (47%)]	Loss: 0.098605
Train Epoch: 71 [17280/35339 (49%)]	Loss: 0.114737
Train Epoch: 71 [17920/35339 (51%)]	Loss: 0.066488
Train Epoch: 71 [18560/35339 (52%)]	Loss: 0.143739
Train Epoch: 71 [19200/35339 (54%)]	Loss: 0.095606
Train Epoch: 71 [19840/35339 (56%)]	Loss: 0.106782
Train Epoch: 71 [20480/35339 (58%)]	Loss: 0.153595
Train Epoch: 71 [21120/35339 (60%)]	Loss: 0.108769
Train Epoch: 71 [21760/35339 (61%)]	Loss: 0.071090
Train Epoch: 71 [22400/35339 (63%)]	Loss: 0.065204
Train Epoch: 71 [23040/35339 (65%)]	Loss: 0.061593
Train Epoch: 71 [23680/35339 (67%)]	Loss: 0.153698
Train Epoch: 71 [24320/35339 (69%)]	Loss: 0.078964
Train Epoch: 71 [24960/35339 (71%)]	Loss: 0.114393
Train Epoch: 71 [25600/35339 (72%)]	Loss: 0.064024
Train Epoch: 71 [26240/35339 (74%)]	Loss: 0.089301
Train Epoch: 71 [26880/35339 (76%)]	Loss: 0.070598
Train Epoch: 71 [27520/35339 (78%)]	Loss: 0.065455
Train Epoch: 71 [28160/35339 (80%)]	Loss: 0.070550
Train Epoch: 71 [28800/35339 (81%)]	Loss: 0.094789
Train Epoch: 71 [29440/35339 (83%)]	Loss: 0.155304
Train Epoch: 71 [30080/35339 (85%)]	Loss: 0.082247
Train Epoch: 71 [30720/35339 (87%)]	Loss: 0.057522
Train Epoch: 71 [31360/35339 (89%)]	Loss: 0.064486
Train Epoch: 71 [32000/35339 (90%)]	Loss: 0.081587
Train Epoch: 71 [32640/35339 (92%)]	Loss: 0.066331
Train Epoch: 71 [33280/35339 (94%)]	Loss: 0.066466
Train Epoch: 71 [33920/35339 (96%)]	Loss: 0.067017
Train Epoch: 71 [34560/35339 (98%)]	Loss: 0.076334
Train Epoch: 71 [35200/35339 (99%)]	Loss: 0.061541

Validation set: Average loss: 3.0816, Accuracy: 1407/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 72 [0/35339 (0%)]	Loss: 0.065078
Train Epoch: 72 [640/35339 (2%)]	Loss: 0.087961
Train Epoch: 72 [1280/35339 (4%)]	Loss: 0.060960
Train Epoch: 72 [1920/35339 (5%)]	Loss: 0.090374
Train Epoch: 72 [2560/35339 (7%)]	Loss: 0.098621
Train Epoch: 72 [3200/35339 (9%)]	Loss: 0.071715
Train Epoch: 72 [3840/35339 (11%)]	Loss: 0.070499
Train Epoch: 72 [4480/35339 (13%)]	Loss: 0.087461
Train Epoch: 72 [5120/35339 (14%)]	Loss: 0.071129
Train Epoch: 72 [5760/35339 (16%)]	Loss: 0.102122
Train Epoch: 72 [6400/35339 (18%)]	Loss: 0.083086
Train Epoch: 72 [7040/35339 (20%)]	Loss: 0.067916
Train Epoch: 72 [7680/35339 (22%)]	Loss: 0.105829
Train Epoch: 72 [8320/35339 (24%)]	Loss: 0.159333
Train Epoch: 72 [8960/35339 (25%)]	Loss: 0.150001
Train Epoch: 72 [9600/35339 (27%)]	Loss: 0.083251
Train Epoch: 72 [10240/35339 (29%)]	Loss: 0.064898
Train Epoch: 72 [10880/35339 (31%)]	Loss: 0.112687
Train Epoch: 72 [11520/35339 (33%)]	Loss: 0.201130
Train Epoch: 72 [12160/35339 (34%)]	Loss: 0.108076
Train Epoch: 72 [12800/35339 (36%)]	Loss: 0.096855
Train Epoch: 72 [13440/35339 (38%)]	Loss: 0.107002
Train Epoch: 72 [14080/35339 (40%)]	Loss: 0.063077
Train Epoch: 72 [14720/35339 (42%)]	Loss: 0.112703
Train Epoch: 72 [15360/35339 (43%)]	Loss: 0.120758
Train Epoch: 72 [16000/35339 (45%)]	Loss: 0.070987
Train Epoch: 72 [16640/35339 (47%)]	Loss: 0.073430
Train Epoch: 72 [17280/35339 (49%)]	Loss: 0.072273
Train Epoch: 72 [17920/35339 (51%)]	Loss: 0.066624
Train Epoch: 72 [18560/35339 (52%)]	Loss: 0.076927
Train Epoch: 72 [19200/35339 (54%)]	Loss: 0.069087
Train Epoch: 72 [19840/35339 (56%)]	Loss: 0.119840
Train Epoch: 72 [20480/35339 (58%)]	Loss: 0.110305
Train Epoch: 72 [21120/35339 (60%)]	Loss: 0.064063
Train Epoch: 72 [21760/35339 (61%)]	Loss: 0.097360
Train Epoch: 72 [22400/35339 (63%)]	Loss: 0.077156
Train Epoch: 72 [23040/35339 (65%)]	Loss: 0.112517
Train Epoch: 72 [23680/35339 (67%)]	Loss: 0.232371
Train Epoch: 72 [24320/35339 (69%)]	Loss: 0.118391
Train Epoch: 72 [24960/35339 (71%)]	Loss: 0.063293
Train Epoch: 72 [25600/35339 (72%)]	Loss: 0.131270
Train Epoch: 72 [26240/35339 (74%)]	Loss: 0.073559
Train Epoch: 72 [26880/35339 (76%)]	Loss: 0.066054
Train Epoch: 72 [27520/35339 (78%)]	Loss: 0.111149
Train Epoch: 72 [28160/35339 (80%)]	Loss: 0.097278
Train Epoch: 72 [28800/35339 (81%)]	Loss: 0.117995
Train Epoch: 72 [29440/35339 (83%)]	Loss: 0.093460
Train Epoch: 72 [30080/35339 (85%)]	Loss: 0.064833
Train Epoch: 72 [30720/35339 (87%)]	Loss: 0.081534
Train Epoch: 72 [31360/35339 (89%)]	Loss: 0.061741
Train Epoch: 72 [32000/35339 (90%)]	Loss: 0.078979
Train Epoch: 72 [32640/35339 (92%)]	Loss: 0.166492
Train Epoch: 72 [33280/35339 (94%)]	Loss: 0.086683
Train Epoch: 72 [33920/35339 (96%)]	Loss: 0.172817
Train Epoch: 72 [34560/35339 (98%)]	Loss: 0.081653
Train Epoch: 72 [35200/35339 (99%)]	Loss: 0.117694

Validation set: Average loss: 3.1727, Accuracy: 1378/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 73 [0/35339 (0%)]	Loss: 0.079749
Train Epoch: 73 [640/35339 (2%)]	Loss: 0.063088
Train Epoch: 73 [1280/35339 (4%)]	Loss: 0.105935
Train Epoch: 73 [1920/35339 (5%)]	Loss: 0.179842
Train Epoch: 73 [2560/35339 (7%)]	Loss: 0.117459
Train Epoch: 73 [3200/35339 (9%)]	Loss: 0.081709
Train Epoch: 73 [3840/35339 (11%)]	Loss: 0.106614
Train Epoch: 73 [4480/35339 (13%)]	Loss: 0.097696
Train Epoch: 73 [5120/35339 (14%)]	Loss: 0.097867
Train Epoch: 73 [5760/35339 (16%)]	Loss: 0.086594
Train Epoch: 73 [6400/35339 (18%)]	Loss: 0.066719
Train Epoch: 73 [7040/35339 (20%)]	Loss: 0.125149
Train Epoch: 73 [7680/35339 (22%)]	Loss: 0.082082
Train Epoch: 73 [8320/35339 (24%)]	Loss: 0.111836
Train Epoch: 73 [8960/35339 (25%)]	Loss: 0.067282
Train Epoch: 73 [9600/35339 (27%)]	Loss: 0.138013
Train Epoch: 73 [10240/35339 (29%)]	Loss: 0.093644
Train Epoch: 73 [10880/35339 (31%)]	Loss: 0.108329
Train Epoch: 73 [11520/35339 (33%)]	Loss: 0.187105
Train Epoch: 73 [12160/35339 (34%)]	Loss: 0.216855
Train Epoch: 73 [12800/35339 (36%)]	Loss: 0.060902
Train Epoch: 73 [13440/35339 (38%)]	Loss: 0.110787
Train Epoch: 73 [14080/35339 (40%)]	Loss: 0.118163
Train Epoch: 73 [14720/35339 (42%)]	Loss: 0.115356
Train Epoch: 73 [15360/35339 (43%)]	Loss: 0.133445
Train Epoch: 73 [16000/35339 (45%)]	Loss: 0.159983
Train Epoch: 73 [16640/35339 (47%)]	Loss: 0.196654
Train Epoch: 73 [17280/35339 (49%)]	Loss: 0.065003
Train Epoch: 73 [17920/35339 (51%)]	Loss: 0.148926
Train Epoch: 73 [18560/35339 (52%)]	Loss: 0.228400
Train Epoch: 73 [19200/35339 (54%)]	Loss: 0.096562
Train Epoch: 73 [19840/35339 (56%)]	Loss: 0.064488
Train Epoch: 73 [20480/35339 (58%)]	Loss: 0.095274
Train Epoch: 73 [21120/35339 (60%)]	Loss: 0.091228
Train Epoch: 73 [21760/35339 (61%)]	Loss: 0.123859
Train Epoch: 73 [22400/35339 (63%)]	Loss: 0.091753
Train Epoch: 73 [23040/35339 (65%)]	Loss: 0.162131
Train Epoch: 73 [23680/35339 (67%)]	Loss: 0.148275
Train Epoch: 73 [24320/35339 (69%)]	Loss: 0.123654
Train Epoch: 73 [24960/35339 (71%)]	Loss: 0.121763
Train Epoch: 73 [25600/35339 (72%)]	Loss: 0.064277
Train Epoch: 73 [26240/35339 (74%)]	Loss: 0.115990
Train Epoch: 73 [26880/35339 (76%)]	Loss: 0.067584
Train Epoch: 73 [27520/35339 (78%)]	Loss: 0.072471
Train Epoch: 73 [28160/35339 (80%)]	Loss: 0.134850
Train Epoch: 73 [28800/35339 (81%)]	Loss: 0.117766
Train Epoch: 73 [29440/35339 (83%)]	Loss: 0.092857
Train Epoch: 73 [30080/35339 (85%)]	Loss: 0.068280
Train Epoch: 73 [30720/35339 (87%)]	Loss: 0.069160
Train Epoch: 73 [31360/35339 (89%)]	Loss: 0.201103
Train Epoch: 73 [32000/35339 (90%)]	Loss: 0.077900
Train Epoch: 73 [32640/35339 (92%)]	Loss: 0.131612
Train Epoch: 73 [33280/35339 (94%)]	Loss: 0.121752
Train Epoch: 73 [33920/35339 (96%)]	Loss: 0.119120
Train Epoch: 73 [34560/35339 (98%)]	Loss: 0.109557
Train Epoch: 73 [35200/35339 (99%)]	Loss: 0.063551

Validation set: Average loss: 3.1896, Accuracy: 1423/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 74 [0/35339 (0%)]	Loss: 0.062759
Train Epoch: 74 [640/35339 (2%)]	Loss: 0.083304
Train Epoch: 74 [1280/35339 (4%)]	Loss: 0.086205
Train Epoch: 74 [1920/35339 (5%)]	Loss: 0.081573
Train Epoch: 74 [2560/35339 (7%)]	Loss: 0.092223
Train Epoch: 74 [3200/35339 (9%)]	Loss: 0.118106
Train Epoch: 74 [3840/35339 (11%)]	Loss: 0.094760
Train Epoch: 74 [4480/35339 (13%)]	Loss: 0.069123
Train Epoch: 74 [5120/35339 (14%)]	Loss: 0.118863
Train Epoch: 74 [5760/35339 (16%)]	Loss: 0.124310
Train Epoch: 74 [6400/35339 (18%)]	Loss: 0.063574
Train Epoch: 74 [7040/35339 (20%)]	Loss: 0.113595
Train Epoch: 74 [7680/35339 (22%)]	Loss: 0.107440
Train Epoch: 74 [8320/35339 (24%)]	Loss: 0.106833
Train Epoch: 74 [8960/35339 (25%)]	Loss: 0.098545
Train Epoch: 74 [9600/35339 (27%)]	Loss: 0.077663
Train Epoch: 74 [10240/35339 (29%)]	Loss: 0.118054
Train Epoch: 74 [10880/35339 (31%)]	Loss: 0.119168
Train Epoch: 74 [11520/35339 (33%)]	Loss: 0.103507
Train Epoch: 74 [12160/35339 (34%)]	Loss: 0.195389
Train Epoch: 74 [12800/35339 (36%)]	Loss: 0.073940
Train Epoch: 74 [13440/35339 (38%)]	Loss: 0.110155
Train Epoch: 74 [14080/35339 (40%)]	Loss: 0.102715
Train Epoch: 74 [14720/35339 (42%)]	Loss: 0.164042
Train Epoch: 74 [15360/35339 (43%)]	Loss: 0.089024
Train Epoch: 74 [16000/35339 (45%)]	Loss: 0.064429
Train Epoch: 74 [16640/35339 (47%)]	Loss: 0.135910
Train Epoch: 74 [17280/35339 (49%)]	Loss: 0.356276
Train Epoch: 74 [17920/35339 (51%)]	Loss: 0.107011
Train Epoch: 74 [18560/35339 (52%)]	Loss: 0.109355
Train Epoch: 74 [19200/35339 (54%)]	Loss: 0.100653
Train Epoch: 74 [19840/35339 (56%)]	Loss: 0.086505
Train Epoch: 74 [20480/35339 (58%)]	Loss: 0.148129
Train Epoch: 74 [21120/35339 (60%)]	Loss: 0.154554
Train Epoch: 74 [21760/35339 (61%)]	Loss: 0.082599
Train Epoch: 74 [22400/35339 (63%)]	Loss: 0.060243
Train Epoch: 74 [23040/35339 (65%)]	Loss: 0.096312
Train Epoch: 74 [23680/35339 (67%)]	Loss: 0.088711
Train Epoch: 74 [24320/35339 (69%)]	Loss: 0.085689
Train Epoch: 74 [24960/35339 (71%)]	Loss: 0.158953
Train Epoch: 74 [25600/35339 (72%)]	Loss: 0.111262
Train Epoch: 74 [26240/35339 (74%)]	Loss: 0.121903
Train Epoch: 74 [26880/35339 (76%)]	Loss: 0.086019
Train Epoch: 74 [27520/35339 (78%)]	Loss: 0.112749
Train Epoch: 74 [28160/35339 (80%)]	Loss: 0.096672
Train Epoch: 74 [28800/35339 (81%)]	Loss: 0.079833
Train Epoch: 74 [29440/35339 (83%)]	Loss: 0.059640
Train Epoch: 74 [30080/35339 (85%)]	Loss: 0.132067
Train Epoch: 74 [30720/35339 (87%)]	Loss: 0.111225
Train Epoch: 74 [31360/35339 (89%)]	Loss: 0.119170
Train Epoch: 74 [32000/35339 (90%)]	Loss: 0.091964
Train Epoch: 74 [32640/35339 (92%)]	Loss: 0.070689
Train Epoch: 74 [33280/35339 (94%)]	Loss: 0.188715
Train Epoch: 74 [33920/35339 (96%)]	Loss: 0.096883
Train Epoch: 74 [34560/35339 (98%)]	Loss: 0.084752
Train Epoch: 74 [35200/35339 (99%)]	Loss: 0.068835

Validation set: Average loss: 3.0938, Accuracy: 1451/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 75 [0/35339 (0%)]	Loss: 0.182973
Train Epoch: 75 [640/35339 (2%)]	Loss: 0.120293
Train Epoch: 75 [1280/35339 (4%)]	Loss: 0.110415
Train Epoch: 75 [1920/35339 (5%)]	Loss: 0.068104
Train Epoch: 75 [2560/35339 (7%)]	Loss: 0.109573
Train Epoch: 75 [3200/35339 (9%)]	Loss: 0.082976
Train Epoch: 75 [3840/35339 (11%)]	Loss: 0.108749
Train Epoch: 75 [4480/35339 (13%)]	Loss: 0.128646
Train Epoch: 75 [5120/35339 (14%)]	Loss: 0.101616
Train Epoch: 75 [5760/35339 (16%)]	Loss: 0.088640
Train Epoch: 75 [6400/35339 (18%)]	Loss: 0.088160
Train Epoch: 75 [7040/35339 (20%)]	Loss: 0.089241
Train Epoch: 75 [7680/35339 (22%)]	Loss: 0.064973
Train Epoch: 75 [8320/35339 (24%)]	Loss: 0.074906
Train Epoch: 75 [8960/35339 (25%)]	Loss: 0.083388
Train Epoch: 75 [9600/35339 (27%)]	Loss: 0.109146
Train Epoch: 75 [10240/35339 (29%)]	Loss: 0.061034
Train Epoch: 75 [10880/35339 (31%)]	Loss: 0.117156
Train Epoch: 75 [11520/35339 (33%)]	Loss: 0.140665
Train Epoch: 75 [12160/35339 (34%)]	Loss: 0.094782
Train Epoch: 75 [12800/35339 (36%)]	Loss: 0.083743
Train Epoch: 75 [13440/35339 (38%)]	Loss: 0.202658
Train Epoch: 75 [14080/35339 (40%)]	Loss: 0.127151
Train Epoch: 75 [14720/35339 (42%)]	Loss: 0.134831
Train Epoch: 75 [15360/35339 (43%)]	Loss: 0.067276
Train Epoch: 75 [16000/35339 (45%)]	Loss: 0.119313
Train Epoch: 75 [16640/35339 (47%)]	Loss: 0.074116
Train Epoch: 75 [17280/35339 (49%)]	Loss: 0.058166
Train Epoch: 75 [17920/35339 (51%)]	Loss: 0.065786
Train Epoch: 75 [18560/35339 (52%)]	Loss: 0.079285
Train Epoch: 75 [19200/35339 (54%)]	Loss: 0.218025
Train Epoch: 75 [19840/35339 (56%)]	Loss: 0.177945
Train Epoch: 75 [20480/35339 (58%)]	Loss: 0.067519
Train Epoch: 75 [21120/35339 (60%)]	Loss: 0.104969
Train Epoch: 75 [21760/35339 (61%)]	Loss: 0.111750
Train Epoch: 75 [22400/35339 (63%)]	Loss: 0.200122
Train Epoch: 75 [23040/35339 (65%)]	Loss: 0.111334
Train Epoch: 75 [23680/35339 (67%)]	Loss: 0.097233
Train Epoch: 75 [24320/35339 (69%)]	Loss: 0.100363
Train Epoch: 75 [24960/35339 (71%)]	Loss: 0.084701
Train Epoch: 75 [25600/35339 (72%)]	Loss: 0.071776
Train Epoch: 75 [26240/35339 (74%)]	Loss: 0.095451
Train Epoch: 75 [26880/35339 (76%)]	Loss: 0.105833
Train Epoch: 75 [27520/35339 (78%)]	Loss: 0.206186
Train Epoch: 75 [28160/35339 (80%)]	Loss: 0.087818
Train Epoch: 75 [28800/35339 (81%)]	Loss: 0.085724
Train Epoch: 75 [29440/35339 (83%)]	Loss: 0.136558
Train Epoch: 75 [30080/35339 (85%)]	Loss: 0.134696
Train Epoch: 75 [30720/35339 (87%)]	Loss: 0.228275
Train Epoch: 75 [31360/35339 (89%)]	Loss: 0.117108
Train Epoch: 75 [32000/35339 (90%)]	Loss: 0.142964
Train Epoch: 75 [32640/35339 (92%)]	Loss: 0.106889
Train Epoch: 75 [33280/35339 (94%)]	Loss: 0.071749
Train Epoch: 75 [33920/35339 (96%)]	Loss: 0.115442
Train Epoch: 75 [34560/35339 (98%)]	Loss: 0.094793
Train Epoch: 75 [35200/35339 (99%)]	Loss: 0.095509

Validation set: Average loss: 2.9815, Accuracy: 1525/3870 (39%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 76 [0/35339 (0%)]	Loss: 0.070064
Train Epoch: 76 [640/35339 (2%)]	Loss: 0.112463
Train Epoch: 76 [1280/35339 (4%)]	Loss: 0.077754
Train Epoch: 76 [1920/35339 (5%)]	Loss: 0.120544
Train Epoch: 76 [2560/35339 (7%)]	Loss: 0.064786
Train Epoch: 76 [3200/35339 (9%)]	Loss: 0.060787
Train Epoch: 76 [3840/35339 (11%)]	Loss: 0.141826
Train Epoch: 76 [4480/35339 (13%)]	Loss: 0.081335
Train Epoch: 76 [5120/35339 (14%)]	Loss: 0.075221
Train Epoch: 76 [5760/35339 (16%)]	Loss: 0.068814
Train Epoch: 76 [6400/35339 (18%)]	Loss: 0.093999
Train Epoch: 76 [7040/35339 (20%)]	Loss: 0.090168
Train Epoch: 76 [7680/35339 (22%)]	Loss: 0.131166
Train Epoch: 76 [8320/35339 (24%)]	Loss: 0.095242
Train Epoch: 76 [8960/35339 (25%)]	Loss: 0.072665
Train Epoch: 76 [9600/35339 (27%)]	Loss: 0.200734
Train Epoch: 76 [10240/35339 (29%)]	Loss: 0.065651
Train Epoch: 76 [10880/35339 (31%)]	Loss: 0.061298
Train Epoch: 76 [11520/35339 (33%)]	Loss: 0.181334
Train Epoch: 76 [12160/35339 (34%)]	Loss: 0.091176
Train Epoch: 76 [12800/35339 (36%)]	Loss: 0.094594
Train Epoch: 76 [13440/35339 (38%)]	Loss: 0.077015
Train Epoch: 76 [14080/35339 (40%)]	Loss: 0.084169
Train Epoch: 76 [14720/35339 (42%)]	Loss: 0.122571
Train Epoch: 76 [15360/35339 (43%)]	Loss: 0.148157
Train Epoch: 76 [16000/35339 (45%)]	Loss: 0.059897
Train Epoch: 76 [16640/35339 (47%)]	Loss: 0.065775
Train Epoch: 76 [17280/35339 (49%)]	Loss: 0.088018
Train Epoch: 76 [17920/35339 (51%)]	Loss: 0.133731
Train Epoch: 76 [18560/35339 (52%)]	Loss: 0.106065
Train Epoch: 76 [19200/35339 (54%)]	Loss: 0.080983
Train Epoch: 76 [19840/35339 (56%)]	Loss: 0.107497
Train Epoch: 76 [20480/35339 (58%)]	Loss: 0.080437
Train Epoch: 76 [21120/35339 (60%)]	Loss: 0.063243
Train Epoch: 76 [21760/35339 (61%)]	Loss: 0.095833
Train Epoch: 76 [22400/35339 (63%)]	Loss: 0.121639
Train Epoch: 76 [23040/35339 (65%)]	Loss: 0.173635
Train Epoch: 76 [23680/35339 (67%)]	Loss: 0.108234
Train Epoch: 76 [24320/35339 (69%)]	Loss: 0.071980
Train Epoch: 76 [24960/35339 (71%)]	Loss: 0.113195
Train Epoch: 76 [25600/35339 (72%)]	Loss: 0.109287
Train Epoch: 76 [26240/35339 (74%)]	Loss: 0.096516
Train Epoch: 76 [26880/35339 (76%)]	Loss: 0.075527
Train Epoch: 76 [27520/35339 (78%)]	Loss: 0.129865
Train Epoch: 76 [28160/35339 (80%)]	Loss: 0.077876
Train Epoch: 76 [28800/35339 (81%)]	Loss: 0.104832
Train Epoch: 76 [29440/35339 (83%)]	Loss: 0.084324
Train Epoch: 76 [30080/35339 (85%)]	Loss: 0.064919
Train Epoch: 76 [30720/35339 (87%)]	Loss: 0.096943
Train Epoch: 76 [31360/35339 (89%)]	Loss: 0.296719
Train Epoch: 76 [32000/35339 (90%)]	Loss: 0.140255
Train Epoch: 76 [32640/35339 (92%)]	Loss: 0.091804
Train Epoch: 76 [33280/35339 (94%)]	Loss: 0.153649
Train Epoch: 76 [33920/35339 (96%)]	Loss: 0.108274
Train Epoch: 76 [34560/35339 (98%)]	Loss: 0.103750
Train Epoch: 76 [35200/35339 (99%)]	Loss: 0.063467

Validation set: Average loss: 3.1710, Accuracy: 1375/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 77 [0/35339 (0%)]	Loss: 0.080407
Train Epoch: 77 [640/35339 (2%)]	Loss: 0.088583
Train Epoch: 77 [1280/35339 (4%)]	Loss: 0.167909
Train Epoch: 77 [1920/35339 (5%)]	Loss: 0.085539
Train Epoch: 77 [2560/35339 (7%)]	Loss: 0.067395
Train Epoch: 77 [3200/35339 (9%)]	Loss: 0.130345
Train Epoch: 77 [3840/35339 (11%)]	Loss: 0.289342
Train Epoch: 77 [4480/35339 (13%)]	Loss: 0.106579
Train Epoch: 77 [5120/35339 (14%)]	Loss: 0.089242
Train Epoch: 77 [5760/35339 (16%)]	Loss: 0.121529
Train Epoch: 77 [6400/35339 (18%)]	Loss: 0.104461
Train Epoch: 77 [7040/35339 (20%)]	Loss: 0.127477
Train Epoch: 77 [7680/35339 (22%)]	Loss: 0.149814
Train Epoch: 77 [8320/35339 (24%)]	Loss: 0.112860
Train Epoch: 77 [8960/35339 (25%)]	Loss: 0.093536
Train Epoch: 77 [9600/35339 (27%)]	Loss: 0.079718
Train Epoch: 77 [10240/35339 (29%)]	Loss: 0.078636
Train Epoch: 77 [10880/35339 (31%)]	Loss: 0.104705
Train Epoch: 77 [11520/35339 (33%)]	Loss: 0.194006
Train Epoch: 77 [12160/35339 (34%)]	Loss: 0.065402
Train Epoch: 77 [12800/35339 (36%)]	Loss: 0.068519
Train Epoch: 77 [13440/35339 (38%)]	Loss: 0.086629
Train Epoch: 77 [14080/35339 (40%)]	Loss: 0.192443
Train Epoch: 77 [14720/35339 (42%)]	Loss: 0.180737
Train Epoch: 77 [15360/35339 (43%)]	Loss: 0.071041
Train Epoch: 77 [16000/35339 (45%)]	Loss: 0.062585
Train Epoch: 77 [16640/35339 (47%)]	Loss: 0.067776
Train Epoch: 77 [17280/35339 (49%)]	Loss: 0.060639
Train Epoch: 77 [17920/35339 (51%)]	Loss: 0.117589
Train Epoch: 77 [18560/35339 (52%)]	Loss: 0.193982
Train Epoch: 77 [19200/35339 (54%)]	Loss: 0.092306
Train Epoch: 77 [19840/35339 (56%)]	Loss: 0.132601
Train Epoch: 77 [20480/35339 (58%)]	Loss: 0.073257
Train Epoch: 77 [21120/35339 (60%)]	Loss: 0.104394
Train Epoch: 77 [21760/35339 (61%)]	Loss: 0.123092
Train Epoch: 77 [22400/35339 (63%)]	Loss: 0.110804
Train Epoch: 77 [23040/35339 (65%)]	Loss: 0.071313
Train Epoch: 77 [23680/35339 (67%)]	Loss: 0.131027
Train Epoch: 77 [24320/35339 (69%)]	Loss: 0.107288
Train Epoch: 77 [24960/35339 (71%)]	Loss: 0.088900
Train Epoch: 77 [25600/35339 (72%)]	Loss: 0.159676
Train Epoch: 77 [26240/35339 (74%)]	Loss: 0.122038
Train Epoch: 77 [26880/35339 (76%)]	Loss: 0.170640
Train Epoch: 77 [27520/35339 (78%)]	Loss: 0.105552
Train Epoch: 77 [28160/35339 (80%)]	Loss: 0.072525
Train Epoch: 77 [28800/35339 (81%)]	Loss: 0.088366
Train Epoch: 77 [29440/35339 (83%)]	Loss: 0.060825
Train Epoch: 77 [30080/35339 (85%)]	Loss: 0.106962
Train Epoch: 77 [30720/35339 (87%)]	Loss: 0.071293
Train Epoch: 77 [31360/35339 (89%)]	Loss: 0.109802
Train Epoch: 77 [32000/35339 (90%)]	Loss: 0.075951
Train Epoch: 77 [32640/35339 (92%)]	Loss: 0.050437
Train Epoch: 77 [33280/35339 (94%)]	Loss: 0.118637
Train Epoch: 77 [33920/35339 (96%)]	Loss: 0.071386
Train Epoch: 77 [34560/35339 (98%)]	Loss: 0.140171
Train Epoch: 77 [35200/35339 (99%)]	Loss: 0.103880

Validation set: Average loss: 3.2601, Accuracy: 1341/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 78 [0/35339 (0%)]	Loss: 0.086607
Train Epoch: 78 [640/35339 (2%)]	Loss: 0.062991
Train Epoch: 78 [1280/35339 (4%)]	Loss: 0.131305
Train Epoch: 78 [1920/35339 (5%)]	Loss: 0.098363
Train Epoch: 78 [2560/35339 (7%)]	Loss: 0.090121
Train Epoch: 78 [3200/35339 (9%)]	Loss: 0.094361
Train Epoch: 78 [3840/35339 (11%)]	Loss: 0.068975
Train Epoch: 78 [4480/35339 (13%)]	Loss: 0.080697
Train Epoch: 78 [5120/35339 (14%)]	Loss: 0.071063
Train Epoch: 78 [5760/35339 (16%)]	Loss: 0.092520
Train Epoch: 78 [6400/35339 (18%)]	Loss: 0.088376
Train Epoch: 78 [7040/35339 (20%)]	Loss: 0.106600
Train Epoch: 78 [7680/35339 (22%)]	Loss: 0.093196
Train Epoch: 78 [8320/35339 (24%)]	Loss: 0.078345
Train Epoch: 78 [8960/35339 (25%)]	Loss: 0.080210
Train Epoch: 78 [9600/35339 (27%)]	Loss: 0.208184
Train Epoch: 78 [10240/35339 (29%)]	Loss: 0.104802
Train Epoch: 78 [10880/35339 (31%)]	Loss: 0.057131
Train Epoch: 78 [11520/35339 (33%)]	Loss: 0.063616
Train Epoch: 78 [12160/35339 (34%)]	Loss: 0.123638
Train Epoch: 78 [12800/35339 (36%)]	Loss: 0.082311
Train Epoch: 78 [13440/35339 (38%)]	Loss: 0.079398
Train Epoch: 78 [14080/35339 (40%)]	Loss: 0.081284
Train Epoch: 78 [14720/35339 (42%)]	Loss: 0.117452
Train Epoch: 78 [15360/35339 (43%)]	Loss: 0.108440
Train Epoch: 78 [16000/35339 (45%)]	Loss: 0.123195
Train Epoch: 78 [16640/35339 (47%)]	Loss: 0.063429
Train Epoch: 78 [17280/35339 (49%)]	Loss: 0.093606
Train Epoch: 78 [17920/35339 (51%)]	Loss: 0.098657
Train Epoch: 78 [18560/35339 (52%)]	Loss: 0.074857
Train Epoch: 78 [19200/35339 (54%)]	Loss: 0.099386
Train Epoch: 78 [19840/35339 (56%)]	Loss: 0.105755
Train Epoch: 78 [20480/35339 (58%)]	Loss: 0.102946
Train Epoch: 78 [21120/35339 (60%)]	Loss: 0.061012
Train Epoch: 78 [21760/35339 (61%)]	Loss: 0.060474
Train Epoch: 78 [22400/35339 (63%)]	Loss: 0.141214
Train Epoch: 78 [23040/35339 (65%)]	Loss: 0.094483
Train Epoch: 78 [23680/35339 (67%)]	Loss: 0.098617
Train Epoch: 78 [24320/35339 (69%)]	Loss: 0.110776
Train Epoch: 78 [24960/35339 (71%)]	Loss: 0.103161
Train Epoch: 78 [25600/35339 (72%)]	Loss: 0.066542
Train Epoch: 78 [26240/35339 (74%)]	Loss: 0.111046
Train Epoch: 78 [26880/35339 (76%)]	Loss: 0.063374
Train Epoch: 78 [27520/35339 (78%)]	Loss: 0.083896
Train Epoch: 78 [28160/35339 (80%)]	Loss: 0.148792
Train Epoch: 78 [28800/35339 (81%)]	Loss: 0.127603
Train Epoch: 78 [29440/35339 (83%)]	Loss: 0.096003
Train Epoch: 78 [30080/35339 (85%)]	Loss: 0.181997
Train Epoch: 78 [30720/35339 (87%)]	Loss: 0.073115
Train Epoch: 78 [31360/35339 (89%)]	Loss: 0.113224
Train Epoch: 78 [32000/35339 (90%)]	Loss: 0.183533
Train Epoch: 78 [32640/35339 (92%)]	Loss: 0.085686
Train Epoch: 78 [33280/35339 (94%)]	Loss: 0.122877
Train Epoch: 78 [33920/35339 (96%)]	Loss: 0.076256
Train Epoch: 78 [34560/35339 (98%)]	Loss: 0.089968
Train Epoch: 78 [35200/35339 (99%)]	Loss: 0.085463

Validation set: Average loss: 3.0689, Accuracy: 1491/3870 (39%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 79 [0/35339 (0%)]	Loss: 0.065404
Train Epoch: 79 [640/35339 (2%)]	Loss: 0.089212
Train Epoch: 79 [1280/35339 (4%)]	Loss: 0.161708
Train Epoch: 79 [1920/35339 (5%)]	Loss: 0.119738
Train Epoch: 79 [2560/35339 (7%)]	Loss: 0.089658
Train Epoch: 79 [3200/35339 (9%)]	Loss: 0.099082
Train Epoch: 79 [3840/35339 (11%)]	Loss: 0.077378
Train Epoch: 79 [4480/35339 (13%)]	Loss: 0.139059
Train Epoch: 79 [5120/35339 (14%)]	Loss: 0.076026
Train Epoch: 79 [5760/35339 (16%)]	Loss: 0.068881
Train Epoch: 79 [6400/35339 (18%)]	Loss: 0.064576
Train Epoch: 79 [7040/35339 (20%)]	Loss: 0.080773
Train Epoch: 79 [7680/35339 (22%)]	Loss: 0.060659
Train Epoch: 79 [8320/35339 (24%)]	Loss: 0.072700
Train Epoch: 79 [8960/35339 (25%)]	Loss: 0.080379
Train Epoch: 79 [9600/35339 (27%)]	Loss: 0.177011
Train Epoch: 79 [10240/35339 (29%)]	Loss: 0.152218
Train Epoch: 79 [10880/35339 (31%)]	Loss: 0.131062
Train Epoch: 79 [11520/35339 (33%)]	Loss: 0.101213
Train Epoch: 79 [12160/35339 (34%)]	Loss: 0.101463
Train Epoch: 79 [12800/35339 (36%)]	Loss: 0.077968
Train Epoch: 79 [13440/35339 (38%)]	Loss: 0.083273
Train Epoch: 79 [14080/35339 (40%)]	Loss: 0.082711
Train Epoch: 79 [14720/35339 (42%)]	Loss: 0.212786
Train Epoch: 79 [15360/35339 (43%)]	Loss: 0.080208
Train Epoch: 79 [16000/35339 (45%)]	Loss: 0.131903
Train Epoch: 79 [16640/35339 (47%)]	Loss: 0.086591
Train Epoch: 79 [17280/35339 (49%)]	Loss: 0.128946
Train Epoch: 79 [17920/35339 (51%)]	Loss: 0.124249
Train Epoch: 79 [18560/35339 (52%)]	Loss: 0.172135
Train Epoch: 79 [19200/35339 (54%)]	Loss: 0.064004
Train Epoch: 79 [19840/35339 (56%)]	Loss: 0.058994
Train Epoch: 79 [20480/35339 (58%)]	Loss: 0.112245
Train Epoch: 79 [21120/35339 (60%)]	Loss: 0.094269
Train Epoch: 79 [21760/35339 (61%)]	Loss: 0.133104
Train Epoch: 79 [22400/35339 (63%)]	Loss: 0.125078
Train Epoch: 79 [23040/35339 (65%)]	Loss: 0.173424
Train Epoch: 79 [23680/35339 (67%)]	Loss: 0.077129
Train Epoch: 79 [24320/35339 (69%)]	Loss: 0.083903
Train Epoch: 79 [24960/35339 (71%)]	Loss: 0.071639
Train Epoch: 79 [25600/35339 (72%)]	Loss: 0.075608
Train Epoch: 79 [26240/35339 (74%)]	Loss: 0.117732
Train Epoch: 79 [26880/35339 (76%)]	Loss: 0.062733
Train Epoch: 79 [27520/35339 (78%)]	Loss: 0.109409
Train Epoch: 79 [28160/35339 (80%)]	Loss: 0.061983
Train Epoch: 79 [28800/35339 (81%)]	Loss: 0.088594
Train Epoch: 79 [29440/35339 (83%)]	Loss: 0.065054
Train Epoch: 79 [30080/35339 (85%)]	Loss: 0.095679
Train Epoch: 79 [30720/35339 (87%)]	Loss: 0.065647
Train Epoch: 79 [31360/35339 (89%)]	Loss: 0.094416
Train Epoch: 79 [32000/35339 (90%)]	Loss: 0.059541
Train Epoch: 79 [32640/35339 (92%)]	Loss: 0.113265
Train Epoch: 79 [33280/35339 (94%)]	Loss: 0.129002
Train Epoch: 79 [33920/35339 (96%)]	Loss: 0.082499
Train Epoch: 79 [34560/35339 (98%)]	Loss: 0.085205
Train Epoch: 79 [35200/35339 (99%)]	Loss: 0.148017

Validation set: Average loss: 3.1603, Accuracy: 1393/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 80 [0/35339 (0%)]	Loss: 0.091287
Train Epoch: 80 [640/35339 (2%)]	Loss: 0.066073
Train Epoch: 80 [1280/35339 (4%)]	Loss: 0.098974
Train Epoch: 80 [1920/35339 (5%)]	Loss: 0.115164
Train Epoch: 80 [2560/35339 (7%)]	Loss: 0.090190
Train Epoch: 80 [3200/35339 (9%)]	Loss: 0.101065
Train Epoch: 80 [3840/35339 (11%)]	Loss: 0.104382
Train Epoch: 80 [4480/35339 (13%)]	Loss: 0.119234
Train Epoch: 80 [5120/35339 (14%)]	Loss: 0.130126
Train Epoch: 80 [5760/35339 (16%)]	Loss: 0.099783
Train Epoch: 80 [6400/35339 (18%)]	Loss: 0.099383
Train Epoch: 80 [7040/35339 (20%)]	Loss: 0.107080
Train Epoch: 80 [7680/35339 (22%)]	Loss: 0.130621
Train Epoch: 80 [8320/35339 (24%)]	Loss: 0.091841
Train Epoch: 80 [8960/35339 (25%)]	Loss: 0.186747
Train Epoch: 80 [9600/35339 (27%)]	Loss: 0.139119
Train Epoch: 80 [10240/35339 (29%)]	Loss: 0.075538
Train Epoch: 80 [10880/35339 (31%)]	Loss: 0.083245
Train Epoch: 80 [11520/35339 (33%)]	Loss: 0.073980
Train Epoch: 80 [12160/35339 (34%)]	Loss: 0.060434
Train Epoch: 80 [12800/35339 (36%)]	Loss: 0.063526
Train Epoch: 80 [13440/35339 (38%)]	Loss: 0.116253
Train Epoch: 80 [14080/35339 (40%)]	Loss: 0.062855
Train Epoch: 80 [14720/35339 (42%)]	Loss: 0.076536
Train Epoch: 80 [15360/35339 (43%)]	Loss: 0.072906
Train Epoch: 80 [16000/35339 (45%)]	Loss: 0.063142
Train Epoch: 80 [16640/35339 (47%)]	Loss: 0.138745
Train Epoch: 80 [17280/35339 (49%)]	Loss: 0.094147
Train Epoch: 80 [17920/35339 (51%)]	Loss: 0.079533
Train Epoch: 80 [18560/35339 (52%)]	Loss: 0.065940
Train Epoch: 80 [19200/35339 (54%)]	Loss: 0.076443
Train Epoch: 80 [19840/35339 (56%)]	Loss: 0.152629
Train Epoch: 80 [20480/35339 (58%)]	Loss: 0.061628
Train Epoch: 80 [21120/35339 (60%)]	Loss: 0.062011
Train Epoch: 80 [21760/35339 (61%)]	Loss: 0.157475
Train Epoch: 80 [22400/35339 (63%)]	Loss: 0.061803
Train Epoch: 80 [23040/35339 (65%)]	Loss: 0.063005
Train Epoch: 80 [23680/35339 (67%)]	Loss: 0.102644
Train Epoch: 80 [24320/35339 (69%)]	Loss: 0.076382
Train Epoch: 80 [24960/35339 (71%)]	Loss: 0.259093
Train Epoch: 80 [25600/35339 (72%)]	Loss: 0.076705
Train Epoch: 80 [26240/35339 (74%)]	Loss: 0.070772
Train Epoch: 80 [26880/35339 (76%)]	Loss: 0.140814
Train Epoch: 80 [27520/35339 (78%)]	Loss: 0.080372
Train Epoch: 80 [28160/35339 (80%)]	Loss: 0.083658
Train Epoch: 80 [28800/35339 (81%)]	Loss: 0.147258
Train Epoch: 80 [29440/35339 (83%)]	Loss: 0.063774
Train Epoch: 80 [30080/35339 (85%)]	Loss: 0.114772
Train Epoch: 80 [30720/35339 (87%)]	Loss: 0.085684
Train Epoch: 80 [31360/35339 (89%)]	Loss: 0.071996
Train Epoch: 80 [32000/35339 (90%)]	Loss: 0.113747
Train Epoch: 80 [32640/35339 (92%)]	Loss: 0.133942
Train Epoch: 80 [33280/35339 (94%)]	Loss: 0.073889
Train Epoch: 80 [33920/35339 (96%)]	Loss: 0.066047
Train Epoch: 80 [34560/35339 (98%)]	Loss: 0.087106
Train Epoch: 80 [35200/35339 (99%)]	Loss: 0.094076

Validation set: Average loss: 3.0113, Accuracy: 1534/3870 (40%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 81 [0/35339 (0%)]	Loss: 0.086551
Train Epoch: 81 [640/35339 (2%)]	Loss: 0.096507
Train Epoch: 81 [1280/35339 (4%)]	Loss: 0.065326
Train Epoch: 81 [1920/35339 (5%)]	Loss: 0.100065
Train Epoch: 81 [2560/35339 (7%)]	Loss: 0.076293
Train Epoch: 81 [3200/35339 (9%)]	Loss: 0.099901
Train Epoch: 81 [3840/35339 (11%)]	Loss: 0.106038
Train Epoch: 81 [4480/35339 (13%)]	Loss: 0.110465
Train Epoch: 81 [5120/35339 (14%)]	Loss: 0.105044
Train Epoch: 81 [5760/35339 (16%)]	Loss: 0.064867
Train Epoch: 81 [6400/35339 (18%)]	Loss: 0.097143
Train Epoch: 81 [7040/35339 (20%)]	Loss: 0.081018
Train Epoch: 81 [7680/35339 (22%)]	Loss: 0.147395
Train Epoch: 81 [8320/35339 (24%)]	Loss: 0.116921
Train Epoch: 81 [8960/35339 (25%)]	Loss: 0.067234
Train Epoch: 81 [9600/35339 (27%)]	Loss: 0.065362
Train Epoch: 81 [10240/35339 (29%)]	Loss: 0.064338
Train Epoch: 81 [10880/35339 (31%)]	Loss: 0.099529
Train Epoch: 81 [11520/35339 (33%)]	Loss: 0.115493
Train Epoch: 81 [12160/35339 (34%)]	Loss: 0.058623
Train Epoch: 81 [12800/35339 (36%)]	Loss: 0.061431
Train Epoch: 81 [13440/35339 (38%)]	Loss: 0.136790
Train Epoch: 81 [14080/35339 (40%)]	Loss: 0.069599
Train Epoch: 81 [14720/35339 (42%)]	Loss: 0.067756
Train Epoch: 81 [15360/35339 (43%)]	Loss: 0.081231
Train Epoch: 81 [16000/35339 (45%)]	Loss: 0.070674
Train Epoch: 81 [16640/35339 (47%)]	Loss: 0.066191
Train Epoch: 81 [17280/35339 (49%)]	Loss: 0.060234
Train Epoch: 81 [17920/35339 (51%)]	Loss: 0.061063
Train Epoch: 81 [18560/35339 (52%)]	Loss: 0.128700
Train Epoch: 81 [19200/35339 (54%)]	Loss: 0.230148
Train Epoch: 81 [19840/35339 (56%)]	Loss: 0.064562
Train Epoch: 81 [20480/35339 (58%)]	Loss: 0.062066
Train Epoch: 81 [21120/35339 (60%)]	Loss: 0.061945
Train Epoch: 81 [21760/35339 (61%)]	Loss: 0.076029
Train Epoch: 81 [22400/35339 (63%)]	Loss: 0.076800
Train Epoch: 81 [23040/35339 (65%)]	Loss: 0.133946
Train Epoch: 81 [23680/35339 (67%)]	Loss: 0.060064
Train Epoch: 81 [24320/35339 (69%)]	Loss: 0.097085
Train Epoch: 81 [24960/35339 (71%)]	Loss: 0.058276
Train Epoch: 81 [25600/35339 (72%)]	Loss: 0.085637
Train Epoch: 81 [26240/35339 (74%)]	Loss: 0.069056
Train Epoch: 81 [26880/35339 (76%)]	Loss: 0.098816
Train Epoch: 81 [27520/35339 (78%)]	Loss: 0.072785
Train Epoch: 81 [28160/35339 (80%)]	Loss: 0.070816
Train Epoch: 81 [28800/35339 (81%)]	Loss: 0.083980
Train Epoch: 81 [29440/35339 (83%)]	Loss: 0.077926
Train Epoch: 81 [30080/35339 (85%)]	Loss: 0.125365
Train Epoch: 81 [30720/35339 (87%)]	Loss: 0.067292
Train Epoch: 81 [31360/35339 (89%)]	Loss: 0.121117
Train Epoch: 81 [32000/35339 (90%)]	Loss: 0.115573
Train Epoch: 81 [32640/35339 (92%)]	Loss: 0.136513
Train Epoch: 81 [33280/35339 (94%)]	Loss: 0.089740
Train Epoch: 81 [33920/35339 (96%)]	Loss: 0.087559
Train Epoch: 81 [34560/35339 (98%)]	Loss: 0.065883
Train Epoch: 81 [35200/35339 (99%)]	Loss: 0.066750

Validation set: Average loss: 2.8389, Accuracy: 1636/3870 (42%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 82 [0/35339 (0%)]	Loss: 0.092920
Train Epoch: 82 [640/35339 (2%)]	Loss: 0.068159
Train Epoch: 82 [1280/35339 (4%)]	Loss: 0.104350
Train Epoch: 82 [1920/35339 (5%)]	Loss: 0.085552
Train Epoch: 82 [2560/35339 (7%)]	Loss: 0.077246
Train Epoch: 82 [3200/35339 (9%)]	Loss: 0.136111
Train Epoch: 82 [3840/35339 (11%)]	Loss: 0.104190
Train Epoch: 82 [4480/35339 (13%)]	Loss: 0.081069
Train Epoch: 82 [5120/35339 (14%)]	Loss: 0.093652
Train Epoch: 82 [5760/35339 (16%)]	Loss: 0.087477
Train Epoch: 82 [6400/35339 (18%)]	Loss: 0.064138
Train Epoch: 82 [7040/35339 (20%)]	Loss: 0.226386
Train Epoch: 82 [7680/35339 (22%)]	Loss: 0.060395
Train Epoch: 82 [8320/35339 (24%)]	Loss: 0.116735
Train Epoch: 82 [8960/35339 (25%)]	Loss: 0.093719
Train Epoch: 82 [9600/35339 (27%)]	Loss: 0.156622
Train Epoch: 82 [10240/35339 (29%)]	Loss: 0.071187
Train Epoch: 82 [10880/35339 (31%)]	Loss: 0.112769
Train Epoch: 82 [11520/35339 (33%)]	Loss: 0.105695
Train Epoch: 82 [12160/35339 (34%)]	Loss: 0.066686
Train Epoch: 82 [12800/35339 (36%)]	Loss: 0.175806
Train Epoch: 82 [13440/35339 (38%)]	Loss: 0.149373
Train Epoch: 82 [14080/35339 (40%)]	Loss: 0.072630
Train Epoch: 82 [14720/35339 (42%)]	Loss: 0.122641
Train Epoch: 82 [15360/35339 (43%)]	Loss: 0.093405
Train Epoch: 82 [16000/35339 (45%)]	Loss: 0.061212
Train Epoch: 82 [16640/35339 (47%)]	Loss: 0.136767
Train Epoch: 82 [17280/35339 (49%)]	Loss: 0.128280
Train Epoch: 82 [17920/35339 (51%)]	Loss: 0.063822
Train Epoch: 82 [18560/35339 (52%)]	Loss: 0.104257
Train Epoch: 82 [19200/35339 (54%)]	Loss: 0.132347
Train Epoch: 82 [19840/35339 (56%)]	Loss: 0.141606
Train Epoch: 82 [20480/35339 (58%)]	Loss: 0.065417
Train Epoch: 82 [21120/35339 (60%)]	Loss: 0.119720
Train Epoch: 82 [21760/35339 (61%)]	Loss: 0.126707
Train Epoch: 82 [22400/35339 (63%)]	Loss: 0.083434
Train Epoch: 82 [23040/35339 (65%)]	Loss: 0.128012
Train Epoch: 82 [23680/35339 (67%)]	Loss: 0.079602
Train Epoch: 82 [24320/35339 (69%)]	Loss: 0.067414
Train Epoch: 82 [24960/35339 (71%)]	Loss: 0.062032
Train Epoch: 82 [25600/35339 (72%)]	Loss: 0.099057
Train Epoch: 82 [26240/35339 (74%)]	Loss: 0.080912
Train Epoch: 82 [26880/35339 (76%)]	Loss: 0.059774
Train Epoch: 82 [27520/35339 (78%)]	Loss: 0.064329
Train Epoch: 82 [28160/35339 (80%)]	Loss: 0.087903
Train Epoch: 82 [28800/35339 (81%)]	Loss: 0.107587
Train Epoch: 82 [29440/35339 (83%)]	Loss: 0.074734
Train Epoch: 82 [30080/35339 (85%)]	Loss: 0.131879
Train Epoch: 82 [30720/35339 (87%)]	Loss: 0.083808
Train Epoch: 82 [31360/35339 (89%)]	Loss: 0.105210
Train Epoch: 82 [32000/35339 (90%)]	Loss: 0.103348
Train Epoch: 82 [32640/35339 (92%)]	Loss: 0.120710
Train Epoch: 82 [33280/35339 (94%)]	Loss: 0.090823
Train Epoch: 82 [33920/35339 (96%)]	Loss: 0.185023
Train Epoch: 82 [34560/35339 (98%)]	Loss: 0.147521
Train Epoch: 82 [35200/35339 (99%)]	Loss: 0.085285

Validation set: Average loss: 2.6859, Accuracy: 1772/3870 (46%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 83 [0/35339 (0%)]	Loss: 0.123478
Train Epoch: 83 [640/35339 (2%)]	Loss: 0.095107
Train Epoch: 83 [1280/35339 (4%)]	Loss: 0.148291
Train Epoch: 83 [1920/35339 (5%)]	Loss: 0.072743
Train Epoch: 83 [2560/35339 (7%)]	Loss: 0.109754
Train Epoch: 83 [3200/35339 (9%)]	Loss: 0.149519
Train Epoch: 83 [3840/35339 (11%)]	Loss: 0.082630
Train Epoch: 83 [4480/35339 (13%)]	Loss: 0.142344
Train Epoch: 83 [5120/35339 (14%)]	Loss: 0.127830
Train Epoch: 83 [5760/35339 (16%)]	Loss: 0.076810
Train Epoch: 83 [6400/35339 (18%)]	Loss: 0.125136
Train Epoch: 83 [7040/35339 (20%)]	Loss: 0.064028
Train Epoch: 83 [7680/35339 (22%)]	Loss: 0.100491
Train Epoch: 83 [8320/35339 (24%)]	Loss: 0.157534
Train Epoch: 83 [8960/35339 (25%)]	Loss: 0.062086
Train Epoch: 83 [9600/35339 (27%)]	Loss: 0.098291
Train Epoch: 83 [10240/35339 (29%)]	Loss: 0.147944
Train Epoch: 83 [10880/35339 (31%)]	Loss: 0.113985
Train Epoch: 83 [11520/35339 (33%)]	Loss: 0.178455
Train Epoch: 83 [12160/35339 (34%)]	Loss: 0.104122
Train Epoch: 83 [12800/35339 (36%)]	Loss: 0.089675
Train Epoch: 83 [13440/35339 (38%)]	Loss: 0.099940
Train Epoch: 83 [14080/35339 (40%)]	Loss: 0.119444
Train Epoch: 83 [14720/35339 (42%)]	Loss: 0.188728
Train Epoch: 83 [15360/35339 (43%)]	Loss: 0.124290
Train Epoch: 83 [16000/35339 (45%)]	Loss: 0.142894
Train Epoch: 83 [16640/35339 (47%)]	Loss: 0.092337
Train Epoch: 83 [17280/35339 (49%)]	Loss: 0.130204
Train Epoch: 83 [17920/35339 (51%)]	Loss: 0.125032
Train Epoch: 83 [18560/35339 (52%)]	Loss: 0.093126
Train Epoch: 83 [19200/35339 (54%)]	Loss: 0.184278
Train Epoch: 83 [19840/35339 (56%)]	Loss: 0.085416
Train Epoch: 83 [20480/35339 (58%)]	Loss: 0.170565
Train Epoch: 83 [21120/35339 (60%)]	Loss: 0.071730
Train Epoch: 83 [21760/35339 (61%)]	Loss: 0.068808
Train Epoch: 83 [22400/35339 (63%)]	Loss: 0.123974
Train Epoch: 83 [23040/35339 (65%)]	Loss: 0.101092
Train Epoch: 83 [23680/35339 (67%)]	Loss: 0.080827
Train Epoch: 83 [24320/35339 (69%)]	Loss: 0.123249
Train Epoch: 83 [24960/35339 (71%)]	Loss: 0.101729
Train Epoch: 83 [25600/35339 (72%)]	Loss: 0.121454
Train Epoch: 83 [26240/35339 (74%)]	Loss: 0.100000
Train Epoch: 83 [26880/35339 (76%)]	Loss: 0.061799
Train Epoch: 83 [27520/35339 (78%)]	Loss: 0.094609
Train Epoch: 83 [28160/35339 (80%)]	Loss: 0.157686
Train Epoch: 83 [28800/35339 (81%)]	Loss: 0.090851
Train Epoch: 83 [29440/35339 (83%)]	Loss: 0.080802
Train Epoch: 83 [30080/35339 (85%)]	Loss: 0.122291
Train Epoch: 83 [30720/35339 (87%)]	Loss: 0.105211
Train Epoch: 83 [31360/35339 (89%)]	Loss: 0.079388
Train Epoch: 83 [32000/35339 (90%)]	Loss: 0.099809
Train Epoch: 83 [32640/35339 (92%)]	Loss: 0.063343
Train Epoch: 83 [33280/35339 (94%)]	Loss: 0.185583
Train Epoch: 83 [33920/35339 (96%)]	Loss: 0.081405
Train Epoch: 83 [34560/35339 (98%)]	Loss: 0.077434
Train Epoch: 83 [35200/35339 (99%)]	Loss: 0.062775

Validation set: Average loss: 3.2340, Accuracy: 1377/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 84 [0/35339 (0%)]	Loss: 0.083650
Train Epoch: 84 [640/35339 (2%)]	Loss: 0.155352
Train Epoch: 84 [1280/35339 (4%)]	Loss: 0.076344
Train Epoch: 84 [1920/35339 (5%)]	Loss: 0.088603
Train Epoch: 84 [2560/35339 (7%)]	Loss: 0.093971
Train Epoch: 84 [3200/35339 (9%)]	Loss: 0.076404
Train Epoch: 84 [3840/35339 (11%)]	Loss: 0.087748
Train Epoch: 84 [4480/35339 (13%)]	Loss: 0.168887
Train Epoch: 84 [5120/35339 (14%)]	Loss: 0.149211
Train Epoch: 84 [5760/35339 (16%)]	Loss: 0.154888
Train Epoch: 84 [6400/35339 (18%)]	Loss: 0.149466
Train Epoch: 84 [7040/35339 (20%)]	Loss: 0.103777
Train Epoch: 84 [7680/35339 (22%)]	Loss: 0.147723
Train Epoch: 84 [8320/35339 (24%)]	Loss: 0.095221
Train Epoch: 84 [8960/35339 (25%)]	Loss: 0.086593
Train Epoch: 84 [9600/35339 (27%)]	Loss: 0.136944
Train Epoch: 84 [10240/35339 (29%)]	Loss: 0.075140
Train Epoch: 84 [10880/35339 (31%)]	Loss: 0.067581
Train Epoch: 84 [11520/35339 (33%)]	Loss: 0.087915
Train Epoch: 84 [12160/35339 (34%)]	Loss: 0.132037
Train Epoch: 84 [12800/35339 (36%)]	Loss: 0.080621
Train Epoch: 84 [13440/35339 (38%)]	Loss: 0.110907
Train Epoch: 84 [14080/35339 (40%)]	Loss: 0.086925
Train Epoch: 84 [14720/35339 (42%)]	Loss: 0.071627
Train Epoch: 84 [15360/35339 (43%)]	Loss: 0.107292
Train Epoch: 84 [16000/35339 (45%)]	Loss: 0.081891
Train Epoch: 84 [16640/35339 (47%)]	Loss: 0.101339
Train Epoch: 84 [17280/35339 (49%)]	Loss: 0.064438
Train Epoch: 84 [17920/35339 (51%)]	Loss: 0.088805
Train Epoch: 84 [18560/35339 (52%)]	Loss: 0.099858
Train Epoch: 84 [19200/35339 (54%)]	Loss: 0.129288
Train Epoch: 84 [19840/35339 (56%)]	Loss: 0.125748
Train Epoch: 84 [20480/35339 (58%)]	Loss: 0.155411
Train Epoch: 84 [21120/35339 (60%)]	Loss: 0.116576
Train Epoch: 84 [21760/35339 (61%)]	Loss: 0.080632
Train Epoch: 84 [22400/35339 (63%)]	Loss: 0.065023
Train Epoch: 84 [23040/35339 (65%)]	Loss: 0.102886
Train Epoch: 84 [23680/35339 (67%)]	Loss: 0.061035
Train Epoch: 84 [24320/35339 (69%)]	Loss: 0.100294
Train Epoch: 84 [24960/35339 (71%)]	Loss: 0.120790
Train Epoch: 84 [25600/35339 (72%)]	Loss: 0.093576
Train Epoch: 84 [26240/35339 (74%)]	Loss: 0.064158
Train Epoch: 84 [26880/35339 (76%)]	Loss: 0.134812
Train Epoch: 84 [27520/35339 (78%)]	Loss: 0.083729
Train Epoch: 84 [28160/35339 (80%)]	Loss: 0.100266
Train Epoch: 84 [28800/35339 (81%)]	Loss: 0.130239
Train Epoch: 84 [29440/35339 (83%)]	Loss: 0.077430
Train Epoch: 84 [30080/35339 (85%)]	Loss: 0.156342
Train Epoch: 84 [30720/35339 (87%)]	Loss: 0.137097
Train Epoch: 84 [31360/35339 (89%)]	Loss: 0.069424
Train Epoch: 84 [32000/35339 (90%)]	Loss: 0.104290
Train Epoch: 84 [32640/35339 (92%)]	Loss: 0.091945
Train Epoch: 84 [33280/35339 (94%)]	Loss: 0.123844
Train Epoch: 84 [33920/35339 (96%)]	Loss: 0.066407
Train Epoch: 84 [34560/35339 (98%)]	Loss: 0.177768
Train Epoch: 84 [35200/35339 (99%)]	Loss: 0.084041

Validation set: Average loss: 3.0314, Accuracy: 1477/3870 (38%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 85 [0/35339 (0%)]	Loss: 0.103257
Train Epoch: 85 [640/35339 (2%)]	Loss: 0.069104
Train Epoch: 85 [1280/35339 (4%)]	Loss: 0.065933
Train Epoch: 85 [1920/35339 (5%)]	Loss: 0.061322
Train Epoch: 85 [2560/35339 (7%)]	Loss: 0.072869
Train Epoch: 85 [3200/35339 (9%)]	Loss: 0.076998
Train Epoch: 85 [3840/35339 (11%)]	Loss: 0.095456
Train Epoch: 85 [4480/35339 (13%)]	Loss: 0.094795
Train Epoch: 85 [5120/35339 (14%)]	Loss: 0.098451
Train Epoch: 85 [5760/35339 (16%)]	Loss: 0.118860
Train Epoch: 85 [6400/35339 (18%)]	Loss: 0.067221
Train Epoch: 85 [7040/35339 (20%)]	Loss: 0.070603
Train Epoch: 85 [7680/35339 (22%)]	Loss: 0.179326
Train Epoch: 85 [8320/35339 (24%)]	Loss: 0.066715
Train Epoch: 85 [8960/35339 (25%)]	Loss: 0.073094
Train Epoch: 85 [9600/35339 (27%)]	Loss: 0.090204
Train Epoch: 85 [10240/35339 (29%)]	Loss: 0.067791
Train Epoch: 85 [10880/35339 (31%)]	Loss: 0.063413
Train Epoch: 85 [11520/35339 (33%)]	Loss: 0.077804
Train Epoch: 85 [12160/35339 (34%)]	Loss: 0.120909
Train Epoch: 85 [12800/35339 (36%)]	Loss: 0.068228
Train Epoch: 85 [13440/35339 (38%)]	Loss: 0.067857
Train Epoch: 85 [14080/35339 (40%)]	Loss: 0.064346
Train Epoch: 85 [14720/35339 (42%)]	Loss: 0.161185
Train Epoch: 85 [15360/35339 (43%)]	Loss: 0.063462
Train Epoch: 85 [16000/35339 (45%)]	Loss: 0.063700
Train Epoch: 85 [16640/35339 (47%)]	Loss: 0.112708
Train Epoch: 85 [17280/35339 (49%)]	Loss: 0.116740
Train Epoch: 85 [17920/35339 (51%)]	Loss: 0.122914
Train Epoch: 85 [18560/35339 (52%)]	Loss: 0.091632
Train Epoch: 85 [19200/35339 (54%)]	Loss: 0.071720
Train Epoch: 85 [19840/35339 (56%)]	Loss: 0.088139
Train Epoch: 85 [20480/35339 (58%)]	Loss: 0.083041
Train Epoch: 85 [21120/35339 (60%)]	Loss: 0.109039
Train Epoch: 85 [21760/35339 (61%)]	Loss: 0.107947
Train Epoch: 85 [22400/35339 (63%)]	Loss: 0.095078
Train Epoch: 85 [23040/35339 (65%)]	Loss: 0.089032
Train Epoch: 85 [23680/35339 (67%)]	Loss: 0.061280
Train Epoch: 85 [24320/35339 (69%)]	Loss: 0.085642
Train Epoch: 85 [24960/35339 (71%)]	Loss: 0.084473
Train Epoch: 85 [25600/35339 (72%)]	Loss: 0.089201
Train Epoch: 85 [26240/35339 (74%)]	Loss: 0.058926
Train Epoch: 85 [26880/35339 (76%)]	Loss: 0.158244
Train Epoch: 85 [27520/35339 (78%)]	Loss: 0.091341
Train Epoch: 85 [28160/35339 (80%)]	Loss: 0.096929
Train Epoch: 85 [28800/35339 (81%)]	Loss: 0.107571
Train Epoch: 85 [29440/35339 (83%)]	Loss: 0.064244
Train Epoch: 85 [30080/35339 (85%)]	Loss: 0.112358
Train Epoch: 85 [30720/35339 (87%)]	Loss: 0.068599
Train Epoch: 85 [31360/35339 (89%)]	Loss: 0.087070
Train Epoch: 85 [32000/35339 (90%)]	Loss: 0.093960
Train Epoch: 85 [32640/35339 (92%)]	Loss: 0.059273
Train Epoch: 85 [33280/35339 (94%)]	Loss: 0.058813
Train Epoch: 85 [33920/35339 (96%)]	Loss: 0.074814
Train Epoch: 85 [34560/35339 (98%)]	Loss: 0.076536
Train Epoch: 85 [35200/35339 (99%)]	Loss: 0.071625

Validation set: Average loss: 3.0972, Accuracy: 1437/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 86 [0/35339 (0%)]	Loss: 0.071363
Train Epoch: 86 [640/35339 (2%)]	Loss: 0.074862
Train Epoch: 86 [1280/35339 (4%)]	Loss: 0.146452
Train Epoch: 86 [1920/35339 (5%)]	Loss: 0.073558
Train Epoch: 86 [2560/35339 (7%)]	Loss: 0.075406
Train Epoch: 86 [3200/35339 (9%)]	Loss: 0.101614
Train Epoch: 86 [3840/35339 (11%)]	Loss: 0.093215
Train Epoch: 86 [4480/35339 (13%)]	Loss: 0.065089
Train Epoch: 86 [5120/35339 (14%)]	Loss: 0.060665
Train Epoch: 86 [5760/35339 (16%)]	Loss: 0.113378
Train Epoch: 86 [6400/35339 (18%)]	Loss: 0.064737
Train Epoch: 86 [7040/35339 (20%)]	Loss: 0.082151
Train Epoch: 86 [7680/35339 (22%)]	Loss: 0.140804
Train Epoch: 86 [8320/35339 (24%)]	Loss: 0.133107
Train Epoch: 86 [8960/35339 (25%)]	Loss: 0.098200
Train Epoch: 86 [9600/35339 (27%)]	Loss: 0.110303
Train Epoch: 86 [10240/35339 (29%)]	Loss: 0.083593
Train Epoch: 86 [10880/35339 (31%)]	Loss: 0.081434
Train Epoch: 86 [11520/35339 (33%)]	Loss: 0.114690
Train Epoch: 86 [12160/35339 (34%)]	Loss: 0.080240
Train Epoch: 86 [12800/35339 (36%)]	Loss: 0.107970
Train Epoch: 86 [13440/35339 (38%)]	Loss: 0.085862
Train Epoch: 86 [14080/35339 (40%)]	Loss: 0.061461
Train Epoch: 86 [14720/35339 (42%)]	Loss: 0.172715
Train Epoch: 86 [15360/35339 (43%)]	Loss: 0.064422
Train Epoch: 86 [16000/35339 (45%)]	Loss: 0.073980
Train Epoch: 86 [16640/35339 (47%)]	Loss: 0.108427
Train Epoch: 86 [17280/35339 (49%)]	Loss: 0.116173
Train Epoch: 86 [17920/35339 (51%)]	Loss: 0.078134
Train Epoch: 86 [18560/35339 (52%)]	Loss: 0.110503
Train Epoch: 86 [19200/35339 (54%)]	Loss: 0.098268
Train Epoch: 86 [19840/35339 (56%)]	Loss: 0.090804
Train Epoch: 86 [20480/35339 (58%)]	Loss: 0.165928
Train Epoch: 86 [21120/35339 (60%)]	Loss: 0.118675
Train Epoch: 86 [21760/35339 (61%)]	Loss: 0.092786
Train Epoch: 86 [22400/35339 (63%)]	Loss: 0.108993
Train Epoch: 86 [23040/35339 (65%)]	Loss: 0.089785
Train Epoch: 86 [23680/35339 (67%)]	Loss: 0.071214
Train Epoch: 86 [24320/35339 (69%)]	Loss: 0.067736
Train Epoch: 86 [24960/35339 (71%)]	Loss: 0.120001
Train Epoch: 86 [25600/35339 (72%)]	Loss: 0.084512
Train Epoch: 86 [26240/35339 (74%)]	Loss: 0.094997
Train Epoch: 86 [26880/35339 (76%)]	Loss: 0.106216
Train Epoch: 86 [27520/35339 (78%)]	Loss: 0.102241
Train Epoch: 86 [28160/35339 (80%)]	Loss: 0.104890
Train Epoch: 86 [28800/35339 (81%)]	Loss: 0.063268
Train Epoch: 86 [29440/35339 (83%)]	Loss: 0.143773
Train Epoch: 86 [30080/35339 (85%)]	Loss: 0.098611
Train Epoch: 86 [30720/35339 (87%)]	Loss: 0.101982
Train Epoch: 86 [31360/35339 (89%)]	Loss: 0.064130
Train Epoch: 86 [32000/35339 (90%)]	Loss: 0.115330
Train Epoch: 86 [32640/35339 (92%)]	Loss: 0.103043
Train Epoch: 86 [33280/35339 (94%)]	Loss: 0.107599
Train Epoch: 86 [33920/35339 (96%)]	Loss: 0.069657
Train Epoch: 86 [34560/35339 (98%)]	Loss: 0.072194
Train Epoch: 86 [35200/35339 (99%)]	Loss: 0.086276

Validation set: Average loss: 3.1464, Accuracy: 1435/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 87 [0/35339 (0%)]	Loss: 0.078775
Train Epoch: 87 [640/35339 (2%)]	Loss: 0.069966
Train Epoch: 87 [1280/35339 (4%)]	Loss: 0.079392
Train Epoch: 87 [1920/35339 (5%)]	Loss: 0.168677
Train Epoch: 87 [2560/35339 (7%)]	Loss: 0.062205
Train Epoch: 87 [3200/35339 (9%)]	Loss: 0.087948
Train Epoch: 87 [3840/35339 (11%)]	Loss: 0.072689
Train Epoch: 87 [4480/35339 (13%)]	Loss: 0.113117
Train Epoch: 87 [5120/35339 (14%)]	Loss: 0.058237
Train Epoch: 87 [5760/35339 (16%)]	Loss: 0.080144
Train Epoch: 87 [6400/35339 (18%)]	Loss: 0.130324
Train Epoch: 87 [7040/35339 (20%)]	Loss: 0.081541
Train Epoch: 87 [7680/35339 (22%)]	Loss: 0.060203
Train Epoch: 87 [8320/35339 (24%)]	Loss: 0.059676
Train Epoch: 87 [8960/35339 (25%)]	Loss: 0.068716
Train Epoch: 87 [9600/35339 (27%)]	Loss: 0.145165
Train Epoch: 87 [10240/35339 (29%)]	Loss: 0.108268
Train Epoch: 87 [10880/35339 (31%)]	Loss: 0.264346
Train Epoch: 87 [11520/35339 (33%)]	Loss: 0.073374
Train Epoch: 87 [12160/35339 (34%)]	Loss: 0.063831
Train Epoch: 87 [12800/35339 (36%)]	Loss: 0.097047
Train Epoch: 87 [13440/35339 (38%)]	Loss: 0.062133
Train Epoch: 87 [14080/35339 (40%)]	Loss: 0.125279
Train Epoch: 87 [14720/35339 (42%)]	Loss: 0.084296
Train Epoch: 87 [15360/35339 (43%)]	Loss: 0.080425
Train Epoch: 87 [16000/35339 (45%)]	Loss: 0.073416
Train Epoch: 87 [16640/35339 (47%)]	Loss: 0.065824
Train Epoch: 87 [17280/35339 (49%)]	Loss: 0.083596
Train Epoch: 87 [17920/35339 (51%)]	Loss: 0.104797
Train Epoch: 87 [18560/35339 (52%)]	Loss: 0.062361
Train Epoch: 87 [19200/35339 (54%)]	Loss: 0.196727
Train Epoch: 87 [19840/35339 (56%)]	Loss: 0.092850
Train Epoch: 87 [20480/35339 (58%)]	Loss: 0.070728
Train Epoch: 87 [21120/35339 (60%)]	Loss: 0.099580
Train Epoch: 87 [21760/35339 (61%)]	Loss: 0.074853
Train Epoch: 87 [22400/35339 (63%)]	Loss: 0.061020
Train Epoch: 87 [23040/35339 (65%)]	Loss: 0.072830
Train Epoch: 87 [23680/35339 (67%)]	Loss: 0.058987
Train Epoch: 87 [24320/35339 (69%)]	Loss: 0.088140
Train Epoch: 87 [24960/35339 (71%)]	Loss: 0.064682
Train Epoch: 87 [25600/35339 (72%)]	Loss: 0.059577
Train Epoch: 87 [26240/35339 (74%)]	Loss: 0.100016
Train Epoch: 87 [26880/35339 (76%)]	Loss: 0.110802
Train Epoch: 87 [27520/35339 (78%)]	Loss: 0.063930
Train Epoch: 87 [28160/35339 (80%)]	Loss: 0.314345
Train Epoch: 87 [28800/35339 (81%)]	Loss: 0.086649
Train Epoch: 87 [29440/35339 (83%)]	Loss: 0.126228
Train Epoch: 87 [30080/35339 (85%)]	Loss: 0.150704
Train Epoch: 87 [30720/35339 (87%)]	Loss: 0.102867
Train Epoch: 87 [31360/35339 (89%)]	Loss: 0.095701
Train Epoch: 87 [32000/35339 (90%)]	Loss: 0.091062
Train Epoch: 87 [32640/35339 (92%)]	Loss: 0.138718
Train Epoch: 87 [33280/35339 (94%)]	Loss: 0.114048
Train Epoch: 87 [33920/35339 (96%)]	Loss: 0.091909
Train Epoch: 87 [34560/35339 (98%)]	Loss: 0.073764
Train Epoch: 87 [35200/35339 (99%)]	Loss: 0.122127

Validation set: Average loss: 3.0718, Accuracy: 1475/3870 (38%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 88 [0/35339 (0%)]	Loss: 0.103292
Train Epoch: 88 [640/35339 (2%)]	Loss: 0.098106
Train Epoch: 88 [1280/35339 (4%)]	Loss: 0.123510
Train Epoch: 88 [1920/35339 (5%)]	Loss: 0.085065
Train Epoch: 88 [2560/35339 (7%)]	Loss: 0.155277
Train Epoch: 88 [3200/35339 (9%)]	Loss: 0.101238
Train Epoch: 88 [3840/35339 (11%)]	Loss: 0.107924
Train Epoch: 88 [4480/35339 (13%)]	Loss: 0.090844
Train Epoch: 88 [5120/35339 (14%)]	Loss: 0.147376
Train Epoch: 88 [5760/35339 (16%)]	Loss: 0.096684
Train Epoch: 88 [6400/35339 (18%)]	Loss: 0.089094
Train Epoch: 88 [7040/35339 (20%)]	Loss: 0.092077
Train Epoch: 88 [7680/35339 (22%)]	Loss: 0.108402
Train Epoch: 88 [8320/35339 (24%)]	Loss: 0.118765
Train Epoch: 88 [8960/35339 (25%)]	Loss: 0.095747
Train Epoch: 88 [9600/35339 (27%)]	Loss: 0.100167
Train Epoch: 88 [10240/35339 (29%)]	Loss: 0.061053
Train Epoch: 88 [10880/35339 (31%)]	Loss: 0.090567
Train Epoch: 88 [11520/35339 (33%)]	Loss: 0.300383
Train Epoch: 88 [12160/35339 (34%)]	Loss: 0.070021
Train Epoch: 88 [12800/35339 (36%)]	Loss: 0.133043
Train Epoch: 88 [13440/35339 (38%)]	Loss: 0.101578
Train Epoch: 88 [14080/35339 (40%)]	Loss: 0.074891
Train Epoch: 88 [14720/35339 (42%)]	Loss: 0.057065
Train Epoch: 88 [15360/35339 (43%)]	Loss: 0.124333
Train Epoch: 88 [16000/35339 (45%)]	Loss: 0.117712
Train Epoch: 88 [16640/35339 (47%)]	Loss: 0.073012
Train Epoch: 88 [17280/35339 (49%)]	Loss: 0.102464
Train Epoch: 88 [17920/35339 (51%)]	Loss: 0.088564
Train Epoch: 88 [18560/35339 (52%)]	Loss: 0.060815
Train Epoch: 88 [19200/35339 (54%)]	Loss: 0.079043
Train Epoch: 88 [19840/35339 (56%)]	Loss: 0.077387
Train Epoch: 88 [20480/35339 (58%)]	Loss: 0.153602
Train Epoch: 88 [21120/35339 (60%)]	Loss: 0.120579
Train Epoch: 88 [21760/35339 (61%)]	Loss: 0.085382
Train Epoch: 88 [22400/35339 (63%)]	Loss: 0.103846
Train Epoch: 88 [23040/35339 (65%)]	Loss: 0.161513
Train Epoch: 88 [23680/35339 (67%)]	Loss: 0.174007
Train Epoch: 88 [24320/35339 (69%)]	Loss: 0.121511
Train Epoch: 88 [24960/35339 (71%)]	Loss: 0.104926
Train Epoch: 88 [25600/35339 (72%)]	Loss: 0.084142
Train Epoch: 88 [26240/35339 (74%)]	Loss: 0.059045
Train Epoch: 88 [26880/35339 (76%)]	Loss: 0.068655
Train Epoch: 88 [27520/35339 (78%)]	Loss: 0.169388
Train Epoch: 88 [28160/35339 (80%)]	Loss: 0.081905
Train Epoch: 88 [28800/35339 (81%)]	Loss: 0.067550
Train Epoch: 88 [29440/35339 (83%)]	Loss: 0.079433
Train Epoch: 88 [30080/35339 (85%)]	Loss: 0.069841
Train Epoch: 88 [30720/35339 (87%)]	Loss: 0.167089
Train Epoch: 88 [31360/35339 (89%)]	Loss: 0.067015
Train Epoch: 88 [32000/35339 (90%)]	Loss: 0.109381
Train Epoch: 88 [32640/35339 (92%)]	Loss: 0.079359
Train Epoch: 88 [33280/35339 (94%)]	Loss: 0.096176
Train Epoch: 88 [33920/35339 (96%)]	Loss: 0.065255
Train Epoch: 88 [34560/35339 (98%)]	Loss: 0.080394
Train Epoch: 88 [35200/35339 (99%)]	Loss: 0.096289

Validation set: Average loss: 3.1755, Accuracy: 1457/3870 (38%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 89 [0/35339 (0%)]	Loss: 0.118065
Train Epoch: 89 [640/35339 (2%)]	Loss: 0.088154
Train Epoch: 89 [1280/35339 (4%)]	Loss: 0.076272
Train Epoch: 89 [1920/35339 (5%)]	Loss: 0.105017
Train Epoch: 89 [2560/35339 (7%)]	Loss: 0.146933
Train Epoch: 89 [3200/35339 (9%)]	Loss: 0.214800
Train Epoch: 89 [3840/35339 (11%)]	Loss: 0.072269
Train Epoch: 89 [4480/35339 (13%)]	Loss: 0.086539
Train Epoch: 89 [5120/35339 (14%)]	Loss: 0.184470
Train Epoch: 89 [5760/35339 (16%)]	Loss: 0.104760
Train Epoch: 89 [6400/35339 (18%)]	Loss: 0.120987
Train Epoch: 89 [7040/35339 (20%)]	Loss: 0.068879
Train Epoch: 89 [7680/35339 (22%)]	Loss: 0.109658
Train Epoch: 89 [8320/35339 (24%)]	Loss: 0.110746
Train Epoch: 89 [8960/35339 (25%)]	Loss: 0.117247
Train Epoch: 89 [9600/35339 (27%)]	Loss: 0.126868
Train Epoch: 89 [10240/35339 (29%)]	Loss: 0.116962
Train Epoch: 89 [10880/35339 (31%)]	Loss: 0.085262
Train Epoch: 89 [11520/35339 (33%)]	Loss: 0.102042
Train Epoch: 89 [12160/35339 (34%)]	Loss: 0.179749
Train Epoch: 89 [12800/35339 (36%)]	Loss: 0.087278
Train Epoch: 89 [13440/35339 (38%)]	Loss: 0.066823
Train Epoch: 89 [14080/35339 (40%)]	Loss: 0.148159
Train Epoch: 89 [14720/35339 (42%)]	Loss: 0.063623
Train Epoch: 89 [15360/35339 (43%)]	Loss: 0.069908
Train Epoch: 89 [16000/35339 (45%)]	Loss: 0.113021
Train Epoch: 89 [16640/35339 (47%)]	Loss: 0.092044
Train Epoch: 89 [17280/35339 (49%)]	Loss: 0.098549
Train Epoch: 89 [17920/35339 (51%)]	Loss: 0.071890
Train Epoch: 89 [18560/35339 (52%)]	Loss: 0.119823
Train Epoch: 89 [19200/35339 (54%)]	Loss: 0.137360
Train Epoch: 89 [19840/35339 (56%)]	Loss: 0.068671
Train Epoch: 89 [20480/35339 (58%)]	Loss: 0.100583
Train Epoch: 89 [21120/35339 (60%)]	Loss: 0.064786
Train Epoch: 89 [21760/35339 (61%)]	Loss: 0.058674
Train Epoch: 89 [22400/35339 (63%)]	Loss: 0.128944
Train Epoch: 89 [23040/35339 (65%)]	Loss: 0.062444
Train Epoch: 89 [23680/35339 (67%)]	Loss: 0.090235
Train Epoch: 89 [24320/35339 (69%)]	Loss: 0.133418
Train Epoch: 89 [24960/35339 (71%)]	Loss: 0.065944
Train Epoch: 89 [25600/35339 (72%)]	Loss: 0.096038
Train Epoch: 89 [26240/35339 (74%)]	Loss: 0.096220
Train Epoch: 89 [26880/35339 (76%)]	Loss: 0.107499
Train Epoch: 89 [27520/35339 (78%)]	Loss: 0.114614
Train Epoch: 89 [28160/35339 (80%)]	Loss: 0.100812
Train Epoch: 89 [28800/35339 (81%)]	Loss: 0.116260
Train Epoch: 89 [29440/35339 (83%)]	Loss: 0.123130
Train Epoch: 89 [30080/35339 (85%)]	Loss: 0.110572
Train Epoch: 89 [30720/35339 (87%)]	Loss: 0.081322
Train Epoch: 89 [31360/35339 (89%)]	Loss: 0.075248
Train Epoch: 89 [32000/35339 (90%)]	Loss: 0.105229
Train Epoch: 89 [32640/35339 (92%)]	Loss: 0.112292
Train Epoch: 89 [33280/35339 (94%)]	Loss: 0.071537
Train Epoch: 89 [33920/35339 (96%)]	Loss: 0.114680
Train Epoch: 89 [34560/35339 (98%)]	Loss: 0.095681
Train Epoch: 89 [35200/35339 (99%)]	Loss: 0.068105

Validation set: Average loss: 3.1561, Accuracy: 1439/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 90 [0/35339 (0%)]	Loss: 0.097869
Train Epoch: 90 [640/35339 (2%)]	Loss: 0.061181
Train Epoch: 90 [1280/35339 (4%)]	Loss: 0.095688
Train Epoch: 90 [1920/35339 (5%)]	Loss: 0.081794
Train Epoch: 90 [2560/35339 (7%)]	Loss: 0.113841
Train Epoch: 90 [3200/35339 (9%)]	Loss: 0.113543
Train Epoch: 90 [3840/35339 (11%)]	Loss: 0.137767
Train Epoch: 90 [4480/35339 (13%)]	Loss: 0.062786
Train Epoch: 90 [5120/35339 (14%)]	Loss: 0.062170
Train Epoch: 90 [5760/35339 (16%)]	Loss: 0.140076
Train Epoch: 90 [6400/35339 (18%)]	Loss: 0.177074
Train Epoch: 90 [7040/35339 (20%)]	Loss: 0.099405
Train Epoch: 90 [7680/35339 (22%)]	Loss: 0.112207
Train Epoch: 90 [8320/35339 (24%)]	Loss: 0.153031
Train Epoch: 90 [8960/35339 (25%)]	Loss: 0.136646
Train Epoch: 90 [9600/35339 (27%)]	Loss: 0.105201
Train Epoch: 90 [10240/35339 (29%)]	Loss: 0.069649
Train Epoch: 90 [10880/35339 (31%)]	Loss: 0.083615
Train Epoch: 90 [11520/35339 (33%)]	Loss: 0.062677
Train Epoch: 90 [12160/35339 (34%)]	Loss: 0.099884
Train Epoch: 90 [12800/35339 (36%)]	Loss: 0.100777
Train Epoch: 90 [13440/35339 (38%)]	Loss: 0.060138
Train Epoch: 90 [14080/35339 (40%)]	Loss: 0.106894
Train Epoch: 90 [14720/35339 (42%)]	Loss: 0.097115
Train Epoch: 90 [15360/35339 (43%)]	Loss: 0.076328
Train Epoch: 90 [16000/35339 (45%)]	Loss: 0.109559
Train Epoch: 90 [16640/35339 (47%)]	Loss: 0.119221
Train Epoch: 90 [17280/35339 (49%)]	Loss: 0.070006
Train Epoch: 90 [17920/35339 (51%)]	Loss: 0.127386
Train Epoch: 90 [18560/35339 (52%)]	Loss: 0.059490
Train Epoch: 90 [19200/35339 (54%)]	Loss: 0.100742
Train Epoch: 90 [19840/35339 (56%)]	Loss: 0.103613
Train Epoch: 90 [20480/35339 (58%)]	Loss: 0.093060
Train Epoch: 90 [21120/35339 (60%)]	Loss: 0.061479
Train Epoch: 90 [21760/35339 (61%)]	Loss: 0.186886
Train Epoch: 90 [22400/35339 (63%)]	Loss: 0.100884
Train Epoch: 90 [23040/35339 (65%)]	Loss: 0.132063
Train Epoch: 90 [23680/35339 (67%)]	Loss: 0.059925
Train Epoch: 90 [24320/35339 (69%)]	Loss: 0.080533
Train Epoch: 90 [24960/35339 (71%)]	Loss: 0.113552
Train Epoch: 90 [25600/35339 (72%)]	Loss: 0.095839
Train Epoch: 90 [26240/35339 (74%)]	Loss: 0.158923
Train Epoch: 90 [26880/35339 (76%)]	Loss: 0.076342
Train Epoch: 90 [27520/35339 (78%)]	Loss: 0.104134
Train Epoch: 90 [28160/35339 (80%)]	Loss: 0.099259
Train Epoch: 90 [28800/35339 (81%)]	Loss: 0.092627
Train Epoch: 90 [29440/35339 (83%)]	Loss: 0.149167
Train Epoch: 90 [30080/35339 (85%)]	Loss: 0.060111
Train Epoch: 90 [30720/35339 (87%)]	Loss: 0.120138
Train Epoch: 90 [31360/35339 (89%)]	Loss: 0.105782
Train Epoch: 90 [32000/35339 (90%)]	Loss: 0.115511
Train Epoch: 90 [32640/35339 (92%)]	Loss: 0.105088
Train Epoch: 90 [33280/35339 (94%)]	Loss: 0.127955
Train Epoch: 90 [33920/35339 (96%)]	Loss: 0.070742
Train Epoch: 90 [34560/35339 (98%)]	Loss: 0.086673
Train Epoch: 90 [35200/35339 (99%)]	Loss: 0.111009

Validation set: Average loss: 3.2564, Accuracy: 1379/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 91 [0/35339 (0%)]	Loss: 0.092683
Train Epoch: 91 [640/35339 (2%)]	Loss: 0.108365
Train Epoch: 91 [1280/35339 (4%)]	Loss: 0.145474
Train Epoch: 91 [1920/35339 (5%)]	Loss: 0.087880
Train Epoch: 91 [2560/35339 (7%)]	Loss: 0.062670
Train Epoch: 91 [3200/35339 (9%)]	Loss: 0.070038
Train Epoch: 91 [3840/35339 (11%)]	Loss: 0.297872
Train Epoch: 91 [4480/35339 (13%)]	Loss: 0.153884
Train Epoch: 91 [5120/35339 (14%)]	Loss: 0.084918
Train Epoch: 91 [5760/35339 (16%)]	Loss: 0.310676
Train Epoch: 91 [6400/35339 (18%)]	Loss: 0.104161
Train Epoch: 91 [7040/35339 (20%)]	Loss: 0.066757
Train Epoch: 91 [7680/35339 (22%)]	Loss: 0.095529
Train Epoch: 91 [8320/35339 (24%)]	Loss: 0.082754
Train Epoch: 91 [8960/35339 (25%)]	Loss: 0.084186
Train Epoch: 91 [9600/35339 (27%)]	Loss: 0.061169
Train Epoch: 91 [10240/35339 (29%)]	Loss: 0.105422
Train Epoch: 91 [10880/35339 (31%)]	Loss: 0.082884
Train Epoch: 91 [11520/35339 (33%)]	Loss: 0.077747
Train Epoch: 91 [12160/35339 (34%)]	Loss: 0.091112
Train Epoch: 91 [12800/35339 (36%)]	Loss: 0.098817
Train Epoch: 91 [13440/35339 (38%)]	Loss: 0.080578
Train Epoch: 91 [14080/35339 (40%)]	Loss: 0.120823
Train Epoch: 91 [14720/35339 (42%)]	Loss: 0.113925
Train Epoch: 91 [15360/35339 (43%)]	Loss: 0.176592
Train Epoch: 91 [16000/35339 (45%)]	Loss: 0.062636
Train Epoch: 91 [16640/35339 (47%)]	Loss: 0.067463
Train Epoch: 91 [17280/35339 (49%)]	Loss: 0.127379
Train Epoch: 91 [17920/35339 (51%)]	Loss: 0.067705
Train Epoch: 91 [18560/35339 (52%)]	Loss: 0.059856
Train Epoch: 91 [19200/35339 (54%)]	Loss: 0.075974
Train Epoch: 91 [19840/35339 (56%)]	Loss: 0.066494
Train Epoch: 91 [20480/35339 (58%)]	Loss: 0.063284
Train Epoch: 91 [21120/35339 (60%)]	Loss: 0.106002
Train Epoch: 91 [21760/35339 (61%)]	Loss: 0.070988
Train Epoch: 91 [22400/35339 (63%)]	Loss: 0.095548
Train Epoch: 91 [23040/35339 (65%)]	Loss: 0.065728
Train Epoch: 91 [23680/35339 (67%)]	Loss: 0.111282
Train Epoch: 91 [24320/35339 (69%)]	Loss: 0.072095
Train Epoch: 91 [24960/35339 (71%)]	Loss: 0.081903
Train Epoch: 91 [25600/35339 (72%)]	Loss: 0.128535
Train Epoch: 91 [26240/35339 (74%)]	Loss: 0.060278
Train Epoch: 91 [26880/35339 (76%)]	Loss: 0.118691
Train Epoch: 91 [27520/35339 (78%)]	Loss: 0.060908
Train Epoch: 91 [28160/35339 (80%)]	Loss: 0.091348
Train Epoch: 91 [28800/35339 (81%)]	Loss: 0.099031
Train Epoch: 91 [29440/35339 (83%)]	Loss: 0.075677
Train Epoch: 91 [30080/35339 (85%)]	Loss: 0.164685
Train Epoch: 91 [30720/35339 (87%)]	Loss: 0.135966
Train Epoch: 91 [31360/35339 (89%)]	Loss: 0.106456
Train Epoch: 91 [32000/35339 (90%)]	Loss: 0.083677
Train Epoch: 91 [32640/35339 (92%)]	Loss: 0.081006
Train Epoch: 91 [33280/35339 (94%)]	Loss: 0.059519
Train Epoch: 91 [33920/35339 (96%)]	Loss: 0.066054
Train Epoch: 91 [34560/35339 (98%)]	Loss: 0.108235
Train Epoch: 91 [35200/35339 (99%)]	Loss: 0.061874

Validation set: Average loss: 3.1670, Accuracy: 1436/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 92 [0/35339 (0%)]	Loss: 0.065009
Train Epoch: 92 [640/35339 (2%)]	Loss: 0.081505
Train Epoch: 92 [1280/35339 (4%)]	Loss: 0.083727
Train Epoch: 92 [1920/35339 (5%)]	Loss: 0.070208
Train Epoch: 92 [2560/35339 (7%)]	Loss: 0.109710
Train Epoch: 92 [3200/35339 (9%)]	Loss: 0.096280
Train Epoch: 92 [3840/35339 (11%)]	Loss: 0.099278
Train Epoch: 92 [4480/35339 (13%)]	Loss: 0.125532
Train Epoch: 92 [5120/35339 (14%)]	Loss: 0.119890
Train Epoch: 92 [5760/35339 (16%)]	Loss: 0.067967
Train Epoch: 92 [6400/35339 (18%)]	Loss: 0.075738
Train Epoch: 92 [7040/35339 (20%)]	Loss: 0.069906
Train Epoch: 92 [7680/35339 (22%)]	Loss: 0.087095
Train Epoch: 92 [8320/35339 (24%)]	Loss: 0.118996
Train Epoch: 92 [8960/35339 (25%)]	Loss: 0.110525
Train Epoch: 92 [9600/35339 (27%)]	Loss: 0.112765
Train Epoch: 92 [10240/35339 (29%)]	Loss: 0.074383
Train Epoch: 92 [10880/35339 (31%)]	Loss: 0.065421
Train Epoch: 92 [11520/35339 (33%)]	Loss: 0.122289
Train Epoch: 92 [12160/35339 (34%)]	Loss: 0.081584
Train Epoch: 92 [12800/35339 (36%)]	Loss: 0.137885
Train Epoch: 92 [13440/35339 (38%)]	Loss: 0.086134
Train Epoch: 92 [14080/35339 (40%)]	Loss: 0.072880
Train Epoch: 92 [14720/35339 (42%)]	Loss: 0.084769
Train Epoch: 92 [15360/35339 (43%)]	Loss: 0.067608
Train Epoch: 92 [16000/35339 (45%)]	Loss: 0.061630
Train Epoch: 92 [16640/35339 (47%)]	Loss: 0.062083
Train Epoch: 92 [17280/35339 (49%)]	Loss: 0.154407
Train Epoch: 92 [17920/35339 (51%)]	Loss: 0.058610
Train Epoch: 92 [18560/35339 (52%)]	Loss: 0.115704
Train Epoch: 92 [19200/35339 (54%)]	Loss: 0.072401
Train Epoch: 92 [19840/35339 (56%)]	Loss: 0.089616
Train Epoch: 92 [20480/35339 (58%)]	Loss: 0.061530
Train Epoch: 92 [21120/35339 (60%)]	Loss: 0.079779
Train Epoch: 92 [21760/35339 (61%)]	Loss: 0.067954
Train Epoch: 92 [22400/35339 (63%)]	Loss: 0.062924
Train Epoch: 92 [23040/35339 (65%)]	Loss: 0.061311
Train Epoch: 92 [23680/35339 (67%)]	Loss: 0.080601
Train Epoch: 92 [24320/35339 (69%)]	Loss: 0.059361
Train Epoch: 92 [24960/35339 (71%)]	Loss: 0.093881
Train Epoch: 92 [25600/35339 (72%)]	Loss: 0.102056
Train Epoch: 92 [26240/35339 (74%)]	Loss: 0.131255
Train Epoch: 92 [26880/35339 (76%)]	Loss: 0.087568
Train Epoch: 92 [27520/35339 (78%)]	Loss: 0.060607
Train Epoch: 92 [28160/35339 (80%)]	Loss: 0.122988
Train Epoch: 92 [28800/35339 (81%)]	Loss: 0.064010
Train Epoch: 92 [29440/35339 (83%)]	Loss: 0.101972
Train Epoch: 92 [30080/35339 (85%)]	Loss: 0.127625
Train Epoch: 92 [30720/35339 (87%)]	Loss: 0.101648
Train Epoch: 92 [31360/35339 (89%)]	Loss: 0.079572
Train Epoch: 92 [32000/35339 (90%)]	Loss: 0.065308
Train Epoch: 92 [32640/35339 (92%)]	Loss: 0.108072
Train Epoch: 92 [33280/35339 (94%)]	Loss: 0.113315
Train Epoch: 92 [33920/35339 (96%)]	Loss: 0.061687
Train Epoch: 92 [34560/35339 (98%)]	Loss: 0.114693
Train Epoch: 92 [35200/35339 (99%)]	Loss: 0.111318

Validation set: Average loss: 3.3763, Accuracy: 1326/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 93 [0/35339 (0%)]	Loss: 0.059332
Train Epoch: 93 [640/35339 (2%)]	Loss: 0.079600
Train Epoch: 93 [1280/35339 (4%)]	Loss: 0.079077
Train Epoch: 93 [1920/35339 (5%)]	Loss: 0.119046
Train Epoch: 93 [2560/35339 (7%)]	Loss: 0.070256
Train Epoch: 93 [3200/35339 (9%)]	Loss: 0.105896
Train Epoch: 93 [3840/35339 (11%)]	Loss: 0.103417
Train Epoch: 93 [4480/35339 (13%)]	Loss: 0.066981
Train Epoch: 93 [5120/35339 (14%)]	Loss: 0.099498
Train Epoch: 93 [5760/35339 (16%)]	Loss: 0.064676
Train Epoch: 93 [6400/35339 (18%)]	Loss: 0.117296
Train Epoch: 93 [7040/35339 (20%)]	Loss: 0.268038
Train Epoch: 93 [7680/35339 (22%)]	Loss: 0.095807
Train Epoch: 93 [8320/35339 (24%)]	Loss: 0.132771
Train Epoch: 93 [8960/35339 (25%)]	Loss: 0.113237
Train Epoch: 93 [9600/35339 (27%)]	Loss: 0.082339
Train Epoch: 93 [10240/35339 (29%)]	Loss: 0.068334
Train Epoch: 93 [10880/35339 (31%)]	Loss: 0.097544
Train Epoch: 93 [11520/35339 (33%)]	Loss: 0.122193
Train Epoch: 93 [12160/35339 (34%)]	Loss: 0.064628
Train Epoch: 93 [12800/35339 (36%)]	Loss: 0.062915
Train Epoch: 93 [13440/35339 (38%)]	Loss: 0.067386
Train Epoch: 93 [14080/35339 (40%)]	Loss: 0.097794
Train Epoch: 93 [14720/35339 (42%)]	Loss: 0.064663
Train Epoch: 93 [15360/35339 (43%)]	Loss: 0.100046
Train Epoch: 93 [16000/35339 (45%)]	Loss: 0.062128
Train Epoch: 93 [16640/35339 (47%)]	Loss: 0.074279
Train Epoch: 93 [17280/35339 (49%)]	Loss: 0.080467
Train Epoch: 93 [17920/35339 (51%)]	Loss: 0.098890
Train Epoch: 93 [18560/35339 (52%)]	Loss: 0.062178
Train Epoch: 93 [19200/35339 (54%)]	Loss: 0.161141
Train Epoch: 93 [19840/35339 (56%)]	Loss: 0.053424
Train Epoch: 93 [20480/35339 (58%)]	Loss: 0.070768
Train Epoch: 93 [21120/35339 (60%)]	Loss: 0.088563
Train Epoch: 93 [21760/35339 (61%)]	Loss: 0.114733
Train Epoch: 93 [22400/35339 (63%)]	Loss: 0.108412
Train Epoch: 93 [23040/35339 (65%)]	Loss: 0.114136
Train Epoch: 93 [23680/35339 (67%)]	Loss: 0.072574
Train Epoch: 93 [24320/35339 (69%)]	Loss: 0.097506
Train Epoch: 93 [24960/35339 (71%)]	Loss: 0.312914
Train Epoch: 93 [25600/35339 (72%)]	Loss: 0.068516
Train Epoch: 93 [26240/35339 (74%)]	Loss: 0.152106
Train Epoch: 93 [26880/35339 (76%)]	Loss: 0.092875
Train Epoch: 93 [27520/35339 (78%)]	Loss: 0.064197
Train Epoch: 93 [28160/35339 (80%)]	Loss: 0.066095
Train Epoch: 93 [28800/35339 (81%)]	Loss: 0.109751
Train Epoch: 93 [29440/35339 (83%)]	Loss: 0.106857
Train Epoch: 93 [30080/35339 (85%)]	Loss: 0.090431
Train Epoch: 93 [30720/35339 (87%)]	Loss: 0.066276
Train Epoch: 93 [31360/35339 (89%)]	Loss: 0.066950
Train Epoch: 93 [32000/35339 (90%)]	Loss: 0.059383
Train Epoch: 93 [32640/35339 (92%)]	Loss: 0.127188
Train Epoch: 93 [33280/35339 (94%)]	Loss: 0.058770
Train Epoch: 93 [33920/35339 (96%)]	Loss: 0.105651
Train Epoch: 93 [34560/35339 (98%)]	Loss: 0.104411
Train Epoch: 93 [35200/35339 (99%)]	Loss: 0.059456

Validation set: Average loss: 3.3329, Accuracy: 1343/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 94 [0/35339 (0%)]	Loss: 0.067620
Train Epoch: 94 [640/35339 (2%)]	Loss: 0.067276
Train Epoch: 94 [1280/35339 (4%)]	Loss: 0.062457
Train Epoch: 94 [1920/35339 (5%)]	Loss: 0.078760
Train Epoch: 94 [2560/35339 (7%)]	Loss: 0.112150
Train Epoch: 94 [3200/35339 (9%)]	Loss: 0.083912
Train Epoch: 94 [3840/35339 (11%)]	Loss: 0.062113
Train Epoch: 94 [4480/35339 (13%)]	Loss: 0.125877
Train Epoch: 94 [5120/35339 (14%)]	Loss: 0.219692
Train Epoch: 94 [5760/35339 (16%)]	Loss: 0.066121
Train Epoch: 94 [6400/35339 (18%)]	Loss: 0.062441
Train Epoch: 94 [7040/35339 (20%)]	Loss: 0.085271
Train Epoch: 94 [7680/35339 (22%)]	Loss: 0.088641
Train Epoch: 94 [8320/35339 (24%)]	Loss: 0.113345
Train Epoch: 94 [8960/35339 (25%)]	Loss: 0.108461
Train Epoch: 94 [9600/35339 (27%)]	Loss: 0.067232
Train Epoch: 94 [10240/35339 (29%)]	Loss: 0.062994
Train Epoch: 94 [10880/35339 (31%)]	Loss: 0.166223
Train Epoch: 94 [11520/35339 (33%)]	Loss: 0.059601
Train Epoch: 94 [12160/35339 (34%)]	Loss: 0.061771
Train Epoch: 94 [12800/35339 (36%)]	Loss: 0.072320
Train Epoch: 94 [13440/35339 (38%)]	Loss: 0.111614
Train Epoch: 94 [14080/35339 (40%)]	Loss: 0.078449
Train Epoch: 94 [14720/35339 (42%)]	Loss: 0.148391
Train Epoch: 94 [15360/35339 (43%)]	Loss: 0.060979
Train Epoch: 94 [16000/35339 (45%)]	Loss: 0.105965
Train Epoch: 94 [16640/35339 (47%)]	Loss: 0.098304
Train Epoch: 94 [17280/35339 (49%)]	Loss: 0.105776
Train Epoch: 94 [17920/35339 (51%)]	Loss: 0.064698
Train Epoch: 94 [18560/35339 (52%)]	Loss: 0.068098
Train Epoch: 94 [19200/35339 (54%)]	Loss: 0.081585
Train Epoch: 94 [19840/35339 (56%)]	Loss: 0.068786
Train Epoch: 94 [20480/35339 (58%)]	Loss: 0.098617
Train Epoch: 94 [21120/35339 (60%)]	Loss: 0.070417
Train Epoch: 94 [21760/35339 (61%)]	Loss: 0.110485
Train Epoch: 94 [22400/35339 (63%)]	Loss: 0.064353
Train Epoch: 94 [23040/35339 (65%)]	Loss: 0.064363
Train Epoch: 94 [23680/35339 (67%)]	Loss: 0.085266
Train Epoch: 94 [24320/35339 (69%)]	Loss: 0.207825
Train Epoch: 94 [24960/35339 (71%)]	Loss: 0.125178
Train Epoch: 94 [25600/35339 (72%)]	Loss: 0.094425
Train Epoch: 94 [26240/35339 (74%)]	Loss: 0.086236
Train Epoch: 94 [26880/35339 (76%)]	Loss: 0.060603
Train Epoch: 94 [27520/35339 (78%)]	Loss: 0.075254
Train Epoch: 94 [28160/35339 (80%)]	Loss: 0.087181
Train Epoch: 94 [28800/35339 (81%)]	Loss: 0.198267
Train Epoch: 94 [29440/35339 (83%)]	Loss: 0.099025
Train Epoch: 94 [30080/35339 (85%)]	Loss: 0.065862
Train Epoch: 94 [30720/35339 (87%)]	Loss: 0.070880
Train Epoch: 94 [31360/35339 (89%)]	Loss: 0.070785
Train Epoch: 94 [32000/35339 (90%)]	Loss: 0.087276
Train Epoch: 94 [32640/35339 (92%)]	Loss: 0.106747
Train Epoch: 94 [33280/35339 (94%)]	Loss: 0.080182
Train Epoch: 94 [33920/35339 (96%)]	Loss: 0.218675
Train Epoch: 94 [34560/35339 (98%)]	Loss: 0.101874
Train Epoch: 94 [35200/35339 (99%)]	Loss: 0.125868

Validation set: Average loss: 3.4569, Accuracy: 1314/3870 (34%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 95 [0/35339 (0%)]	Loss: 0.092887
Train Epoch: 95 [640/35339 (2%)]	Loss: 0.094923
Train Epoch: 95 [1280/35339 (4%)]	Loss: 0.091290
Train Epoch: 95 [1920/35339 (5%)]	Loss: 0.101294
Train Epoch: 95 [2560/35339 (7%)]	Loss: 0.073290
Train Epoch: 95 [3200/35339 (9%)]	Loss: 0.150819
Train Epoch: 95 [3840/35339 (11%)]	Loss: 0.196354
Train Epoch: 95 [4480/35339 (13%)]	Loss: 0.093802
Train Epoch: 95 [5120/35339 (14%)]	Loss: 0.093558
Train Epoch: 95 [5760/35339 (16%)]	Loss: 0.073446
Train Epoch: 95 [6400/35339 (18%)]	Loss: 0.367213
Train Epoch: 95 [7040/35339 (20%)]	Loss: 0.135304
Train Epoch: 95 [7680/35339 (22%)]	Loss: 0.073230
Train Epoch: 95 [8320/35339 (24%)]	Loss: 0.082161
Train Epoch: 95 [8960/35339 (25%)]	Loss: 0.072682
Train Epoch: 95 [9600/35339 (27%)]	Loss: 0.068797
Train Epoch: 95 [10240/35339 (29%)]	Loss: 0.071356
Train Epoch: 95 [10880/35339 (31%)]	Loss: 0.084112
Train Epoch: 95 [11520/35339 (33%)]	Loss: 0.200285
Train Epoch: 95 [12160/35339 (34%)]	Loss: 0.114514
Train Epoch: 95 [12800/35339 (36%)]	Loss: 0.065526
Train Epoch: 95 [13440/35339 (38%)]	Loss: 0.087095
Train Epoch: 95 [14080/35339 (40%)]	Loss: 0.100250
Train Epoch: 95 [14720/35339 (42%)]	Loss: 0.209197
Train Epoch: 95 [15360/35339 (43%)]	Loss: 0.094591
Train Epoch: 95 [16000/35339 (45%)]	Loss: 0.119608
Train Epoch: 95 [16640/35339 (47%)]	Loss: 0.068090
Train Epoch: 95 [17280/35339 (49%)]	Loss: 0.123523
Train Epoch: 95 [17920/35339 (51%)]	Loss: 0.156391
Train Epoch: 95 [18560/35339 (52%)]	Loss: 0.087100
Train Epoch: 95 [19200/35339 (54%)]	Loss: 0.086113
Train Epoch: 95 [19840/35339 (56%)]	Loss: 0.062692
Train Epoch: 95 [20480/35339 (58%)]	Loss: 0.165423
Train Epoch: 95 [21120/35339 (60%)]	Loss: 0.092606
Train Epoch: 95 [21760/35339 (61%)]	Loss: 0.063626
Train Epoch: 95 [22400/35339 (63%)]	Loss: 0.068779
Train Epoch: 95 [23040/35339 (65%)]	Loss: 0.078495
Train Epoch: 95 [23680/35339 (67%)]	Loss: 0.064714
Train Epoch: 95 [24320/35339 (69%)]	Loss: 0.056175
Train Epoch: 95 [24960/35339 (71%)]	Loss: 0.073834
Train Epoch: 95 [25600/35339 (72%)]	Loss: 0.114247
Train Epoch: 95 [26240/35339 (74%)]	Loss: 0.078258
Train Epoch: 95 [26880/35339 (76%)]	Loss: 0.067886
Train Epoch: 95 [27520/35339 (78%)]	Loss: 0.086276
Train Epoch: 95 [28160/35339 (80%)]	Loss: 0.087314
Train Epoch: 95 [28800/35339 (81%)]	Loss: 0.081528
Train Epoch: 95 [29440/35339 (83%)]	Loss: 0.076908
Train Epoch: 95 [30080/35339 (85%)]	Loss: 0.059836
Train Epoch: 95 [30720/35339 (87%)]	Loss: 0.073295
Train Epoch: 95 [31360/35339 (89%)]	Loss: 0.122838
Train Epoch: 95 [32000/35339 (90%)]	Loss: 0.062543
Train Epoch: 95 [32640/35339 (92%)]	Loss: 0.090321
Train Epoch: 95 [33280/35339 (94%)]	Loss: 0.088401
Train Epoch: 95 [33920/35339 (96%)]	Loss: 0.076328
Train Epoch: 95 [34560/35339 (98%)]	Loss: 0.079295
Train Epoch: 95 [35200/35339 (99%)]	Loss: 0.067864

Validation set: Average loss: 3.2534, Accuracy: 1415/3870 (37%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 96 [0/35339 (0%)]	Loss: 0.089318
Train Epoch: 96 [640/35339 (2%)]	Loss: 0.102901
Train Epoch: 96 [1280/35339 (4%)]	Loss: 0.058151
Train Epoch: 96 [1920/35339 (5%)]	Loss: 0.074138
Train Epoch: 96 [2560/35339 (7%)]	Loss: 0.100882
Train Epoch: 96 [3200/35339 (9%)]	Loss: 0.066907
Train Epoch: 96 [3840/35339 (11%)]	Loss: 0.064622
Train Epoch: 96 [4480/35339 (13%)]	Loss: 0.139955
Train Epoch: 96 [5120/35339 (14%)]	Loss: 0.078127
Train Epoch: 96 [5760/35339 (16%)]	Loss: 0.074761
Train Epoch: 96 [6400/35339 (18%)]	Loss: 0.061922
Train Epoch: 96 [7040/35339 (20%)]	Loss: 0.154072
Train Epoch: 96 [7680/35339 (22%)]	Loss: 0.185047
Train Epoch: 96 [8320/35339 (24%)]	Loss: 0.091298
Train Epoch: 96 [8960/35339 (25%)]	Loss: 0.066743
Train Epoch: 96 [9600/35339 (27%)]	Loss: 0.062139
Train Epoch: 96 [10240/35339 (29%)]	Loss: 0.139804
Train Epoch: 96 [10880/35339 (31%)]	Loss: 0.086525
Train Epoch: 96 [11520/35339 (33%)]	Loss: 0.102218
Train Epoch: 96 [12160/35339 (34%)]	Loss: 0.156522
Train Epoch: 96 [12800/35339 (36%)]	Loss: 0.179150
Train Epoch: 96 [13440/35339 (38%)]	Loss: 0.073160
Train Epoch: 96 [14080/35339 (40%)]	Loss: 0.080008
Train Epoch: 96 [14720/35339 (42%)]	Loss: 0.143387
Train Epoch: 96 [15360/35339 (43%)]	Loss: 0.086987
Train Epoch: 96 [16000/35339 (45%)]	Loss: 0.082525
Train Epoch: 96 [16640/35339 (47%)]	Loss: 0.093733
Train Epoch: 96 [17280/35339 (49%)]	Loss: 0.122749
Train Epoch: 96 [17920/35339 (51%)]	Loss: 0.076803
Train Epoch: 96 [18560/35339 (52%)]	Loss: 0.084829
Train Epoch: 96 [19200/35339 (54%)]	Loss: 0.127008
Train Epoch: 96 [19840/35339 (56%)]	Loss: 0.070452
Train Epoch: 96 [20480/35339 (58%)]	Loss: 0.083673
Train Epoch: 96 [21120/35339 (60%)]	Loss: 0.063367
Train Epoch: 96 [21760/35339 (61%)]	Loss: 0.096090
Train Epoch: 96 [22400/35339 (63%)]	Loss: 0.061855
Train Epoch: 96 [23040/35339 (65%)]	Loss: 0.080252
Train Epoch: 96 [23680/35339 (67%)]	Loss: 0.062048
Train Epoch: 96 [24320/35339 (69%)]	Loss: 0.065792
Train Epoch: 96 [24960/35339 (71%)]	Loss: 0.086402
Train Epoch: 96 [25600/35339 (72%)]	Loss: 0.063898
Train Epoch: 96 [26240/35339 (74%)]	Loss: 0.066575
Train Epoch: 96 [26880/35339 (76%)]	Loss: 0.067486
Train Epoch: 96 [27520/35339 (78%)]	Loss: 0.081028
Train Epoch: 96 [28160/35339 (80%)]	Loss: 0.122631
Train Epoch: 96 [28800/35339 (81%)]	Loss: 0.112991
Train Epoch: 96 [29440/35339 (83%)]	Loss: 0.093914
Train Epoch: 96 [30080/35339 (85%)]	Loss: 0.139773
Train Epoch: 96 [30720/35339 (87%)]	Loss: 0.064495
Train Epoch: 96 [31360/35339 (89%)]	Loss: 0.098298
Train Epoch: 96 [32000/35339 (90%)]	Loss: 0.111130
Train Epoch: 96 [32640/35339 (92%)]	Loss: 0.133864
Train Epoch: 96 [33280/35339 (94%)]	Loss: 0.078163
Train Epoch: 96 [33920/35339 (96%)]	Loss: 0.068718
Train Epoch: 96 [34560/35339 (98%)]	Loss: 0.075577
Train Epoch: 96 [35200/35339 (99%)]	Loss: 0.060580

Validation set: Average loss: 3.1558, Accuracy: 1482/3870 (38%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 97 [0/35339 (0%)]	Loss: 0.095100
Train Epoch: 97 [640/35339 (2%)]	Loss: 0.086437
Train Epoch: 97 [1280/35339 (4%)]	Loss: 0.071215
Train Epoch: 97 [1920/35339 (5%)]	Loss: 0.149191
Train Epoch: 97 [2560/35339 (7%)]	Loss: 0.142222
Train Epoch: 97 [3200/35339 (9%)]	Loss: 0.153347
Train Epoch: 97 [3840/35339 (11%)]	Loss: 0.065823
Train Epoch: 97 [4480/35339 (13%)]	Loss: 0.099666
Train Epoch: 97 [5120/35339 (14%)]	Loss: 0.073795
Train Epoch: 97 [5760/35339 (16%)]	Loss: 0.113811
Train Epoch: 97 [6400/35339 (18%)]	Loss: 0.088508
Train Epoch: 97 [7040/35339 (20%)]	Loss: 0.145602
Train Epoch: 97 [7680/35339 (22%)]	Loss: 0.069050
Train Epoch: 97 [8320/35339 (24%)]	Loss: 0.106617
Train Epoch: 97 [8960/35339 (25%)]	Loss: 0.067252
Train Epoch: 97 [9600/35339 (27%)]	Loss: 0.072069
Train Epoch: 97 [10240/35339 (29%)]	Loss: 0.091974
Train Epoch: 97 [10880/35339 (31%)]	Loss: 0.061660
Train Epoch: 97 [11520/35339 (33%)]	Loss: 0.067338
Train Epoch: 97 [12160/35339 (34%)]	Loss: 0.080360
Train Epoch: 97 [12800/35339 (36%)]	Loss: 0.063995
Train Epoch: 97 [13440/35339 (38%)]	Loss: 0.126167
Train Epoch: 97 [14080/35339 (40%)]	Loss: 0.120158
Train Epoch: 97 [14720/35339 (42%)]	Loss: 0.120769
Train Epoch: 97 [15360/35339 (43%)]	Loss: 0.092887
Train Epoch: 97 [16000/35339 (45%)]	Loss: 0.075029
Train Epoch: 97 [16640/35339 (47%)]	Loss: 0.076662
Train Epoch: 97 [17280/35339 (49%)]	Loss: 0.072049
Train Epoch: 97 [17920/35339 (51%)]	Loss: 0.081518
Train Epoch: 97 [18560/35339 (52%)]	Loss: 0.061447
Train Epoch: 97 [19200/35339 (54%)]	Loss: 0.060985
Train Epoch: 97 [19840/35339 (56%)]	Loss: 0.080968
Train Epoch: 97 [20480/35339 (58%)]	Loss: 0.120365
Train Epoch: 97 [21120/35339 (60%)]	Loss: 0.101944
Train Epoch: 97 [21760/35339 (61%)]	Loss: 0.099797
Train Epoch: 97 [22400/35339 (63%)]	Loss: 0.072952
Train Epoch: 97 [23040/35339 (65%)]	Loss: 0.116449
Train Epoch: 97 [23680/35339 (67%)]	Loss: 0.105338
Train Epoch: 97 [24320/35339 (69%)]	Loss: 0.066677
Train Epoch: 97 [24960/35339 (71%)]	Loss: 0.068211
Train Epoch: 97 [25600/35339 (72%)]	Loss: 0.090758
Train Epoch: 97 [26240/35339 (74%)]	Loss: 0.099386
Train Epoch: 97 [26880/35339 (76%)]	Loss: 0.072245
Train Epoch: 97 [27520/35339 (78%)]	Loss: 0.081035
Train Epoch: 97 [28160/35339 (80%)]	Loss: 0.062150
Train Epoch: 97 [28800/35339 (81%)]	Loss: 0.073786
Train Epoch: 97 [29440/35339 (83%)]	Loss: 0.061361
Train Epoch: 97 [30080/35339 (85%)]	Loss: 0.123635
Train Epoch: 97 [30720/35339 (87%)]	Loss: 0.063872
Train Epoch: 97 [31360/35339 (89%)]	Loss: 0.087458
Train Epoch: 97 [32000/35339 (90%)]	Loss: 0.093773
Train Epoch: 97 [32640/35339 (92%)]	Loss: 0.116566
Train Epoch: 97 [33280/35339 (94%)]	Loss: 0.103686
Train Epoch: 97 [33920/35339 (96%)]	Loss: 0.145940
Train Epoch: 97 [34560/35339 (98%)]	Loss: 0.070694
Train Epoch: 97 [35200/35339 (99%)]	Loss: 0.093548

Validation set: Average loss: 3.1169, Accuracy: 1466/3870 (38%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 98 [0/35339 (0%)]	Loss: 0.074550
Train Epoch: 98 [640/35339 (2%)]	Loss: 0.069535
Train Epoch: 98 [1280/35339 (4%)]	Loss: 0.067625
Train Epoch: 98 [1920/35339 (5%)]	Loss: 0.060159
Train Epoch: 98 [2560/35339 (7%)]	Loss: 0.081804
Train Epoch: 98 [3200/35339 (9%)]	Loss: 0.061776
Train Epoch: 98 [3840/35339 (11%)]	Loss: 0.161871
Train Epoch: 98 [4480/35339 (13%)]	Loss: 0.083606
Train Epoch: 98 [5120/35339 (14%)]	Loss: 0.062599
Train Epoch: 98 [5760/35339 (16%)]	Loss: 0.101783
Train Epoch: 98 [6400/35339 (18%)]	Loss: 0.078389
Train Epoch: 98 [7040/35339 (20%)]	Loss: 0.062576
Train Epoch: 98 [7680/35339 (22%)]	Loss: 0.093137
Train Epoch: 98 [8320/35339 (24%)]	Loss: 0.119139
Train Epoch: 98 [8960/35339 (25%)]	Loss: 0.102982
Train Epoch: 98 [9600/35339 (27%)]	Loss: 0.065392
Train Epoch: 98 [10240/35339 (29%)]	Loss: 0.066826
Train Epoch: 98 [10880/35339 (31%)]	Loss: 0.169585
Train Epoch: 98 [11520/35339 (33%)]	Loss: 0.100519
Train Epoch: 98 [12160/35339 (34%)]	Loss: 0.063285
Train Epoch: 98 [12800/35339 (36%)]	Loss: 0.093505
Train Epoch: 98 [13440/35339 (38%)]	Loss: 0.073621
Train Epoch: 98 [14080/35339 (40%)]	Loss: 0.098694
Train Epoch: 98 [14720/35339 (42%)]	Loss: 0.071140
Train Epoch: 98 [15360/35339 (43%)]	Loss: 0.110817
Train Epoch: 98 [16000/35339 (45%)]	Loss: 0.076116
Train Epoch: 98 [16640/35339 (47%)]	Loss: 0.060486
Train Epoch: 98 [17280/35339 (49%)]	Loss: 0.088584
Train Epoch: 98 [17920/35339 (51%)]	Loss: 0.070279
Train Epoch: 98 [18560/35339 (52%)]	Loss: 0.086843
Train Epoch: 98 [19200/35339 (54%)]	Loss: 0.094798
Train Epoch: 98 [19840/35339 (56%)]	Loss: 0.061180
Train Epoch: 98 [20480/35339 (58%)]	Loss: 0.076434
Train Epoch: 98 [21120/35339 (60%)]	Loss: 0.074524
Train Epoch: 98 [21760/35339 (61%)]	Loss: 0.117284
Train Epoch: 98 [22400/35339 (63%)]	Loss: 0.070127
Train Epoch: 98 [23040/35339 (65%)]	Loss: 0.067977
Train Epoch: 98 [23680/35339 (67%)]	Loss: 0.061166
Train Epoch: 98 [24320/35339 (69%)]	Loss: 0.115734
Train Epoch: 98 [24960/35339 (71%)]	Loss: 0.081346
Train Epoch: 98 [25600/35339 (72%)]	Loss: 0.108213
Train Epoch: 98 [26240/35339 (74%)]	Loss: 0.169529
Train Epoch: 98 [26880/35339 (76%)]	Loss: 0.129897
Train Epoch: 98 [27520/35339 (78%)]	Loss: 0.086094
Train Epoch: 98 [28160/35339 (80%)]	Loss: 0.099569
Train Epoch: 98 [28800/35339 (81%)]	Loss: 0.067695
Train Epoch: 98 [29440/35339 (83%)]	Loss: 0.064162
Train Epoch: 98 [30080/35339 (85%)]	Loss: 0.073197
Train Epoch: 98 [30720/35339 (87%)]	Loss: 0.061129
Train Epoch: 98 [31360/35339 (89%)]	Loss: 0.121841
Train Epoch: 98 [32000/35339 (90%)]	Loss: 0.069909
Train Epoch: 98 [32640/35339 (92%)]	Loss: 0.061967
Train Epoch: 98 [33280/35339 (94%)]	Loss: 0.060956
Train Epoch: 98 [33920/35339 (96%)]	Loss: 0.070173
Train Epoch: 98 [34560/35339 (98%)]	Loss: 0.075847
Train Epoch: 98 [35200/35339 (99%)]	Loss: 0.062138

Validation set: Average loss: 3.2338, Accuracy: 1370/3870 (35%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 99 [0/35339 (0%)]	Loss: 0.099687
Train Epoch: 99 [640/35339 (2%)]	Loss: 0.098934
Train Epoch: 99 [1280/35339 (4%)]	Loss: 0.066302
Train Epoch: 99 [1920/35339 (5%)]	Loss: 0.069439
Train Epoch: 99 [2560/35339 (7%)]	Loss: 0.064541
Train Epoch: 99 [3200/35339 (9%)]	Loss: 0.095449
Train Epoch: 99 [3840/35339 (11%)]	Loss: 0.092966
Train Epoch: 99 [4480/35339 (13%)]	Loss: 0.061315
Train Epoch: 99 [5120/35339 (14%)]	Loss: 0.108300
Train Epoch: 99 [5760/35339 (16%)]	Loss: 0.061254
Train Epoch: 99 [6400/35339 (18%)]	Loss: 0.118535
Train Epoch: 99 [7040/35339 (20%)]	Loss: 0.106674
Train Epoch: 99 [7680/35339 (22%)]	Loss: 0.060995
Train Epoch: 99 [8320/35339 (24%)]	Loss: 0.064516
Train Epoch: 99 [8960/35339 (25%)]	Loss: 0.060221
Train Epoch: 99 [9600/35339 (27%)]	Loss: 0.083003
Train Epoch: 99 [10240/35339 (29%)]	Loss: 0.077076
Train Epoch: 99 [10880/35339 (31%)]	Loss: 0.065226
Train Epoch: 99 [11520/35339 (33%)]	Loss: 0.087327
Train Epoch: 99 [12160/35339 (34%)]	Loss: 0.054544
Train Epoch: 99 [12800/35339 (36%)]	Loss: 0.275738
Train Epoch: 99 [13440/35339 (38%)]	Loss: 0.079533
Train Epoch: 99 [14080/35339 (40%)]	Loss: 0.096469
Train Epoch: 99 [14720/35339 (42%)]	Loss: 0.118793
Train Epoch: 99 [15360/35339 (43%)]	Loss: 0.072581
Train Epoch: 99 [16000/35339 (45%)]	Loss: 0.072972
Train Epoch: 99 [16640/35339 (47%)]	Loss: 0.075147
Train Epoch: 99 [17280/35339 (49%)]	Loss: 0.095877
Train Epoch: 99 [17920/35339 (51%)]	Loss: 0.133407
Train Epoch: 99 [18560/35339 (52%)]	Loss: 0.063711
Train Epoch: 99 [19200/35339 (54%)]	Loss: 0.064936
Train Epoch: 99 [19840/35339 (56%)]	Loss: 0.069165
Train Epoch: 99 [20480/35339 (58%)]	Loss: 0.104749
Train Epoch: 99 [21120/35339 (60%)]	Loss: 0.089234
Train Epoch: 99 [21760/35339 (61%)]	Loss: 0.076023
Train Epoch: 99 [22400/35339 (63%)]	Loss: 0.115618
Train Epoch: 99 [23040/35339 (65%)]	Loss: 0.060052
Train Epoch: 99 [23680/35339 (67%)]	Loss: 0.121584
Train Epoch: 99 [24320/35339 (69%)]	Loss: 0.110424
Train Epoch: 99 [24960/35339 (71%)]	Loss: 0.065233
Train Epoch: 99 [25600/35339 (72%)]	Loss: 0.080291
Train Epoch: 99 [26240/35339 (74%)]	Loss: 0.097185
Train Epoch: 99 [26880/35339 (76%)]	Loss: 0.086531
Train Epoch: 99 [27520/35339 (78%)]	Loss: 0.096610
Train Epoch: 99 [28160/35339 (80%)]	Loss: 0.090270
Train Epoch: 99 [28800/35339 (81%)]	Loss: 0.071071
Train Epoch: 99 [29440/35339 (83%)]	Loss: 0.084785
Train Epoch: 99 [30080/35339 (85%)]	Loss: 0.091413
Train Epoch: 99 [30720/35339 (87%)]	Loss: 0.064999
Train Epoch: 99 [31360/35339 (89%)]	Loss: 0.104603
Train Epoch: 99 [32000/35339 (90%)]	Loss: 0.073719
Train Epoch: 99 [32640/35339 (92%)]	Loss: 0.112782
Train Epoch: 99 [33280/35339 (94%)]	Loss: 0.101599
Train Epoch: 99 [33920/35339 (96%)]	Loss: 0.240990
Train Epoch: 99 [34560/35339 (98%)]	Loss: 0.094581
Train Epoch: 99 [35200/35339 (99%)]	Loss: 0.064971

Validation set: Average loss: 3.2003, Accuracy: 1389/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
Train Epoch: 100 [0/35339 (0%)]	Loss: 0.055877
Train Epoch: 100 [640/35339 (2%)]	Loss: 0.065600
Train Epoch: 100 [1280/35339 (4%)]	Loss: 0.107609
Train Epoch: 100 [1920/35339 (5%)]	Loss: 0.067737
Train Epoch: 100 [2560/35339 (7%)]	Loss: 0.062847
Train Epoch: 100 [3200/35339 (9%)]	Loss: 0.074245
Train Epoch: 100 [3840/35339 (11%)]	Loss: 0.093495
Train Epoch: 100 [4480/35339 (13%)]	Loss: 0.100516
Train Epoch: 100 [5120/35339 (14%)]	Loss: 0.065911
Train Epoch: 100 [5760/35339 (16%)]	Loss: 0.084707
Train Epoch: 100 [6400/35339 (18%)]	Loss: 0.095821
Train Epoch: 100 [7040/35339 (20%)]	Loss: 0.123565
Train Epoch: 100 [7680/35339 (22%)]	Loss: 0.088442
Train Epoch: 100 [8320/35339 (24%)]	Loss: 0.117082
Train Epoch: 100 [8960/35339 (25%)]	Loss: 0.076033
Train Epoch: 100 [9600/35339 (27%)]	Loss: 0.076552
Train Epoch: 100 [10240/35339 (29%)]	Loss: 0.060945
Train Epoch: 100 [10880/35339 (31%)]	Loss: 0.082583
Train Epoch: 100 [11520/35339 (33%)]	Loss: 0.058069
Train Epoch: 100 [12160/35339 (34%)]	Loss: 0.131984
Train Epoch: 100 [12800/35339 (36%)]	Loss: 0.061024
Train Epoch: 100 [13440/35339 (38%)]	Loss: 0.097571
Train Epoch: 100 [14080/35339 (40%)]	Loss: 0.107676
Train Epoch: 100 [14720/35339 (42%)]	Loss: 0.128272
Train Epoch: 100 [15360/35339 (43%)]	Loss: 0.070047
Train Epoch: 100 [16000/35339 (45%)]	Loss: 0.061691
Train Epoch: 100 [16640/35339 (47%)]	Loss: 0.087932
Train Epoch: 100 [17280/35339 (49%)]	Loss: 0.068580
Train Epoch: 100 [17920/35339 (51%)]	Loss: 0.122191
Train Epoch: 100 [18560/35339 (52%)]	Loss: 0.203048
Train Epoch: 100 [19200/35339 (54%)]	Loss: 0.075385
Train Epoch: 100 [19840/35339 (56%)]	Loss: 0.119435
Train Epoch: 100 [20480/35339 (58%)]	Loss: 0.099190
Train Epoch: 100 [21120/35339 (60%)]	Loss: 0.063954
Train Epoch: 100 [21760/35339 (61%)]	Loss: 0.107241
Train Epoch: 100 [22400/35339 (63%)]	Loss: 0.117705
Train Epoch: 100 [23040/35339 (65%)]	Loss: 0.108737
Train Epoch: 100 [23680/35339 (67%)]	Loss: 0.123437
Train Epoch: 100 [24320/35339 (69%)]	Loss: 0.080028
Train Epoch: 100 [24960/35339 (71%)]	Loss: 0.060423
Train Epoch: 100 [25600/35339 (72%)]	Loss: 0.084809
Train Epoch: 100 [26240/35339 (74%)]	Loss: 0.089309
Train Epoch: 100 [26880/35339 (76%)]	Loss: 0.083836
Train Epoch: 100 [27520/35339 (78%)]	Loss: 0.069856
Train Epoch: 100 [28160/35339 (80%)]	Loss: 0.100863
Train Epoch: 100 [28800/35339 (81%)]	Loss: 0.098405
Train Epoch: 100 [29440/35339 (83%)]	Loss: 0.096266
Train Epoch: 100 [30080/35339 (85%)]	Loss: 0.055988
Train Epoch: 100 [30720/35339 (87%)]	Loss: 0.065816
Train Epoch: 100 [31360/35339 (89%)]	Loss: 0.062890
Train Epoch: 100 [32000/35339 (90%)]	Loss: 0.080595
Train Epoch: 100 [32640/35339 (92%)]	Loss: 0.129499
Train Epoch: 100 [33280/35339 (94%)]	Loss: 0.116652
Train Epoch: 100 [33920/35339 (96%)]	Loss: 0.107376
Train Epoch: 100 [34560/35339 (98%)]	Loss: 0.060442
Train Epoch: 100 [35200/35339 (99%)]	Loss: 0.131856

Validation set: Average loss: 3.2160, Accuracy: 1395/3870 (36%)


Saved model to model_latest_Adagrad_dataAugmentation.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation.pth` to generate the Kaggle formatted csv file
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
  0%|          | 0/12631 [00:00<?, ?it/s]  0%|          | 5/12631 [00:00<04:36, 45.73it/s]  0%|          | 14/12631 [00:00<04:26, 47.41it/s]  0%|          | 19/12631 [00:00<04:49, 43.62it/s]  0%|          | 27/12631 [00:00<04:12, 49.94it/s]  0%|          | 35/12631 [00:00<03:48, 55.13it/s]  0%|          | 45/12631 [00:00<03:19, 63.18it/s]  0%|          | 55/12631 [00:00<02:58, 70.34it/s]  1%|          | 66/12631 [00:00<02:39, 78.56it/s]  1%|          | 80/12631 [00:01<02:20, 89.49it/s]  1%|          | 91/12631 [00:01<02:13, 93.73it/s]  1%|          | 103/12631 [00:01<02:05, 100.08it/s]  1%|          | 114/12631 [00:01<02:03, 101.56it/s]  1%|1         | 129/12631 [00:01<01:52, 110.87it/s]  1%|1         | 141/12631 [00:01<01:50, 112.55it/s]  1%|1         | 156/12631 [00:01<01:43, 120.29it/s]  1%|1         | 169/12631 [00:01<01:44, 119.15it/s]  1%|1         | 182/12631 [00:01<01:55, 107.76it/s]  2%|1         | 196/12631 [00:02<01:47, 115.49it/s]  2%|1         | 208/12631 [00:02<01:47, 115.89it/s]  2%|1         | 223/12631 [00:02<01:42, 121.61it/s]  2%|1         | 236/12631 [00:02<01:40, 122.93it/s]  2%|1         | 250/12631 [00:02<01:37, 127.25it/s]  2%|2         | 266/12631 [00:02<01:32, 133.16it/s]  2%|2         | 280/12631 [00:02<01:35, 129.26it/s]  2%|2         | 294/12631 [00:02<01:35, 128.66it/s]  2%|2         | 309/12631 [00:02<01:32, 132.99it/s]  3%|2         | 324/12631 [00:02<01:29, 136.87it/s]  3%|2         | 339/12631 [00:03<01:29, 137.22it/s]  3%|2         | 353/12631 [00:03<01:29, 137.05it/s]  3%|2         | 367/12631 [00:03<01:31, 133.54it/s]  3%|3         | 384/12631 [00:03<01:25, 142.44it/s]  3%|3         | 399/12631 [00:03<01:30, 135.79it/s]  3%|3         | 413/12631 [00:03<02:15, 90.41it/s]   3%|3         | 425/12631 [00:04<02:49, 71.86it/s]  3%|3         | 435/12631 [00:04<03:25, 59.31it/s]  4%|3         | 444/12631 [00:04<03:04, 65.99it/s]  4%|3         | 456/12631 [00:04<02:41, 75.46it/s]  4%|3         | 470/12631 [00:04<02:19, 87.09it/s]  4%|3         | 486/12631 [00:04<02:01, 100.23it/s]  4%|3         | 499/12631 [00:04<01:53, 107.16it/s]  4%|4         | 514/12631 [00:04<01:45, 115.24it/s]  4%|4         | 528/12631 [00:05<01:41, 119.51it/s]  4%|4         | 541/12631 [00:05<01:39, 120.90it/s]  4%|4         | 559/12631 [00:05<01:31, 131.86it/s]  5%|4         | 575/12631 [00:05<01:26, 139.04it/s]  5%|4         | 591/12631 [00:05<01:23, 143.44it/s]  5%|4         | 609/12631 [00:05<01:19, 150.78it/s]  5%|4         | 630/12631 [00:05<01:13, 164.05it/s]  5%|5         | 650/12631 [00:05<01:09, 171.57it/s]  5%|5         | 668/12631 [00:05<01:13, 161.75it/s]  5%|5         | 685/12631 [00:05<01:16, 155.17it/s]  6%|5         | 703/12631 [00:06<01:13, 161.57it/s]  6%|5         | 720/12631 [00:06<01:15, 158.10it/s]  6%|5         | 740/12631 [00:06<01:10, 167.50it/s]  6%|6         | 758/12631 [00:06<01:12, 163.62it/s]  6%|6         | 775/12631 [00:06<01:14, 159.98it/s]  6%|6         | 792/12631 [00:06<01:14, 158.99it/s]  6%|6         | 809/12631 [00:06<01:14, 158.34it/s]  7%|6         | 825/12631 [00:06<01:16, 154.53it/s]  7%|6         | 846/12631 [00:06<01:10, 167.81it/s]  7%|6         | 864/12631 [00:07<01:09, 169.75it/s]  7%|6         | 882/12631 [00:07<01:13, 158.97it/s]  7%|7         | 899/12631 [00:07<01:12, 160.84it/s]  7%|7         | 916/12631 [00:07<01:15, 155.32it/s]  7%|7         | 935/12631 [00:07<01:12, 161.70it/s]  8%|7         | 952/12631 [00:07<01:11, 163.16it/s]  8%|7         | 969/12631 [00:07<01:34, 123.65it/s]  8%|7         | 983/12631 [00:08<02:36, 74.51it/s]   8%|7         | 997/12631 [00:08<02:15, 86.03it/s]  8%|7         | 1009/12631 [00:08<02:24, 80.40it/s]  8%|8         | 1026/12631 [00:08<02:02, 94.71it/s]  8%|8         | 1044/12631 [00:08<01:45, 109.41it/s]  8%|8         | 1060/12631 [00:08<01:53, 101.70it/s]  9%|8         | 1075/12631 [00:08<01:46, 108.65it/s]  9%|8         | 1092/12631 [00:09<01:35, 121.02it/s]  9%|8         | 1110/12631 [00:09<01:27, 132.28it/s]  9%|8         | 1132/12631 [00:09<01:16, 149.54it/s]  9%|9         | 1149/12631 [00:09<01:15, 152.59it/s]  9%|9         | 1171/12631 [00:09<01:08, 167.62it/s]  9%|9         | 1190/12631 [00:09<01:05, 173.58it/s] 10%|9         | 1212/12631 [00:09<01:01, 184.38it/s] 10%|9         | 1232/12631 [00:09<01:25, 132.76it/s] 10%|9         | 1248/12631 [00:10<01:22, 138.54it/s] 10%|#         | 1266/12631 [00:10<01:16, 148.42it/s] 10%|#         | 1283/12631 [00:10<01:13, 153.37it/s] 10%|#         | 1303/12631 [00:10<01:08, 164.68it/s] 10%|#         | 1321/12631 [00:10<01:06, 168.96it/s] 11%|#         | 1339/12631 [00:10<01:05, 171.97it/s] 11%|#         | 1357/12631 [00:10<01:06, 169.43it/s] 11%|#         | 1375/12631 [00:10<01:05, 170.83it/s] 11%|#1        | 1393/12631 [00:10<01:05, 172.30it/s] 11%|#1        | 1411/12631 [00:11<01:09, 161.66it/s] 11%|#1        | 1430/12631 [00:11<01:06, 168.06it/s] 11%|#1        | 1448/12631 [00:11<01:06, 169.26it/s] 12%|#1        | 1466/12631 [00:11<01:05, 170.03it/s] 12%|#1        | 1484/12631 [00:11<01:09, 161.21it/s] 12%|#1        | 1504/12631 [00:11<01:06, 168.52it/s] 12%|#2        | 1522/12631 [00:11<01:59, 93.14it/s]  12%|#2        | 1536/12631 [00:12<01:52, 98.76it/s] 12%|#2        | 1555/12631 [00:12<01:37, 114.14it/s] 12%|#2        | 1573/12631 [00:12<01:26, 128.10it/s] 13%|#2        | 1589/12631 [00:12<01:22, 134.08it/s] 13%|#2        | 1608/12631 [00:12<01:15, 145.63it/s] 13%|#2        | 1628/12631 [00:12<01:09, 157.85it/s] 13%|#3        | 1646/12631 [00:12<01:09, 157.28it/s] 13%|#3        | 1666/12631 [00:12<01:05, 166.64it/s] 13%|#3        | 1684/12631 [00:12<01:17, 141.83it/s] 13%|#3        | 1700/12631 [00:13<01:17, 140.28it/s] 14%|#3        | 1715/12631 [00:13<01:30, 120.24it/s] 14%|#3        | 1731/12631 [00:13<01:24, 129.69it/s] 14%|#3        | 1745/12631 [00:13<01:42, 106.07it/s] 14%|#3        | 1758/12631 [00:13<01:50, 98.50it/s]  14%|#4        | 1769/12631 [00:13<01:49, 98.77it/s] 14%|#4        | 1780/12631 [00:13<01:51, 97.75it/s] 14%|#4        | 1791/12631 [00:14<01:48, 100.29it/s] 14%|#4        | 1804/12631 [00:14<01:41, 107.08it/s] 14%|#4        | 1816/12631 [00:14<01:40, 107.71it/s] 14%|#4        | 1831/12631 [00:14<01:32, 117.33it/s] 15%|#4        | 1845/12631 [00:14<01:28, 122.43it/s] 15%|#4        | 1859/12631 [00:14<01:28, 121.49it/s] 15%|#4        | 1872/12631 [00:14<01:28, 121.09it/s] 15%|#4        | 1885/12631 [00:14<01:33, 115.21it/s] 15%|#5        | 1897/12631 [00:14<01:43, 104.14it/s] 15%|#5        | 1908/12631 [00:15<01:59, 89.56it/s]  15%|#5        | 1918/12631 [00:15<01:55, 92.43it/s] 15%|#5        | 1929/12631 [00:15<01:53, 94.03it/s] 15%|#5        | 1943/12631 [00:15<01:43, 103.48it/s] 16%|#5        | 1958/12631 [00:15<01:33, 114.00it/s] 16%|#5        | 1972/12631 [00:15<01:28, 119.98it/s] 16%|#5        | 1985/12631 [00:15<02:13, 79.52it/s]  16%|#5        | 1996/12631 [00:16<02:04, 85.29it/s] 16%|#5        | 2007/12631 [00:16<02:17, 77.54it/s] 16%|#6        | 2021/12631 [00:16<02:04, 85.17it/s] 16%|#6        | 2031/12631 [00:16<02:00, 88.15it/s] 16%|#6        | 2049/12631 [00:16<01:42, 103.65it/s] 16%|#6        | 2062/12631 [00:16<01:36, 109.45it/s] 16%|#6        | 2075/12631 [00:16<01:32, 114.24it/s] 17%|#6        | 2088/12631 [00:16<01:43, 101.93it/s] 17%|#6        | 2102/12631 [00:17<01:35, 110.03it/s] 17%|#6        | 2114/12631 [00:17<01:34, 111.58it/s] 17%|#6        | 2130/12631 [00:17<01:25, 122.63it/s] 17%|#6        | 2145/12631 [00:17<01:21, 128.96it/s] 17%|#7        | 2159/12631 [00:17<01:21, 127.93it/s] 17%|#7        | 2175/12631 [00:17<01:18, 133.56it/s] 17%|#7        | 2189/12631 [00:17<01:17, 134.54it/s] 17%|#7        | 2203/12631 [00:17<01:19, 131.68it/s] 18%|#7        | 2218/12631 [00:17<01:17, 133.66it/s] 18%|#7        | 2232/12631 [00:17<01:18, 132.21it/s] 18%|#7        | 2247/12631 [00:18<01:16, 136.42it/s] 18%|#7        | 2261/12631 [00:18<01:16, 134.99it/s] 18%|#8        | 2278/12631 [00:18<01:12, 143.75it/s] 18%|#8        | 2293/12631 [00:18<01:28, 117.25it/s] 18%|#8        | 2311/12631 [00:18<01:20, 128.47it/s] 18%|#8        | 2329/12631 [00:18<01:14, 138.49it/s] 19%|#8        | 2346/12631 [00:18<01:10, 146.51it/s] 19%|#8        | 2362/12631 [00:18<01:17, 132.01it/s] 19%|#8        | 2377/12631 [00:19<01:20, 126.84it/s] 19%|#8        | 2396/12631 [00:19<01:13, 140.06it/s] 19%|#9        | 2412/12631 [00:19<01:10, 144.28it/s] 19%|#9        | 2428/12631 [00:19<01:10, 144.27it/s] 19%|#9        | 2443/12631 [00:19<01:10, 144.99it/s] 19%|#9        | 2459/12631 [00:19<01:08, 148.45it/s] 20%|#9        | 2479/12631 [00:19<01:03, 158.68it/s] 20%|#9        | 2496/12631 [00:19<01:03, 159.16it/s] 20%|#9        | 2513/12631 [00:19<01:18, 129.59it/s] 20%|##        | 2528/12631 [00:20<01:15, 133.38it/s] 20%|##        | 2546/12631 [00:20<01:11, 141.72it/s] 20%|##        | 2564/12631 [00:20<01:06, 151.37it/s] 20%|##        | 2580/12631 [00:20<01:17, 129.50it/s] 21%|##        | 2594/12631 [00:20<01:18, 127.88it/s] 21%|##        | 2608/12631 [00:20<01:16, 130.61it/s] 21%|##        | 2624/12631 [00:20<01:12, 137.53it/s] 21%|##        | 2644/12631 [00:20<01:06, 150.88it/s] 21%|##1       | 2660/12631 [00:20<01:08, 144.83it/s] 21%|##1       | 2678/12631 [00:21<01:05, 151.32it/s] 21%|##1       | 2694/12631 [00:21<01:08, 144.66it/s] 21%|##1       | 2713/12631 [00:21<01:05, 152.55it/s] 22%|##1       | 2729/12631 [00:21<01:06, 150.00it/s] 22%|##1       | 2746/12631 [00:21<01:04, 153.12it/s] 22%|##1       | 2764/12631 [00:21<01:01, 159.83it/s] 22%|##2       | 2781/12631 [00:21<01:02, 156.50it/s] 22%|##2       | 2797/12631 [00:21<01:04, 151.99it/s] 22%|##2       | 2813/12631 [00:21<01:05, 150.04it/s] 22%|##2       | 2829/12631 [00:22<01:04, 151.56it/s] 23%|##2       | 2845/12631 [00:22<01:04, 152.86it/s] 23%|##2       | 2864/12631 [00:22<01:00, 160.91it/s] 23%|##2       | 2883/12631 [00:22<00:58, 166.99it/s] 23%|##2       | 2900/12631 [00:22<01:00, 160.60it/s] 23%|##3       | 2918/12631 [00:22<00:59, 164.61it/s] 23%|##3       | 2935/12631 [00:22<00:58, 166.01it/s] 23%|##3       | 2955/12631 [00:22<00:55, 174.78it/s] 24%|##3       | 2973/12631 [00:22<00:56, 172.26it/s] 24%|##3       | 2993/12631 [00:23<00:53, 179.02it/s] 24%|##3       | 3012/12631 [00:23<00:55, 174.59it/s] 24%|##3       | 3030/12631 [00:23<00:55, 173.56it/s] 24%|##4       | 3048/12631 [00:23<00:54, 174.47it/s] 24%|##4       | 3066/12631 [00:23<00:55, 173.15it/s] 24%|##4       | 3086/12631 [00:23<00:52, 180.31it/s] 25%|##4       | 3105/12631 [00:23<01:36, 98.99it/s]  25%|##4       | 3120/12631 [00:24<02:02, 77.69it/s] 25%|##4       | 3132/12631 [00:24<01:50, 85.84it/s] 25%|##4       | 3152/12631 [00:24<01:31, 103.16it/s] 25%|##5       | 3170/12631 [00:24<01:20, 118.20it/s] 25%|##5       | 3192/12631 [00:24<01:09, 135.65it/s] 25%|##5       | 3216/12631 [00:24<01:00, 154.75it/s] 26%|##5       | 3235/12631 [00:24<01:14, 125.46it/s] 26%|##5       | 3253/12631 [00:25<01:08, 136.62it/s] 26%|##5       | 3274/12631 [00:25<01:02, 150.78it/s] 26%|##6       | 3293/12631 [00:25<00:58, 159.82it/s] 26%|##6       | 3313/12631 [00:25<00:55, 168.28it/s] 26%|##6       | 3332/12631 [00:25<01:01, 152.02it/s] 27%|##6       | 3349/12631 [00:25<00:59, 155.62it/s] 27%|##6       | 3366/12631 [00:25<01:13, 126.16it/s] 27%|##6       | 3385/12631 [00:25<01:06, 139.99it/s] 27%|##6       | 3403/12631 [00:26<01:02, 147.52it/s] 27%|##7       | 3423/12631 [00:26<00:57, 159.05it/s] 27%|##7       | 3442/12631 [00:26<00:55, 165.47it/s] 27%|##7       | 3460/12631 [00:26<00:57, 159.65it/s] 28%|##7       | 3477/12631 [00:26<00:57, 159.02it/s] 28%|##7       | 3497/12631 [00:26<00:55, 165.47it/s] 28%|##7       | 3514/12631 [00:26<00:54, 165.97it/s] 28%|##7       | 3534/12631 [00:26<00:52, 173.14it/s] 28%|##8       | 3554/12631 [00:26<00:51, 176.25it/s] 28%|##8       | 3573/12631 [00:26<00:50, 179.49it/s] 28%|##8       | 3592/12631 [00:27<00:53, 170.50it/s] 29%|##8       | 3610/12631 [00:27<00:52, 171.35it/s] 29%|##8       | 3631/12631 [00:27<00:49, 180.55it/s] 29%|##8       | 3651/12631 [00:27<00:48, 184.47it/s] 29%|##9       | 3670/12631 [00:27<00:49, 179.67it/s] 29%|##9       | 3689/12631 [00:27<01:19, 112.08it/s] 29%|##9       | 3704/12631 [00:27<01:13, 121.09it/s] 29%|##9       | 3720/12631 [00:28<01:08, 129.27it/s] 30%|##9       | 3735/12631 [00:28<01:13, 120.71it/s] 30%|##9       | 3752/12631 [00:28<01:07, 131.32it/s] 30%|##9       | 3770/12631 [00:28<01:02, 141.23it/s] 30%|##9       | 3786/12631 [00:28<01:08, 128.69it/s] 30%|###       | 3802/12631 [00:28<01:04, 136.05it/s] 30%|###       | 3821/12631 [00:28<00:59, 148.16it/s] 30%|###       | 3838/12631 [00:28<00:57, 153.78it/s] 31%|###       | 3856/12631 [00:28<00:55, 159.30it/s] 31%|###       | 3875/12631 [00:29<00:53, 162.95it/s] 31%|###       | 3893/12631 [00:29<00:52, 166.68it/s] 31%|###       | 3911/12631 [00:29<00:51, 169.98it/s] 31%|###1      | 3930/12631 [00:29<00:49, 174.44it/s] 31%|###1      | 3948/12631 [00:29<00:50, 172.95it/s] 31%|###1      | 3966/12631 [00:29<00:52, 166.06it/s] 32%|###1      | 3983/12631 [00:29<00:52, 164.59it/s] 32%|###1      | 4004/12631 [00:29<00:49, 173.47it/s] 32%|###1      | 4023/12631 [00:29<00:49, 175.35it/s] 32%|###1      | 4041/12631 [00:30<00:49, 174.19it/s] 32%|###2      | 4062/12631 [00:30<00:47, 181.61it/s] 32%|###2      | 4084/12631 [00:30<00:44, 189.94it/s] 32%|###2      | 4104/12631 [00:30<00:44, 190.42it/s] 33%|###2      | 4125/12631 [00:30<00:44, 190.34it/s] 33%|###2      | 4145/12631 [00:30<00:44, 190.86it/s] 33%|###2      | 4165/12631 [00:30<00:47, 179.99it/s] 33%|###3      | 4186/12631 [00:30<00:45, 186.15it/s] 33%|###3      | 4205/12631 [00:30<00:46, 182.74it/s] 33%|###3      | 4224/12631 [00:31<00:45, 184.25it/s] 34%|###3      | 4243/12631 [00:31<00:46, 180.90it/s] 34%|###3      | 4266/12631 [00:31<00:43, 191.44it/s] 34%|###3      | 4286/12631 [00:31<00:44, 185.72it/s] 34%|###4      | 4305/12631 [00:31<00:45, 182.91it/s] 34%|###4      | 4325/12631 [00:31<00:44, 185.51it/s] 34%|###4      | 4344/12631 [00:31<01:02, 132.33it/s] 35%|###4      | 4366/12631 [00:31<00:55, 149.28it/s] 35%|###4      | 4384/12631 [00:32<01:12, 114.34it/s] 35%|###4      | 4400/12631 [00:32<01:10, 117.46it/s] 35%|###5      | 4421/12631 [00:32<01:00, 134.59it/s] 35%|###5      | 4442/12631 [00:32<00:55, 148.50it/s] 35%|###5      | 4462/12631 [00:32<00:51, 159.91it/s] 35%|###5      | 4480/12631 [00:32<01:06, 121.80it/s] 36%|###5      | 4498/12631 [00:32<01:00, 133.58it/s] 36%|###5      | 4514/12631 [00:33<01:10, 114.59it/s] 36%|###5      | 4536/12631 [00:33<01:00, 132.86it/s] 36%|###6      | 4554/12631 [00:33<00:56, 143.02it/s] 36%|###6      | 4579/12631 [00:33<00:49, 161.21it/s] 36%|###6      | 4598/12631 [00:33<00:48, 165.37it/s] 37%|###6      | 4617/12631 [00:33<00:48, 166.20it/s] 37%|###6      | 4635/12631 [00:33<00:58, 137.34it/s] 37%|###6      | 4655/12631 [00:33<00:52, 151.13it/s] 37%|###7      | 4676/12631 [00:34<00:48, 164.06it/s] 37%|###7      | 4694/12631 [00:34<00:49, 160.49it/s] 37%|###7      | 4713/12631 [00:34<00:47, 167.61it/s] 37%|###7      | 4734/12631 [00:34<00:44, 176.70it/s] 38%|###7      | 4754/12631 [00:34<00:43, 181.79it/s] 38%|###7      | 4775/12631 [00:34<00:41, 188.96it/s] 38%|###7      | 4795/12631 [00:34<00:43, 181.71it/s] 38%|###8      | 4815/12631 [00:34<00:42, 184.80it/s] 38%|###8      | 4836/12631 [00:34<00:41, 188.50it/s] 38%|###8      | 4856/12631 [00:34<00:41, 188.85it/s] 39%|###8      | 4877/12631 [00:35<00:40, 193.12it/s] 39%|###8      | 4897/12631 [00:35<00:41, 185.55it/s] 39%|###8      | 4917/12631 [00:35<00:41, 187.77it/s] 39%|###9      | 4937/12631 [00:35<00:40, 188.55it/s] 39%|###9      | 4958/12631 [00:35<00:39, 193.81it/s] 39%|###9      | 4979/12631 [00:35<00:38, 197.72it/s] 40%|###9      | 5003/12631 [00:35<00:36, 208.36it/s] 40%|###9      | 5025/12631 [00:35<00:44, 170.00it/s] 40%|###9      | 5044/12631 [00:36<00:44, 172.29it/s] 40%|####      | 5063/12631 [00:36<00:56, 134.58it/s] 40%|####      | 5079/12631 [00:36<00:53, 140.61it/s] 40%|####      | 5100/12631 [00:36<00:48, 154.54it/s] 41%|####      | 5117/12631 [00:36<00:48, 154.95it/s] 41%|####      | 5136/12631 [00:36<00:46, 162.23it/s] 41%|####      | 5157/12631 [00:36<00:43, 172.98it/s] 41%|####1     | 5179/12631 [00:36<00:40, 184.42it/s] 41%|####1     | 5199/12631 [00:36<00:40, 181.54it/s] 41%|####1     | 5219/12631 [00:37<00:40, 184.66it/s] 41%|####1     | 5239/12631 [00:37<00:39, 188.86it/s] 42%|####1     | 5259/12631 [00:37<00:40, 183.60it/s] 42%|####1     | 5278/12631 [00:37<00:40, 180.08it/s] 42%|####1     | 5297/12631 [00:37<00:40, 182.13it/s] 42%|####2     | 5318/12631 [00:37<00:38, 188.43it/s] 42%|####2     | 5337/12631 [00:37<00:40, 181.76it/s] 42%|####2     | 5356/12631 [00:37<00:40, 178.50it/s] 43%|####2     | 5376/12631 [00:37<00:39, 183.95it/s] 43%|####2     | 5395/12631 [00:38<00:43, 164.78it/s] 43%|####2     | 5412/12631 [00:38<00:43, 164.09it/s] 43%|####2     | 5429/12631 [00:38<00:46, 154.09it/s] 43%|####3     | 5445/12631 [00:38<00:50, 142.75it/s] 43%|####3     | 5463/12631 [00:38<00:47, 151.24it/s] 43%|####3     | 5483/12631 [00:38<00:44, 161.88it/s] 44%|####3     | 5502/12631 [00:38<00:42, 169.22it/s] 44%|####3     | 5523/12631 [00:38<00:39, 179.64it/s] 44%|####3     | 5543/12631 [00:38<00:38, 184.37it/s] 44%|####4     | 5564/12631 [00:39<00:37, 190.69it/s] 44%|####4     | 5586/12631 [00:39<00:35, 198.23it/s] 44%|####4     | 5607/12631 [00:39<00:35, 196.40it/s] 45%|####4     | 5628/12631 [00:39<00:35, 198.06it/s] 45%|####4     | 5651/12631 [00:39<00:34, 205.14it/s] 45%|####4     | 5673/12631 [00:39<00:33, 208.90it/s] 45%|####5     | 5695/12631 [00:40<01:44, 66.25it/s]  45%|####5     | 5711/12631 [00:40<01:40, 69.07it/s] 45%|####5     | 5725/12631 [00:40<01:35, 72.24it/s] 45%|####5     | 5737/12631 [00:40<01:29, 77.16it/s] 46%|####5     | 5748/12631 [00:49<27:43,  4.14it/s] 46%|####5     | 5761/12631 [00:49<19:38,  5.83it/s] 46%|####5     | 5774/12631 [00:49<14:00,  8.16it/s] 46%|####5     | 5784/12631 [00:49<10:30, 10.86it/s] 46%|####5     | 5797/12631 [00:49<07:37, 14.94it/s] 46%|####6     | 5818/12631 [00:50<05:29, 20.70it/s] 46%|####6     | 5833/12631 [00:50<04:04, 27.85it/s] 46%|####6     | 5847/12631 [00:50<03:17, 34.29it/s] 46%|####6     | 5861/12631 [00:50<02:33, 44.19it/s] 47%|####6     | 5878/12631 [00:50<01:59, 56.68it/s] 47%|####6     | 5893/12631 [00:50<01:37, 69.03it/s] 47%|####6     | 5907/12631 [00:50<01:22, 81.11it/s] 47%|####6     | 5922/12631 [00:50<01:11, 93.98it/s] 47%|####7     | 5939/12631 [00:50<01:03, 105.82it/s] 47%|####7     | 5954/12631 [00:51<00:57, 115.62it/s] 47%|####7     | 5969/12631 [00:51<00:54, 121.41it/s] 47%|####7     | 5987/12631 [00:51<00:49, 134.22it/s] 48%|####7     | 6003/12631 [00:51<00:48, 135.51it/s] 48%|####7     | 6020/12631 [00:51<00:45, 143.95it/s] 48%|####7     | 6036/12631 [00:51<00:45, 145.48it/s] 48%|####7     | 6052/12631 [00:51<00:44, 148.36it/s] 48%|####8     | 6072/12631 [00:51<00:41, 157.01it/s] 48%|####8     | 6089/12631 [00:51<00:40, 159.68it/s] 48%|####8     | 6106/12631 [00:52<00:42, 151.86it/s] 48%|####8     | 6125/12631 [00:52<00:40, 159.57it/s] 49%|####8     | 6142/12631 [00:52<00:40, 158.57it/s] 49%|####8     | 6162/12631 [00:52<00:38, 168.28it/s] 49%|####8     | 6180/12631 [00:52<00:37, 170.26it/s] 49%|####9     | 6198/12631 [00:52<00:38, 168.00it/s] 49%|####9     | 6215/12631 [00:52<01:00, 106.13it/s] 49%|####9     | 6229/12631 [00:53<00:55, 114.37it/s] 49%|####9     | 6246/12631 [00:53<00:51, 124.90it/s] 50%|####9     | 6261/12631 [00:53<00:49, 129.60it/s] 50%|####9     | 6276/12631 [00:53<00:47, 134.12it/s] 50%|####9     | 6293/12631 [00:53<00:45, 140.57it/s] 50%|####9     | 6310/12631 [00:53<00:42, 148.03it/s] 50%|#####     | 6328/12631 [00:53<00:40, 156.06it/s] 50%|#####     | 6345/12631 [00:53<00:39, 157.83it/s] 50%|#####     | 6362/12631 [00:53<00:43, 144.64it/s] 50%|#####     | 6377/12631 [00:53<00:43, 145.29it/s] 51%|#####     | 6392/12631 [00:54<00:44, 141.41it/s] 51%|#####     | 6408/12631 [00:54<00:42, 145.15it/s] 51%|#####     | 6423/12631 [00:54<00:44, 140.18it/s] 51%|#####     | 6438/12631 [00:54<00:45, 137.53it/s] 51%|#####1    | 6454/12631 [00:54<00:43, 141.88it/s] 51%|#####1    | 6469/12631 [00:54<00:43, 141.56it/s] 51%|#####1    | 6486/12631 [00:54<00:42, 144.97it/s] 51%|#####1    | 6502/12631 [00:54<00:41, 148.37it/s] 52%|#####1    | 6517/12631 [00:54<00:42, 142.35it/s] 52%|#####1    | 6532/12631 [00:55<00:48, 126.86it/s] 52%|#####1    | 6546/12631 [00:55<00:46, 129.72it/s] 52%|#####1    | 6560/12631 [00:55<00:46, 130.25it/s] 52%|#####2    | 6579/12631 [00:55<00:42, 142.67it/s] 52%|#####2    | 6599/12631 [00:55<00:38, 155.08it/s] 52%|#####2    | 6617/12631 [00:55<00:37, 161.31it/s] 53%|#####2    | 6638/12631 [00:55<00:34, 172.05it/s] 53%|#####2    | 6660/12631 [00:55<00:32, 180.96it/s] 53%|#####2    | 6679/12631 [00:55<00:33, 178.41it/s] 53%|#####3    | 6698/12631 [00:56<00:34, 173.03it/s] 53%|#####3    | 6717/12631 [00:56<00:34, 173.18it/s] 53%|#####3    | 6735/12631 [00:56<00:34, 168.97it/s] 53%|#####3    | 6755/12631 [00:56<00:33, 174.41it/s] 54%|#####3    | 6773/12631 [00:56<00:35, 162.90it/s] 54%|#####3    | 6790/12631 [00:56<00:35, 163.75it/s] 54%|#####3    | 6807/12631 [00:56<00:45, 128.55it/s] 54%|#####4    | 6822/12631 [00:57<00:56, 103.32it/s] 54%|#####4    | 6835/12631 [00:57<00:54, 105.54it/s] 54%|#####4    | 6853/12631 [00:57<00:48, 120.23it/s] 54%|#####4    | 6867/12631 [00:57<00:46, 124.34it/s] 55%|#####4    | 6887/12631 [00:57<00:41, 139.14it/s] 55%|#####4    | 6907/12631 [00:57<00:38, 148.92it/s] 55%|#####4    | 6924/12631 [00:57<00:47, 120.90it/s] 55%|#####4    | 6940/12631 [00:57<00:47, 120.85it/s] 55%|#####5    | 6954/12631 [00:58<00:53, 106.71it/s] 55%|#####5    | 6966/12631 [00:58<01:17, 73.14it/s]  55%|#####5    | 6979/12631 [00:58<01:07, 83.22it/s] 55%|#####5    | 6996/12631 [00:58<00:57, 97.57it/s] 55%|#####5    | 7009/12631 [00:58<00:53, 105.08it/s] 56%|#####5    | 7024/12631 [00:58<00:49, 113.78it/s] 56%|#####5    | 7041/12631 [00:58<00:44, 126.07it/s] 56%|#####5    | 7056/12631 [00:58<00:42, 129.95it/s] 56%|#####6    | 7077/12631 [00:59<00:38, 144.78it/s] 56%|#####6    | 7093/12631 [00:59<00:38, 145.21it/s] 56%|#####6    | 7114/12631 [00:59<00:34, 159.62it/s] 56%|#####6    | 7132/12631 [00:59<00:33, 164.68it/s] 57%|#####6    | 7150/12631 [00:59<00:33, 165.79it/s] 57%|#####6    | 7168/12631 [00:59<00:32, 168.70it/s] 57%|#####6    | 7188/12631 [00:59<00:30, 176.50it/s] 57%|#####7    | 7207/12631 [00:59<00:37, 144.92it/s] 57%|#####7    | 7223/12631 [00:59<00:36, 146.57it/s] 57%|#####7    | 7241/12631 [01:00<00:35, 153.69it/s] 57%|#####7    | 7258/12631 [01:00<00:34, 156.25it/s] 58%|#####7    | 7278/12631 [01:00<00:32, 166.40it/s] 58%|#####7    | 7297/12631 [01:00<00:31, 170.82it/s] 58%|#####7    | 7318/12631 [01:00<00:29, 180.82it/s] 58%|#####8    | 7337/12631 [01:00<00:53, 98.85it/s]  58%|#####8    | 7352/12631 [01:01<00:50, 105.47it/s] 58%|#####8    | 7367/12631 [01:01<00:46, 112.48it/s] 58%|#####8    | 7389/12631 [01:01<00:40, 129.33it/s] 59%|#####8    | 7410/12631 [01:01<00:35, 145.31it/s] 59%|#####8    | 7428/12631 [01:01<00:35, 146.93it/s] 59%|#####8    | 7445/12631 [01:01<00:34, 150.62it/s] 59%|#####9    | 7462/12631 [01:02<01:10, 73.59it/s]  59%|#####9    | 7475/12631 [01:02<01:02, 82.26it/s] 59%|#####9    | 7488/12631 [01:02<01:05, 78.66it/s] 59%|#####9    | 7499/12631 [01:02<01:05, 78.87it/s] 59%|#####9    | 7510/12631 [01:02<00:59, 85.43it/s] 60%|#####9    | 7525/12631 [01:02<00:53, 95.60it/s] 60%|#####9    | 7537/12631 [01:02<00:53, 95.58it/s] 60%|#####9    | 7548/12631 [01:03<00:57, 88.41it/s] 60%|#####9    | 7568/12631 [01:03<00:47, 105.98it/s] 60%|######    | 7583/12631 [01:03<00:44, 112.26it/s] 60%|######    | 7600/12631 [01:03<00:40, 124.60it/s] 60%|######    | 7618/12631 [01:03<00:36, 136.72it/s] 60%|######    | 7634/12631 [01:03<00:37, 134.75it/s] 61%|######    | 7653/12631 [01:03<00:33, 146.93it/s] 61%|######    | 7671/12631 [01:03<00:33, 150.26it/s] 61%|######    | 7691/12631 [01:03<00:30, 161.59it/s] 61%|######1   | 7708/12631 [01:03<00:30, 161.31it/s] 61%|######1   | 7726/12631 [01:04<00:29, 164.95it/s] 61%|######1   | 7743/12631 [01:04<00:29, 166.03it/s] 61%|######1   | 7760/12631 [01:04<00:29, 166.28it/s] 62%|######1   | 7777/12631 [01:04<00:29, 162.86it/s] 62%|######1   | 7794/12631 [01:04<00:30, 161.09it/s] 62%|######1   | 7811/12631 [01:04<00:30, 159.01it/s] 62%|######1   | 7827/12631 [01:04<00:30, 156.44it/s] 62%|######2   | 7843/12631 [01:05<00:51, 93.14it/s]  62%|######2   | 7856/12631 [01:05<00:51, 92.76it/s] 62%|######2   | 7868/12631 [01:05<00:49, 95.40it/s] 62%|######2   | 7881/12631 [01:05<00:45, 103.62it/s] 63%|######2   | 7902/12631 [01:05<00:39, 121.04it/s] 63%|######2   | 7917/12631 [01:05<01:04, 72.81it/s]  63%|######2   | 7929/12631 [01:06<00:57, 82.41it/s] 63%|######2   | 7946/12631 [01:06<00:48, 97.45it/s] 63%|######3   | 7965/12631 [01:06<00:40, 113.99it/s] 63%|######3   | 7985/12631 [01:06<00:35, 130.00it/s] 63%|######3   | 8002/12631 [01:06<00:33, 137.25it/s] 63%|######3   | 8019/12631 [01:06<00:35, 129.73it/s] 64%|######3   | 8034/12631 [01:06<00:36, 126.76it/s] 64%|######3   | 8048/12631 [01:06<00:38, 119.95it/s] 64%|######3   | 8061/12631 [01:06<00:38, 120.15it/s] 64%|######3   | 8074/12631 [01:07<00:39, 114.03it/s] 64%|######4   | 8086/12631 [01:07<00:39, 114.32it/s] 64%|######4   | 8098/12631 [01:07<00:39, 113.59it/s] 64%|######4   | 8110/12631 [01:07<00:42, 107.40it/s] 64%|######4   | 8126/12631 [01:07<00:38, 118.27it/s] 64%|######4   | 8142/12631 [01:07<00:35, 127.62it/s] 65%|######4   | 8159/12631 [01:07<00:32, 136.83it/s] 65%|######4   | 8178/12631 [01:07<00:30, 144.96it/s] 65%|######4   | 8197/12631 [01:07<00:28, 154.78it/s] 65%|######5   | 8214/12631 [01:08<00:29, 151.31it/s] 65%|######5   | 8230/12631 [01:08<00:31, 141.10it/s] 65%|######5   | 8247/12631 [01:08<00:29, 148.57it/s] 65%|######5   | 8263/12631 [01:08<00:28, 151.64it/s] 66%|######5   | 8285/12631 [01:08<00:26, 165.41it/s] 66%|######5   | 8306/12631 [01:08<00:25, 171.59it/s] 66%|######5   | 8324/12631 [01:08<00:36, 117.36it/s] 66%|######6   | 8339/12631 [01:09<00:40, 104.97it/s] 66%|######6   | 8352/12631 [01:09<00:51, 82.39it/s]  66%|######6   | 8365/12631 [01:09<00:46, 91.03it/s] 66%|######6   | 8382/12631 [01:09<00:40, 105.44it/s] 66%|######6   | 8395/12631 [01:09<00:41, 101.28it/s] 67%|######6   | 8414/12631 [01:09<00:35, 117.37it/s] 67%|######6   | 8435/12631 [01:09<00:31, 134.74it/s] 67%|######6   | 8451/12631 [01:09<00:29, 140.26it/s] 67%|######7   | 8473/12631 [01:10<00:26, 156.36it/s] 67%|######7   | 8493/12631 [01:10<00:24, 167.21it/s] 67%|######7   | 8512/12631 [01:10<00:25, 164.01it/s] 68%|######7   | 8532/12631 [01:10<00:23, 172.65it/s] 68%|######7   | 8551/12631 [01:10<00:23, 176.51it/s] 68%|######7   | 8571/12631 [01:10<00:22, 182.27it/s] 68%|######8   | 8590/12631 [01:10<00:22, 176.65it/s] 68%|######8   | 8612/12631 [01:10<00:21, 186.74it/s] 68%|######8   | 8633/12631 [01:10<00:20, 191.61it/s] 69%|######8   | 8653/12631 [01:10<00:21, 187.59it/s] 69%|######8   | 8673/12631 [01:11<00:21, 186.54it/s] 69%|######8   | 8693/12631 [01:11<00:20, 189.53it/s] 69%|######9   | 8718/12631 [01:11<00:19, 203.04it/s] 69%|######9   | 8740/12631 [01:11<00:18, 205.72it/s] 69%|######9   | 8761/12631 [01:11<00:18, 205.70it/s] 70%|######9   | 8783/12631 [01:11<00:19, 194.66it/s] 70%|######9   | 8803/12631 [01:11<00:20, 183.15it/s] 70%|######9   | 8822/12631 [01:11<00:24, 155.03it/s] 70%|######9   | 8839/12631 [01:12<00:26, 145.16it/s] 70%|#######   | 8855/12631 [01:12<00:25, 148.62it/s] 70%|#######   | 8871/12631 [01:12<00:26, 140.40it/s] 70%|#######   | 8886/12631 [01:12<00:30, 123.87it/s] 70%|#######   | 8900/12631 [01:12<00:29, 126.55it/s] 71%|#######   | 8917/12631 [01:12<00:27, 135.82it/s] 71%|#######   | 8932/12631 [01:12<00:31, 118.84it/s] 71%|#######   | 8948/12631 [01:12<00:29, 123.70it/s] 71%|#######   | 8966/12631 [01:13<00:26, 135.93it/s] 71%|#######1  | 8983/12631 [01:13<00:25, 144.09it/s] 71%|#######1  | 8999/12631 [01:13<00:24, 147.27it/s] 71%|#######1  | 9016/12631 [01:13<00:23, 153.04it/s] 72%|#######1  | 9033/12631 [01:13<00:24, 149.55it/s] 72%|#######1  | 9050/12631 [01:13<00:23, 154.95it/s] 72%|#######1  | 9066/12631 [01:13<00:32, 109.61it/s] 72%|#######1  | 9085/12631 [01:13<00:28, 124.32it/s] 72%|#######2  | 9100/12631 [01:14<00:30, 116.40it/s] 72%|#######2  | 9114/12631 [01:14<00:39, 89.58it/s]  72%|#######2  | 9130/12631 [01:14<00:33, 103.09it/s] 72%|#######2  | 9147/12631 [01:14<00:29, 116.72it/s] 73%|#######2  | 9164/12631 [01:14<00:29, 116.59it/s] 73%|#######2  | 9178/12631 [01:14<00:29, 115.89it/s] 73%|#######2  | 9192/12631 [01:14<00:28, 120.55it/s] 73%|#######2  | 9206/12631 [01:14<00:27, 125.45it/s] 73%|#######3  | 9228/12631 [01:15<00:23, 143.52it/s] 73%|#######3  | 9248/12631 [01:15<00:21, 156.60it/s] 73%|#######3  | 9265/12631 [01:15<00:21, 158.26it/s] 73%|#######3  | 9282/12631 [01:15<00:20, 159.99it/s] 74%|#######3  | 9303/12631 [01:15<00:19, 169.82it/s] 74%|#######3  | 9323/12631 [01:15<00:20, 158.37it/s] 74%|#######3  | 9340/12631 [01:15<00:21, 151.77it/s] 74%|#######4  | 9356/12631 [01:15<00:22, 144.66it/s] 74%|#######4  | 9371/12631 [01:16<00:23, 137.33it/s] 74%|#######4  | 9386/12631 [01:16<00:23, 138.79it/s] 74%|#######4  | 9405/12631 [01:16<00:21, 150.16it/s] 75%|#######4  | 9424/12631 [01:16<00:20, 160.18it/s] 75%|#######4  | 9443/12631 [01:16<00:19, 166.82it/s] 75%|#######4  | 9463/12631 [01:16<00:18, 174.10it/s] 75%|#######5  | 9481/12631 [01:16<00:18, 174.21it/s] 75%|#######5  | 9499/12631 [01:16<00:28, 110.14it/s] 75%|#######5  | 9514/12631 [01:17<00:26, 116.80it/s] 75%|#######5  | 9528/12631 [01:17<00:25, 122.25it/s] 76%|#######5  | 9551/12631 [01:17<00:21, 140.95it/s] 76%|#######5  | 9570/12631 [01:17<00:20, 151.87it/s] 76%|#######5  | 9587/12631 [01:17<00:24, 122.92it/s] 76%|#######6  | 9605/12631 [01:17<00:22, 135.21it/s] 76%|#######6  | 9621/12631 [01:17<00:21, 140.47it/s] 76%|#######6  | 9637/12631 [01:17<00:23, 128.56it/s] 76%|#######6  | 9656/12631 [01:18<00:20, 142.03it/s] 77%|#######6  | 9675/12631 [01:18<00:19, 153.27it/s] 77%|#######6  | 9692/12631 [01:18<00:22, 133.40it/s] 77%|#######6  | 9711/12631 [01:18<00:19, 146.37it/s] 77%|#######7  | 9727/12631 [01:18<00:19, 148.62it/s] 77%|#######7  | 9748/12631 [01:18<00:17, 162.87it/s] 77%|#######7  | 9766/12631 [01:18<00:17, 167.29it/s] 77%|#######7  | 9786/12631 [01:18<00:16, 174.48it/s] 78%|#######7  | 9808/12631 [01:18<00:15, 181.72it/s] 78%|#######7  | 9830/12631 [01:18<00:14, 190.40it/s] 78%|#######7  | 9850/12631 [01:19<00:15, 180.25it/s] 78%|#######8  | 9869/12631 [01:19<00:15, 182.35it/s] 78%|#######8  | 9888/12631 [01:19<00:14, 183.73it/s] 78%|#######8  | 9909/12631 [01:19<00:14, 189.21it/s] 79%|#######8  | 9929/12631 [01:19<00:14, 181.28it/s] 79%|#######8  | 9950/12631 [01:19<00:14, 186.98it/s] 79%|#######8  | 9969/12631 [01:19<00:14, 180.37it/s] 79%|#######9  | 9988/12631 [01:19<00:15, 169.63it/s] 79%|#######9  | 10007/12631 [01:19<00:15, 174.03it/s] 79%|#######9  | 10029/12631 [01:20<00:14, 183.87it/s] 80%|#######9  | 10048/12631 [01:20<00:14, 183.64it/s] 80%|#######9  | 10068/12631 [01:20<00:13, 186.39it/s] 80%|#######9  | 10088/12631 [01:20<00:13, 189.46it/s] 80%|########  | 10108/12631 [01:20<00:13, 185.10it/s] 80%|########  | 10127/12631 [01:20<00:18, 134.83it/s] 80%|########  | 10143/12631 [01:20<00:19, 130.88it/s] 80%|########  | 10159/12631 [01:20<00:18, 135.67it/s] 81%|########  | 10174/12631 [01:21<00:19, 127.24it/s] 81%|########  | 10188/12631 [01:21<00:21, 113.50it/s] 81%|########  | 10201/12631 [01:21<00:21, 114.80it/s] 81%|########  | 10214/12631 [01:21<00:21, 110.71it/s] 81%|########  | 10230/12631 [01:21<00:19, 121.15it/s] 81%|########1 | 10243/12631 [01:21<00:21, 110.59it/s] 81%|########1 | 10255/12631 [01:21<00:25, 95.01it/s]  81%|########1 | 10269/12631 [01:22<00:23, 102.07it/s] 81%|########1 | 10283/12631 [01:22<00:21, 110.72it/s] 82%|########1 | 10302/12631 [01:22<00:18, 126.03it/s] 82%|########1 | 10323/12631 [01:22<00:16, 141.89it/s] 82%|########1 | 10343/12631 [01:22<00:14, 153.07it/s] 82%|########2 | 10363/12631 [01:22<00:13, 164.30it/s] 82%|########2 | 10384/12631 [01:22<00:12, 175.77it/s] 82%|########2 | 10403/12631 [01:22<00:12, 176.94it/s] 83%|########2 | 10423/12631 [01:22<00:12, 181.60it/s] 83%|########2 | 10445/12631 [01:22<00:11, 187.91it/s] 83%|########2 | 10465/12631 [01:23<00:14, 147.10it/s] 83%|########3 | 10484/12631 [01:23<00:13, 156.52it/s] 83%|########3 | 10509/12631 [01:23<00:12, 174.60it/s] 83%|########3 | 10533/12631 [01:23<00:11, 189.40it/s] 84%|########3 | 10555/12631 [01:23<00:10, 195.95it/s] 84%|########3 | 10576/12631 [01:23<00:10, 197.03it/s] 84%|########3 | 10598/12631 [01:23<00:10, 197.67it/s] 84%|########4 | 10619/12631 [01:23<00:10, 185.80it/s] 84%|########4 | 10639/12631 [01:24<00:10, 184.74it/s] 84%|########4 | 10658/12631 [01:24<00:10, 180.42it/s] 85%|########4 | 10678/12631 [01:24<00:10, 183.85it/s] 85%|########4 | 10701/12631 [01:24<00:10, 190.68it/s] 85%|########4 | 10721/12631 [01:24<00:10, 182.88it/s] 85%|########5 | 10741/12631 [01:24<00:10, 185.53it/s] 85%|########5 | 10760/12631 [01:24<00:17, 109.28it/s] 85%|########5 | 10775/12631 [01:25<00:18, 99.20it/s]  85%|########5 | 10791/12631 [01:25<00:16, 111.18it/s] 86%|########5 | 10811/12631 [01:25<00:14, 127.82it/s] 86%|########5 | 10831/12631 [01:25<00:12, 142.68it/s] 86%|########5 | 10853/12631 [01:25<00:11, 158.24it/s] 86%|########6 | 10876/12631 [01:25<00:10, 171.09it/s] 86%|########6 | 10895/12631 [01:25<00:10, 172.76it/s] 86%|########6 | 10916/12631 [01:25<00:09, 181.66it/s] 87%|########6 | 10936/12631 [01:26<00:13, 128.95it/s] 87%|########6 | 10958/12631 [01:26<00:11, 146.19it/s] 87%|########6 | 10977/12631 [01:26<00:10, 155.39it/s] 87%|########7 | 10997/12631 [01:26<00:09, 165.38it/s] 87%|########7 | 11016/12631 [01:26<00:09, 164.89it/s] 87%|########7 | 11037/12631 [01:26<00:09, 176.05it/s] 88%|########7 | 11056/12631 [01:26<00:09, 167.74it/s] 88%|########7 | 11076/12631 [01:26<00:08, 175.16it/s] 88%|########7 | 11095/12631 [01:26<00:08, 176.10it/s] 88%|########7 | 11114/12631 [01:27<00:08, 174.66it/s] 88%|########8 | 11133/12631 [01:27<00:08, 178.28it/s] 88%|########8 | 11152/12631 [01:27<00:08, 175.34it/s] 88%|########8 | 11174/12631 [01:27<00:07, 185.36it/s] 89%|########8 | 11193/12631 [01:27<00:07, 180.09it/s] 89%|########8 | 11216/12631 [01:27<00:07, 192.19it/s] 89%|########8 | 11236/12631 [01:27<00:07, 183.81it/s] 89%|########9 | 11256/12631 [01:27<00:07, 186.82it/s] 89%|########9 | 11275/12631 [01:27<00:07, 181.84it/s] 89%|########9 | 11294/12631 [01:28<00:07, 181.09it/s] 90%|########9 | 11316/12631 [01:28<00:07, 187.28it/s] 90%|########9 | 11336/12631 [01:28<00:06, 187.38it/s] 90%|########9 | 11356/12631 [01:28<00:06, 188.56it/s] 90%|######### | 11375/12631 [01:28<00:06, 183.85it/s] 90%|######### | 11394/12631 [01:28<00:06, 183.81it/s] 90%|######### | 11413/12631 [01:28<00:10, 119.07it/s] 90%|######### | 11428/12631 [01:29<00:11, 108.02it/s] 91%|######### | 11442/12631 [01:29<00:10, 114.06it/s] 91%|######### | 11464/12631 [01:29<00:08, 131.95it/s] 91%|######### | 11481/12631 [01:29<00:08, 141.38it/s] 91%|#########1| 11497/12631 [01:29<00:07, 146.40it/s] 91%|#########1| 11516/12631 [01:29<00:07, 156.06it/s] 91%|#########1| 11538/12631 [01:29<00:06, 170.80it/s] 91%|#########1| 11557/12631 [01:29<00:09, 117.64it/s] 92%|#########1| 11572/12631 [01:30<00:11, 95.14it/s]  92%|#########1| 11586/12631 [01:30<00:09, 105.11it/s] 92%|#########1| 11605/12631 [01:30<00:08, 121.13it/s] 92%|#########2| 11627/12631 [01:30<00:07, 139.68it/s] 92%|#########2| 11646/12631 [01:30<00:06, 150.69it/s] 92%|#########2| 11670/12631 [01:30<00:05, 166.47it/s] 93%|#########2| 11689/12631 [01:30<00:05, 170.28it/s] 93%|#########2| 11712/12631 [01:30<00:05, 182.69it/s] 93%|#########2| 11732/12631 [01:31<00:06, 132.24it/s] 93%|#########3| 11749/12631 [01:31<00:06, 135.76it/s] 93%|#########3| 11767/12631 [01:31<00:05, 145.71it/s] 93%|#########3| 11785/12631 [01:31<00:05, 151.55it/s] 93%|#########3| 11807/12631 [01:31<00:04, 166.06it/s] 94%|#########3| 11826/12631 [01:31<00:04, 172.51it/s] 94%|#########3| 11848/12631 [01:31<00:04, 180.56it/s] 94%|#########3| 11867/12631 [01:31<00:04, 178.58it/s] 94%|#########4| 11886/12631 [01:32<00:04, 176.72it/s] 94%|#########4| 11907/12631 [01:32<00:03, 184.15it/s] 94%|#########4| 11926/12631 [01:32<00:04, 168.07it/s] 95%|#########4| 11944/12631 [01:32<00:04, 165.72it/s] 95%|#########4| 11964/12631 [01:32<00:03, 168.52it/s] 95%|#########4| 11984/12631 [01:32<00:03, 172.91it/s] 95%|#########5| 12002/12631 [01:32<00:05, 124.37it/s] 95%|#########5| 12017/12631 [01:32<00:04, 124.13it/s] 95%|#########5| 12034/12631 [01:33<00:05, 110.42it/s] 95%|#########5| 12049/12631 [01:33<00:04, 119.56it/s] 96%|#########5| 12068/12631 [01:33<00:04, 133.89it/s] 96%|#########5| 12087/12631 [01:33<00:03, 145.77it/s] 96%|#########5| 12109/12631 [01:33<00:03, 162.19it/s] 96%|#########6| 12127/12631 [01:33<00:03, 166.91it/s] 96%|#########6| 12148/12631 [01:33<00:02, 177.35it/s] 96%|#########6| 12167/12631 [01:33<00:02, 170.89it/s] 96%|#########6| 12185/12631 [01:33<00:02, 170.01it/s] 97%|#########6| 12207/12631 [01:34<00:02, 180.89it/s] 97%|#########6| 12228/12631 [01:34<00:02, 188.31it/s] 97%|#########6| 12251/12631 [01:34<00:01, 197.92it/s] 97%|#########7| 12275/12631 [01:34<00:01, 204.68it/s] 97%|#########7| 12296/12631 [01:34<00:01, 203.04it/s] 98%|#########7| 12317/12631 [01:34<00:01, 204.51it/s] 98%|#########7| 12338/12631 [01:34<00:01, 181.93it/s] 98%|#########7| 12358/12631 [01:34<00:01, 185.38it/s] 98%|#########7| 12377/12631 [01:34<00:01, 184.45it/s] 98%|#########8| 12398/12631 [01:35<00:01, 191.08it/s] 98%|#########8| 12421/12631 [01:35<00:01, 199.50it/s] 99%|#########8| 12443/12631 [01:35<00:00, 203.30it/s] 99%|#########8| 12464/12631 [01:35<00:00, 204.84it/s] 99%|#########8| 12486/12631 [01:35<00:00, 206.88it/s] 99%|#########9| 12507/12631 [01:35<00:00, 204.99it/s] 99%|#########9| 12529/12631 [01:35<00:00, 207.66it/s] 99%|#########9| 12550/12631 [01:35<00:00, 199.23it/s]100%|#########9| 12571/12631 [01:35<00:00, 199.62it/s]100%|#########9| 12592/12631 [01:35<00:00, 201.19it/s]100%|#########9| 12613/12631 [01:36<00:00, 187.12it/s]100%|##########| 12631/12631 [01:36<00:00, 131.29it/s]
Succesfully wrote out_latest_Adagrad_dataAugmentation.csv, you can upload this file to the kaggle competition at https://www.kaggle.com/c/nyu-cv-fall-2017/
