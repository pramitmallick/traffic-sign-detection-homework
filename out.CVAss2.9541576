Lmod has detected the following error: You can only have one PYTORCH  module
loaded at a time.
You already have pytorch/python2.7  loaded.
To correct the situation, please enter the following command:

  module swap pytorch/python2.7  pytorch/0.2.0_1


While processing the following module(s):

Module fullname  Module Filename
---------------  ---------------
pytorch/0.2.0_1  /share/apps/modulefiles/pytorch/0.2.0_1.lua
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
Train Epoch: 1 [0/35339 (0%)]	Loss: 3.777333
Train Epoch: 1 [640/35339 (2%)]	Loss: 3.768349
Train Epoch: 1 [1280/35339 (4%)]	Loss: 3.768452
Train Epoch: 1 [1920/35339 (5%)]	Loss: 3.760699
Train Epoch: 1 [2560/35339 (7%)]	Loss: 3.770729
Train Epoch: 1 [3200/35339 (9%)]	Loss: 3.741342
Train Epoch: 1 [3840/35339 (11%)]	Loss: 3.750482
Train Epoch: 1 [4480/35339 (13%)]	Loss: 3.812726
Train Epoch: 1 [5120/35339 (14%)]	Loss: 3.747195
Train Epoch: 1 [5760/35339 (16%)]	Loss: 3.718851
Train Epoch: 1 [6400/35339 (18%)]	Loss: 3.695712
Train Epoch: 1 [7040/35339 (20%)]	Loss: 3.719064
Train Epoch: 1 [7680/35339 (22%)]	Loss: 3.776212
Train Epoch: 1 [8320/35339 (24%)]	Loss: 3.732857
Train Epoch: 1 [8960/35339 (25%)]	Loss: 3.716258
Train Epoch: 1 [9600/35339 (27%)]	Loss: 3.692592
Train Epoch: 1 [10240/35339 (29%)]	Loss: 3.539273
Train Epoch: 1 [10880/35339 (31%)]	Loss: 3.629350
Train Epoch: 1 [11520/35339 (33%)]	Loss: 3.556433
Train Epoch: 1 [12160/35339 (34%)]	Loss: 3.404409
Train Epoch: 1 [12800/35339 (36%)]	Loss: 3.328984
Train Epoch: 1 [13440/35339 (38%)]	Loss: 3.287005
Train Epoch: 1 [14080/35339 (40%)]	Loss: 3.283577
Train Epoch: 1 [14720/35339 (42%)]	Loss: 3.273876
Train Epoch: 1 [15360/35339 (43%)]	Loss: 3.131619
Train Epoch: 1 [16000/35339 (45%)]	Loss: 2.999215
Train Epoch: 1 [16640/35339 (47%)]	Loss: 3.115986
Train Epoch: 1 [17280/35339 (49%)]	Loss: 3.251698
Train Epoch: 1 [17920/35339 (51%)]	Loss: 3.032614
Train Epoch: 1 [18560/35339 (52%)]	Loss: 2.962264
Train Epoch: 1 [19200/35339 (54%)]	Loss: 3.005511
Train Epoch: 1 [19840/35339 (56%)]	Loss: 3.129017
Train Epoch: 1 [20480/35339 (58%)]	Loss: 2.803748
Train Epoch: 1 [21120/35339 (60%)]	Loss: 2.737789
Train Epoch: 1 [21760/35339 (61%)]	Loss: 2.889834
Train Epoch: 1 [22400/35339 (63%)]	Loss: 2.831194
Train Epoch: 1 [23040/35339 (65%)]	Loss: 2.677903
Train Epoch: 1 [23680/35339 (67%)]	Loss: 2.497326
Train Epoch: 1 [24320/35339 (69%)]	Loss: 2.735258
Train Epoch: 1 [24960/35339 (71%)]	Loss: 2.518684
Train Epoch: 1 [25600/35339 (72%)]	Loss: 2.497133
Train Epoch: 1 [26240/35339 (74%)]	Loss: 2.430952
Train Epoch: 1 [26880/35339 (76%)]	Loss: 2.294292
Train Epoch: 1 [27520/35339 (78%)]	Loss: 2.286373
Train Epoch: 1 [28160/35339 (80%)]	Loss: 2.392340
Train Epoch: 1 [28800/35339 (81%)]	Loss: 2.685170
Train Epoch: 1 [29440/35339 (83%)]	Loss: 2.569782
Train Epoch: 1 [30080/35339 (85%)]	Loss: 2.408395
Train Epoch: 1 [30720/35339 (87%)]	Loss: 2.487137
Train Epoch: 1 [31360/35339 (89%)]	Loss: 2.187654
Train Epoch: 1 [32000/35339 (90%)]	Loss: 2.225976
Train Epoch: 1 [32640/35339 (92%)]	Loss: 2.491081
Train Epoch: 1 [33280/35339 (94%)]	Loss: 2.107697
Train Epoch: 1 [33920/35339 (96%)]	Loss: 2.272513
Train Epoch: 1 [34560/35339 (98%)]	Loss: 2.260309
Train Epoch: 1 [35200/35339 (99%)]	Loss: 2.293637

Validation set: Average loss: 3.6368, Accuracy: 534/3870 (14%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 2 [0/35339 (0%)]	Loss: 1.951559
Train Epoch: 2 [640/35339 (2%)]	Loss: 2.188750
Train Epoch: 2 [1280/35339 (4%)]	Loss: 2.334824
Train Epoch: 2 [1920/35339 (5%)]	Loss: 1.780699
Train Epoch: 2 [2560/35339 (7%)]	Loss: 2.286061
Train Epoch: 2 [3200/35339 (9%)]	Loss: 2.045396
Train Epoch: 2 [3840/35339 (11%)]	Loss: 2.347000
Train Epoch: 2 [4480/35339 (13%)]	Loss: 2.058525
Train Epoch: 2 [5120/35339 (14%)]	Loss: 1.866951
Train Epoch: 2 [5760/35339 (16%)]	Loss: 2.561038
Train Epoch: 2 [6400/35339 (18%)]	Loss: 2.065700
Train Epoch: 2 [7040/35339 (20%)]	Loss: 2.017021
Train Epoch: 2 [7680/35339 (22%)]	Loss: 1.974984
Train Epoch: 2 [8320/35339 (24%)]	Loss: 1.897678
Train Epoch: 2 [8960/35339 (25%)]	Loss: 1.935156
Train Epoch: 2 [9600/35339 (27%)]	Loss: 1.842509
Train Epoch: 2 [10240/35339 (29%)]	Loss: 1.685151
Train Epoch: 2 [10880/35339 (31%)]	Loss: 1.920837
Train Epoch: 2 [11520/35339 (33%)]	Loss: 2.068332
Train Epoch: 2 [12160/35339 (34%)]	Loss: 1.977729
Train Epoch: 2 [12800/35339 (36%)]	Loss: 1.878637
Train Epoch: 2 [13440/35339 (38%)]	Loss: 1.845138
Train Epoch: 2 [14080/35339 (40%)]	Loss: 1.897625
Train Epoch: 2 [14720/35339 (42%)]	Loss: 1.484943
Train Epoch: 2 [15360/35339 (43%)]	Loss: 1.558524
Train Epoch: 2 [16000/35339 (45%)]	Loss: 1.636518
Train Epoch: 2 [16640/35339 (47%)]	Loss: 1.800096
Train Epoch: 2 [17280/35339 (49%)]	Loss: 1.568304
Train Epoch: 2 [17920/35339 (51%)]	Loss: 1.903989
Train Epoch: 2 [18560/35339 (52%)]	Loss: 1.855191
Train Epoch: 2 [19200/35339 (54%)]	Loss: 1.632104
Train Epoch: 2 [19840/35339 (56%)]	Loss: 1.388128
Train Epoch: 2 [20480/35339 (58%)]	Loss: 1.481087
Train Epoch: 2 [21120/35339 (60%)]	Loss: 1.708515
Train Epoch: 2 [21760/35339 (61%)]	Loss: 1.762184
Train Epoch: 2 [22400/35339 (63%)]	Loss: 1.711800
Train Epoch: 2 [23040/35339 (65%)]	Loss: 1.754247
Train Epoch: 2 [23680/35339 (67%)]	Loss: 1.607832
Train Epoch: 2 [24320/35339 (69%)]	Loss: 1.396579
Train Epoch: 2 [24960/35339 (71%)]	Loss: 1.394994
Train Epoch: 2 [25600/35339 (72%)]	Loss: 1.490870
Train Epoch: 2 [26240/35339 (74%)]	Loss: 1.363525
Train Epoch: 2 [26880/35339 (76%)]	Loss: 1.354585
Train Epoch: 2 [27520/35339 (78%)]	Loss: 1.347513
Train Epoch: 2 [28160/35339 (80%)]	Loss: 1.772577
Train Epoch: 2 [28800/35339 (81%)]	Loss: 1.559716
Train Epoch: 2 [29440/35339 (83%)]	Loss: 1.603568
Train Epoch: 2 [30080/35339 (85%)]	Loss: 1.371623
Train Epoch: 2 [30720/35339 (87%)]	Loss: 1.505274
Train Epoch: 2 [31360/35339 (89%)]	Loss: 1.413771
Train Epoch: 2 [32000/35339 (90%)]	Loss: 1.590898
Train Epoch: 2 [32640/35339 (92%)]	Loss: 1.485536
Train Epoch: 2 [33280/35339 (94%)]	Loss: 1.097620
Train Epoch: 2 [33920/35339 (96%)]	Loss: 1.339822
Train Epoch: 2 [34560/35339 (98%)]	Loss: 1.460686
Train Epoch: 2 [35200/35339 (99%)]	Loss: 1.287359

Validation set: Average loss: 3.4191, Accuracy: 693/3870 (18%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 3 [0/35339 (0%)]	Loss: 1.594069
Train Epoch: 3 [640/35339 (2%)]	Loss: 1.174668
Train Epoch: 3 [1280/35339 (4%)]	Loss: 1.329422
Train Epoch: 3 [1920/35339 (5%)]	Loss: 1.395865
Train Epoch: 3 [2560/35339 (7%)]	Loss: 1.215035
Train Epoch: 3 [3200/35339 (9%)]	Loss: 1.345307
Train Epoch: 3 [3840/35339 (11%)]	Loss: 1.698521
Train Epoch: 3 [4480/35339 (13%)]	Loss: 1.606997
Train Epoch: 3 [5120/35339 (14%)]	Loss: 1.213191
Train Epoch: 3 [5760/35339 (16%)]	Loss: 1.425378
Train Epoch: 3 [6400/35339 (18%)]	Loss: 1.574320
Train Epoch: 3 [7040/35339 (20%)]	Loss: 1.470130
Train Epoch: 3 [7680/35339 (22%)]	Loss: 1.445086
Train Epoch: 3 [8320/35339 (24%)]	Loss: 1.258691
Train Epoch: 3 [8960/35339 (25%)]	Loss: 1.249165
Train Epoch: 3 [9600/35339 (27%)]	Loss: 1.564576
Train Epoch: 3 [10240/35339 (29%)]	Loss: 1.228218
Train Epoch: 3 [10880/35339 (31%)]	Loss: 1.110865
Train Epoch: 3 [11520/35339 (33%)]	Loss: 1.550630
Train Epoch: 3 [12160/35339 (34%)]	Loss: 1.541485
Train Epoch: 3 [12800/35339 (36%)]	Loss: 1.578915
Train Epoch: 3 [13440/35339 (38%)]	Loss: 0.905778
Train Epoch: 3 [14080/35339 (40%)]	Loss: 1.192193
Train Epoch: 3 [14720/35339 (42%)]	Loss: 1.444528
Train Epoch: 3 [15360/35339 (43%)]	Loss: 0.908666
Train Epoch: 3 [16000/35339 (45%)]	Loss: 1.226454
Train Epoch: 3 [16640/35339 (47%)]	Loss: 1.185706
Train Epoch: 3 [17280/35339 (49%)]	Loss: 1.354416
Train Epoch: 3 [17920/35339 (51%)]	Loss: 1.590969
Train Epoch: 3 [18560/35339 (52%)]	Loss: 1.007488
Train Epoch: 3 [19200/35339 (54%)]	Loss: 1.137310
Train Epoch: 3 [19840/35339 (56%)]	Loss: 1.156292
Train Epoch: 3 [20480/35339 (58%)]	Loss: 1.170511
Train Epoch: 3 [21120/35339 (60%)]	Loss: 1.039417
Train Epoch: 3 [21760/35339 (61%)]	Loss: 1.569628
Train Epoch: 3 [22400/35339 (63%)]	Loss: 0.854212
Train Epoch: 3 [23040/35339 (65%)]	Loss: 1.316535
Train Epoch: 3 [23680/35339 (67%)]	Loss: 1.312809
Train Epoch: 3 [24320/35339 (69%)]	Loss: 1.165190
Train Epoch: 3 [24960/35339 (71%)]	Loss: 1.076793
Train Epoch: 3 [25600/35339 (72%)]	Loss: 1.335249
Train Epoch: 3 [26240/35339 (74%)]	Loss: 0.976130
Train Epoch: 3 [26880/35339 (76%)]	Loss: 0.876555
Train Epoch: 3 [27520/35339 (78%)]	Loss: 1.132460
Train Epoch: 3 [28160/35339 (80%)]	Loss: 0.967351
Train Epoch: 3 [28800/35339 (81%)]	Loss: 1.246878
Train Epoch: 3 [29440/35339 (83%)]	Loss: 1.325282
Train Epoch: 3 [30080/35339 (85%)]	Loss: 1.156427
Train Epoch: 3 [30720/35339 (87%)]	Loss: 1.064350
Train Epoch: 3 [31360/35339 (89%)]	Loss: 0.957691
Train Epoch: 3 [32000/35339 (90%)]	Loss: 0.932765
Train Epoch: 3 [32640/35339 (92%)]	Loss: 1.025231
Train Epoch: 3 [33280/35339 (94%)]	Loss: 1.181114
Train Epoch: 3 [33920/35339 (96%)]	Loss: 1.168684
Train Epoch: 3 [34560/35339 (98%)]	Loss: 0.965002
Train Epoch: 3 [35200/35339 (99%)]	Loss: 0.849965

Validation set: Average loss: 3.0114, Accuracy: 1126/3870 (29%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 4 [0/35339 (0%)]	Loss: 0.968595
Train Epoch: 4 [640/35339 (2%)]	Loss: 1.072720
Train Epoch: 4 [1280/35339 (4%)]	Loss: 1.005672
Train Epoch: 4 [1920/35339 (5%)]	Loss: 0.995301
Train Epoch: 4 [2560/35339 (7%)]	Loss: 1.131561
Train Epoch: 4 [3200/35339 (9%)]	Loss: 0.884443
Train Epoch: 4 [3840/35339 (11%)]	Loss: 0.811687
Train Epoch: 4 [4480/35339 (13%)]	Loss: 1.001466
Train Epoch: 4 [5120/35339 (14%)]	Loss: 1.181174
Train Epoch: 4 [5760/35339 (16%)]	Loss: 0.997075
Train Epoch: 4 [6400/35339 (18%)]	Loss: 0.750092
Train Epoch: 4 [7040/35339 (20%)]	Loss: 0.787558
Train Epoch: 4 [7680/35339 (22%)]	Loss: 0.983047
Train Epoch: 4 [8320/35339 (24%)]	Loss: 1.098526
Train Epoch: 4 [8960/35339 (25%)]	Loss: 0.843058
Train Epoch: 4 [9600/35339 (27%)]	Loss: 0.953210
Train Epoch: 4 [10240/35339 (29%)]	Loss: 0.809946
Train Epoch: 4 [10880/35339 (31%)]	Loss: 1.123515
Train Epoch: 4 [11520/35339 (33%)]	Loss: 1.158218
Train Epoch: 4 [12160/35339 (34%)]	Loss: 0.856899
Train Epoch: 4 [12800/35339 (36%)]	Loss: 0.826132
Train Epoch: 4 [13440/35339 (38%)]	Loss: 1.111470
Train Epoch: 4 [14080/35339 (40%)]	Loss: 0.916672
Train Epoch: 4 [14720/35339 (42%)]	Loss: 0.545256
Train Epoch: 4 [15360/35339 (43%)]	Loss: 0.977987
Train Epoch: 4 [16000/35339 (45%)]	Loss: 0.782647
Train Epoch: 4 [16640/35339 (47%)]	Loss: 0.672431
Train Epoch: 4 [17280/35339 (49%)]	Loss: 0.987771
Train Epoch: 4 [17920/35339 (51%)]	Loss: 0.957932
Train Epoch: 4 [18560/35339 (52%)]	Loss: 0.868301
Train Epoch: 4 [19200/35339 (54%)]	Loss: 0.710337
Train Epoch: 4 [19840/35339 (56%)]	Loss: 1.265769
Train Epoch: 4 [20480/35339 (58%)]	Loss: 0.974939
Train Epoch: 4 [21120/35339 (60%)]	Loss: 0.921234
Train Epoch: 4 [21760/35339 (61%)]	Loss: 1.011011
Train Epoch: 4 [22400/35339 (63%)]	Loss: 1.083389
Train Epoch: 4 [23040/35339 (65%)]	Loss: 1.116910
Train Epoch: 4 [23680/35339 (67%)]	Loss: 0.994508
Train Epoch: 4 [24320/35339 (69%)]	Loss: 0.803274
Train Epoch: 4 [24960/35339 (71%)]	Loss: 0.844149
Train Epoch: 4 [25600/35339 (72%)]	Loss: 0.978511
Train Epoch: 4 [26240/35339 (74%)]	Loss: 1.098316
Train Epoch: 4 [26880/35339 (76%)]	Loss: 0.862394
Train Epoch: 4 [27520/35339 (78%)]	Loss: 0.786224
Train Epoch: 4 [28160/35339 (80%)]	Loss: 0.677072
Train Epoch: 4 [28800/35339 (81%)]	Loss: 0.798269
Train Epoch: 4 [29440/35339 (83%)]	Loss: 0.870314
Train Epoch: 4 [30080/35339 (85%)]	Loss: 0.994615
Train Epoch: 4 [30720/35339 (87%)]	Loss: 1.057971
Train Epoch: 4 [31360/35339 (89%)]	Loss: 0.807358
Train Epoch: 4 [32000/35339 (90%)]	Loss: 0.708412
Train Epoch: 4 [32640/35339 (92%)]	Loss: 0.784811
Train Epoch: 4 [33280/35339 (94%)]	Loss: 0.821374
Train Epoch: 4 [33920/35339 (96%)]	Loss: 0.788806
Train Epoch: 4 [34560/35339 (98%)]	Loss: 0.604054
Train Epoch: 4 [35200/35339 (99%)]	Loss: 0.694007

Validation set: Average loss: 2.8030, Accuracy: 1338/3870 (35%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 5 [0/35339 (0%)]	Loss: 0.912488
Train Epoch: 5 [640/35339 (2%)]	Loss: 0.943296
Train Epoch: 5 [1280/35339 (4%)]	Loss: 0.833119
Train Epoch: 5 [1920/35339 (5%)]	Loss: 0.756653
Train Epoch: 5 [2560/35339 (7%)]	Loss: 1.020552
Train Epoch: 5 [3200/35339 (9%)]	Loss: 0.993758
Train Epoch: 5 [3840/35339 (11%)]	Loss: 1.042372
Train Epoch: 5 [4480/35339 (13%)]	Loss: 0.917060
Train Epoch: 5 [5120/35339 (14%)]	Loss: 0.786380
Train Epoch: 5 [5760/35339 (16%)]	Loss: 0.963296
Train Epoch: 5 [6400/35339 (18%)]	Loss: 0.757168
Train Epoch: 5 [7040/35339 (20%)]	Loss: 0.847023
Train Epoch: 5 [7680/35339 (22%)]	Loss: 0.862281
Train Epoch: 5 [8320/35339 (24%)]	Loss: 0.685099
Train Epoch: 5 [8960/35339 (25%)]	Loss: 0.821905
Train Epoch: 5 [9600/35339 (27%)]	Loss: 0.801172
Train Epoch: 5 [10240/35339 (29%)]	Loss: 0.681244
Train Epoch: 5 [10880/35339 (31%)]	Loss: 0.732944
Train Epoch: 5 [11520/35339 (33%)]	Loss: 0.876785
Train Epoch: 5 [12160/35339 (34%)]	Loss: 0.726970
Train Epoch: 5 [12800/35339 (36%)]	Loss: 0.606359
Train Epoch: 5 [13440/35339 (38%)]	Loss: 0.883938
Train Epoch: 5 [14080/35339 (40%)]	Loss: 0.538575
Train Epoch: 5 [14720/35339 (42%)]	Loss: 0.985392
Train Epoch: 5 [15360/35339 (43%)]	Loss: 0.652433
Train Epoch: 5 [16000/35339 (45%)]	Loss: 0.555970
Train Epoch: 5 [16640/35339 (47%)]	Loss: 0.827929
Train Epoch: 5 [17280/35339 (49%)]	Loss: 0.774568
Train Epoch: 5 [17920/35339 (51%)]	Loss: 1.021267
Train Epoch: 5 [18560/35339 (52%)]	Loss: 0.672028
Train Epoch: 5 [19200/35339 (54%)]	Loss: 0.736686
Train Epoch: 5 [19840/35339 (56%)]	Loss: 1.159593
Train Epoch: 5 [20480/35339 (58%)]	Loss: 0.829031
Train Epoch: 5 [21120/35339 (60%)]	Loss: 0.644487
Train Epoch: 5 [21760/35339 (61%)]	Loss: 0.871816
Train Epoch: 5 [22400/35339 (63%)]	Loss: 0.827377
Train Epoch: 5 [23040/35339 (65%)]	Loss: 0.647913
Train Epoch: 5 [23680/35339 (67%)]	Loss: 0.684264
Train Epoch: 5 [24320/35339 (69%)]	Loss: 0.785151
Train Epoch: 5 [24960/35339 (71%)]	Loss: 0.698894
Train Epoch: 5 [25600/35339 (72%)]	Loss: 0.635952
Train Epoch: 5 [26240/35339 (74%)]	Loss: 0.765957
Train Epoch: 5 [26880/35339 (76%)]	Loss: 0.713709
Train Epoch: 5 [27520/35339 (78%)]	Loss: 0.778151
Train Epoch: 5 [28160/35339 (80%)]	Loss: 0.491896
Train Epoch: 5 [28800/35339 (81%)]	Loss: 0.561693
Train Epoch: 5 [29440/35339 (83%)]	Loss: 0.782898
Train Epoch: 5 [30080/35339 (85%)]	Loss: 0.487937
Train Epoch: 5 [30720/35339 (87%)]	Loss: 1.413223
Train Epoch: 5 [31360/35339 (89%)]	Loss: 0.734651
Train Epoch: 5 [32000/35339 (90%)]	Loss: 0.688323
Train Epoch: 5 [32640/35339 (92%)]	Loss: 0.565088
Train Epoch: 5 [33280/35339 (94%)]	Loss: 0.585336
Train Epoch: 5 [33920/35339 (96%)]	Loss: 0.625232
Train Epoch: 5 [34560/35339 (98%)]	Loss: 0.698110
Train Epoch: 5 [35200/35339 (99%)]	Loss: 0.750551

Validation set: Average loss: 2.6327, Accuracy: 1448/3870 (37%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 6 [0/35339 (0%)]	Loss: 0.748049
Train Epoch: 6 [640/35339 (2%)]	Loss: 0.927080
Train Epoch: 6 [1280/35339 (4%)]	Loss: 0.518685
Train Epoch: 6 [1920/35339 (5%)]	Loss: 0.755384
Train Epoch: 6 [2560/35339 (7%)]	Loss: 0.754225
Train Epoch: 6 [3200/35339 (9%)]	Loss: 0.754555
Train Epoch: 6 [3840/35339 (11%)]	Loss: 0.558377
Train Epoch: 6 [4480/35339 (13%)]	Loss: 0.869232
Train Epoch: 6 [5120/35339 (14%)]	Loss: 0.828445
Train Epoch: 6 [5760/35339 (16%)]	Loss: 0.639839
Train Epoch: 6 [6400/35339 (18%)]	Loss: 0.907352
Train Epoch: 6 [7040/35339 (20%)]	Loss: 0.812409
Train Epoch: 6 [7680/35339 (22%)]	Loss: 0.859242
Train Epoch: 6 [8320/35339 (24%)]	Loss: 0.552035
Train Epoch: 6 [8960/35339 (25%)]	Loss: 0.621736
Train Epoch: 6 [9600/35339 (27%)]	Loss: 0.722913
Train Epoch: 6 [10240/35339 (29%)]	Loss: 0.717511
Train Epoch: 6 [10880/35339 (31%)]	Loss: 0.589847
Train Epoch: 6 [11520/35339 (33%)]	Loss: 0.608706
Train Epoch: 6 [12160/35339 (34%)]	Loss: 0.739532
Train Epoch: 6 [12800/35339 (36%)]	Loss: 0.463590
Train Epoch: 6 [13440/35339 (38%)]	Loss: 0.606271
Train Epoch: 6 [14080/35339 (40%)]	Loss: 0.557485
Train Epoch: 6 [14720/35339 (42%)]	Loss: 0.837385
Train Epoch: 6 [15360/35339 (43%)]	Loss: 1.059307
Train Epoch: 6 [16000/35339 (45%)]	Loss: 0.607061
Train Epoch: 6 [16640/35339 (47%)]	Loss: 0.606683
Train Epoch: 6 [17280/35339 (49%)]	Loss: 1.088020
Train Epoch: 6 [17920/35339 (51%)]	Loss: 0.710660
Train Epoch: 6 [18560/35339 (52%)]	Loss: 0.716810
Train Epoch: 6 [19200/35339 (54%)]	Loss: 0.732120
Train Epoch: 6 [19840/35339 (56%)]	Loss: 0.854090
Train Epoch: 6 [20480/35339 (58%)]	Loss: 0.618689
Train Epoch: 6 [21120/35339 (60%)]	Loss: 0.933446
Train Epoch: 6 [21760/35339 (61%)]	Loss: 0.775231
Train Epoch: 6 [22400/35339 (63%)]	Loss: 0.766458
Train Epoch: 6 [23040/35339 (65%)]	Loss: 0.659026
Train Epoch: 6 [23680/35339 (67%)]	Loss: 1.161124
Train Epoch: 6 [24320/35339 (69%)]	Loss: 0.599830
Train Epoch: 6 [24960/35339 (71%)]	Loss: 0.724832
Train Epoch: 6 [25600/35339 (72%)]	Loss: 0.605679
Train Epoch: 6 [26240/35339 (74%)]	Loss: 0.636698
Train Epoch: 6 [26880/35339 (76%)]	Loss: 0.821505
Train Epoch: 6 [27520/35339 (78%)]	Loss: 0.666582
Train Epoch: 6 [28160/35339 (80%)]	Loss: 0.917491
Train Epoch: 6 [28800/35339 (81%)]	Loss: 0.492231
Train Epoch: 6 [29440/35339 (83%)]	Loss: 0.559742
Train Epoch: 6 [30080/35339 (85%)]	Loss: 0.609128
Train Epoch: 6 [30720/35339 (87%)]	Loss: 0.600060
Train Epoch: 6 [31360/35339 (89%)]	Loss: 0.540398
Train Epoch: 6 [32000/35339 (90%)]	Loss: 0.955956
Train Epoch: 6 [32640/35339 (92%)]	Loss: 0.549484
Train Epoch: 6 [33280/35339 (94%)]	Loss: 0.740224
Train Epoch: 6 [33920/35339 (96%)]	Loss: 0.665884
Train Epoch: 6 [34560/35339 (98%)]	Loss: 0.705497
Train Epoch: 6 [35200/35339 (99%)]	Loss: 0.748395

Validation set: Average loss: 2.4970, Accuracy: 1497/3870 (39%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 7 [0/35339 (0%)]	Loss: 0.642628
Train Epoch: 7 [640/35339 (2%)]	Loss: 0.558711
Train Epoch: 7 [1280/35339 (4%)]	Loss: 0.645046
Train Epoch: 7 [1920/35339 (5%)]	Loss: 0.677892
Train Epoch: 7 [2560/35339 (7%)]	Loss: 0.610936
Train Epoch: 7 [3200/35339 (9%)]	Loss: 0.733096
Train Epoch: 7 [3840/35339 (11%)]	Loss: 0.663385
Train Epoch: 7 [4480/35339 (13%)]	Loss: 0.875864
Train Epoch: 7 [5120/35339 (14%)]	Loss: 0.983848
Train Epoch: 7 [5760/35339 (16%)]	Loss: 0.592302
Train Epoch: 7 [6400/35339 (18%)]	Loss: 0.678718
Train Epoch: 7 [7040/35339 (20%)]	Loss: 0.786587
Train Epoch: 7 [7680/35339 (22%)]	Loss: 0.458161
Train Epoch: 7 [8320/35339 (24%)]	Loss: 0.707156
Train Epoch: 7 [8960/35339 (25%)]	Loss: 0.764291
Train Epoch: 7 [9600/35339 (27%)]	Loss: 0.526168
Train Epoch: 7 [10240/35339 (29%)]	Loss: 0.459678
Train Epoch: 7 [10880/35339 (31%)]	Loss: 0.577315
Train Epoch: 7 [11520/35339 (33%)]	Loss: 0.722831
Train Epoch: 7 [12160/35339 (34%)]	Loss: 0.655483
Train Epoch: 7 [12800/35339 (36%)]	Loss: 0.548407
Train Epoch: 7 [13440/35339 (38%)]	Loss: 0.673722
Train Epoch: 7 [14080/35339 (40%)]	Loss: 0.445420
Train Epoch: 7 [14720/35339 (42%)]	Loss: 0.900789
Train Epoch: 7 [15360/35339 (43%)]	Loss: 0.966268
Train Epoch: 7 [16000/35339 (45%)]	Loss: 0.532316
Train Epoch: 7 [16640/35339 (47%)]	Loss: 0.467333
Train Epoch: 7 [17280/35339 (49%)]	Loss: 0.619134
Train Epoch: 7 [17920/35339 (51%)]	Loss: 0.815767
Train Epoch: 7 [18560/35339 (52%)]	Loss: 0.711348
Train Epoch: 7 [19200/35339 (54%)]	Loss: 0.675409
Train Epoch: 7 [19840/35339 (56%)]	Loss: 0.517683
Train Epoch: 7 [20480/35339 (58%)]	Loss: 0.829760
Train Epoch: 7 [21120/35339 (60%)]	Loss: 0.701003
Train Epoch: 7 [21760/35339 (61%)]	Loss: 0.814167
Train Epoch: 7 [22400/35339 (63%)]	Loss: 0.598832
Train Epoch: 7 [23040/35339 (65%)]	Loss: 0.488554
Train Epoch: 7 [23680/35339 (67%)]	Loss: 0.614345
Train Epoch: 7 [24320/35339 (69%)]	Loss: 0.659602
Train Epoch: 7 [24960/35339 (71%)]	Loss: 0.679290
Train Epoch: 7 [25600/35339 (72%)]	Loss: 0.531908
Train Epoch: 7 [26240/35339 (74%)]	Loss: 0.542363
Train Epoch: 7 [26880/35339 (76%)]	Loss: 0.745290
Train Epoch: 7 [27520/35339 (78%)]	Loss: 0.602872
Train Epoch: 7 [28160/35339 (80%)]	Loss: 0.638063
Train Epoch: 7 [28800/35339 (81%)]	Loss: 0.698642
Train Epoch: 7 [29440/35339 (83%)]	Loss: 0.505894
Train Epoch: 7 [30080/35339 (85%)]	Loss: 0.703128
Train Epoch: 7 [30720/35339 (87%)]	Loss: 0.680836
Train Epoch: 7 [31360/35339 (89%)]	Loss: 0.713298
Train Epoch: 7 [32000/35339 (90%)]	Loss: 0.582630
Train Epoch: 7 [32640/35339 (92%)]	Loss: 0.716830
Train Epoch: 7 [33280/35339 (94%)]	Loss: 0.669900
Train Epoch: 7 [33920/35339 (96%)]	Loss: 0.646404
Train Epoch: 7 [34560/35339 (98%)]	Loss: 0.469175
Train Epoch: 7 [35200/35339 (99%)]	Loss: 0.852905

Validation set: Average loss: 2.4323, Accuracy: 1687/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 8 [0/35339 (0%)]	Loss: 0.597321
Train Epoch: 8 [640/35339 (2%)]	Loss: 0.684950
Train Epoch: 8 [1280/35339 (4%)]	Loss: 0.779170
Train Epoch: 8 [1920/35339 (5%)]	Loss: 0.532408
Train Epoch: 8 [2560/35339 (7%)]	Loss: 0.668400
Train Epoch: 8 [3200/35339 (9%)]	Loss: 0.590539
Train Epoch: 8 [3840/35339 (11%)]	Loss: 0.714676
Train Epoch: 8 [4480/35339 (13%)]	Loss: 0.541503
Train Epoch: 8 [5120/35339 (14%)]	Loss: 0.561872
Train Epoch: 8 [5760/35339 (16%)]	Loss: 0.447785
Train Epoch: 8 [6400/35339 (18%)]	Loss: 0.592266
Train Epoch: 8 [7040/35339 (20%)]	Loss: 0.543329
Train Epoch: 8 [7680/35339 (22%)]	Loss: 0.709038
Train Epoch: 8 [8320/35339 (24%)]	Loss: 0.519136
Train Epoch: 8 [8960/35339 (25%)]	Loss: 0.557048
Train Epoch: 8 [9600/35339 (27%)]	Loss: 0.431423
Train Epoch: 8 [10240/35339 (29%)]	Loss: 0.697028
Train Epoch: 8 [10880/35339 (31%)]	Loss: 0.623543
Train Epoch: 8 [11520/35339 (33%)]	Loss: 0.423027
Train Epoch: 8 [12160/35339 (34%)]	Loss: 0.559680
Train Epoch: 8 [12800/35339 (36%)]	Loss: 0.479292
Train Epoch: 8 [13440/35339 (38%)]	Loss: 0.589383
Train Epoch: 8 [14080/35339 (40%)]	Loss: 0.548112
Train Epoch: 8 [14720/35339 (42%)]	Loss: 0.661625
Train Epoch: 8 [15360/35339 (43%)]	Loss: 0.880199
Train Epoch: 8 [16000/35339 (45%)]	Loss: 0.658551
Train Epoch: 8 [16640/35339 (47%)]	Loss: 0.741770
Train Epoch: 8 [17280/35339 (49%)]	Loss: 0.447729
Train Epoch: 8 [17920/35339 (51%)]	Loss: 0.508717
Train Epoch: 8 [18560/35339 (52%)]	Loss: 0.442676
Train Epoch: 8 [19200/35339 (54%)]	Loss: 0.590695
Train Epoch: 8 [19840/35339 (56%)]	Loss: 0.614309
Train Epoch: 8 [20480/35339 (58%)]	Loss: 0.453794
Train Epoch: 8 [21120/35339 (60%)]	Loss: 0.595139
Train Epoch: 8 [21760/35339 (61%)]	Loss: 0.477312
Train Epoch: 8 [22400/35339 (63%)]	Loss: 0.556278
Train Epoch: 8 [23040/35339 (65%)]	Loss: 0.592479
Train Epoch: 8 [23680/35339 (67%)]	Loss: 0.659382
Train Epoch: 8 [24320/35339 (69%)]	Loss: 0.499101
Train Epoch: 8 [24960/35339 (71%)]	Loss: 0.791417
Train Epoch: 8 [25600/35339 (72%)]	Loss: 0.695912
Train Epoch: 8 [26240/35339 (74%)]	Loss: 0.669287
Train Epoch: 8 [26880/35339 (76%)]	Loss: 0.771897
Train Epoch: 8 [27520/35339 (78%)]	Loss: 0.704844
Train Epoch: 8 [28160/35339 (80%)]	Loss: 0.604492
Train Epoch: 8 [28800/35339 (81%)]	Loss: 0.401245
Train Epoch: 8 [29440/35339 (83%)]	Loss: 0.544042
Train Epoch: 8 [30080/35339 (85%)]	Loss: 0.498642
Train Epoch: 8 [30720/35339 (87%)]	Loss: 0.573336
Train Epoch: 8 [31360/35339 (89%)]	Loss: 0.605856
Train Epoch: 8 [32000/35339 (90%)]	Loss: 0.570604
Train Epoch: 8 [32640/35339 (92%)]	Loss: 0.668234
Train Epoch: 8 [33280/35339 (94%)]	Loss: 0.695208
Train Epoch: 8 [33920/35339 (96%)]	Loss: 0.848514
Train Epoch: 8 [34560/35339 (98%)]	Loss: 0.458205
Train Epoch: 8 [35200/35339 (99%)]	Loss: 0.458201

Validation set: Average loss: 2.3420, Accuracy: 1733/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 9 [0/35339 (0%)]	Loss: 0.634910
Train Epoch: 9 [640/35339 (2%)]	Loss: 0.541657
Train Epoch: 9 [1280/35339 (4%)]	Loss: 0.853593
Train Epoch: 9 [1920/35339 (5%)]	Loss: 0.372228
Train Epoch: 9 [2560/35339 (7%)]	Loss: 0.616464
Train Epoch: 9 [3200/35339 (9%)]	Loss: 0.569397
Train Epoch: 9 [3840/35339 (11%)]	Loss: 0.521669
Train Epoch: 9 [4480/35339 (13%)]	Loss: 0.504441
Train Epoch: 9 [5120/35339 (14%)]	Loss: 0.632269
Train Epoch: 9 [5760/35339 (16%)]	Loss: 0.754651
Train Epoch: 9 [6400/35339 (18%)]	Loss: 0.549385
Train Epoch: 9 [7040/35339 (20%)]	Loss: 0.628480
Train Epoch: 9 [7680/35339 (22%)]	Loss: 0.625365
Train Epoch: 9 [8320/35339 (24%)]	Loss: 0.717317
Train Epoch: 9 [8960/35339 (25%)]	Loss: 0.586483
Train Epoch: 9 [9600/35339 (27%)]	Loss: 0.437881
Train Epoch: 9 [10240/35339 (29%)]	Loss: 0.567106
Train Epoch: 9 [10880/35339 (31%)]	Loss: 0.734045
Train Epoch: 9 [11520/35339 (33%)]	Loss: 0.566771
Train Epoch: 9 [12160/35339 (34%)]	Loss: 0.560411
Train Epoch: 9 [12800/35339 (36%)]	Loss: 0.714650
Train Epoch: 9 [13440/35339 (38%)]	Loss: 0.439462
Train Epoch: 9 [14080/35339 (40%)]	Loss: 0.548547
Train Epoch: 9 [14720/35339 (42%)]	Loss: 0.409356
Train Epoch: 9 [15360/35339 (43%)]	Loss: 0.849509
Train Epoch: 9 [16000/35339 (45%)]	Loss: 0.600675
Train Epoch: 9 [16640/35339 (47%)]	Loss: 0.517840
Train Epoch: 9 [17280/35339 (49%)]	Loss: 0.589113
Train Epoch: 9 [17920/35339 (51%)]	Loss: 0.484191
Train Epoch: 9 [18560/35339 (52%)]	Loss: 0.636185
Train Epoch: 9 [19200/35339 (54%)]	Loss: 0.523739
Train Epoch: 9 [19840/35339 (56%)]	Loss: 0.391936
Train Epoch: 9 [20480/35339 (58%)]	Loss: 0.497327
Train Epoch: 9 [21120/35339 (60%)]	Loss: 0.586532
Train Epoch: 9 [21760/35339 (61%)]	Loss: 0.435664
Train Epoch: 9 [22400/35339 (63%)]	Loss: 0.560017
Train Epoch: 9 [23040/35339 (65%)]	Loss: 0.623790
Train Epoch: 9 [23680/35339 (67%)]	Loss: 0.475661
Train Epoch: 9 [24320/35339 (69%)]	Loss: 0.455747
Train Epoch: 9 [24960/35339 (71%)]	Loss: 0.409130
Train Epoch: 9 [25600/35339 (72%)]	Loss: 0.628119
Train Epoch: 9 [26240/35339 (74%)]	Loss: 0.362926
Train Epoch: 9 [26880/35339 (76%)]	Loss: 0.489827
Train Epoch: 9 [27520/35339 (78%)]	Loss: 0.543088
Train Epoch: 9 [28160/35339 (80%)]	Loss: 0.565048
Train Epoch: 9 [28800/35339 (81%)]	Loss: 0.470108
Train Epoch: 9 [29440/35339 (83%)]	Loss: 0.646581
Train Epoch: 9 [30080/35339 (85%)]	Loss: 0.477595
Train Epoch: 9 [30720/35339 (87%)]	Loss: 0.397498
Train Epoch: 9 [31360/35339 (89%)]	Loss: 0.460317
Train Epoch: 9 [32000/35339 (90%)]	Loss: 0.553266
Train Epoch: 9 [32640/35339 (92%)]	Loss: 0.619320
Train Epoch: 9 [33280/35339 (94%)]	Loss: 0.567062
Train Epoch: 9 [33920/35339 (96%)]	Loss: 0.510390
Train Epoch: 9 [34560/35339 (98%)]	Loss: 0.836059
Train Epoch: 9 [35200/35339 (99%)]	Loss: 0.531249

Validation set: Average loss: 2.1992, Accuracy: 1869/3870 (48%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 10 [0/35339 (0%)]	Loss: 0.478634
Train Epoch: 10 [640/35339 (2%)]	Loss: 0.558443
Train Epoch: 10 [1280/35339 (4%)]	Loss: 0.513157
Train Epoch: 10 [1920/35339 (5%)]	Loss: 0.572168
Train Epoch: 10 [2560/35339 (7%)]	Loss: 0.506110
Train Epoch: 10 [3200/35339 (9%)]	Loss: 0.657559
Train Epoch: 10 [3840/35339 (11%)]	Loss: 0.692363
Train Epoch: 10 [4480/35339 (13%)]	Loss: 0.300983
Train Epoch: 10 [5120/35339 (14%)]	Loss: 0.480357
Train Epoch: 10 [5760/35339 (16%)]	Loss: 1.147059
Train Epoch: 10 [6400/35339 (18%)]	Loss: 0.418854
Train Epoch: 10 [7040/35339 (20%)]	Loss: 0.548223
Train Epoch: 10 [7680/35339 (22%)]	Loss: 0.644136
Train Epoch: 10 [8320/35339 (24%)]	Loss: 0.513740
Train Epoch: 10 [8960/35339 (25%)]	Loss: 0.465288
Train Epoch: 10 [9600/35339 (27%)]	Loss: 0.880940
Train Epoch: 10 [10240/35339 (29%)]	Loss: 0.513859
Train Epoch: 10 [10880/35339 (31%)]	Loss: 0.456083
Train Epoch: 10 [11520/35339 (33%)]	Loss: 0.508696
Train Epoch: 10 [12160/35339 (34%)]	Loss: 0.530240
Train Epoch: 10 [12800/35339 (36%)]	Loss: 0.647302
Train Epoch: 10 [13440/35339 (38%)]	Loss: 0.500451
Train Epoch: 10 [14080/35339 (40%)]	Loss: 0.429101
Train Epoch: 10 [14720/35339 (42%)]	Loss: 0.568512
Train Epoch: 10 [15360/35339 (43%)]	Loss: 0.481478
Train Epoch: 10 [16000/35339 (45%)]	Loss: 0.609144
Train Epoch: 10 [16640/35339 (47%)]	Loss: 0.385865
Train Epoch: 10 [17280/35339 (49%)]	Loss: 0.534513
Train Epoch: 10 [17920/35339 (51%)]	Loss: 0.561596
Train Epoch: 10 [18560/35339 (52%)]	Loss: 0.628787
Train Epoch: 10 [19200/35339 (54%)]	Loss: 0.595448
Train Epoch: 10 [19840/35339 (56%)]	Loss: 0.463521
Train Epoch: 10 [20480/35339 (58%)]	Loss: 0.579300
Train Epoch: 10 [21120/35339 (60%)]	Loss: 0.746156
Train Epoch: 10 [21760/35339 (61%)]	Loss: 0.644471
Train Epoch: 10 [22400/35339 (63%)]	Loss: 0.307683
Train Epoch: 10 [23040/35339 (65%)]	Loss: 0.436754
Train Epoch: 10 [23680/35339 (67%)]	Loss: 0.384278
Train Epoch: 10 [24320/35339 (69%)]	Loss: 0.440209
Train Epoch: 10 [24960/35339 (71%)]	Loss: 0.495136
Train Epoch: 10 [25600/35339 (72%)]	Loss: 0.362694
Train Epoch: 10 [26240/35339 (74%)]	Loss: 0.422772
Train Epoch: 10 [26880/35339 (76%)]	Loss: 0.605766
Train Epoch: 10 [27520/35339 (78%)]	Loss: 0.437573
Train Epoch: 10 [28160/35339 (80%)]	Loss: 0.337630
Train Epoch: 10 [28800/35339 (81%)]	Loss: 0.445679
Train Epoch: 10 [29440/35339 (83%)]	Loss: 0.495995
Train Epoch: 10 [30080/35339 (85%)]	Loss: 0.434017
Train Epoch: 10 [30720/35339 (87%)]	Loss: 0.372433
Train Epoch: 10 [31360/35339 (89%)]	Loss: 0.383833
Train Epoch: 10 [32000/35339 (90%)]	Loss: 0.465648
Train Epoch: 10 [32640/35339 (92%)]	Loss: 0.470011
Train Epoch: 10 [33280/35339 (94%)]	Loss: 0.510741
Train Epoch: 10 [33920/35339 (96%)]	Loss: 0.441853
Train Epoch: 10 [34560/35339 (98%)]	Loss: 0.488523
Train Epoch: 10 [35200/35339 (99%)]	Loss: 0.649159

Validation set: Average loss: 2.2125, Accuracy: 1913/3870 (49%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 11 [0/35339 (0%)]	Loss: 0.414189
Train Epoch: 11 [640/35339 (2%)]	Loss: 0.557561
Train Epoch: 11 [1280/35339 (4%)]	Loss: 0.464221
Train Epoch: 11 [1920/35339 (5%)]	Loss: 0.474660
Train Epoch: 11 [2560/35339 (7%)]	Loss: 0.468444
Train Epoch: 11 [3200/35339 (9%)]	Loss: 0.564591
Train Epoch: 11 [3840/35339 (11%)]	Loss: 0.548922
Train Epoch: 11 [4480/35339 (13%)]	Loss: 0.541863
Train Epoch: 11 [5120/35339 (14%)]	Loss: 0.562163
Train Epoch: 11 [5760/35339 (16%)]	Loss: 0.439882
Train Epoch: 11 [6400/35339 (18%)]	Loss: 0.481727
Train Epoch: 11 [7040/35339 (20%)]	Loss: 0.432587
Train Epoch: 11 [7680/35339 (22%)]	Loss: 0.410531
Train Epoch: 11 [8320/35339 (24%)]	Loss: 0.627525
Train Epoch: 11 [8960/35339 (25%)]	Loss: 0.510666
Train Epoch: 11 [9600/35339 (27%)]	Loss: 0.363465
Train Epoch: 11 [10240/35339 (29%)]	Loss: 0.619984
Train Epoch: 11 [10880/35339 (31%)]	Loss: 0.505849
Train Epoch: 11 [11520/35339 (33%)]	Loss: 0.490772
Train Epoch: 11 [12160/35339 (34%)]	Loss: 0.671194
Train Epoch: 11 [12800/35339 (36%)]	Loss: 0.350881
Train Epoch: 11 [13440/35339 (38%)]	Loss: 0.550003
Train Epoch: 11 [14080/35339 (40%)]	Loss: 0.319215
Train Epoch: 11 [14720/35339 (42%)]	Loss: 0.789984
Train Epoch: 11 [15360/35339 (43%)]	Loss: 0.516492
Train Epoch: 11 [16000/35339 (45%)]	Loss: 0.485867
Train Epoch: 11 [16640/35339 (47%)]	Loss: 0.558091
Train Epoch: 11 [17280/35339 (49%)]	Loss: 0.499348
Train Epoch: 11 [17920/35339 (51%)]	Loss: 0.348018
Train Epoch: 11 [18560/35339 (52%)]	Loss: 0.410857
Train Epoch: 11 [19200/35339 (54%)]	Loss: 0.418361
Train Epoch: 11 [19840/35339 (56%)]	Loss: 0.670780
Train Epoch: 11 [20480/35339 (58%)]	Loss: 0.396574
Train Epoch: 11 [21120/35339 (60%)]	Loss: 0.352905
Train Epoch: 11 [21760/35339 (61%)]	Loss: 0.655812
Train Epoch: 11 [22400/35339 (63%)]	Loss: 0.410043
Train Epoch: 11 [23040/35339 (65%)]	Loss: 0.655941
Train Epoch: 11 [23680/35339 (67%)]	Loss: 0.414661
Train Epoch: 11 [24320/35339 (69%)]	Loss: 0.270890
Train Epoch: 11 [24960/35339 (71%)]	Loss: 0.311171
Train Epoch: 11 [25600/35339 (72%)]	Loss: 1.071903
Train Epoch: 11 [26240/35339 (74%)]	Loss: 0.432976
Train Epoch: 11 [26880/35339 (76%)]	Loss: 0.386921
Train Epoch: 11 [27520/35339 (78%)]	Loss: 0.463802
Train Epoch: 11 [28160/35339 (80%)]	Loss: 0.517625
Train Epoch: 11 [28800/35339 (81%)]	Loss: 0.571324
Train Epoch: 11 [29440/35339 (83%)]	Loss: 0.825994
Train Epoch: 11 [30080/35339 (85%)]	Loss: 0.751966
Train Epoch: 11 [30720/35339 (87%)]	Loss: 0.466122
Train Epoch: 11 [31360/35339 (89%)]	Loss: 0.425631
Train Epoch: 11 [32000/35339 (90%)]	Loss: 0.651655
Train Epoch: 11 [32640/35339 (92%)]	Loss: 0.617036
Train Epoch: 11 [33280/35339 (94%)]	Loss: 0.435282
Train Epoch: 11 [33920/35339 (96%)]	Loss: 0.434722
Train Epoch: 11 [34560/35339 (98%)]	Loss: 0.402196
Train Epoch: 11 [35200/35339 (99%)]	Loss: 0.404578

Validation set: Average loss: 2.1182, Accuracy: 1967/3870 (51%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 12 [0/35339 (0%)]	Loss: 0.391645
Train Epoch: 12 [640/35339 (2%)]	Loss: 0.509919
Train Epoch: 12 [1280/35339 (4%)]	Loss: 0.478979
Train Epoch: 12 [1920/35339 (5%)]	Loss: 0.508096
Train Epoch: 12 [2560/35339 (7%)]	Loss: 0.524531
Train Epoch: 12 [3200/35339 (9%)]	Loss: 0.393443
Train Epoch: 12 [3840/35339 (11%)]	Loss: 0.433988
Train Epoch: 12 [4480/35339 (13%)]	Loss: 0.360296
Train Epoch: 12 [5120/35339 (14%)]	Loss: 0.486658
Train Epoch: 12 [5760/35339 (16%)]	Loss: 0.624200
Train Epoch: 12 [6400/35339 (18%)]	Loss: 0.498338
Train Epoch: 12 [7040/35339 (20%)]	Loss: 0.768103
Train Epoch: 12 [7680/35339 (22%)]	Loss: 0.474133
Train Epoch: 12 [8320/35339 (24%)]	Loss: 0.371229
Train Epoch: 12 [8960/35339 (25%)]	Loss: 0.602368
Train Epoch: 12 [9600/35339 (27%)]	Loss: 0.595582
Train Epoch: 12 [10240/35339 (29%)]	Loss: 0.371208
Train Epoch: 12 [10880/35339 (31%)]	Loss: 0.468828
Train Epoch: 12 [11520/35339 (33%)]	Loss: 0.467192
Train Epoch: 12 [12160/35339 (34%)]	Loss: 0.853395
Train Epoch: 12 [12800/35339 (36%)]	Loss: 0.490287
Train Epoch: 12 [13440/35339 (38%)]	Loss: 0.548256
Train Epoch: 12 [14080/35339 (40%)]	Loss: 0.597652
Train Epoch: 12 [14720/35339 (42%)]	Loss: 0.377962
Train Epoch: 12 [15360/35339 (43%)]	Loss: 0.496556
Train Epoch: 12 [16000/35339 (45%)]	Loss: 0.541264
Train Epoch: 12 [16640/35339 (47%)]	Loss: 0.527149
Train Epoch: 12 [17280/35339 (49%)]	Loss: 1.172161
Train Epoch: 12 [17920/35339 (51%)]	Loss: 0.402105
Train Epoch: 12 [18560/35339 (52%)]	Loss: 0.476414
Train Epoch: 12 [19200/35339 (54%)]	Loss: 0.579767
Train Epoch: 12 [19840/35339 (56%)]	Loss: 0.373083
Train Epoch: 12 [20480/35339 (58%)]	Loss: 0.511247
Train Epoch: 12 [21120/35339 (60%)]	Loss: 0.634963
Train Epoch: 12 [21760/35339 (61%)]	Loss: 0.523014
Train Epoch: 12 [22400/35339 (63%)]	Loss: 0.577167
Train Epoch: 12 [23040/35339 (65%)]	Loss: 0.474659
Train Epoch: 12 [23680/35339 (67%)]	Loss: 0.424964
Train Epoch: 12 [24320/35339 (69%)]	Loss: 0.522706
Train Epoch: 12 [24960/35339 (71%)]	Loss: 0.411553
Train Epoch: 12 [25600/35339 (72%)]	Loss: 0.325911
Train Epoch: 12 [26240/35339 (74%)]	Loss: 0.312559
Train Epoch: 12 [26880/35339 (76%)]	Loss: 0.932378
Train Epoch: 12 [27520/35339 (78%)]	Loss: 0.411002
Train Epoch: 12 [28160/35339 (80%)]	Loss: 0.401184
Train Epoch: 12 [28800/35339 (81%)]	Loss: 0.470624
Train Epoch: 12 [29440/35339 (83%)]	Loss: 0.738881
Train Epoch: 12 [30080/35339 (85%)]	Loss: 0.483708
Train Epoch: 12 [30720/35339 (87%)]	Loss: 0.369565
Train Epoch: 12 [31360/35339 (89%)]	Loss: 0.577374
Train Epoch: 12 [32000/35339 (90%)]	Loss: 0.479656
Train Epoch: 12 [32640/35339 (92%)]	Loss: 0.545415
Train Epoch: 12 [33280/35339 (94%)]	Loss: 0.420991
Train Epoch: 12 [33920/35339 (96%)]	Loss: 0.328179
Train Epoch: 12 [34560/35339 (98%)]	Loss: 0.428436
Train Epoch: 12 [35200/35339 (99%)]	Loss: 0.490758

Validation set: Average loss: 2.0487, Accuracy: 2006/3870 (52%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 13 [0/35339 (0%)]	Loss: 0.370250
Train Epoch: 13 [640/35339 (2%)]	Loss: 0.387093
Train Epoch: 13 [1280/35339 (4%)]	Loss: 0.422733
Train Epoch: 13 [1920/35339 (5%)]	Loss: 0.458875
Train Epoch: 13 [2560/35339 (7%)]	Loss: 0.730145
Train Epoch: 13 [3200/35339 (9%)]	Loss: 0.448870
Train Epoch: 13 [3840/35339 (11%)]	Loss: 0.320659
Train Epoch: 13 [4480/35339 (13%)]	Loss: 0.385381
Train Epoch: 13 [5120/35339 (14%)]	Loss: 0.520257
Train Epoch: 13 [5760/35339 (16%)]	Loss: 0.303070
Train Epoch: 13 [6400/35339 (18%)]	Loss: 0.453505
Train Epoch: 13 [7040/35339 (20%)]	Loss: 0.385231
Train Epoch: 13 [7680/35339 (22%)]	Loss: 0.242529
Train Epoch: 13 [8320/35339 (24%)]	Loss: 0.558883
Train Epoch: 13 [8960/35339 (25%)]	Loss: 0.545972
Train Epoch: 13 [9600/35339 (27%)]	Loss: 0.565158
Train Epoch: 13 [10240/35339 (29%)]	Loss: 0.527158
Train Epoch: 13 [10880/35339 (31%)]	Loss: 0.505181
Train Epoch: 13 [11520/35339 (33%)]	Loss: 0.738546
Train Epoch: 13 [12160/35339 (34%)]	Loss: 0.547163
Train Epoch: 13 [12800/35339 (36%)]	Loss: 0.317141
Train Epoch: 13 [13440/35339 (38%)]	Loss: 0.397693
Train Epoch: 13 [14080/35339 (40%)]	Loss: 0.542631
Train Epoch: 13 [14720/35339 (42%)]	Loss: 0.415546
Train Epoch: 13 [15360/35339 (43%)]	Loss: 0.369128
Train Epoch: 13 [16000/35339 (45%)]	Loss: 0.500038
Train Epoch: 13 [16640/35339 (47%)]	Loss: 0.391792
Train Epoch: 13 [17280/35339 (49%)]	Loss: 0.480117
Train Epoch: 13 [17920/35339 (51%)]	Loss: 0.477561
Train Epoch: 13 [18560/35339 (52%)]	Loss: 0.564844
Train Epoch: 13 [19200/35339 (54%)]	Loss: 0.357148
Train Epoch: 13 [19840/35339 (56%)]	Loss: 0.463838
Train Epoch: 13 [20480/35339 (58%)]	Loss: 0.423373
Train Epoch: 13 [21120/35339 (60%)]	Loss: 0.519545
Train Epoch: 13 [21760/35339 (61%)]	Loss: 0.457878
Train Epoch: 13 [22400/35339 (63%)]	Loss: 0.541842
Train Epoch: 13 [23040/35339 (65%)]	Loss: 0.498837
Train Epoch: 13 [23680/35339 (67%)]	Loss: 0.589161
Train Epoch: 13 [24320/35339 (69%)]	Loss: 0.428775
Train Epoch: 13 [24960/35339 (71%)]	Loss: 0.534922
Train Epoch: 13 [25600/35339 (72%)]	Loss: 0.507439
Train Epoch: 13 [26240/35339 (74%)]	Loss: 0.370499
Train Epoch: 13 [26880/35339 (76%)]	Loss: 0.480965
Train Epoch: 13 [27520/35339 (78%)]	Loss: 0.563761
Train Epoch: 13 [28160/35339 (80%)]	Loss: 0.415120
Train Epoch: 13 [28800/35339 (81%)]	Loss: 0.453607
Train Epoch: 13 [29440/35339 (83%)]	Loss: 0.483132
Train Epoch: 13 [30080/35339 (85%)]	Loss: 0.382051
Train Epoch: 13 [30720/35339 (87%)]	Loss: 0.505226
Train Epoch: 13 [31360/35339 (89%)]	Loss: 0.536478
Train Epoch: 13 [32000/35339 (90%)]	Loss: 0.521859
Train Epoch: 13 [32640/35339 (92%)]	Loss: 0.424842
Train Epoch: 13 [33280/35339 (94%)]	Loss: 0.386263
Train Epoch: 13 [33920/35339 (96%)]	Loss: 0.476456
Train Epoch: 13 [34560/35339 (98%)]	Loss: 0.377749
Train Epoch: 13 [35200/35339 (99%)]	Loss: 0.408779

Validation set: Average loss: 2.0574, Accuracy: 2054/3870 (53%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 14 [0/35339 (0%)]	Loss: 0.653071
Train Epoch: 14 [640/35339 (2%)]	Loss: 0.453210
Train Epoch: 14 [1280/35339 (4%)]	Loss: 0.567663
Train Epoch: 14 [1920/35339 (5%)]	Loss: 0.294142
Train Epoch: 14 [2560/35339 (7%)]	Loss: 0.342035
Train Epoch: 14 [3200/35339 (9%)]	Loss: 0.307062
Train Epoch: 14 [3840/35339 (11%)]	Loss: 0.429780
Train Epoch: 14 [4480/35339 (13%)]	Loss: 0.322180
Train Epoch: 14 [5120/35339 (14%)]	Loss: 0.466462
Train Epoch: 14 [5760/35339 (16%)]	Loss: 0.332997
Train Epoch: 14 [6400/35339 (18%)]	Loss: 0.400026
Train Epoch: 14 [7040/35339 (20%)]	Loss: 0.420338
Train Epoch: 14 [7680/35339 (22%)]	Loss: 0.525032
Train Epoch: 14 [8320/35339 (24%)]	Loss: 0.388816
Train Epoch: 14 [8960/35339 (25%)]	Loss: 0.473905
Train Epoch: 14 [9600/35339 (27%)]	Loss: 0.597408
Train Epoch: 14 [10240/35339 (29%)]	Loss: 0.373023
Train Epoch: 14 [10880/35339 (31%)]	Loss: 0.371903
Train Epoch: 14 [11520/35339 (33%)]	Loss: 0.368098
Train Epoch: 14 [12160/35339 (34%)]	Loss: 0.442423
Train Epoch: 14 [12800/35339 (36%)]	Loss: 0.739974
Train Epoch: 14 [13440/35339 (38%)]	Loss: 0.443920
Train Epoch: 14 [14080/35339 (40%)]	Loss: 0.476747
Train Epoch: 14 [14720/35339 (42%)]	Loss: 0.517868
Train Epoch: 14 [15360/35339 (43%)]	Loss: 0.500979
Train Epoch: 14 [16000/35339 (45%)]	Loss: 0.408226
Train Epoch: 14 [16640/35339 (47%)]	Loss: 0.834093
Train Epoch: 14 [17280/35339 (49%)]	Loss: 0.487872
Train Epoch: 14 [17920/35339 (51%)]	Loss: 0.520315
Train Epoch: 14 [18560/35339 (52%)]	Loss: 0.862349
Train Epoch: 14 [19200/35339 (54%)]	Loss: 0.410712
Train Epoch: 14 [19840/35339 (56%)]	Loss: 0.414952
Train Epoch: 14 [20480/35339 (58%)]	Loss: 0.636070
Train Epoch: 14 [21120/35339 (60%)]	Loss: 0.390345
Train Epoch: 14 [21760/35339 (61%)]	Loss: 0.452554
Train Epoch: 14 [22400/35339 (63%)]	Loss: 0.644882
Train Epoch: 14 [23040/35339 (65%)]	Loss: 0.430611
Train Epoch: 14 [23680/35339 (67%)]	Loss: 0.419730
Train Epoch: 14 [24320/35339 (69%)]	Loss: 0.649553
Train Epoch: 14 [24960/35339 (71%)]	Loss: 0.338488
Train Epoch: 14 [25600/35339 (72%)]	Loss: 0.336196
Train Epoch: 14 [26240/35339 (74%)]	Loss: 0.759432
Train Epoch: 14 [26880/35339 (76%)]	Loss: 0.472210
Train Epoch: 14 [27520/35339 (78%)]	Loss: 0.476976
Train Epoch: 14 [28160/35339 (80%)]	Loss: 0.387871
Train Epoch: 14 [28800/35339 (81%)]	Loss: 0.919264
Train Epoch: 14 [29440/35339 (83%)]	Loss: 0.482481
Train Epoch: 14 [30080/35339 (85%)]	Loss: 0.463503
Train Epoch: 14 [30720/35339 (87%)]	Loss: 0.654298
Train Epoch: 14 [31360/35339 (89%)]	Loss: 0.500084
Train Epoch: 14 [32000/35339 (90%)]	Loss: 0.413580
Train Epoch: 14 [32640/35339 (92%)]	Loss: 0.649225
Train Epoch: 14 [33280/35339 (94%)]	Loss: 0.265663
Train Epoch: 14 [33920/35339 (96%)]	Loss: 0.427216
Train Epoch: 14 [34560/35339 (98%)]	Loss: 0.646850
Train Epoch: 14 [35200/35339 (99%)]	Loss: 0.586739

Validation set: Average loss: 2.0138, Accuracy: 2092/3870 (54%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 15 [0/35339 (0%)]	Loss: 0.558031
Train Epoch: 15 [640/35339 (2%)]	Loss: 0.397736
Train Epoch: 15 [1280/35339 (4%)]	Loss: 0.583407
Train Epoch: 15 [1920/35339 (5%)]	Loss: 0.374615
Train Epoch: 15 [2560/35339 (7%)]	Loss: 0.486948
Train Epoch: 15 [3200/35339 (9%)]	Loss: 0.539535
Train Epoch: 15 [3840/35339 (11%)]	Loss: 0.595185
Train Epoch: 15 [4480/35339 (13%)]	Loss: 0.497167
Train Epoch: 15 [5120/35339 (14%)]	Loss: 0.500208
Train Epoch: 15 [5760/35339 (16%)]	Loss: 0.503172
Train Epoch: 15 [6400/35339 (18%)]	Loss: 0.532323
Train Epoch: 15 [7040/35339 (20%)]	Loss: 0.449039
Train Epoch: 15 [7680/35339 (22%)]	Loss: 0.826593
Train Epoch: 15 [8320/35339 (24%)]	Loss: 0.520516
Train Epoch: 15 [8960/35339 (25%)]	Loss: 0.442764
Train Epoch: 15 [9600/35339 (27%)]	Loss: 0.557998
Train Epoch: 15 [10240/35339 (29%)]	Loss: 0.592531
Train Epoch: 15 [10880/35339 (31%)]	Loss: 0.422820
Train Epoch: 15 [11520/35339 (33%)]	Loss: 0.460500
Train Epoch: 15 [12160/35339 (34%)]	Loss: 0.757578
Train Epoch: 15 [12800/35339 (36%)]	Loss: 0.523875
Train Epoch: 15 [13440/35339 (38%)]	Loss: 0.338626
Train Epoch: 15 [14080/35339 (40%)]	Loss: 0.326809
Train Epoch: 15 [14720/35339 (42%)]	Loss: 0.329803
Train Epoch: 15 [15360/35339 (43%)]	Loss: 0.461954
Train Epoch: 15 [16000/35339 (45%)]	Loss: 0.379795
Train Epoch: 15 [16640/35339 (47%)]	Loss: 0.414899
Train Epoch: 15 [17280/35339 (49%)]	Loss: 0.342078
Train Epoch: 15 [17920/35339 (51%)]	Loss: 0.382916
Train Epoch: 15 [18560/35339 (52%)]	Loss: 0.448810
Train Epoch: 15 [19200/35339 (54%)]	Loss: 0.516679
Train Epoch: 15 [19840/35339 (56%)]	Loss: 0.306577
Train Epoch: 15 [20480/35339 (58%)]	Loss: 0.394851
Train Epoch: 15 [21120/35339 (60%)]	Loss: 0.402377
Train Epoch: 15 [21760/35339 (61%)]	Loss: 0.415982
Train Epoch: 15 [22400/35339 (63%)]	Loss: 0.413490
Train Epoch: 15 [23040/35339 (65%)]	Loss: 0.580988
Train Epoch: 15 [23680/35339 (67%)]	Loss: 0.409172
Train Epoch: 15 [24320/35339 (69%)]	Loss: 0.507519
Train Epoch: 15 [24960/35339 (71%)]	Loss: 0.510774
Train Epoch: 15 [25600/35339 (72%)]	Loss: 0.527831
Train Epoch: 15 [26240/35339 (74%)]	Loss: 0.425475
Train Epoch: 15 [26880/35339 (76%)]	Loss: 0.446000
Train Epoch: 15 [27520/35339 (78%)]	Loss: 0.432974
Train Epoch: 15 [28160/35339 (80%)]	Loss: 0.418849
Train Epoch: 15 [28800/35339 (81%)]	Loss: 0.417632
Train Epoch: 15 [29440/35339 (83%)]	Loss: 0.645162
Train Epoch: 15 [30080/35339 (85%)]	Loss: 0.373962
Train Epoch: 15 [30720/35339 (87%)]	Loss: 0.551619
Train Epoch: 15 [31360/35339 (89%)]	Loss: 0.451046
Train Epoch: 15 [32000/35339 (90%)]	Loss: 0.238902
Train Epoch: 15 [32640/35339 (92%)]	Loss: 0.395745
Train Epoch: 15 [33280/35339 (94%)]	Loss: 0.578406
Train Epoch: 15 [33920/35339 (96%)]	Loss: 0.366569
Train Epoch: 15 [34560/35339 (98%)]	Loss: 0.333895
Train Epoch: 15 [35200/35339 (99%)]	Loss: 0.670287

Validation set: Average loss: 1.9715, Accuracy: 2124/3870 (55%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 16 [0/35339 (0%)]	Loss: 0.532547
Train Epoch: 16 [640/35339 (2%)]	Loss: 0.581725
Train Epoch: 16 [1280/35339 (4%)]	Loss: 0.784528
Train Epoch: 16 [1920/35339 (5%)]	Loss: 0.464272
Train Epoch: 16 [2560/35339 (7%)]	Loss: 0.531190
Train Epoch: 16 [3200/35339 (9%)]	Loss: 0.395600
Train Epoch: 16 [3840/35339 (11%)]	Loss: 0.478097
Train Epoch: 16 [4480/35339 (13%)]	Loss: 0.379714
Train Epoch: 16 [5120/35339 (14%)]	Loss: 0.507082
Train Epoch: 16 [5760/35339 (16%)]	Loss: 0.379367
Train Epoch: 16 [6400/35339 (18%)]	Loss: 0.472316
Train Epoch: 16 [7040/35339 (20%)]	Loss: 0.496585
Train Epoch: 16 [7680/35339 (22%)]	Loss: 0.463861
Train Epoch: 16 [8320/35339 (24%)]	Loss: 0.542564
Train Epoch: 16 [8960/35339 (25%)]	Loss: 0.382253
Train Epoch: 16 [9600/35339 (27%)]	Loss: 0.390662
Train Epoch: 16 [10240/35339 (29%)]	Loss: 0.540671
Train Epoch: 16 [10880/35339 (31%)]	Loss: 0.340342
Train Epoch: 16 [11520/35339 (33%)]	Loss: 0.313915
Train Epoch: 16 [12160/35339 (34%)]	Loss: 0.478279
Train Epoch: 16 [12800/35339 (36%)]	Loss: 0.406028
Train Epoch: 16 [13440/35339 (38%)]	Loss: 0.529483
Train Epoch: 16 [14080/35339 (40%)]	Loss: 0.406873
Train Epoch: 16 [14720/35339 (42%)]	Loss: 0.566168
Train Epoch: 16 [15360/35339 (43%)]	Loss: 0.378318
Train Epoch: 16 [16000/35339 (45%)]	Loss: 0.713206
Train Epoch: 16 [16640/35339 (47%)]	Loss: 0.513139
Train Epoch: 16 [17280/35339 (49%)]	Loss: 0.530570
Train Epoch: 16 [17920/35339 (51%)]	Loss: 0.345345
Train Epoch: 16 [18560/35339 (52%)]	Loss: 0.400535
Train Epoch: 16 [19200/35339 (54%)]	Loss: 0.585605
Train Epoch: 16 [19840/35339 (56%)]	Loss: 0.306249
Train Epoch: 16 [20480/35339 (58%)]	Loss: 0.472216
Train Epoch: 16 [21120/35339 (60%)]	Loss: 0.456826
Train Epoch: 16 [21760/35339 (61%)]	Loss: 0.329674
Train Epoch: 16 [22400/35339 (63%)]	Loss: 0.419945
Train Epoch: 16 [23040/35339 (65%)]	Loss: 0.426355
Train Epoch: 16 [23680/35339 (67%)]	Loss: 0.671104
Train Epoch: 16 [24320/35339 (69%)]	Loss: 0.414020
Train Epoch: 16 [24960/35339 (71%)]	Loss: 0.456535
Train Epoch: 16 [25600/35339 (72%)]	Loss: 0.291861
Train Epoch: 16 [26240/35339 (74%)]	Loss: 0.618065
Train Epoch: 16 [26880/35339 (76%)]	Loss: 0.354031
Train Epoch: 16 [27520/35339 (78%)]	Loss: 0.357294
Train Epoch: 16 [28160/35339 (80%)]	Loss: 0.932779
Train Epoch: 16 [28800/35339 (81%)]	Loss: 0.341545
Train Epoch: 16 [29440/35339 (83%)]	Loss: 0.412234
Train Epoch: 16 [30080/35339 (85%)]	Loss: 0.467069
Train Epoch: 16 [30720/35339 (87%)]	Loss: 0.310870
Train Epoch: 16 [31360/35339 (89%)]	Loss: 0.275030
Train Epoch: 16 [32000/35339 (90%)]	Loss: 0.252043
Train Epoch: 16 [32640/35339 (92%)]	Loss: 0.548507
Train Epoch: 16 [33280/35339 (94%)]	Loss: 0.540073
Train Epoch: 16 [33920/35339 (96%)]	Loss: 0.406820
Train Epoch: 16 [34560/35339 (98%)]	Loss: 0.536101
Train Epoch: 16 [35200/35339 (99%)]	Loss: 0.511270

Validation set: Average loss: 1.9379, Accuracy: 2166/3870 (56%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 17 [0/35339 (0%)]	Loss: 0.489334
Train Epoch: 17 [640/35339 (2%)]	Loss: 0.531205
Train Epoch: 17 [1280/35339 (4%)]	Loss: 0.295146
Train Epoch: 17 [1920/35339 (5%)]	Loss: 0.516480
Train Epoch: 17 [2560/35339 (7%)]	Loss: 0.326005
Train Epoch: 17 [3200/35339 (9%)]	Loss: 0.510766
Train Epoch: 17 [3840/35339 (11%)]	Loss: 0.524688
Train Epoch: 17 [4480/35339 (13%)]	Loss: 0.461699
Train Epoch: 17 [5120/35339 (14%)]	Loss: 0.418242
Train Epoch: 17 [5760/35339 (16%)]	Loss: 0.398425
Train Epoch: 17 [6400/35339 (18%)]	Loss: 0.477286
Train Epoch: 17 [7040/35339 (20%)]	Loss: 0.476096
Train Epoch: 17 [7680/35339 (22%)]	Loss: 0.492782
Train Epoch: 17 [8320/35339 (24%)]	Loss: 0.421811
Train Epoch: 17 [8960/35339 (25%)]	Loss: 0.473151
Train Epoch: 17 [9600/35339 (27%)]	Loss: 0.389772
Train Epoch: 17 [10240/35339 (29%)]	Loss: 0.418912
Train Epoch: 17 [10880/35339 (31%)]	Loss: 0.422989
Train Epoch: 17 [11520/35339 (33%)]	Loss: 0.479318
Train Epoch: 17 [12160/35339 (34%)]	Loss: 0.363036
Train Epoch: 17 [12800/35339 (36%)]	Loss: 0.503567
Train Epoch: 17 [13440/35339 (38%)]	Loss: 0.433911
Train Epoch: 17 [14080/35339 (40%)]	Loss: 0.353125
Train Epoch: 17 [14720/35339 (42%)]	Loss: 0.292393
Train Epoch: 17 [15360/35339 (43%)]	Loss: 0.379840
Train Epoch: 17 [16000/35339 (45%)]	Loss: 0.697302
Train Epoch: 17 [16640/35339 (47%)]	Loss: 0.466280
Train Epoch: 17 [17280/35339 (49%)]	Loss: 0.347752
Train Epoch: 17 [17920/35339 (51%)]	Loss: 0.347141
Train Epoch: 17 [18560/35339 (52%)]	Loss: 0.625090
Train Epoch: 17 [19200/35339 (54%)]	Loss: 0.442359
Train Epoch: 17 [19840/35339 (56%)]	Loss: 0.448821
Train Epoch: 17 [20480/35339 (58%)]	Loss: 0.283485
Train Epoch: 17 [21120/35339 (60%)]	Loss: 0.344535
Train Epoch: 17 [21760/35339 (61%)]	Loss: 0.403959
Train Epoch: 17 [22400/35339 (63%)]	Loss: 0.759410
Train Epoch: 17 [23040/35339 (65%)]	Loss: 0.444242
Train Epoch: 17 [23680/35339 (67%)]	Loss: 0.498718
Train Epoch: 17 [24320/35339 (69%)]	Loss: 0.279954
Train Epoch: 17 [24960/35339 (71%)]	Loss: 0.331165
Train Epoch: 17 [25600/35339 (72%)]	Loss: 0.310429
Train Epoch: 17 [26240/35339 (74%)]	Loss: 0.376306
Train Epoch: 17 [26880/35339 (76%)]	Loss: 0.334488
Train Epoch: 17 [27520/35339 (78%)]	Loss: 0.305454
Train Epoch: 17 [28160/35339 (80%)]	Loss: 0.406124
Train Epoch: 17 [28800/35339 (81%)]	Loss: 0.386080
Train Epoch: 17 [29440/35339 (83%)]	Loss: 0.435245
Train Epoch: 17 [30080/35339 (85%)]	Loss: 0.552847
Train Epoch: 17 [30720/35339 (87%)]	Loss: 0.349590
Train Epoch: 17 [31360/35339 (89%)]	Loss: 0.379371
Train Epoch: 17 [32000/35339 (90%)]	Loss: 0.415601
Train Epoch: 17 [32640/35339 (92%)]	Loss: 0.287102
Train Epoch: 17 [33280/35339 (94%)]	Loss: 0.406146
Train Epoch: 17 [33920/35339 (96%)]	Loss: 0.635990
Train Epoch: 17 [34560/35339 (98%)]	Loss: 0.446242
Train Epoch: 17 [35200/35339 (99%)]	Loss: 0.367133

Validation set: Average loss: 1.9753, Accuracy: 2190/3870 (57%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 18 [0/35339 (0%)]	Loss: 0.398487
Train Epoch: 18 [640/35339 (2%)]	Loss: 0.402948
Train Epoch: 18 [1280/35339 (4%)]	Loss: 0.349428
Train Epoch: 18 [1920/35339 (5%)]	Loss: 0.453478
Train Epoch: 18 [2560/35339 (7%)]	Loss: 0.282313
Train Epoch: 18 [3200/35339 (9%)]	Loss: 0.414753
Train Epoch: 18 [3840/35339 (11%)]	Loss: 0.364090
Train Epoch: 18 [4480/35339 (13%)]	Loss: 0.480518
Train Epoch: 18 [5120/35339 (14%)]	Loss: 0.270395
Train Epoch: 18 [5760/35339 (16%)]	Loss: 0.585586
Train Epoch: 18 [6400/35339 (18%)]	Loss: 0.451143
Train Epoch: 18 [7040/35339 (20%)]	Loss: 0.573228
Train Epoch: 18 [7680/35339 (22%)]	Loss: 0.550861
Train Epoch: 18 [8320/35339 (24%)]	Loss: 0.500411
Train Epoch: 18 [8960/35339 (25%)]	Loss: 0.500973
Train Epoch: 18 [9600/35339 (27%)]	Loss: 0.653590
Train Epoch: 18 [10240/35339 (29%)]	Loss: 0.611674
Train Epoch: 18 [10880/35339 (31%)]	Loss: 0.391551
Train Epoch: 18 [11520/35339 (33%)]	Loss: 0.393256
Train Epoch: 18 [12160/35339 (34%)]	Loss: 0.404673
Train Epoch: 18 [12800/35339 (36%)]	Loss: 0.508774
Train Epoch: 18 [13440/35339 (38%)]	Loss: 0.280467
Train Epoch: 18 [14080/35339 (40%)]	Loss: 0.546442
Train Epoch: 18 [14720/35339 (42%)]	Loss: 0.399201
Train Epoch: 18 [15360/35339 (43%)]	Loss: 0.399281
Train Epoch: 18 [16000/35339 (45%)]	Loss: 0.440000
Train Epoch: 18 [16640/35339 (47%)]	Loss: 0.314081
Train Epoch: 18 [17280/35339 (49%)]	Loss: 0.371440
Train Epoch: 18 [17920/35339 (51%)]	Loss: 0.601304
Train Epoch: 18 [18560/35339 (52%)]	Loss: 0.528305
Train Epoch: 18 [19200/35339 (54%)]	Loss: 0.513530
Train Epoch: 18 [19840/35339 (56%)]	Loss: 0.671854
Train Epoch: 18 [20480/35339 (58%)]	Loss: 0.370943
Train Epoch: 18 [21120/35339 (60%)]	Loss: 0.455674
Train Epoch: 18 [21760/35339 (61%)]	Loss: 0.413958
Train Epoch: 18 [22400/35339 (63%)]	Loss: 0.256157
Train Epoch: 18 [23040/35339 (65%)]	Loss: 0.497588
Train Epoch: 18 [23680/35339 (67%)]	Loss: 0.352996
Train Epoch: 18 [24320/35339 (69%)]	Loss: 0.463618
Train Epoch: 18 [24960/35339 (71%)]	Loss: 0.391169
Train Epoch: 18 [25600/35339 (72%)]	Loss: 0.468119
Train Epoch: 18 [26240/35339 (74%)]	Loss: 0.359636
Train Epoch: 18 [26880/35339 (76%)]	Loss: 0.451332
Train Epoch: 18 [27520/35339 (78%)]	Loss: 0.383706
Train Epoch: 18 [28160/35339 (80%)]	Loss: 0.586312
Train Epoch: 18 [28800/35339 (81%)]	Loss: 0.311954
Train Epoch: 18 [29440/35339 (83%)]	Loss: 0.421146
Train Epoch: 18 [30080/35339 (85%)]	Loss: 0.503989
Train Epoch: 18 [30720/35339 (87%)]	Loss: 0.392982
Train Epoch: 18 [31360/35339 (89%)]	Loss: 0.505065
Train Epoch: 18 [32000/35339 (90%)]	Loss: 0.342989
Train Epoch: 18 [32640/35339 (92%)]	Loss: 0.518101
Train Epoch: 18 [33280/35339 (94%)]	Loss: 0.509104
Train Epoch: 18 [33920/35339 (96%)]	Loss: 0.556592
Train Epoch: 18 [34560/35339 (98%)]	Loss: 0.327141
Train Epoch: 18 [35200/35339 (99%)]	Loss: 0.438552

Validation set: Average loss: 1.8968, Accuracy: 2215/3870 (57%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 19 [0/35339 (0%)]	Loss: 0.328514
Train Epoch: 19 [640/35339 (2%)]	Loss: 0.591379
Train Epoch: 19 [1280/35339 (4%)]	Loss: 0.562901
Train Epoch: 19 [1920/35339 (5%)]	Loss: 0.475010
Train Epoch: 19 [2560/35339 (7%)]	Loss: 0.283939
Train Epoch: 19 [3200/35339 (9%)]	Loss: 0.534859
Train Epoch: 19 [3840/35339 (11%)]	Loss: 0.341608
Train Epoch: 19 [4480/35339 (13%)]	Loss: 0.349267
Train Epoch: 19 [5120/35339 (14%)]	Loss: 0.435347
Train Epoch: 19 [5760/35339 (16%)]	Loss: 0.292574
Train Epoch: 19 [6400/35339 (18%)]	Loss: 0.420970
Train Epoch: 19 [7040/35339 (20%)]	Loss: 0.490929
Train Epoch: 19 [7680/35339 (22%)]	Loss: 0.398573
Train Epoch: 19 [8320/35339 (24%)]	Loss: 0.332100
Train Epoch: 19 [8960/35339 (25%)]	Loss: 0.367561
Train Epoch: 19 [9600/35339 (27%)]	Loss: 0.454404
Train Epoch: 19 [10240/35339 (29%)]	Loss: 0.622790
Train Epoch: 19 [10880/35339 (31%)]	Loss: 0.482099
Train Epoch: 19 [11520/35339 (33%)]	Loss: 0.480557
Train Epoch: 19 [12160/35339 (34%)]	Loss: 0.239859
Train Epoch: 19 [12800/35339 (36%)]	Loss: 0.571665
Train Epoch: 19 [13440/35339 (38%)]	Loss: 0.378661
Train Epoch: 19 [14080/35339 (40%)]	Loss: 0.283595
Train Epoch: 19 [14720/35339 (42%)]	Loss: 0.567839
Train Epoch: 19 [15360/35339 (43%)]	Loss: 0.279604
Train Epoch: 19 [16000/35339 (45%)]	Loss: 0.371915
Train Epoch: 19 [16640/35339 (47%)]	Loss: 0.391357
Train Epoch: 19 [17280/35339 (49%)]	Loss: 0.475483
Train Epoch: 19 [17920/35339 (51%)]	Loss: 0.488692
Train Epoch: 19 [18560/35339 (52%)]	Loss: 0.432894
Train Epoch: 19 [19200/35339 (54%)]	Loss: 0.483000
Train Epoch: 19 [19840/35339 (56%)]	Loss: 0.402980
Train Epoch: 19 [20480/35339 (58%)]	Loss: 0.314403
Train Epoch: 19 [21120/35339 (60%)]	Loss: 0.339119
Train Epoch: 19 [21760/35339 (61%)]	Loss: 0.313174
Train Epoch: 19 [22400/35339 (63%)]	Loss: 0.452282
Train Epoch: 19 [23040/35339 (65%)]	Loss: 0.453925
Train Epoch: 19 [23680/35339 (67%)]	Loss: 0.491986
Train Epoch: 19 [24320/35339 (69%)]	Loss: 0.361166
Train Epoch: 19 [24960/35339 (71%)]	Loss: 0.381177
Train Epoch: 19 [25600/35339 (72%)]	Loss: 0.447950
Train Epoch: 19 [26240/35339 (74%)]	Loss: 0.382547
Train Epoch: 19 [26880/35339 (76%)]	Loss: 0.508508
Train Epoch: 19 [27520/35339 (78%)]	Loss: 0.377164
Train Epoch: 19 [28160/35339 (80%)]	Loss: 0.350831
Train Epoch: 19 [28800/35339 (81%)]	Loss: 0.553850
Train Epoch: 19 [29440/35339 (83%)]	Loss: 0.487362
Train Epoch: 19 [30080/35339 (85%)]	Loss: 0.475389
Train Epoch: 19 [30720/35339 (87%)]	Loss: 0.336255
Train Epoch: 19 [31360/35339 (89%)]	Loss: 0.349869
Train Epoch: 19 [32000/35339 (90%)]	Loss: 0.271000
Train Epoch: 19 [32640/35339 (92%)]	Loss: 0.329674
Train Epoch: 19 [33280/35339 (94%)]	Loss: 0.316057
Train Epoch: 19 [33920/35339 (96%)]	Loss: 0.344192
Train Epoch: 19 [34560/35339 (98%)]	Loss: 0.297333
Train Epoch: 19 [35200/35339 (99%)]	Loss: 0.386849

Validation set: Average loss: 1.9835, Accuracy: 2193/3870 (57%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 20 [0/35339 (0%)]	Loss: 0.395329
Train Epoch: 20 [640/35339 (2%)]	Loss: 0.444131
Train Epoch: 20 [1280/35339 (4%)]	Loss: 0.622770
Train Epoch: 20 [1920/35339 (5%)]	Loss: 0.424753
Train Epoch: 20 [2560/35339 (7%)]	Loss: 0.415793
Train Epoch: 20 [3200/35339 (9%)]	Loss: 0.572737
Train Epoch: 20 [3840/35339 (11%)]	Loss: 0.421184
Train Epoch: 20 [4480/35339 (13%)]	Loss: 0.525641
Train Epoch: 20 [5120/35339 (14%)]	Loss: 0.351379
Train Epoch: 20 [5760/35339 (16%)]	Loss: 0.485736
Train Epoch: 20 [6400/35339 (18%)]	Loss: 0.612245
Train Epoch: 20 [7040/35339 (20%)]	Loss: 0.346533
Train Epoch: 20 [7680/35339 (22%)]	Loss: 0.312387
Train Epoch: 20 [8320/35339 (24%)]	Loss: 0.379904
Train Epoch: 20 [8960/35339 (25%)]	Loss: 0.379087
Train Epoch: 20 [9600/35339 (27%)]	Loss: 0.633768
Train Epoch: 20 [10240/35339 (29%)]	Loss: 0.364498
Train Epoch: 20 [10880/35339 (31%)]	Loss: 0.377702
Train Epoch: 20 [11520/35339 (33%)]	Loss: 0.489545
Train Epoch: 20 [12160/35339 (34%)]	Loss: 0.469904
Train Epoch: 20 [12800/35339 (36%)]	Loss: 0.411443
Train Epoch: 20 [13440/35339 (38%)]	Loss: 0.497967
Train Epoch: 20 [14080/35339 (40%)]	Loss: 0.371765
Train Epoch: 20 [14720/35339 (42%)]	Loss: 0.390306
Train Epoch: 20 [15360/35339 (43%)]	Loss: 0.370081
Train Epoch: 20 [16000/35339 (45%)]	Loss: 0.353192
Train Epoch: 20 [16640/35339 (47%)]	Loss: 0.279244
Train Epoch: 20 [17280/35339 (49%)]	Loss: 0.555052
Train Epoch: 20 [17920/35339 (51%)]	Loss: 0.565927
Train Epoch: 20 [18560/35339 (52%)]	Loss: 0.403107
Train Epoch: 20 [19200/35339 (54%)]	Loss: 0.368129
Train Epoch: 20 [19840/35339 (56%)]	Loss: 0.339513
Train Epoch: 20 [20480/35339 (58%)]	Loss: 0.312257
Train Epoch: 20 [21120/35339 (60%)]	Loss: 0.370664
Train Epoch: 20 [21760/35339 (61%)]	Loss: 0.438207
Train Epoch: 20 [22400/35339 (63%)]	Loss: 0.542245
Train Epoch: 20 [23040/35339 (65%)]	Loss: 0.334847
Train Epoch: 20 [23680/35339 (67%)]	Loss: 0.318181
Train Epoch: 20 [24320/35339 (69%)]	Loss: 0.453964
Train Epoch: 20 [24960/35339 (71%)]	Loss: 0.414038
Train Epoch: 20 [25600/35339 (72%)]	Loss: 0.327969
Train Epoch: 20 [26240/35339 (74%)]	Loss: 0.403283
Train Epoch: 20 [26880/35339 (76%)]	Loss: 0.271202
Train Epoch: 20 [27520/35339 (78%)]	Loss: 0.396193
Train Epoch: 20 [28160/35339 (80%)]	Loss: 0.414723
Train Epoch: 20 [28800/35339 (81%)]	Loss: 0.456341
Train Epoch: 20 [29440/35339 (83%)]	Loss: 0.334677
Train Epoch: 20 [30080/35339 (85%)]	Loss: 0.521398
Train Epoch: 20 [30720/35339 (87%)]	Loss: 0.328434
Train Epoch: 20 [31360/35339 (89%)]	Loss: 0.311413
Train Epoch: 20 [32000/35339 (90%)]	Loss: 0.462016
Train Epoch: 20 [32640/35339 (92%)]	Loss: 0.487344
Train Epoch: 20 [33280/35339 (94%)]	Loss: 0.331566
Train Epoch: 20 [33920/35339 (96%)]	Loss: 0.216245
Train Epoch: 20 [34560/35339 (98%)]	Loss: 0.376252
Train Epoch: 20 [35200/35339 (99%)]	Loss: 0.302675

Validation set: Average loss: 1.8643, Accuracy: 2225/3870 (57%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 21 [0/35339 (0%)]	Loss: 0.655073
Train Epoch: 21 [640/35339 (2%)]	Loss: 0.267815
Train Epoch: 21 [1280/35339 (4%)]	Loss: 0.363910
Train Epoch: 21 [1920/35339 (5%)]	Loss: 0.396418
Train Epoch: 21 [2560/35339 (7%)]	Loss: 0.314211
Train Epoch: 21 [3200/35339 (9%)]	Loss: 0.358285
Train Epoch: 21 [3840/35339 (11%)]	Loss: 0.539072
Train Epoch: 21 [4480/35339 (13%)]	Loss: 0.439761
Train Epoch: 21 [5120/35339 (14%)]	Loss: 0.352583
Train Epoch: 21 [5760/35339 (16%)]	Loss: 0.370258
Train Epoch: 21 [6400/35339 (18%)]	Loss: 0.531738
Train Epoch: 21 [7040/35339 (20%)]	Loss: 0.455888
Train Epoch: 21 [7680/35339 (22%)]	Loss: 0.386301
Train Epoch: 21 [8320/35339 (24%)]	Loss: 0.433203
Train Epoch: 21 [8960/35339 (25%)]	Loss: 0.346503
Train Epoch: 21 [9600/35339 (27%)]	Loss: 0.287384
Train Epoch: 21 [10240/35339 (29%)]	Loss: 0.417259
Train Epoch: 21 [10880/35339 (31%)]	Loss: 0.459303
Train Epoch: 21 [11520/35339 (33%)]	Loss: 0.317643
Train Epoch: 21 [12160/35339 (34%)]	Loss: 0.379583
Train Epoch: 21 [12800/35339 (36%)]	Loss: 0.317337
Train Epoch: 21 [13440/35339 (38%)]	Loss: 0.471194
Train Epoch: 21 [14080/35339 (40%)]	Loss: 0.362022
Train Epoch: 21 [14720/35339 (42%)]	Loss: 0.284072
Train Epoch: 21 [15360/35339 (43%)]	Loss: 0.376847
Train Epoch: 21 [16000/35339 (45%)]	Loss: 0.360505
Train Epoch: 21 [16640/35339 (47%)]	Loss: 0.435403
Train Epoch: 21 [17280/35339 (49%)]	Loss: 0.285900
Train Epoch: 21 [17920/35339 (51%)]	Loss: 0.368429
Train Epoch: 21 [18560/35339 (52%)]	Loss: 0.385813
Train Epoch: 21 [19200/35339 (54%)]	Loss: 0.500490
Train Epoch: 21 [19840/35339 (56%)]	Loss: 0.261885
Train Epoch: 21 [20480/35339 (58%)]	Loss: 0.491591
Train Epoch: 21 [21120/35339 (60%)]	Loss: 0.281627
Train Epoch: 21 [21760/35339 (61%)]	Loss: 0.400660
Train Epoch: 21 [22400/35339 (63%)]	Loss: 0.268295
Train Epoch: 21 [23040/35339 (65%)]	Loss: 0.237163
Train Epoch: 21 [23680/35339 (67%)]	Loss: 0.360341
Train Epoch: 21 [24320/35339 (69%)]	Loss: 0.311911
Train Epoch: 21 [24960/35339 (71%)]	Loss: 0.333528
Train Epoch: 21 [25600/35339 (72%)]	Loss: 0.430044
Train Epoch: 21 [26240/35339 (74%)]	Loss: 0.576862
Train Epoch: 21 [26880/35339 (76%)]	Loss: 0.238832
Train Epoch: 21 [27520/35339 (78%)]	Loss: 0.416605
Train Epoch: 21 [28160/35339 (80%)]	Loss: 0.495942
Train Epoch: 21 [28800/35339 (81%)]	Loss: 0.387629
Train Epoch: 21 [29440/35339 (83%)]	Loss: 0.424664
Train Epoch: 21 [30080/35339 (85%)]	Loss: 0.188590
Train Epoch: 21 [30720/35339 (87%)]	Loss: 0.312824
Train Epoch: 21 [31360/35339 (89%)]	Loss: 0.385726
Train Epoch: 21 [32000/35339 (90%)]	Loss: 0.428862
Train Epoch: 21 [32640/35339 (92%)]	Loss: 0.374149
Train Epoch: 21 [33280/35339 (94%)]	Loss: 0.458487
Train Epoch: 21 [33920/35339 (96%)]	Loss: 0.396452
Train Epoch: 21 [34560/35339 (98%)]	Loss: 0.439630
Train Epoch: 21 [35200/35339 (99%)]	Loss: 0.485553

Validation set: Average loss: 1.8272, Accuracy: 2254/3870 (58%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 22 [0/35339 (0%)]	Loss: 0.372417
Train Epoch: 22 [640/35339 (2%)]	Loss: 0.488045
Train Epoch: 22 [1280/35339 (4%)]	Loss: 0.284868
Train Epoch: 22 [1920/35339 (5%)]	Loss: 0.280820
Train Epoch: 22 [2560/35339 (7%)]	Loss: 0.382695
Train Epoch: 22 [3200/35339 (9%)]	Loss: 0.362061
Train Epoch: 22 [3840/35339 (11%)]	Loss: 0.396037
Train Epoch: 22 [4480/35339 (13%)]	Loss: 0.422880
Train Epoch: 22 [5120/35339 (14%)]	Loss: 0.405442
Train Epoch: 22 [5760/35339 (16%)]	Loss: 0.417084
Train Epoch: 22 [6400/35339 (18%)]	Loss: 0.405475
Train Epoch: 22 [7040/35339 (20%)]	Loss: 0.388551
Train Epoch: 22 [7680/35339 (22%)]	Loss: 0.304983
Train Epoch: 22 [8320/35339 (24%)]	Loss: 0.249168
Train Epoch: 22 [8960/35339 (25%)]	Loss: 0.569710
Train Epoch: 22 [9600/35339 (27%)]	Loss: 0.388722
Train Epoch: 22 [10240/35339 (29%)]	Loss: 0.623729
Train Epoch: 22 [10880/35339 (31%)]	Loss: 0.496771
Train Epoch: 22 [11520/35339 (33%)]	Loss: 0.314677
Train Epoch: 22 [12160/35339 (34%)]	Loss: 0.217714
Train Epoch: 22 [12800/35339 (36%)]	Loss: 0.563445
Train Epoch: 22 [13440/35339 (38%)]	Loss: 0.294053
Train Epoch: 22 [14080/35339 (40%)]	Loss: 0.490869
Train Epoch: 22 [14720/35339 (42%)]	Loss: 0.459733
Train Epoch: 22 [15360/35339 (43%)]	Loss: 0.395390
Train Epoch: 22 [16000/35339 (45%)]	Loss: 0.284827
Train Epoch: 22 [16640/35339 (47%)]	Loss: 0.309371
Train Epoch: 22 [17280/35339 (49%)]	Loss: 0.320053
Train Epoch: 22 [17920/35339 (51%)]	Loss: 0.508541
Train Epoch: 22 [18560/35339 (52%)]	Loss: 0.464926
Train Epoch: 22 [19200/35339 (54%)]	Loss: 0.875494
Train Epoch: 22 [19840/35339 (56%)]	Loss: 0.498477
Train Epoch: 22 [20480/35339 (58%)]	Loss: 0.347881
Train Epoch: 22 [21120/35339 (60%)]	Loss: 0.296836
Train Epoch: 22 [21760/35339 (61%)]	Loss: 0.310372
Train Epoch: 22 [22400/35339 (63%)]	Loss: 0.201638
Train Epoch: 22 [23040/35339 (65%)]	Loss: 0.476010
Train Epoch: 22 [23680/35339 (67%)]	Loss: 0.261689
Train Epoch: 22 [24320/35339 (69%)]	Loss: 0.662508
Train Epoch: 22 [24960/35339 (71%)]	Loss: 0.340299
Train Epoch: 22 [25600/35339 (72%)]	Loss: 0.364349
Train Epoch: 22 [26240/35339 (74%)]	Loss: 0.470035
Train Epoch: 22 [26880/35339 (76%)]	Loss: 0.462869
Train Epoch: 22 [27520/35339 (78%)]	Loss: 0.273022
Train Epoch: 22 [28160/35339 (80%)]	Loss: 0.329190
Train Epoch: 22 [28800/35339 (81%)]	Loss: 0.498841
Train Epoch: 22 [29440/35339 (83%)]	Loss: 0.365316
Train Epoch: 22 [30080/35339 (85%)]	Loss: 0.394795
Train Epoch: 22 [30720/35339 (87%)]	Loss: 0.371289
Train Epoch: 22 [31360/35339 (89%)]	Loss: 0.338485
Train Epoch: 22 [32000/35339 (90%)]	Loss: 0.362656
Train Epoch: 22 [32640/35339 (92%)]	Loss: 0.439797
Train Epoch: 22 [33280/35339 (94%)]	Loss: 0.378111
Train Epoch: 22 [33920/35339 (96%)]	Loss: 0.354101
Train Epoch: 22 [34560/35339 (98%)]	Loss: 0.435697
Train Epoch: 22 [35200/35339 (99%)]	Loss: 0.557784

Validation set: Average loss: 1.8265, Accuracy: 2230/3870 (58%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 23 [0/35339 (0%)]	Loss: 0.491778
Train Epoch: 23 [640/35339 (2%)]	Loss: 0.414420
Train Epoch: 23 [1280/35339 (4%)]	Loss: 0.425644
Train Epoch: 23 [1920/35339 (5%)]	Loss: 0.302689
Train Epoch: 23 [2560/35339 (7%)]	Loss: 0.410841
Train Epoch: 23 [3200/35339 (9%)]	Loss: 0.374294
Train Epoch: 23 [3840/35339 (11%)]	Loss: 0.427983
Train Epoch: 23 [4480/35339 (13%)]	Loss: 0.297549
Train Epoch: 23 [5120/35339 (14%)]	Loss: 0.396480
Train Epoch: 23 [5760/35339 (16%)]	Loss: 0.454413
Train Epoch: 23 [6400/35339 (18%)]	Loss: 0.367081
Train Epoch: 23 [7040/35339 (20%)]	Loss: 0.412581
Train Epoch: 23 [7680/35339 (22%)]	Loss: 0.355247
Train Epoch: 23 [8320/35339 (24%)]	Loss: 0.499400
Train Epoch: 23 [8960/35339 (25%)]	Loss: 0.366039
Train Epoch: 23 [9600/35339 (27%)]	Loss: 0.314432
Train Epoch: 23 [10240/35339 (29%)]	Loss: 0.361811
Train Epoch: 23 [10880/35339 (31%)]	Loss: 0.577745
Train Epoch: 23 [11520/35339 (33%)]	Loss: 0.514660
Train Epoch: 23 [12160/35339 (34%)]	Loss: 0.387293
Train Epoch: 23 [12800/35339 (36%)]	Loss: 0.491000
Train Epoch: 23 [13440/35339 (38%)]	Loss: 0.934283
Train Epoch: 23 [14080/35339 (40%)]	Loss: 0.432998
Train Epoch: 23 [14720/35339 (42%)]	Loss: 0.365663
Train Epoch: 23 [15360/35339 (43%)]	Loss: 0.231597
Train Epoch: 23 [16000/35339 (45%)]	Loss: 0.358177
Train Epoch: 23 [16640/35339 (47%)]	Loss: 0.468605
Train Epoch: 23 [17280/35339 (49%)]	Loss: 0.411297
Train Epoch: 23 [17920/35339 (51%)]	Loss: 0.208266
Train Epoch: 23 [18560/35339 (52%)]	Loss: 0.593229
Train Epoch: 23 [19200/35339 (54%)]	Loss: 0.380688
Train Epoch: 23 [19840/35339 (56%)]	Loss: 0.294825
Train Epoch: 23 [20480/35339 (58%)]	Loss: 0.443551
Train Epoch: 23 [21120/35339 (60%)]	Loss: 0.305579
Train Epoch: 23 [21760/35339 (61%)]	Loss: 0.508363
Train Epoch: 23 [22400/35339 (63%)]	Loss: 0.356583
Train Epoch: 23 [23040/35339 (65%)]	Loss: 0.447184
Train Epoch: 23 [23680/35339 (67%)]	Loss: 0.398662
Train Epoch: 23 [24320/35339 (69%)]	Loss: 0.350037
Train Epoch: 23 [24960/35339 (71%)]	Loss: 0.446252
Train Epoch: 23 [25600/35339 (72%)]	Loss: 0.243636
Train Epoch: 23 [26240/35339 (74%)]	Loss: 0.287556
Train Epoch: 23 [26880/35339 (76%)]	Loss: 0.666141
Train Epoch: 23 [27520/35339 (78%)]	Loss: 0.335099
Train Epoch: 23 [28160/35339 (80%)]	Loss: 0.406200
Train Epoch: 23 [28800/35339 (81%)]	Loss: 0.458880
Train Epoch: 23 [29440/35339 (83%)]	Loss: 0.263470
Train Epoch: 23 [30080/35339 (85%)]	Loss: 0.654369
Train Epoch: 23 [30720/35339 (87%)]	Loss: 0.732694
Train Epoch: 23 [31360/35339 (89%)]	Loss: 0.339549
Train Epoch: 23 [32000/35339 (90%)]	Loss: 0.398271
Train Epoch: 23 [32640/35339 (92%)]	Loss: 0.428163
Train Epoch: 23 [33280/35339 (94%)]	Loss: 0.269577
Train Epoch: 23 [33920/35339 (96%)]	Loss: 0.476454
Train Epoch: 23 [34560/35339 (98%)]	Loss: 0.577877
Train Epoch: 23 [35200/35339 (99%)]	Loss: 0.312669

Validation set: Average loss: 1.7830, Accuracy: 2307/3870 (60%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 24 [0/35339 (0%)]	Loss: 0.413743
Train Epoch: 24 [640/35339 (2%)]	Loss: 0.374664
Train Epoch: 24 [1280/35339 (4%)]	Loss: 0.234465
Train Epoch: 24 [1920/35339 (5%)]	Loss: 0.438321
Train Epoch: 24 [2560/35339 (7%)]	Loss: 0.452941
Train Epoch: 24 [3200/35339 (9%)]	Loss: 0.381116
Train Epoch: 24 [3840/35339 (11%)]	Loss: 0.619705
Train Epoch: 24 [4480/35339 (13%)]	Loss: 0.503966
Train Epoch: 24 [5120/35339 (14%)]	Loss: 0.465179
Train Epoch: 24 [5760/35339 (16%)]	Loss: 0.361461
Train Epoch: 24 [6400/35339 (18%)]	Loss: 0.489873
Train Epoch: 24 [7040/35339 (20%)]	Loss: 0.290575
Train Epoch: 24 [7680/35339 (22%)]	Loss: 0.430511
Train Epoch: 24 [8320/35339 (24%)]	Loss: 0.412629
Train Epoch: 24 [8960/35339 (25%)]	Loss: 0.402810
Train Epoch: 24 [9600/35339 (27%)]	Loss: 0.470405
Train Epoch: 24 [10240/35339 (29%)]	Loss: 0.592239
Train Epoch: 24 [10880/35339 (31%)]	Loss: 0.190551
Train Epoch: 24 [11520/35339 (33%)]	Loss: 0.353087
Train Epoch: 24 [12160/35339 (34%)]	Loss: 0.220375
Train Epoch: 24 [12800/35339 (36%)]	Loss: 0.436961
Train Epoch: 24 [13440/35339 (38%)]	Loss: 0.718966
Train Epoch: 24 [14080/35339 (40%)]	Loss: 0.350924
Train Epoch: 24 [14720/35339 (42%)]	Loss: 0.351710
Train Epoch: 24 [15360/35339 (43%)]	Loss: 0.287924
Train Epoch: 24 [16000/35339 (45%)]	Loss: 0.409762
Train Epoch: 24 [16640/35339 (47%)]	Loss: 0.357707
Train Epoch: 24 [17280/35339 (49%)]	Loss: 0.382606
Train Epoch: 24 [17920/35339 (51%)]	Loss: 0.538986
Train Epoch: 24 [18560/35339 (52%)]	Loss: 0.286662
Train Epoch: 24 [19200/35339 (54%)]	Loss: 0.408432
Train Epoch: 24 [19840/35339 (56%)]	Loss: 0.392385
Train Epoch: 24 [20480/35339 (58%)]	Loss: 0.370023
Train Epoch: 24 [21120/35339 (60%)]	Loss: 0.364028
Train Epoch: 24 [21760/35339 (61%)]	Loss: 0.278423
Train Epoch: 24 [22400/35339 (63%)]	Loss: 0.537289
Train Epoch: 24 [23040/35339 (65%)]	Loss: 0.390625
Train Epoch: 24 [23680/35339 (67%)]	Loss: 0.461656
Train Epoch: 24 [24320/35339 (69%)]	Loss: 0.341454
Train Epoch: 24 [24960/35339 (71%)]	Loss: 0.563396
Train Epoch: 24 [25600/35339 (72%)]	Loss: 0.629170
Train Epoch: 24 [26240/35339 (74%)]	Loss: 0.305263
Train Epoch: 24 [26880/35339 (76%)]	Loss: 0.474333
Train Epoch: 24 [27520/35339 (78%)]	Loss: 0.282178
Train Epoch: 24 [28160/35339 (80%)]	Loss: 0.426219
Train Epoch: 24 [28800/35339 (81%)]	Loss: 0.484846
Train Epoch: 24 [29440/35339 (83%)]	Loss: 0.409279
Train Epoch: 24 [30080/35339 (85%)]	Loss: 0.283321
Train Epoch: 24 [30720/35339 (87%)]	Loss: 0.270728
Train Epoch: 24 [31360/35339 (89%)]	Loss: 0.403549
Train Epoch: 24 [32000/35339 (90%)]	Loss: 0.198639
Train Epoch: 24 [32640/35339 (92%)]	Loss: 0.341987
Train Epoch: 24 [33280/35339 (94%)]	Loss: 0.305748
Train Epoch: 24 [33920/35339 (96%)]	Loss: 0.292567
Train Epoch: 24 [34560/35339 (98%)]	Loss: 0.587398
Train Epoch: 24 [35200/35339 (99%)]	Loss: 0.304510

Validation set: Average loss: 1.8392, Accuracy: 2292/3870 (59%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 25 [0/35339 (0%)]	Loss: 0.335171
Train Epoch: 25 [640/35339 (2%)]	Loss: 0.250699
Train Epoch: 25 [1280/35339 (4%)]	Loss: 0.248718
Train Epoch: 25 [1920/35339 (5%)]	Loss: 0.402245
Train Epoch: 25 [2560/35339 (7%)]	Loss: 0.361046
Train Epoch: 25 [3200/35339 (9%)]	Loss: 0.474496
Train Epoch: 25 [3840/35339 (11%)]	Loss: 0.256666
Train Epoch: 25 [4480/35339 (13%)]	Loss: 0.345151
Train Epoch: 25 [5120/35339 (14%)]	Loss: 0.671554
Train Epoch: 25 [5760/35339 (16%)]	Loss: 0.483020
Train Epoch: 25 [6400/35339 (18%)]	Loss: 0.472659
Train Epoch: 25 [7040/35339 (20%)]	Loss: 0.330997
Train Epoch: 25 [7680/35339 (22%)]	Loss: 0.273111
Train Epoch: 25 [8320/35339 (24%)]	Loss: 0.363055
Train Epoch: 25 [8960/35339 (25%)]	Loss: 0.391288
Train Epoch: 25 [9600/35339 (27%)]	Loss: 0.286208
Train Epoch: 25 [10240/35339 (29%)]	Loss: 0.421920
Train Epoch: 25 [10880/35339 (31%)]	Loss: 0.258043
Train Epoch: 25 [11520/35339 (33%)]	Loss: 0.346755
Train Epoch: 25 [12160/35339 (34%)]	Loss: 0.379339
Train Epoch: 25 [12800/35339 (36%)]	Loss: 0.399302
Train Epoch: 25 [13440/35339 (38%)]	Loss: 0.600186
Train Epoch: 25 [14080/35339 (40%)]	Loss: 0.385748
Train Epoch: 25 [14720/35339 (42%)]	Loss: 0.336581
Train Epoch: 25 [15360/35339 (43%)]	Loss: 0.457179
Train Epoch: 25 [16000/35339 (45%)]	Loss: 0.471380
Train Epoch: 25 [16640/35339 (47%)]	Loss: 0.397613
Train Epoch: 25 [17280/35339 (49%)]	Loss: 0.483070
Train Epoch: 25 [17920/35339 (51%)]	Loss: 0.292783
Train Epoch: 25 [18560/35339 (52%)]	Loss: 0.392941
Train Epoch: 25 [19200/35339 (54%)]	Loss: 0.440605
Train Epoch: 25 [19840/35339 (56%)]	Loss: 0.552608
Train Epoch: 25 [20480/35339 (58%)]	Loss: 0.417548
Train Epoch: 25 [21120/35339 (60%)]	Loss: 0.580164
Train Epoch: 25 [21760/35339 (61%)]	Loss: 0.404134
Train Epoch: 25 [22400/35339 (63%)]	Loss: 0.218123
Train Epoch: 25 [23040/35339 (65%)]	Loss: 0.373295
Train Epoch: 25 [23680/35339 (67%)]	Loss: 0.191426
Train Epoch: 25 [24320/35339 (69%)]	Loss: 0.392809
Train Epoch: 25 [24960/35339 (71%)]	Loss: 0.371571
Train Epoch: 25 [25600/35339 (72%)]	Loss: 0.398283
Train Epoch: 25 [26240/35339 (74%)]	Loss: 0.372934
Train Epoch: 25 [26880/35339 (76%)]	Loss: 0.206881
Train Epoch: 25 [27520/35339 (78%)]	Loss: 0.236900
Train Epoch: 25 [28160/35339 (80%)]	Loss: 0.241061
Train Epoch: 25 [28800/35339 (81%)]	Loss: 0.259912
Train Epoch: 25 [29440/35339 (83%)]	Loss: 0.272823
Train Epoch: 25 [30080/35339 (85%)]	Loss: 0.169070
Train Epoch: 25 [30720/35339 (87%)]	Loss: 0.533883
Train Epoch: 25 [31360/35339 (89%)]	Loss: 0.516307
Train Epoch: 25 [32000/35339 (90%)]	Loss: 0.302979
Train Epoch: 25 [32640/35339 (92%)]	Loss: 0.333523
Train Epoch: 25 [33280/35339 (94%)]	Loss: 0.362251
Train Epoch: 25 [33920/35339 (96%)]	Loss: 0.445179
Train Epoch: 25 [34560/35339 (98%)]	Loss: 0.950945
Train Epoch: 25 [35200/35339 (99%)]	Loss: 0.357532

Validation set: Average loss: 1.8338, Accuracy: 2294/3870 (59%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 26 [0/35339 (0%)]	Loss: 0.374257
Train Epoch: 26 [640/35339 (2%)]	Loss: 0.262025
Train Epoch: 26 [1280/35339 (4%)]	Loss: 0.637158
Train Epoch: 26 [1920/35339 (5%)]	Loss: 0.308514
Train Epoch: 26 [2560/35339 (7%)]	Loss: 0.331602
Train Epoch: 26 [3200/35339 (9%)]	Loss: 0.334661
Train Epoch: 26 [3840/35339 (11%)]	Loss: 0.469566
Train Epoch: 26 [4480/35339 (13%)]	Loss: 0.397155
Train Epoch: 26 [5120/35339 (14%)]	Loss: 0.339901
Train Epoch: 26 [5760/35339 (16%)]	Loss: 0.572333
Train Epoch: 26 [6400/35339 (18%)]	Loss: 0.312407
Train Epoch: 26 [7040/35339 (20%)]	Loss: 0.349491
Train Epoch: 26 [7680/35339 (22%)]	Loss: 0.345515
Train Epoch: 26 [8320/35339 (24%)]	Loss: 0.321876
Train Epoch: 26 [8960/35339 (25%)]	Loss: 0.297431
Train Epoch: 26 [9600/35339 (27%)]	Loss: 0.346479
Train Epoch: 26 [10240/35339 (29%)]	Loss: 0.295851
Train Epoch: 26 [10880/35339 (31%)]	Loss: 0.345304
Train Epoch: 26 [11520/35339 (33%)]	Loss: 0.395232
Train Epoch: 26 [12160/35339 (34%)]	Loss: 0.426461
Train Epoch: 26 [12800/35339 (36%)]	Loss: 0.352671
Train Epoch: 26 [13440/35339 (38%)]	Loss: 0.398430
Train Epoch: 26 [14080/35339 (40%)]	Loss: 0.303097
Train Epoch: 26 [14720/35339 (42%)]	Loss: 0.611050
Train Epoch: 26 [15360/35339 (43%)]	Loss: 0.383038
Train Epoch: 26 [16000/35339 (45%)]	Loss: 0.260617
Train Epoch: 26 [16640/35339 (47%)]	Loss: 0.394734
Train Epoch: 26 [17280/35339 (49%)]	Loss: 0.618638
Train Epoch: 26 [17920/35339 (51%)]	Loss: 0.117705
Train Epoch: 26 [18560/35339 (52%)]	Loss: 0.392002
Train Epoch: 26 [19200/35339 (54%)]	Loss: 0.387311
Train Epoch: 26 [19840/35339 (56%)]	Loss: 0.401241
Train Epoch: 26 [20480/35339 (58%)]	Loss: 0.493667
Train Epoch: 26 [21120/35339 (60%)]	Loss: 0.416530
Train Epoch: 26 [21760/35339 (61%)]	Loss: 0.316716
Train Epoch: 26 [22400/35339 (63%)]	Loss: 0.318583
Train Epoch: 26 [23040/35339 (65%)]	Loss: 0.503012
Train Epoch: 26 [23680/35339 (67%)]	Loss: 0.247533
Train Epoch: 26 [24320/35339 (69%)]	Loss: 0.307481
Train Epoch: 26 [24960/35339 (71%)]	Loss: 0.245854
Train Epoch: 26 [25600/35339 (72%)]	Loss: 0.475284
Train Epoch: 26 [26240/35339 (74%)]	Loss: 0.321950
Train Epoch: 26 [26880/35339 (76%)]	Loss: 0.369211
Train Epoch: 26 [27520/35339 (78%)]	Loss: 0.264324
Train Epoch: 26 [28160/35339 (80%)]	Loss: 0.277201
Train Epoch: 26 [28800/35339 (81%)]	Loss: 0.523603
Train Epoch: 26 [29440/35339 (83%)]	Loss: 0.427939
Train Epoch: 26 [30080/35339 (85%)]	Loss: 0.393028
Train Epoch: 26 [30720/35339 (87%)]	Loss: 0.299223
Train Epoch: 26 [31360/35339 (89%)]	Loss: 0.423129
Train Epoch: 26 [32000/35339 (90%)]	Loss: 0.348013
Train Epoch: 26 [32640/35339 (92%)]	Loss: 0.506089
Train Epoch: 26 [33280/35339 (94%)]	Loss: 0.255712
Train Epoch: 26 [33920/35339 (96%)]	Loss: 0.226734
Train Epoch: 26 [34560/35339 (98%)]	Loss: 0.427555
Train Epoch: 26 [35200/35339 (99%)]	Loss: 0.237905

Validation set: Average loss: 1.8327, Accuracy: 2291/3870 (59%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 27 [0/35339 (0%)]	Loss: 0.329734
Train Epoch: 27 [640/35339 (2%)]	Loss: 0.326342
Train Epoch: 27 [1280/35339 (4%)]	Loss: 0.339438
Train Epoch: 27 [1920/35339 (5%)]	Loss: 0.543701
Train Epoch: 27 [2560/35339 (7%)]	Loss: 0.313333
Train Epoch: 27 [3200/35339 (9%)]	Loss: 0.349818
Train Epoch: 27 [3840/35339 (11%)]	Loss: 0.382317
Train Epoch: 27 [4480/35339 (13%)]	Loss: 0.250479
Train Epoch: 27 [5120/35339 (14%)]	Loss: 0.425343
Train Epoch: 27 [5760/35339 (16%)]	Loss: 0.348006
Train Epoch: 27 [6400/35339 (18%)]	Loss: 0.336134
Train Epoch: 27 [7040/35339 (20%)]	Loss: 0.372255
Train Epoch: 27 [7680/35339 (22%)]	Loss: 0.455094
Train Epoch: 27 [8320/35339 (24%)]	Loss: 0.326266
Train Epoch: 27 [8960/35339 (25%)]	Loss: 0.529437
Train Epoch: 27 [9600/35339 (27%)]	Loss: 0.425579
Train Epoch: 27 [10240/35339 (29%)]	Loss: 0.291432
Train Epoch: 27 [10880/35339 (31%)]	Loss: 0.271243
Train Epoch: 27 [11520/35339 (33%)]	Loss: 0.312022
Train Epoch: 27 [12160/35339 (34%)]	Loss: 0.422120
Train Epoch: 27 [12800/35339 (36%)]	Loss: 0.317562
Train Epoch: 27 [13440/35339 (38%)]	Loss: 0.330740
Train Epoch: 27 [14080/35339 (40%)]	Loss: 0.237192
Train Epoch: 27 [14720/35339 (42%)]	Loss: 0.210349
Train Epoch: 27 [15360/35339 (43%)]	Loss: 0.228591
Train Epoch: 27 [16000/35339 (45%)]	Loss: 0.357763
Train Epoch: 27 [16640/35339 (47%)]	Loss: 0.773584
Train Epoch: 27 [17280/35339 (49%)]	Loss: 0.628538
Train Epoch: 27 [17920/35339 (51%)]	Loss: 0.402936
Train Epoch: 27 [18560/35339 (52%)]	Loss: 0.473712
Train Epoch: 27 [19200/35339 (54%)]	Loss: 0.256937
Train Epoch: 27 [19840/35339 (56%)]	Loss: 0.524140
Train Epoch: 27 [20480/35339 (58%)]	Loss: 0.319300
Train Epoch: 27 [21120/35339 (60%)]	Loss: 0.473731
Train Epoch: 27 [21760/35339 (61%)]	Loss: 0.405549
Train Epoch: 27 [22400/35339 (63%)]	Loss: 0.234064
Train Epoch: 27 [23040/35339 (65%)]	Loss: 0.294782
Train Epoch: 27 [23680/35339 (67%)]	Loss: 0.281966
Train Epoch: 27 [24320/35339 (69%)]	Loss: 0.446138
Train Epoch: 27 [24960/35339 (71%)]	Loss: 0.380444
Train Epoch: 27 [25600/35339 (72%)]	Loss: 0.342488
Train Epoch: 27 [26240/35339 (74%)]	Loss: 0.365700
Train Epoch: 27 [26880/35339 (76%)]	Loss: 0.456979
Train Epoch: 27 [27520/35339 (78%)]	Loss: 0.259652
Train Epoch: 27 [28160/35339 (80%)]	Loss: 0.423971
Train Epoch: 27 [28800/35339 (81%)]	Loss: 0.416007
Train Epoch: 27 [29440/35339 (83%)]	Loss: 0.464817
Train Epoch: 27 [30080/35339 (85%)]	Loss: 0.322232
Train Epoch: 27 [30720/35339 (87%)]	Loss: 0.422886
Train Epoch: 27 [31360/35339 (89%)]	Loss: 0.242176
Train Epoch: 27 [32000/35339 (90%)]	Loss: 0.258336
Train Epoch: 27 [32640/35339 (92%)]	Loss: 0.304508
Train Epoch: 27 [33280/35339 (94%)]	Loss: 0.467850
Train Epoch: 27 [33920/35339 (96%)]	Loss: 0.212875
Train Epoch: 27 [34560/35339 (98%)]	Loss: 0.242220
Train Epoch: 27 [35200/35339 (99%)]	Loss: 0.281334

Validation set: Average loss: 1.7584, Accuracy: 2325/3870 (60%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 28 [0/35339 (0%)]	Loss: 0.403905
Train Epoch: 28 [640/35339 (2%)]	Loss: 0.272619
Train Epoch: 28 [1280/35339 (4%)]	Loss: 0.332027
Train Epoch: 28 [1920/35339 (5%)]	Loss: 0.334885
Train Epoch: 28 [2560/35339 (7%)]	Loss: 0.353022
Train Epoch: 28 [3200/35339 (9%)]	Loss: 0.250553
Train Epoch: 28 [3840/35339 (11%)]	Loss: 0.378408
Train Epoch: 28 [4480/35339 (13%)]	Loss: 0.334036
Train Epoch: 28 [5120/35339 (14%)]	Loss: 0.284233
Train Epoch: 28 [5760/35339 (16%)]	Loss: 0.454533
Train Epoch: 28 [6400/35339 (18%)]	Loss: 0.258317
Train Epoch: 28 [7040/35339 (20%)]	Loss: 0.465117
Train Epoch: 28 [7680/35339 (22%)]	Loss: 0.280783
Train Epoch: 28 [8320/35339 (24%)]	Loss: 0.420593
Train Epoch: 28 [8960/35339 (25%)]	Loss: 0.215414
Train Epoch: 28 [9600/35339 (27%)]	Loss: 0.415069
Train Epoch: 28 [10240/35339 (29%)]	Loss: 0.486983
Train Epoch: 28 [10880/35339 (31%)]	Loss: 0.342766
Train Epoch: 28 [11520/35339 (33%)]	Loss: 0.471708
Train Epoch: 28 [12160/35339 (34%)]	Loss: 0.412661
Train Epoch: 28 [12800/35339 (36%)]	Loss: 0.279290
Train Epoch: 28 [13440/35339 (38%)]	Loss: 0.291407
Train Epoch: 28 [14080/35339 (40%)]	Loss: 0.297448
Train Epoch: 28 [14720/35339 (42%)]	Loss: 0.280989
Train Epoch: 28 [15360/35339 (43%)]	Loss: 0.491199
Train Epoch: 28 [16000/35339 (45%)]	Loss: 0.483247
Train Epoch: 28 [16640/35339 (47%)]	Loss: 0.361229
Train Epoch: 28 [17280/35339 (49%)]	Loss: 0.382668
Train Epoch: 28 [17920/35339 (51%)]	Loss: 0.273237
Train Epoch: 28 [18560/35339 (52%)]	Loss: 0.403155
Train Epoch: 28 [19200/35339 (54%)]	Loss: 0.235275
Train Epoch: 28 [19840/35339 (56%)]	Loss: 0.493626
Train Epoch: 28 [20480/35339 (58%)]	Loss: 0.554103
Train Epoch: 28 [21120/35339 (60%)]	Loss: 0.315499
Train Epoch: 28 [21760/35339 (61%)]	Loss: 0.288120
Train Epoch: 28 [22400/35339 (63%)]	Loss: 0.631985
Train Epoch: 28 [23040/35339 (65%)]	Loss: 0.480064
Train Epoch: 28 [23680/35339 (67%)]	Loss: 0.559741
Train Epoch: 28 [24320/35339 (69%)]	Loss: 0.390500
Train Epoch: 28 [24960/35339 (71%)]	Loss: 0.298571
Train Epoch: 28 [25600/35339 (72%)]	Loss: 0.351238
Train Epoch: 28 [26240/35339 (74%)]	Loss: 0.752528
Train Epoch: 28 [26880/35339 (76%)]	Loss: 0.439609
Train Epoch: 28 [27520/35339 (78%)]	Loss: 0.259359
Train Epoch: 28 [28160/35339 (80%)]	Loss: 0.288422
Train Epoch: 28 [28800/35339 (81%)]	Loss: 0.434861
Train Epoch: 28 [29440/35339 (83%)]	Loss: 0.302321
Train Epoch: 28 [30080/35339 (85%)]	Loss: 0.229942
Train Epoch: 28 [30720/35339 (87%)]	Loss: 0.273839
Train Epoch: 28 [31360/35339 (89%)]	Loss: 0.429534
Train Epoch: 28 [32000/35339 (90%)]	Loss: 0.293245
Train Epoch: 28 [32640/35339 (92%)]	Loss: 0.291528
Train Epoch: 28 [33280/35339 (94%)]	Loss: 0.260443
Train Epoch: 28 [33920/35339 (96%)]	Loss: 0.634720
Train Epoch: 28 [34560/35339 (98%)]	Loss: 0.313871
Train Epoch: 28 [35200/35339 (99%)]	Loss: 0.361836

Validation set: Average loss: 1.8814, Accuracy: 2320/3870 (60%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 29 [0/35339 (0%)]	Loss: 0.575441
Train Epoch: 29 [640/35339 (2%)]	Loss: 0.291232
Train Epoch: 29 [1280/35339 (4%)]	Loss: 0.197672
Train Epoch: 29 [1920/35339 (5%)]	Loss: 0.337788
Train Epoch: 29 [2560/35339 (7%)]	Loss: 0.359227
Train Epoch: 29 [3200/35339 (9%)]	Loss: 0.418883
Train Epoch: 29 [3840/35339 (11%)]	Loss: 0.316199
Train Epoch: 29 [4480/35339 (13%)]	Loss: 0.330279
Train Epoch: 29 [5120/35339 (14%)]	Loss: 0.401442
Train Epoch: 29 [5760/35339 (16%)]	Loss: 0.186716
Train Epoch: 29 [6400/35339 (18%)]	Loss: 0.296688
Train Epoch: 29 [7040/35339 (20%)]	Loss: 0.339173
Train Epoch: 29 [7680/35339 (22%)]	Loss: 0.504992
Train Epoch: 29 [8320/35339 (24%)]	Loss: 0.395793
Train Epoch: 29 [8960/35339 (25%)]	Loss: 0.369256
Train Epoch: 29 [9600/35339 (27%)]	Loss: 0.393686
Train Epoch: 29 [10240/35339 (29%)]	Loss: 0.348553
Train Epoch: 29 [10880/35339 (31%)]	Loss: 0.335531
Train Epoch: 29 [11520/35339 (33%)]	Loss: 0.204441
Train Epoch: 29 [12160/35339 (34%)]	Loss: 0.299891
Train Epoch: 29 [12800/35339 (36%)]	Loss: 0.451912
Train Epoch: 29 [13440/35339 (38%)]	Loss: 0.381628
Train Epoch: 29 [14080/35339 (40%)]	Loss: 0.483651
Train Epoch: 29 [14720/35339 (42%)]	Loss: 0.274385
Train Epoch: 29 [15360/35339 (43%)]	Loss: 0.273168
Train Epoch: 29 [16000/35339 (45%)]	Loss: 0.439425
Train Epoch: 29 [16640/35339 (47%)]	Loss: 0.483501
Train Epoch: 29 [17280/35339 (49%)]	Loss: 0.514480
Train Epoch: 29 [17920/35339 (51%)]	Loss: 0.766595
Train Epoch: 29 [18560/35339 (52%)]	Loss: 0.404941
Train Epoch: 29 [19200/35339 (54%)]	Loss: 0.269448
Train Epoch: 29 [19840/35339 (56%)]	Loss: 0.356848
Train Epoch: 29 [20480/35339 (58%)]	Loss: 0.757719
Train Epoch: 29 [21120/35339 (60%)]	Loss: 0.395163
Train Epoch: 29 [21760/35339 (61%)]	Loss: 0.270416
Train Epoch: 29 [22400/35339 (63%)]	Loss: 0.499802
Train Epoch: 29 [23040/35339 (65%)]	Loss: 0.256083
Train Epoch: 29 [23680/35339 (67%)]	Loss: 0.364320
Train Epoch: 29 [24320/35339 (69%)]	Loss: 0.232861
Train Epoch: 29 [24960/35339 (71%)]	Loss: 0.292212
Train Epoch: 29 [25600/35339 (72%)]	Loss: 0.474979
Train Epoch: 29 [26240/35339 (74%)]	Loss: 0.403609
Train Epoch: 29 [26880/35339 (76%)]	Loss: 0.399244
Train Epoch: 29 [27520/35339 (78%)]	Loss: 0.412766
Train Epoch: 29 [28160/35339 (80%)]	Loss: 0.412347
Train Epoch: 29 [28800/35339 (81%)]	Loss: 0.225629
Train Epoch: 29 [29440/35339 (83%)]	Loss: 0.388954
Train Epoch: 29 [30080/35339 (85%)]	Loss: 0.262012
Train Epoch: 29 [30720/35339 (87%)]	Loss: 0.308154
Train Epoch: 29 [31360/35339 (89%)]	Loss: 0.264839
Train Epoch: 29 [32000/35339 (90%)]	Loss: 0.424775
Train Epoch: 29 [32640/35339 (92%)]	Loss: 0.209554
Train Epoch: 29 [33280/35339 (94%)]	Loss: 0.333640
Train Epoch: 29 [33920/35339 (96%)]	Loss: 0.329226
Train Epoch: 29 [34560/35339 (98%)]	Loss: 0.257260
Train Epoch: 29 [35200/35339 (99%)]	Loss: 0.244110

Validation set: Average loss: 1.7869, Accuracy: 2371/3870 (61%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 30 [0/35339 (0%)]	Loss: 0.298041
Train Epoch: 30 [640/35339 (2%)]	Loss: 0.271444
Train Epoch: 30 [1280/35339 (4%)]	Loss: 0.430160
Train Epoch: 30 [1920/35339 (5%)]	Loss: 0.304477
Train Epoch: 30 [2560/35339 (7%)]	Loss: 0.162524
Train Epoch: 30 [3200/35339 (9%)]	Loss: 0.287166
Train Epoch: 30 [3840/35339 (11%)]	Loss: 0.253331
Train Epoch: 30 [4480/35339 (13%)]	Loss: 0.270515
Train Epoch: 30 [5120/35339 (14%)]	Loss: 0.465038
Train Epoch: 30 [5760/35339 (16%)]	Loss: 0.233301
Train Epoch: 30 [6400/35339 (18%)]	Loss: 0.317692
Train Epoch: 30 [7040/35339 (20%)]	Loss: 0.295161
Train Epoch: 30 [7680/35339 (22%)]	Loss: 0.351611
Train Epoch: 30 [8320/35339 (24%)]	Loss: 0.330863
Train Epoch: 30 [8960/35339 (25%)]	Loss: 0.349269
Train Epoch: 30 [9600/35339 (27%)]	Loss: 0.217253
Train Epoch: 30 [10240/35339 (29%)]	Loss: 0.320837
Train Epoch: 30 [10880/35339 (31%)]	Loss: 0.460954
Train Epoch: 30 [11520/35339 (33%)]	Loss: 0.330720
Train Epoch: 30 [12160/35339 (34%)]	Loss: 0.341194
Train Epoch: 30 [12800/35339 (36%)]	Loss: 0.276985
Train Epoch: 30 [13440/35339 (38%)]	Loss: 0.531668
Train Epoch: 30 [14080/35339 (40%)]	Loss: 0.370640
Train Epoch: 30 [14720/35339 (42%)]	Loss: 0.946615
Train Epoch: 30 [15360/35339 (43%)]	Loss: 0.434525
Train Epoch: 30 [16000/35339 (45%)]	Loss: 0.367072
Train Epoch: 30 [16640/35339 (47%)]	Loss: 0.215054
Train Epoch: 30 [17280/35339 (49%)]	Loss: 0.555354
Train Epoch: 30 [17920/35339 (51%)]	Loss: 0.306747
Train Epoch: 30 [18560/35339 (52%)]	Loss: 0.357180
Train Epoch: 30 [19200/35339 (54%)]	Loss: 0.376579
Train Epoch: 30 [19840/35339 (56%)]	Loss: 0.441397
Train Epoch: 30 [20480/35339 (58%)]	Loss: 0.373565
Train Epoch: 30 [21120/35339 (60%)]	Loss: 0.169291
Train Epoch: 30 [21760/35339 (61%)]	Loss: 0.316453
Train Epoch: 30 [22400/35339 (63%)]	Loss: 0.293375
Train Epoch: 30 [23040/35339 (65%)]	Loss: 0.257558
Train Epoch: 30 [23680/35339 (67%)]	Loss: 0.320032
Train Epoch: 30 [24320/35339 (69%)]	Loss: 0.572066
Train Epoch: 30 [24960/35339 (71%)]	Loss: 0.327190
Train Epoch: 30 [25600/35339 (72%)]	Loss: 0.439773
Train Epoch: 30 [26240/35339 (74%)]	Loss: 0.279158
Train Epoch: 30 [26880/35339 (76%)]	Loss: 0.419670
Train Epoch: 30 [27520/35339 (78%)]	Loss: 0.397084
Train Epoch: 30 [28160/35339 (80%)]	Loss: 0.514383
Train Epoch: 30 [28800/35339 (81%)]	Loss: 0.321720
Train Epoch: 30 [29440/35339 (83%)]	Loss: 0.269606
Train Epoch: 30 [30080/35339 (85%)]	Loss: 0.342593
Train Epoch: 30 [30720/35339 (87%)]	Loss: 0.376477
Train Epoch: 30 [31360/35339 (89%)]	Loss: 0.344013
Train Epoch: 30 [32000/35339 (90%)]	Loss: 0.264949
Train Epoch: 30 [32640/35339 (92%)]	Loss: 0.307197
Train Epoch: 30 [33280/35339 (94%)]	Loss: 0.259544
Train Epoch: 30 [33920/35339 (96%)]	Loss: 0.255076
Train Epoch: 30 [34560/35339 (98%)]	Loss: 0.226439
Train Epoch: 30 [35200/35339 (99%)]	Loss: 0.208632

Validation set: Average loss: 1.8274, Accuracy: 2337/3870 (60%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 31 [0/35339 (0%)]	Loss: 0.748476
Train Epoch: 31 [640/35339 (2%)]	Loss: 0.301249
Train Epoch: 31 [1280/35339 (4%)]	Loss: 0.404636
Train Epoch: 31 [1920/35339 (5%)]	Loss: 0.503906
Train Epoch: 31 [2560/35339 (7%)]	Loss: 0.293567
Train Epoch: 31 [3200/35339 (9%)]	Loss: 0.463017
Train Epoch: 31 [3840/35339 (11%)]	Loss: 0.365448
Train Epoch: 31 [4480/35339 (13%)]	Loss: 0.500954
Train Epoch: 31 [5120/35339 (14%)]	Loss: 0.311365
Train Epoch: 31 [5760/35339 (16%)]	Loss: 0.250720
Train Epoch: 31 [6400/35339 (18%)]	Loss: 0.323542
Train Epoch: 31 [7040/35339 (20%)]	Loss: 0.264329
Train Epoch: 31 [7680/35339 (22%)]	Loss: 0.487596
Train Epoch: 31 [8320/35339 (24%)]	Loss: 0.218505
Train Epoch: 31 [8960/35339 (25%)]	Loss: 0.387516
Train Epoch: 31 [9600/35339 (27%)]	Loss: 0.236417
Train Epoch: 31 [10240/35339 (29%)]	Loss: 0.301010
Train Epoch: 31 [10880/35339 (31%)]	Loss: 0.510130
Train Epoch: 31 [11520/35339 (33%)]	Loss: 0.398743
Train Epoch: 31 [12160/35339 (34%)]	Loss: 0.371763
Train Epoch: 31 [12800/35339 (36%)]	Loss: 0.513031
Train Epoch: 31 [13440/35339 (38%)]	Loss: 0.297357
Train Epoch: 31 [14080/35339 (40%)]	Loss: 0.330373
Train Epoch: 31 [14720/35339 (42%)]	Loss: 0.247237
Train Epoch: 31 [15360/35339 (43%)]	Loss: 0.354033
Train Epoch: 31 [16000/35339 (45%)]	Loss: 0.232786
Train Epoch: 31 [16640/35339 (47%)]	Loss: 0.408212
Train Epoch: 31 [17280/35339 (49%)]	Loss: 0.639486
Train Epoch: 31 [17920/35339 (51%)]	Loss: 0.278076
Train Epoch: 31 [18560/35339 (52%)]	Loss: 0.142789
Train Epoch: 31 [19200/35339 (54%)]	Loss: 0.438075
Train Epoch: 31 [19840/35339 (56%)]	Loss: 0.240715
Train Epoch: 31 [20480/35339 (58%)]	Loss: 0.338872
Train Epoch: 31 [21120/35339 (60%)]	Loss: 0.342247
Train Epoch: 31 [21760/35339 (61%)]	Loss: 0.360748
Train Epoch: 31 [22400/35339 (63%)]	Loss: 0.310093
Train Epoch: 31 [23040/35339 (65%)]	Loss: 0.225020
Train Epoch: 31 [23680/35339 (67%)]	Loss: 0.279842
Train Epoch: 31 [24320/35339 (69%)]	Loss: 0.186664
Train Epoch: 31 [24960/35339 (71%)]	Loss: 0.312715
Train Epoch: 31 [25600/35339 (72%)]	Loss: 0.344556
Train Epoch: 31 [26240/35339 (74%)]	Loss: 0.734927
Train Epoch: 31 [26880/35339 (76%)]	Loss: 0.435653
Train Epoch: 31 [27520/35339 (78%)]	Loss: 0.424298
Train Epoch: 31 [28160/35339 (80%)]	Loss: 0.270418
Train Epoch: 31 [28800/35339 (81%)]	Loss: 0.202761
Train Epoch: 31 [29440/35339 (83%)]	Loss: 0.292100
Train Epoch: 31 [30080/35339 (85%)]	Loss: 0.202628
Train Epoch: 31 [30720/35339 (87%)]	Loss: 0.177870
Train Epoch: 31 [31360/35339 (89%)]	Loss: 0.583590
Train Epoch: 31 [32000/35339 (90%)]	Loss: 0.302388
Train Epoch: 31 [32640/35339 (92%)]	Loss: 0.384907
Train Epoch: 31 [33280/35339 (94%)]	Loss: 0.434591
Train Epoch: 31 [33920/35339 (96%)]	Loss: 0.260726
Train Epoch: 31 [34560/35339 (98%)]	Loss: 0.439692
Train Epoch: 31 [35200/35339 (99%)]	Loss: 0.314166

Validation set: Average loss: 1.7001, Accuracy: 2377/3870 (61%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 32 [0/35339 (0%)]	Loss: 0.399240
Train Epoch: 32 [640/35339 (2%)]	Loss: 0.464642
Train Epoch: 32 [1280/35339 (4%)]	Loss: 0.546097
Train Epoch: 32 [1920/35339 (5%)]	Loss: 0.363543
Train Epoch: 32 [2560/35339 (7%)]	Loss: 0.351898
Train Epoch: 32 [3200/35339 (9%)]	Loss: 0.256455
Train Epoch: 32 [3840/35339 (11%)]	Loss: 0.391830
Train Epoch: 32 [4480/35339 (13%)]	Loss: 0.280893
Train Epoch: 32 [5120/35339 (14%)]	Loss: 0.490877
Train Epoch: 32 [5760/35339 (16%)]	Loss: 0.338558
Train Epoch: 32 [6400/35339 (18%)]	Loss: 0.462674
Train Epoch: 32 [7040/35339 (20%)]	Loss: 0.287627
Train Epoch: 32 [7680/35339 (22%)]	Loss: 0.246983
Train Epoch: 32 [8320/35339 (24%)]	Loss: 0.362629
Train Epoch: 32 [8960/35339 (25%)]	Loss: 0.293547
Train Epoch: 32 [9600/35339 (27%)]	Loss: 0.189964
Train Epoch: 32 [10240/35339 (29%)]	Loss: 0.280710
Train Epoch: 32 [10880/35339 (31%)]	Loss: 0.166655
Train Epoch: 32 [11520/35339 (33%)]	Loss: 0.390762
Train Epoch: 32 [12160/35339 (34%)]	Loss: 0.272622
Train Epoch: 32 [12800/35339 (36%)]	Loss: 0.398831
Train Epoch: 32 [13440/35339 (38%)]	Loss: 0.303197
Train Epoch: 32 [14080/35339 (40%)]	Loss: 0.298587
Train Epoch: 32 [14720/35339 (42%)]	Loss: 0.388701
Train Epoch: 32 [15360/35339 (43%)]	Loss: 0.428835
Train Epoch: 32 [16000/35339 (45%)]	Loss: 0.444843
Train Epoch: 32 [16640/35339 (47%)]	Loss: 0.327295
Train Epoch: 32 [17280/35339 (49%)]	Loss: 0.268053
Train Epoch: 32 [17920/35339 (51%)]	Loss: 0.283841
Train Epoch: 32 [18560/35339 (52%)]	Loss: 0.450160
Train Epoch: 32 [19200/35339 (54%)]	Loss: 0.336893
Train Epoch: 32 [19840/35339 (56%)]	Loss: 0.367804
Train Epoch: 32 [20480/35339 (58%)]	Loss: 0.276966
Train Epoch: 32 [21120/35339 (60%)]	Loss: 0.307356
Train Epoch: 32 [21760/35339 (61%)]	Loss: 0.306036
Train Epoch: 32 [22400/35339 (63%)]	Loss: 0.395365
Train Epoch: 32 [23040/35339 (65%)]	Loss: 0.303128
Train Epoch: 32 [23680/35339 (67%)]	Loss: 0.202931
Train Epoch: 32 [24320/35339 (69%)]	Loss: 0.565365
Train Epoch: 32 [24960/35339 (71%)]	Loss: 0.399010
Train Epoch: 32 [25600/35339 (72%)]	Loss: 0.277962
Train Epoch: 32 [26240/35339 (74%)]	Loss: 0.319815
Train Epoch: 32 [26880/35339 (76%)]	Loss: 0.347991
Train Epoch: 32 [27520/35339 (78%)]	Loss: 0.185674
Train Epoch: 32 [28160/35339 (80%)]	Loss: 0.169966
Train Epoch: 32 [28800/35339 (81%)]	Loss: 0.292067
Train Epoch: 32 [29440/35339 (83%)]	Loss: 0.296210
Train Epoch: 32 [30080/35339 (85%)]	Loss: 0.293433
Train Epoch: 32 [30720/35339 (87%)]	Loss: 0.331349
Train Epoch: 32 [31360/35339 (89%)]	Loss: 0.344412
Train Epoch: 32 [32000/35339 (90%)]	Loss: 0.443009
Train Epoch: 32 [32640/35339 (92%)]	Loss: 0.288161
Train Epoch: 32 [33280/35339 (94%)]	Loss: 0.385291
Train Epoch: 32 [33920/35339 (96%)]	Loss: 0.328612
Train Epoch: 32 [34560/35339 (98%)]	Loss: 0.197009
Train Epoch: 32 [35200/35339 (99%)]	Loss: 0.393448

Validation set: Average loss: 1.7195, Accuracy: 2375/3870 (61%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 33 [0/35339 (0%)]	Loss: 0.365487
Train Epoch: 33 [640/35339 (2%)]	Loss: 0.344243
Train Epoch: 33 [1280/35339 (4%)]	Loss: 0.340242
Train Epoch: 33 [1920/35339 (5%)]	Loss: 0.239907
Train Epoch: 33 [2560/35339 (7%)]	Loss: 0.345703
Train Epoch: 33 [3200/35339 (9%)]	Loss: 0.400286
Train Epoch: 33 [3840/35339 (11%)]	Loss: 0.664768
Train Epoch: 33 [4480/35339 (13%)]	Loss: 0.367064
Train Epoch: 33 [5120/35339 (14%)]	Loss: 0.241431
Train Epoch: 33 [5760/35339 (16%)]	Loss: 0.423396
Train Epoch: 33 [6400/35339 (18%)]	Loss: 0.583727
Train Epoch: 33 [7040/35339 (20%)]	Loss: 0.307647
Train Epoch: 33 [7680/35339 (22%)]	Loss: 0.426680
Train Epoch: 33 [8320/35339 (24%)]	Loss: 0.278235
Train Epoch: 33 [8960/35339 (25%)]	Loss: 0.327947
Train Epoch: 33 [9600/35339 (27%)]	Loss: 0.312808
Train Epoch: 33 [10240/35339 (29%)]	Loss: 0.235214
Train Epoch: 33 [10880/35339 (31%)]	Loss: 0.427054
Train Epoch: 33 [11520/35339 (33%)]	Loss: 0.389590
Train Epoch: 33 [12160/35339 (34%)]	Loss: 0.560907
Train Epoch: 33 [12800/35339 (36%)]	Loss: 0.318249
Train Epoch: 33 [13440/35339 (38%)]	Loss: 0.406583
Train Epoch: 33 [14080/35339 (40%)]	Loss: 0.378616
Train Epoch: 33 [14720/35339 (42%)]	Loss: 0.529104
Train Epoch: 33 [15360/35339 (43%)]	Loss: 0.363358
Train Epoch: 33 [16000/35339 (45%)]	Loss: 0.326512
Train Epoch: 33 [16640/35339 (47%)]	Loss: 0.280505
Train Epoch: 33 [17280/35339 (49%)]	Loss: 0.323322
Train Epoch: 33 [17920/35339 (51%)]	Loss: 0.206169
Train Epoch: 33 [18560/35339 (52%)]	Loss: 0.378852
Train Epoch: 33 [19200/35339 (54%)]	Loss: 0.393988
Train Epoch: 33 [19840/35339 (56%)]	Loss: 0.326982
Train Epoch: 33 [20480/35339 (58%)]	Loss: 0.397600
Train Epoch: 33 [21120/35339 (60%)]	Loss: 0.312361
Train Epoch: 33 [21760/35339 (61%)]	Loss: 0.312032
Train Epoch: 33 [22400/35339 (63%)]	Loss: 0.399577
Train Epoch: 33 [23040/35339 (65%)]	Loss: 0.383379
Train Epoch: 33 [23680/35339 (67%)]	Loss: 0.300869
Train Epoch: 33 [24320/35339 (69%)]	Loss: 0.394063
Train Epoch: 33 [24960/35339 (71%)]	Loss: 0.412054
Train Epoch: 33 [25600/35339 (72%)]	Loss: 0.280522
Train Epoch: 33 [26240/35339 (74%)]	Loss: 0.411305
Train Epoch: 33 [26880/35339 (76%)]	Loss: 0.557318
Train Epoch: 33 [27520/35339 (78%)]	Loss: 0.484501
Train Epoch: 33 [28160/35339 (80%)]	Loss: 0.263221
Train Epoch: 33 [28800/35339 (81%)]	Loss: 0.346685
Train Epoch: 33 [29440/35339 (83%)]	Loss: 0.368141
Train Epoch: 33 [30080/35339 (85%)]	Loss: 0.394465
Train Epoch: 33 [30720/35339 (87%)]	Loss: 0.420574
Train Epoch: 33 [31360/35339 (89%)]	Loss: 0.403811
Train Epoch: 33 [32000/35339 (90%)]	Loss: 0.261692
Train Epoch: 33 [32640/35339 (92%)]	Loss: 0.374596
Train Epoch: 33 [33280/35339 (94%)]	Loss: 0.364123
Train Epoch: 33 [33920/35339 (96%)]	Loss: 0.314713
Train Epoch: 33 [34560/35339 (98%)]	Loss: 0.426202
Train Epoch: 33 [35200/35339 (99%)]	Loss: 0.553554

Validation set: Average loss: 1.7291, Accuracy: 2389/3870 (62%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 34 [0/35339 (0%)]	Loss: 0.302743
Train Epoch: 34 [640/35339 (2%)]	Loss: 0.508606
Train Epoch: 34 [1280/35339 (4%)]	Loss: 0.349385
Train Epoch: 34 [1920/35339 (5%)]	Loss: 0.248229
Train Epoch: 34 [2560/35339 (7%)]	Loss: 0.224315
Train Epoch: 34 [3200/35339 (9%)]	Loss: 0.423140
Train Epoch: 34 [3840/35339 (11%)]	Loss: 0.344105
Train Epoch: 34 [4480/35339 (13%)]	Loss: 0.404155
Train Epoch: 34 [5120/35339 (14%)]	Loss: 0.553941
Train Epoch: 34 [5760/35339 (16%)]	Loss: 0.324259
Train Epoch: 34 [6400/35339 (18%)]	Loss: 0.279817
Train Epoch: 34 [7040/35339 (20%)]	Loss: 0.423928
Train Epoch: 34 [7680/35339 (22%)]	Loss: 0.235121
Train Epoch: 34 [8320/35339 (24%)]	Loss: 0.202027
Train Epoch: 34 [8960/35339 (25%)]	Loss: 0.169699
Train Epoch: 34 [9600/35339 (27%)]	Loss: 0.324562
Train Epoch: 34 [10240/35339 (29%)]	Loss: 0.461480
Train Epoch: 34 [10880/35339 (31%)]	Loss: 0.247272
Train Epoch: 34 [11520/35339 (33%)]	Loss: 0.308754
Train Epoch: 34 [12160/35339 (34%)]	Loss: 0.379948
Train Epoch: 34 [12800/35339 (36%)]	Loss: 0.266144
Train Epoch: 34 [13440/35339 (38%)]	Loss: 0.464849
Train Epoch: 34 [14080/35339 (40%)]	Loss: 0.280825
Train Epoch: 34 [14720/35339 (42%)]	Loss: 0.247962
Train Epoch: 34 [15360/35339 (43%)]	Loss: 0.377199
Train Epoch: 34 [16000/35339 (45%)]	Loss: 0.320418
Train Epoch: 34 [16640/35339 (47%)]	Loss: 0.278287
Train Epoch: 34 [17280/35339 (49%)]	Loss: 0.283033
Train Epoch: 34 [17920/35339 (51%)]	Loss: 0.517004
Train Epoch: 34 [18560/35339 (52%)]	Loss: 0.339845
Train Epoch: 34 [19200/35339 (54%)]	Loss: 0.432380
Train Epoch: 34 [19840/35339 (56%)]	Loss: 0.218549
Train Epoch: 34 [20480/35339 (58%)]	Loss: 0.282000
Train Epoch: 34 [21120/35339 (60%)]	Loss: 0.324862
Train Epoch: 34 [21760/35339 (61%)]	Loss: 0.311689
Train Epoch: 34 [22400/35339 (63%)]	Loss: 0.320957
Train Epoch: 34 [23040/35339 (65%)]	Loss: 0.258853
Train Epoch: 34 [23680/35339 (67%)]	Loss: 0.219112
Train Epoch: 34 [24320/35339 (69%)]	Loss: 0.473918
Train Epoch: 34 [24960/35339 (71%)]	Loss: 0.238047
Train Epoch: 34 [25600/35339 (72%)]	Loss: 0.322247
Train Epoch: 34 [26240/35339 (74%)]	Loss: 0.281023
Train Epoch: 34 [26880/35339 (76%)]	Loss: 0.533554
Train Epoch: 34 [27520/35339 (78%)]	Loss: 0.328326
Train Epoch: 34 [28160/35339 (80%)]	Loss: 0.263945
Train Epoch: 34 [28800/35339 (81%)]	Loss: 0.326436
Train Epoch: 34 [29440/35339 (83%)]	Loss: 0.306365
Train Epoch: 34 [30080/35339 (85%)]	Loss: 0.291395
Train Epoch: 34 [30720/35339 (87%)]	Loss: 0.531111
Train Epoch: 34 [31360/35339 (89%)]	Loss: 0.263393
Train Epoch: 34 [32000/35339 (90%)]	Loss: 0.292592
Train Epoch: 34 [32640/35339 (92%)]	Loss: 0.393257
Train Epoch: 34 [33280/35339 (94%)]	Loss: 0.445803
Train Epoch: 34 [33920/35339 (96%)]	Loss: 0.430377
Train Epoch: 34 [34560/35339 (98%)]	Loss: 0.765601
Train Epoch: 34 [35200/35339 (99%)]	Loss: 0.413009

Validation set: Average loss: 1.7552, Accuracy: 2401/3870 (62%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 35 [0/35339 (0%)]	Loss: 0.343883
Train Epoch: 35 [640/35339 (2%)]	Loss: 0.318604
Train Epoch: 35 [1280/35339 (4%)]	Loss: 0.303442
Train Epoch: 35 [1920/35339 (5%)]	Loss: 0.511866
Train Epoch: 35 [2560/35339 (7%)]	Loss: 0.238843
Train Epoch: 35 [3200/35339 (9%)]	Loss: 0.433601
Train Epoch: 35 [3840/35339 (11%)]	Loss: 0.238051
Train Epoch: 35 [4480/35339 (13%)]	Loss: 0.396996
Train Epoch: 35 [5120/35339 (14%)]	Loss: 0.229566
Train Epoch: 35 [5760/35339 (16%)]	Loss: 0.188694
Train Epoch: 35 [6400/35339 (18%)]	Loss: 0.450865
Train Epoch: 35 [7040/35339 (20%)]	Loss: 0.445259
Train Epoch: 35 [7680/35339 (22%)]	Loss: 0.459023
Train Epoch: 35 [8320/35339 (24%)]	Loss: 0.278445
Train Epoch: 35 [8960/35339 (25%)]	Loss: 0.466761
Train Epoch: 35 [9600/35339 (27%)]	Loss: 0.379152
Train Epoch: 35 [10240/35339 (29%)]	Loss: 0.148653
Train Epoch: 35 [10880/35339 (31%)]	Loss: 0.189926
Train Epoch: 35 [11520/35339 (33%)]	Loss: 0.401477
Train Epoch: 35 [12160/35339 (34%)]	Loss: 0.345749
Train Epoch: 35 [12800/35339 (36%)]	Loss: 0.210094
Train Epoch: 35 [13440/35339 (38%)]	Loss: 0.333925
Train Epoch: 35 [14080/35339 (40%)]	Loss: 0.187778
Train Epoch: 35 [14720/35339 (42%)]	Loss: 0.334868
Train Epoch: 35 [15360/35339 (43%)]	Loss: 0.495578
Train Epoch: 35 [16000/35339 (45%)]	Loss: 0.271033
Train Epoch: 35 [16640/35339 (47%)]	Loss: 0.273218
Train Epoch: 35 [17280/35339 (49%)]	Loss: 0.301707
Train Epoch: 35 [17920/35339 (51%)]	Loss: 0.283302
Train Epoch: 35 [18560/35339 (52%)]	Loss: 0.227794
Train Epoch: 35 [19200/35339 (54%)]	Loss: 0.279755
Train Epoch: 35 [19840/35339 (56%)]	Loss: 0.266374
Train Epoch: 35 [20480/35339 (58%)]	Loss: 0.371838
Train Epoch: 35 [21120/35339 (60%)]	Loss: 0.368660
Train Epoch: 35 [21760/35339 (61%)]	Loss: 0.194462
Train Epoch: 35 [22400/35339 (63%)]	Loss: 0.190260
Train Epoch: 35 [23040/35339 (65%)]	Loss: 0.372530
Train Epoch: 35 [23680/35339 (67%)]	Loss: 0.143093
Train Epoch: 35 [24320/35339 (69%)]	Loss: 0.323732
Train Epoch: 35 [24960/35339 (71%)]	Loss: 0.232034
Train Epoch: 35 [25600/35339 (72%)]	Loss: 0.339771
Train Epoch: 35 [26240/35339 (74%)]	Loss: 0.236157
Train Epoch: 35 [26880/35339 (76%)]	Loss: 0.431415
Train Epoch: 35 [27520/35339 (78%)]	Loss: 0.331207
Train Epoch: 35 [28160/35339 (80%)]	Loss: 0.287272
Train Epoch: 35 [28800/35339 (81%)]	Loss: 0.323476
Train Epoch: 35 [29440/35339 (83%)]	Loss: 0.207260
Train Epoch: 35 [30080/35339 (85%)]	Loss: 0.277169
Train Epoch: 35 [30720/35339 (87%)]	Loss: 0.219363
Train Epoch: 35 [31360/35339 (89%)]	Loss: 0.432023
Train Epoch: 35 [32000/35339 (90%)]	Loss: 0.405693
Train Epoch: 35 [32640/35339 (92%)]	Loss: 0.237430
Train Epoch: 35 [33280/35339 (94%)]	Loss: 0.380572
Train Epoch: 35 [33920/35339 (96%)]	Loss: 0.261427
Train Epoch: 35 [34560/35339 (98%)]	Loss: 0.340122
Train Epoch: 35 [35200/35339 (99%)]	Loss: 0.550016

Validation set: Average loss: 1.7093, Accuracy: 2408/3870 (62%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 36 [0/35339 (0%)]	Loss: 0.328577
Train Epoch: 36 [640/35339 (2%)]	Loss: 0.241730
Train Epoch: 36 [1280/35339 (4%)]	Loss: 0.238217
Train Epoch: 36 [1920/35339 (5%)]	Loss: 0.236291
Train Epoch: 36 [2560/35339 (7%)]	Loss: 0.376253
Train Epoch: 36 [3200/35339 (9%)]	Loss: 0.302183
Train Epoch: 36 [3840/35339 (11%)]	Loss: 0.236081
Train Epoch: 36 [4480/35339 (13%)]	Loss: 0.292259
Train Epoch: 36 [5120/35339 (14%)]	Loss: 0.223987
Train Epoch: 36 [5760/35339 (16%)]	Loss: 0.405552
Train Epoch: 36 [6400/35339 (18%)]	Loss: 0.432318
Train Epoch: 36 [7040/35339 (20%)]	Loss: 0.352604
Train Epoch: 36 [7680/35339 (22%)]	Loss: 0.266140
Train Epoch: 36 [8320/35339 (24%)]	Loss: 0.466749
Train Epoch: 36 [8960/35339 (25%)]	Loss: 0.425772
Train Epoch: 36 [9600/35339 (27%)]	Loss: 0.336982
Train Epoch: 36 [10240/35339 (29%)]	Loss: 0.273863
Train Epoch: 36 [10880/35339 (31%)]	Loss: 0.344515
Train Epoch: 36 [11520/35339 (33%)]	Loss: 0.190753
Train Epoch: 36 [12160/35339 (34%)]	Loss: 0.353771
Train Epoch: 36 [12800/35339 (36%)]	Loss: 0.433786
Train Epoch: 36 [13440/35339 (38%)]	Loss: 0.235130
Train Epoch: 36 [14080/35339 (40%)]	Loss: 0.348392
Train Epoch: 36 [14720/35339 (42%)]	Loss: 0.306327
Train Epoch: 36 [15360/35339 (43%)]	Loss: 0.430268
Train Epoch: 36 [16000/35339 (45%)]	Loss: 0.441039
Train Epoch: 36 [16640/35339 (47%)]	Loss: 0.355598
Train Epoch: 36 [17280/35339 (49%)]	Loss: 0.410085
Train Epoch: 36 [17920/35339 (51%)]	Loss: 0.257692
Train Epoch: 36 [18560/35339 (52%)]	Loss: 0.225816
Train Epoch: 36 [19200/35339 (54%)]	Loss: 0.285840
Train Epoch: 36 [19840/35339 (56%)]	Loss: 0.408615
Train Epoch: 36 [20480/35339 (58%)]	Loss: 0.335401
Train Epoch: 36 [21120/35339 (60%)]	Loss: 0.288567
Train Epoch: 36 [21760/35339 (61%)]	Loss: 0.232669
Train Epoch: 36 [22400/35339 (63%)]	Loss: 0.488773
Train Epoch: 36 [23040/35339 (65%)]	Loss: 0.342070
Train Epoch: 36 [23680/35339 (67%)]	Loss: 0.349854
Train Epoch: 36 [24320/35339 (69%)]	Loss: 0.239308
Train Epoch: 36 [24960/35339 (71%)]	Loss: 0.382977
Train Epoch: 36 [25600/35339 (72%)]	Loss: 0.324196
Train Epoch: 36 [26240/35339 (74%)]	Loss: 0.351832
Train Epoch: 36 [26880/35339 (76%)]	Loss: 0.653668
Train Epoch: 36 [27520/35339 (78%)]	Loss: 0.279122
Train Epoch: 36 [28160/35339 (80%)]	Loss: 0.215768
Train Epoch: 36 [28800/35339 (81%)]	Loss: 0.377129
Train Epoch: 36 [29440/35339 (83%)]	Loss: 0.399007
Train Epoch: 36 [30080/35339 (85%)]	Loss: 0.373666
Train Epoch: 36 [30720/35339 (87%)]	Loss: 0.324274
Train Epoch: 36 [31360/35339 (89%)]	Loss: 0.395929
Train Epoch: 36 [32000/35339 (90%)]	Loss: 0.347434
Train Epoch: 36 [32640/35339 (92%)]	Loss: 0.312760
Train Epoch: 36 [33280/35339 (94%)]	Loss: 0.248543
Train Epoch: 36 [33920/35339 (96%)]	Loss: 0.321316
Train Epoch: 36 [34560/35339 (98%)]	Loss: 0.419769
Train Epoch: 36 [35200/35339 (99%)]	Loss: 0.175786

Validation set: Average loss: 1.7062, Accuracy: 2451/3870 (63%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 37 [0/35339 (0%)]	Loss: 0.345640
Train Epoch: 37 [640/35339 (2%)]	Loss: 0.313564
Train Epoch: 37 [1280/35339 (4%)]	Loss: 0.484439
Train Epoch: 37 [1920/35339 (5%)]	Loss: 0.275402
Train Epoch: 37 [2560/35339 (7%)]	Loss: 0.300103
Train Epoch: 37 [3200/35339 (9%)]	Loss: 0.292785
Train Epoch: 37 [3840/35339 (11%)]	Loss: 0.404494
Train Epoch: 37 [4480/35339 (13%)]	Loss: 0.423308
Train Epoch: 37 [5120/35339 (14%)]	Loss: 0.196030
Train Epoch: 37 [5760/35339 (16%)]	Loss: 0.212584
Train Epoch: 37 [6400/35339 (18%)]	Loss: 0.357040
Train Epoch: 37 [7040/35339 (20%)]	Loss: 0.389373
Train Epoch: 37 [7680/35339 (22%)]	Loss: 0.302590
Train Epoch: 37 [8320/35339 (24%)]	Loss: 0.384140
Train Epoch: 37 [8960/35339 (25%)]	Loss: 0.169330
Train Epoch: 37 [9600/35339 (27%)]	Loss: 0.264164
Train Epoch: 37 [10240/35339 (29%)]	Loss: 0.346487
Train Epoch: 37 [10880/35339 (31%)]	Loss: 0.401040
Train Epoch: 37 [11520/35339 (33%)]	Loss: 0.620115
Train Epoch: 37 [12160/35339 (34%)]	Loss: 0.343378
Train Epoch: 37 [12800/35339 (36%)]	Loss: 0.353607
Train Epoch: 37 [13440/35339 (38%)]	Loss: 0.606478
Train Epoch: 37 [14080/35339 (40%)]	Loss: 0.201966
Train Epoch: 37 [14720/35339 (42%)]	Loss: 0.352200
Train Epoch: 37 [15360/35339 (43%)]	Loss: 0.427359
Train Epoch: 37 [16000/35339 (45%)]	Loss: 0.490991
Train Epoch: 37 [16640/35339 (47%)]	Loss: 0.327726
Train Epoch: 37 [17280/35339 (49%)]	Loss: 0.593291
Train Epoch: 37 [17920/35339 (51%)]	Loss: 0.280723
Train Epoch: 37 [18560/35339 (52%)]	Loss: 0.317136
Train Epoch: 37 [19200/35339 (54%)]	Loss: 0.330510
Train Epoch: 37 [19840/35339 (56%)]	Loss: 0.338918
Train Epoch: 37 [20480/35339 (58%)]	Loss: 0.291956
Train Epoch: 37 [21120/35339 (60%)]	Loss: 0.317164
Train Epoch: 37 [21760/35339 (61%)]	Loss: 0.433208
Train Epoch: 37 [22400/35339 (63%)]	Loss: 0.397306
Train Epoch: 37 [23040/35339 (65%)]	Loss: 0.283657
Train Epoch: 37 [23680/35339 (67%)]	Loss: 0.356605
Train Epoch: 37 [24320/35339 (69%)]	Loss: 0.507416
Train Epoch: 37 [24960/35339 (71%)]	Loss: 0.417919
Train Epoch: 37 [25600/35339 (72%)]	Loss: 0.338273
Train Epoch: 37 [26240/35339 (74%)]	Loss: 0.402575
Train Epoch: 37 [26880/35339 (76%)]	Loss: 0.330674
Train Epoch: 37 [27520/35339 (78%)]	Loss: 0.495442
Train Epoch: 37 [28160/35339 (80%)]	Loss: 0.357313
Train Epoch: 37 [28800/35339 (81%)]	Loss: 0.260692
Train Epoch: 37 [29440/35339 (83%)]	Loss: 0.547561
Train Epoch: 37 [30080/35339 (85%)]	Loss: 0.448220
Train Epoch: 37 [30720/35339 (87%)]	Loss: 0.311950
Train Epoch: 37 [31360/35339 (89%)]	Loss: 0.308462
Train Epoch: 37 [32000/35339 (90%)]	Loss: 0.476790
Train Epoch: 37 [32640/35339 (92%)]	Loss: 0.346639
Train Epoch: 37 [33280/35339 (94%)]	Loss: 0.343597
Train Epoch: 37 [33920/35339 (96%)]	Loss: 0.162017
Train Epoch: 37 [34560/35339 (98%)]	Loss: 0.394407
Train Epoch: 37 [35200/35339 (99%)]	Loss: 0.283489

Validation set: Average loss: 1.7629, Accuracy: 2399/3870 (62%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 38 [0/35339 (0%)]	Loss: 0.404452
Train Epoch: 38 [640/35339 (2%)]	Loss: 0.278170
Train Epoch: 38 [1280/35339 (4%)]	Loss: 0.470385
Train Epoch: 38 [1920/35339 (5%)]	Loss: 0.131416
Train Epoch: 38 [2560/35339 (7%)]	Loss: 0.237204
Train Epoch: 38 [3200/35339 (9%)]	Loss: 0.217726
Train Epoch: 38 [3840/35339 (11%)]	Loss: 0.236924
Train Epoch: 38 [4480/35339 (13%)]	Loss: 0.352248
Train Epoch: 38 [5120/35339 (14%)]	Loss: 0.258727
Train Epoch: 38 [5760/35339 (16%)]	Loss: 0.298375
Train Epoch: 38 [6400/35339 (18%)]	Loss: 0.268387
Train Epoch: 38 [7040/35339 (20%)]	Loss: 0.301351
Train Epoch: 38 [7680/35339 (22%)]	Loss: 0.194774
Train Epoch: 38 [8320/35339 (24%)]	Loss: 0.320458
Train Epoch: 38 [8960/35339 (25%)]	Loss: 0.412834
Train Epoch: 38 [9600/35339 (27%)]	Loss: 0.415185
Train Epoch: 38 [10240/35339 (29%)]	Loss: 0.396557
Train Epoch: 38 [10880/35339 (31%)]	Loss: 0.303426
Train Epoch: 38 [11520/35339 (33%)]	Loss: 0.301796
Train Epoch: 38 [12160/35339 (34%)]	Loss: 0.413603
Train Epoch: 38 [12800/35339 (36%)]	Loss: 0.261158
Train Epoch: 38 [13440/35339 (38%)]	Loss: 0.337316
Train Epoch: 38 [14080/35339 (40%)]	Loss: 0.606041
Train Epoch: 38 [14720/35339 (42%)]	Loss: 0.521372
Train Epoch: 38 [15360/35339 (43%)]	Loss: 0.330456
Train Epoch: 38 [16000/35339 (45%)]	Loss: 0.253589
Train Epoch: 38 [16640/35339 (47%)]	Loss: 0.478255
Train Epoch: 38 [17280/35339 (49%)]	Loss: 0.160605
Train Epoch: 38 [17920/35339 (51%)]	Loss: 0.416053
Train Epoch: 38 [18560/35339 (52%)]	Loss: 0.408025
Train Epoch: 38 [19200/35339 (54%)]	Loss: 0.169763
Train Epoch: 38 [19840/35339 (56%)]	Loss: 0.227380
Train Epoch: 38 [20480/35339 (58%)]	Loss: 0.257422
Train Epoch: 38 [21120/35339 (60%)]	Loss: 0.323039
Train Epoch: 38 [21760/35339 (61%)]	Loss: 0.140355
Train Epoch: 38 [22400/35339 (63%)]	Loss: 0.435225
Train Epoch: 38 [23040/35339 (65%)]	Loss: 0.306294
Train Epoch: 38 [23680/35339 (67%)]	Loss: 0.443625
Train Epoch: 38 [24320/35339 (69%)]	Loss: 0.332822
Train Epoch: 38 [24960/35339 (71%)]	Loss: 0.372461
Train Epoch: 38 [25600/35339 (72%)]	Loss: 0.300436
Train Epoch: 38 [26240/35339 (74%)]	Loss: 0.359328
Train Epoch: 38 [26880/35339 (76%)]	Loss: 0.277280
Train Epoch: 38 [27520/35339 (78%)]	Loss: 0.404609
Train Epoch: 38 [28160/35339 (80%)]	Loss: 0.327691
Train Epoch: 38 [28800/35339 (81%)]	Loss: 0.242191
Train Epoch: 38 [29440/35339 (83%)]	Loss: 0.294757
Train Epoch: 38 [30080/35339 (85%)]	Loss: 0.468594
Train Epoch: 38 [30720/35339 (87%)]	Loss: 0.257781
Train Epoch: 38 [31360/35339 (89%)]	Loss: 0.458031
Train Epoch: 38 [32000/35339 (90%)]	Loss: 0.325613
Train Epoch: 38 [32640/35339 (92%)]	Loss: 0.243183
Train Epoch: 38 [33280/35339 (94%)]	Loss: 0.193576
Train Epoch: 38 [33920/35339 (96%)]	Loss: 0.379835
Train Epoch: 38 [34560/35339 (98%)]	Loss: 0.230618
Train Epoch: 38 [35200/35339 (99%)]	Loss: 0.211630

Validation set: Average loss: 1.7210, Accuracy: 2427/3870 (63%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 39 [0/35339 (0%)]	Loss: 0.345889
Train Epoch: 39 [640/35339 (2%)]	Loss: 0.340595
Train Epoch: 39 [1280/35339 (4%)]	Loss: 0.395491
Train Epoch: 39 [1920/35339 (5%)]	Loss: 0.484489
Train Epoch: 39 [2560/35339 (7%)]	Loss: 0.200333
Train Epoch: 39 [3200/35339 (9%)]	Loss: 0.186028
Train Epoch: 39 [3840/35339 (11%)]	Loss: 0.447858
Train Epoch: 39 [4480/35339 (13%)]	Loss: 0.137113
Train Epoch: 39 [5120/35339 (14%)]	Loss: 0.412006
Train Epoch: 39 [5760/35339 (16%)]	Loss: 0.267741
Train Epoch: 39 [6400/35339 (18%)]	Loss: 0.487793
Train Epoch: 39 [7040/35339 (20%)]	Loss: 0.492829
Train Epoch: 39 [7680/35339 (22%)]	Loss: 0.366104
Train Epoch: 39 [8320/35339 (24%)]	Loss: 0.351736
Train Epoch: 39 [8960/35339 (25%)]	Loss: 0.147896
Train Epoch: 39 [9600/35339 (27%)]	Loss: 0.525656
Train Epoch: 39 [10240/35339 (29%)]	Loss: 0.398709
Train Epoch: 39 [10880/35339 (31%)]	Loss: 0.200166
Train Epoch: 39 [11520/35339 (33%)]	Loss: 0.379657
Train Epoch: 39 [12160/35339 (34%)]	Loss: 0.246297
Train Epoch: 39 [12800/35339 (36%)]	Loss: 0.355575
Train Epoch: 39 [13440/35339 (38%)]	Loss: 0.292727
Train Epoch: 39 [14080/35339 (40%)]	Loss: 0.401040
Train Epoch: 39 [14720/35339 (42%)]	Loss: 0.264890
Train Epoch: 39 [15360/35339 (43%)]	Loss: 0.310563
Train Epoch: 39 [16000/35339 (45%)]	Loss: 0.264646
Train Epoch: 39 [16640/35339 (47%)]	Loss: 0.179245
Train Epoch: 39 [17280/35339 (49%)]	Loss: 0.257227
Train Epoch: 39 [17920/35339 (51%)]	Loss: 0.508790
Train Epoch: 39 [18560/35339 (52%)]	Loss: 0.276251
Train Epoch: 39 [19200/35339 (54%)]	Loss: 0.344730
Train Epoch: 39 [19840/35339 (56%)]	Loss: 0.298676
Train Epoch: 39 [20480/35339 (58%)]	Loss: 0.259803
Train Epoch: 39 [21120/35339 (60%)]	Loss: 0.347864
Train Epoch: 39 [21760/35339 (61%)]	Loss: 0.326550
Train Epoch: 39 [22400/35339 (63%)]	Loss: 0.384245
Train Epoch: 39 [23040/35339 (65%)]	Loss: 0.415621
Train Epoch: 39 [23680/35339 (67%)]	Loss: 0.364822
Train Epoch: 39 [24320/35339 (69%)]	Loss: 0.304174
Train Epoch: 39 [24960/35339 (71%)]	Loss: 0.257511
Train Epoch: 39 [25600/35339 (72%)]	Loss: 0.198615
Train Epoch: 39 [26240/35339 (74%)]	Loss: 0.441859
Train Epoch: 39 [26880/35339 (76%)]	Loss: 0.377387
Train Epoch: 39 [27520/35339 (78%)]	Loss: 0.453547
Train Epoch: 39 [28160/35339 (80%)]	Loss: 0.361962
Train Epoch: 39 [28800/35339 (81%)]	Loss: 0.269220
Train Epoch: 39 [29440/35339 (83%)]	Loss: 0.270034
Train Epoch: 39 [30080/35339 (85%)]	Loss: 0.445849
Train Epoch: 39 [30720/35339 (87%)]	Loss: 0.222430
Train Epoch: 39 [31360/35339 (89%)]	Loss: 0.171429
Train Epoch: 39 [32000/35339 (90%)]	Loss: 0.248743
Train Epoch: 39 [32640/35339 (92%)]	Loss: 0.240107
Train Epoch: 39 [33280/35339 (94%)]	Loss: 0.313945
Train Epoch: 39 [33920/35339 (96%)]	Loss: 0.240496
Train Epoch: 39 [34560/35339 (98%)]	Loss: 0.322758
Train Epoch: 39 [35200/35339 (99%)]	Loss: 0.445536

Validation set: Average loss: 1.6354, Accuracy: 2437/3870 (63%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 40 [0/35339 (0%)]	Loss: 0.500260
Train Epoch: 40 [640/35339 (2%)]	Loss: 0.316875
Train Epoch: 40 [1280/35339 (4%)]	Loss: 0.238160
Train Epoch: 40 [1920/35339 (5%)]	Loss: 0.330154
Train Epoch: 40 [2560/35339 (7%)]	Loss: 0.396077
Train Epoch: 40 [3200/35339 (9%)]	Loss: 0.402271
Train Epoch: 40 [3840/35339 (11%)]	Loss: 0.368308
Train Epoch: 40 [4480/35339 (13%)]	Loss: 0.261955
Train Epoch: 40 [5120/35339 (14%)]	Loss: 0.206136
Train Epoch: 40 [5760/35339 (16%)]	Loss: 0.365891
Train Epoch: 40 [6400/35339 (18%)]	Loss: 0.281985
Train Epoch: 40 [7040/35339 (20%)]	Loss: 0.299233
Train Epoch: 40 [7680/35339 (22%)]	Loss: 0.163770
Train Epoch: 40 [8320/35339 (24%)]	Loss: 0.210284
Train Epoch: 40 [8960/35339 (25%)]	Loss: 0.397261
Train Epoch: 40 [9600/35339 (27%)]	Loss: 0.339705
Train Epoch: 40 [10240/35339 (29%)]	Loss: 0.199487
Train Epoch: 40 [10880/35339 (31%)]	Loss: 0.822144
Train Epoch: 40 [11520/35339 (33%)]	Loss: 0.379518
Train Epoch: 40 [12160/35339 (34%)]	Loss: 0.388156
Train Epoch: 40 [12800/35339 (36%)]	Loss: 0.312645
Train Epoch: 40 [13440/35339 (38%)]	Loss: 0.364185
Train Epoch: 40 [14080/35339 (40%)]	Loss: 0.879884
Train Epoch: 40 [14720/35339 (42%)]	Loss: 0.496962
Train Epoch: 40 [15360/35339 (43%)]	Loss: 0.341609
Train Epoch: 40 [16000/35339 (45%)]	Loss: 0.262467
Train Epoch: 40 [16640/35339 (47%)]	Loss: 0.245626
Train Epoch: 40 [17280/35339 (49%)]	Loss: 0.231159
Train Epoch: 40 [17920/35339 (51%)]	Loss: 0.321086
Train Epoch: 40 [18560/35339 (52%)]	Loss: 0.298218
Train Epoch: 40 [19200/35339 (54%)]	Loss: 0.337214
Train Epoch: 40 [19840/35339 (56%)]	Loss: 0.221745
Train Epoch: 40 [20480/35339 (58%)]	Loss: 0.277509
Train Epoch: 40 [21120/35339 (60%)]	Loss: 0.330898
Train Epoch: 40 [21760/35339 (61%)]	Loss: 0.253485
Train Epoch: 40 [22400/35339 (63%)]	Loss: 0.264773
Train Epoch: 40 [23040/35339 (65%)]	Loss: 0.323284
Train Epoch: 40 [23680/35339 (67%)]	Loss: 0.258584
Train Epoch: 40 [24320/35339 (69%)]	Loss: 0.280603
Train Epoch: 40 [24960/35339 (71%)]	Loss: 0.274260
Train Epoch: 40 [25600/35339 (72%)]	Loss: 0.407132
Train Epoch: 40 [26240/35339 (74%)]	Loss: 0.191107
Train Epoch: 40 [26880/35339 (76%)]	Loss: 0.289925
Train Epoch: 40 [27520/35339 (78%)]	Loss: 0.434384
Train Epoch: 40 [28160/35339 (80%)]	Loss: 0.504040
Train Epoch: 40 [28800/35339 (81%)]	Loss: 0.410016
Train Epoch: 40 [29440/35339 (83%)]	Loss: 0.289070
Train Epoch: 40 [30080/35339 (85%)]	Loss: 0.430658
Train Epoch: 40 [30720/35339 (87%)]	Loss: 0.382743
Train Epoch: 40 [31360/35339 (89%)]	Loss: 0.275144
Train Epoch: 40 [32000/35339 (90%)]	Loss: 0.465170
Train Epoch: 40 [32640/35339 (92%)]	Loss: 0.171565
Train Epoch: 40 [33280/35339 (94%)]	Loss: 0.448292
Train Epoch: 40 [33920/35339 (96%)]	Loss: 0.178536
Train Epoch: 40 [34560/35339 (98%)]	Loss: 0.238868
Train Epoch: 40 [35200/35339 (99%)]	Loss: 0.228745

Validation set: Average loss: 1.6805, Accuracy: 2445/3870 (63%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 41 [0/35339 (0%)]	Loss: 0.386935
Train Epoch: 41 [640/35339 (2%)]	Loss: 0.374003
Train Epoch: 41 [1280/35339 (4%)]	Loss: 0.174144
Train Epoch: 41 [1920/35339 (5%)]	Loss: 0.181715
Train Epoch: 41 [2560/35339 (7%)]	Loss: 0.372698
Train Epoch: 41 [3200/35339 (9%)]	Loss: 0.245067
Train Epoch: 41 [3840/35339 (11%)]	Loss: 0.298298
Train Epoch: 41 [4480/35339 (13%)]	Loss: 0.194632
Train Epoch: 41 [5120/35339 (14%)]	Loss: 0.237958
Train Epoch: 41 [5760/35339 (16%)]	Loss: 0.258659
Train Epoch: 41 [6400/35339 (18%)]	Loss: 0.453534
Train Epoch: 41 [7040/35339 (20%)]	Loss: 0.205806
Train Epoch: 41 [7680/35339 (22%)]	Loss: 0.315508
Train Epoch: 41 [8320/35339 (24%)]	Loss: 0.374368
Train Epoch: 41 [8960/35339 (25%)]	Loss: 0.239970
Train Epoch: 41 [9600/35339 (27%)]	Loss: 0.307834
Train Epoch: 41 [10240/35339 (29%)]	Loss: 0.313868
Train Epoch: 41 [10880/35339 (31%)]	Loss: 0.395343
Train Epoch: 41 [11520/35339 (33%)]	Loss: 0.147299
Train Epoch: 41 [12160/35339 (34%)]	Loss: 0.318950
Train Epoch: 41 [12800/35339 (36%)]	Loss: 0.390268
Train Epoch: 41 [13440/35339 (38%)]	Loss: 0.348024
Train Epoch: 41 [14080/35339 (40%)]	Loss: 0.376305
Train Epoch: 41 [14720/35339 (42%)]	Loss: 0.349910
Train Epoch: 41 [15360/35339 (43%)]	Loss: 0.322125
Train Epoch: 41 [16000/35339 (45%)]	Loss: 0.290645
Train Epoch: 41 [16640/35339 (47%)]	Loss: 0.258683
Train Epoch: 41 [17280/35339 (49%)]	Loss: 0.358581
Train Epoch: 41 [17920/35339 (51%)]	Loss: 0.440430
Train Epoch: 41 [18560/35339 (52%)]	Loss: 0.338276
Train Epoch: 41 [19200/35339 (54%)]	Loss: 0.330444
Train Epoch: 41 [19840/35339 (56%)]	Loss: 0.359201
Train Epoch: 41 [20480/35339 (58%)]	Loss: 0.156801
Train Epoch: 41 [21120/35339 (60%)]	Loss: 0.324606
Train Epoch: 41 [21760/35339 (61%)]	Loss: 0.411867
Train Epoch: 41 [22400/35339 (63%)]	Loss: 0.380910
Train Epoch: 41 [23040/35339 (65%)]	Loss: 0.563248
Train Epoch: 41 [23680/35339 (67%)]	Loss: 0.320242
Train Epoch: 41 [24320/35339 (69%)]	Loss: 0.212644
Train Epoch: 41 [24960/35339 (71%)]	Loss: 0.419525
Train Epoch: 41 [25600/35339 (72%)]	Loss: 0.374513
Train Epoch: 41 [26240/35339 (74%)]	Loss: 0.315770
Train Epoch: 41 [26880/35339 (76%)]	Loss: 0.294740
Train Epoch: 41 [27520/35339 (78%)]	Loss: 0.378020
Train Epoch: 41 [28160/35339 (80%)]	Loss: 0.207734
Train Epoch: 41 [28800/35339 (81%)]	Loss: 0.199185
Train Epoch: 41 [29440/35339 (83%)]	Loss: 0.168506
Train Epoch: 41 [30080/35339 (85%)]	Loss: 0.435519
Train Epoch: 41 [30720/35339 (87%)]	Loss: 0.213745
Train Epoch: 41 [31360/35339 (89%)]	Loss: 0.419495
Train Epoch: 41 [32000/35339 (90%)]	Loss: 0.255178
Train Epoch: 41 [32640/35339 (92%)]	Loss: 0.380143
Train Epoch: 41 [33280/35339 (94%)]	Loss: 0.498151
Train Epoch: 41 [33920/35339 (96%)]	Loss: 0.420464
Train Epoch: 41 [34560/35339 (98%)]	Loss: 0.368304
Train Epoch: 41 [35200/35339 (99%)]	Loss: 0.347069

Validation set: Average loss: 1.6360, Accuracy: 2447/3870 (63%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 42 [0/35339 (0%)]	Loss: 0.517162
Train Epoch: 42 [640/35339 (2%)]	Loss: 0.175316
Train Epoch: 42 [1280/35339 (4%)]	Loss: 0.296895
Train Epoch: 42 [1920/35339 (5%)]	Loss: 0.274949
Train Epoch: 42 [2560/35339 (7%)]	Loss: 0.649199
Train Epoch: 42 [3200/35339 (9%)]	Loss: 0.286890
Train Epoch: 42 [3840/35339 (11%)]	Loss: 0.317134
Train Epoch: 42 [4480/35339 (13%)]	Loss: 0.251825
Train Epoch: 42 [5120/35339 (14%)]	Loss: 0.203287
Train Epoch: 42 [5760/35339 (16%)]	Loss: 0.312591
Train Epoch: 42 [6400/35339 (18%)]	Loss: 0.700510
Train Epoch: 42 [7040/35339 (20%)]	Loss: 0.323047
Train Epoch: 42 [7680/35339 (22%)]	Loss: 0.550911
Train Epoch: 42 [8320/35339 (24%)]	Loss: 0.215980
Train Epoch: 42 [8960/35339 (25%)]	Loss: 0.456644
Train Epoch: 42 [9600/35339 (27%)]	Loss: 0.355773
Train Epoch: 42 [10240/35339 (29%)]	Loss: 0.291078
Train Epoch: 42 [10880/35339 (31%)]	Loss: 0.469972
Train Epoch: 42 [11520/35339 (33%)]	Loss: 0.475190
Train Epoch: 42 [12160/35339 (34%)]	Loss: 0.479069
Train Epoch: 42 [12800/35339 (36%)]	Loss: 0.287213
Train Epoch: 42 [13440/35339 (38%)]	Loss: 0.229575
Train Epoch: 42 [14080/35339 (40%)]	Loss: 0.305401
Train Epoch: 42 [14720/35339 (42%)]	Loss: 0.586305
Train Epoch: 42 [15360/35339 (43%)]	Loss: 0.299581
Train Epoch: 42 [16000/35339 (45%)]	Loss: 0.193407
Train Epoch: 42 [16640/35339 (47%)]	Loss: 0.300923
Train Epoch: 42 [17280/35339 (49%)]	Loss: 0.255404
Train Epoch: 42 [17920/35339 (51%)]	Loss: 0.382880
Train Epoch: 42 [18560/35339 (52%)]	Loss: 0.248741
Train Epoch: 42 [19200/35339 (54%)]	Loss: 0.331853
Train Epoch: 42 [19840/35339 (56%)]	Loss: 0.311688
Train Epoch: 42 [20480/35339 (58%)]	Loss: 0.334871
Train Epoch: 42 [21120/35339 (60%)]	Loss: 0.304769
Train Epoch: 42 [21760/35339 (61%)]	Loss: 0.438664
Train Epoch: 42 [22400/35339 (63%)]	Loss: 0.549226
Train Epoch: 42 [23040/35339 (65%)]	Loss: 0.229448
Train Epoch: 42 [23680/35339 (67%)]	Loss: 0.195777
Train Epoch: 42 [24320/35339 (69%)]	Loss: 0.503727
Train Epoch: 42 [24960/35339 (71%)]	Loss: 0.305380
Train Epoch: 42 [25600/35339 (72%)]	Loss: 0.290783
Train Epoch: 42 [26240/35339 (74%)]	Loss: 0.252868
Train Epoch: 42 [26880/35339 (76%)]	Loss: 0.281194
Train Epoch: 42 [27520/35339 (78%)]	Loss: 0.305922
Train Epoch: 42 [28160/35339 (80%)]	Loss: 0.159862
Train Epoch: 42 [28800/35339 (81%)]	Loss: 0.211567
Train Epoch: 42 [29440/35339 (83%)]	Loss: 0.368974
Train Epoch: 42 [30080/35339 (85%)]	Loss: 0.224856
Train Epoch: 42 [30720/35339 (87%)]	Loss: 0.390320
Train Epoch: 42 [31360/35339 (89%)]	Loss: 0.238499
Train Epoch: 42 [32000/35339 (90%)]	Loss: 0.181868
Train Epoch: 42 [32640/35339 (92%)]	Loss: 0.285040
Train Epoch: 42 [33280/35339 (94%)]	Loss: 0.308177
Train Epoch: 42 [33920/35339 (96%)]	Loss: 0.269987
Train Epoch: 42 [34560/35339 (98%)]	Loss: 0.347310
Train Epoch: 42 [35200/35339 (99%)]	Loss: 0.332961

Validation set: Average loss: 1.6204, Accuracy: 2478/3870 (64%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 43 [0/35339 (0%)]	Loss: 0.380737
Train Epoch: 43 [640/35339 (2%)]	Loss: 0.268885
Train Epoch: 43 [1280/35339 (4%)]	Loss: 0.358588
Train Epoch: 43 [1920/35339 (5%)]	Loss: 0.257751
Train Epoch: 43 [2560/35339 (7%)]	Loss: 0.367874
Train Epoch: 43 [3200/35339 (9%)]	Loss: 0.453192
Train Epoch: 43 [3840/35339 (11%)]	Loss: 0.292040
Train Epoch: 43 [4480/35339 (13%)]	Loss: 0.409648
Train Epoch: 43 [5120/35339 (14%)]	Loss: 0.281581
Train Epoch: 43 [5760/35339 (16%)]	Loss: 0.372953
Train Epoch: 43 [6400/35339 (18%)]	Loss: 0.614823
Train Epoch: 43 [7040/35339 (20%)]	Loss: 0.276619
Train Epoch: 43 [7680/35339 (22%)]	Loss: 0.431223
Train Epoch: 43 [8320/35339 (24%)]	Loss: 0.390081
Train Epoch: 43 [8960/35339 (25%)]	Loss: 0.226488
Train Epoch: 43 [9600/35339 (27%)]	Loss: 0.261128
Train Epoch: 43 [10240/35339 (29%)]	Loss: 0.499823
Train Epoch: 43 [10880/35339 (31%)]	Loss: 0.303243
Train Epoch: 43 [11520/35339 (33%)]	Loss: 0.199269
Train Epoch: 43 [12160/35339 (34%)]	Loss: 0.363422
Train Epoch: 43 [12800/35339 (36%)]	Loss: 0.225905
Train Epoch: 43 [13440/35339 (38%)]	Loss: 0.262441
Train Epoch: 43 [14080/35339 (40%)]	Loss: 0.319119
Train Epoch: 43 [14720/35339 (42%)]	Loss: 0.344799
Train Epoch: 43 [15360/35339 (43%)]	Loss: 0.180853
Train Epoch: 43 [16000/35339 (45%)]	Loss: 0.152658
Train Epoch: 43 [16640/35339 (47%)]	Loss: 0.492954
Train Epoch: 43 [17280/35339 (49%)]	Loss: 0.361392
Train Epoch: 43 [17920/35339 (51%)]	Loss: 0.271064
Train Epoch: 43 [18560/35339 (52%)]	Loss: 0.268688
Train Epoch: 43 [19200/35339 (54%)]	Loss: 0.305277
Train Epoch: 43 [19840/35339 (56%)]	Loss: 0.214326
Train Epoch: 43 [20480/35339 (58%)]	Loss: 0.203581
Train Epoch: 43 [21120/35339 (60%)]	Loss: 0.243217
Train Epoch: 43 [21760/35339 (61%)]	Loss: 0.294119
Train Epoch: 43 [22400/35339 (63%)]	Loss: 0.359893
Train Epoch: 43 [23040/35339 (65%)]	Loss: 0.281392
Train Epoch: 43 [23680/35339 (67%)]	Loss: 0.299826
Train Epoch: 43 [24320/35339 (69%)]	Loss: 0.259506
Train Epoch: 43 [24960/35339 (71%)]	Loss: 0.184361
Train Epoch: 43 [25600/35339 (72%)]	Loss: 0.356883
Train Epoch: 43 [26240/35339 (74%)]	Loss: 0.320345
Train Epoch: 43 [26880/35339 (76%)]	Loss: 0.273875
Train Epoch: 43 [27520/35339 (78%)]	Loss: 0.271993
Train Epoch: 43 [28160/35339 (80%)]	Loss: 0.302828
Train Epoch: 43 [28800/35339 (81%)]	Loss: 0.247559
Train Epoch: 43 [29440/35339 (83%)]	Loss: 0.299568
Train Epoch: 43 [30080/35339 (85%)]	Loss: 0.408784
Train Epoch: 43 [30720/35339 (87%)]	Loss: 0.155110
Train Epoch: 43 [31360/35339 (89%)]	Loss: 0.460859
Train Epoch: 43 [32000/35339 (90%)]	Loss: 0.270436
Train Epoch: 43 [32640/35339 (92%)]	Loss: 0.386669
Train Epoch: 43 [33280/35339 (94%)]	Loss: 0.272938
Train Epoch: 43 [33920/35339 (96%)]	Loss: 0.340675
Train Epoch: 43 [34560/35339 (98%)]	Loss: 0.255898
Train Epoch: 43 [35200/35339 (99%)]	Loss: 0.278383

Validation set: Average loss: 1.6362, Accuracy: 2478/3870 (64%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 44 [0/35339 (0%)]	Loss: 0.276477
Train Epoch: 44 [640/35339 (2%)]	Loss: 0.363427
Train Epoch: 44 [1280/35339 (4%)]	Loss: 0.293492
Train Epoch: 44 [1920/35339 (5%)]	Loss: 0.208959
Train Epoch: 44 [2560/35339 (7%)]	Loss: 0.202453
Train Epoch: 44 [3200/35339 (9%)]	Loss: 0.200999
Train Epoch: 44 [3840/35339 (11%)]	Loss: 0.380618
Train Epoch: 44 [4480/35339 (13%)]	Loss: 0.293450
Train Epoch: 44 [5120/35339 (14%)]	Loss: 0.303729
Train Epoch: 44 [5760/35339 (16%)]	Loss: 0.168722
Train Epoch: 44 [6400/35339 (18%)]	Loss: 0.447790
Train Epoch: 44 [7040/35339 (20%)]	Loss: 0.331254
Train Epoch: 44 [7680/35339 (22%)]	Loss: 0.447882
Train Epoch: 44 [8320/35339 (24%)]	Loss: 0.240411
Train Epoch: 44 [8960/35339 (25%)]	Loss: 0.329795
Train Epoch: 44 [9600/35339 (27%)]	Loss: 0.359638
Train Epoch: 44 [10240/35339 (29%)]	Loss: 0.231108
Train Epoch: 44 [10880/35339 (31%)]	Loss: 0.293878
Train Epoch: 44 [11520/35339 (33%)]	Loss: 0.294827
Train Epoch: 44 [12160/35339 (34%)]	Loss: 0.215907
Train Epoch: 44 [12800/35339 (36%)]	Loss: 0.323457
Train Epoch: 44 [13440/35339 (38%)]	Loss: 0.188139
Train Epoch: 44 [14080/35339 (40%)]	Loss: 0.215001
Train Epoch: 44 [14720/35339 (42%)]	Loss: 0.388849
Train Epoch: 44 [15360/35339 (43%)]	Loss: 0.339472
Train Epoch: 44 [16000/35339 (45%)]	Loss: 0.417607
Train Epoch: 44 [16640/35339 (47%)]	Loss: 0.186191
Train Epoch: 44 [17280/35339 (49%)]	Loss: 0.330602
Train Epoch: 44 [17920/35339 (51%)]	Loss: 0.521339
Train Epoch: 44 [18560/35339 (52%)]	Loss: 0.323472
Train Epoch: 44 [19200/35339 (54%)]	Loss: 0.289009
Train Epoch: 44 [19840/35339 (56%)]	Loss: 0.391980
Train Epoch: 44 [20480/35339 (58%)]	Loss: 0.279870
Train Epoch: 44 [21120/35339 (60%)]	Loss: 0.193231
Train Epoch: 44 [21760/35339 (61%)]	Loss: 0.352331
Train Epoch: 44 [22400/35339 (63%)]	Loss: 0.195584
Train Epoch: 44 [23040/35339 (65%)]	Loss: 0.245543
Train Epoch: 44 [23680/35339 (67%)]	Loss: 0.154887
Train Epoch: 44 [24320/35339 (69%)]	Loss: 0.447951
Train Epoch: 44 [24960/35339 (71%)]	Loss: 0.295076
Train Epoch: 44 [25600/35339 (72%)]	Loss: 0.407609
Train Epoch: 44 [26240/35339 (74%)]	Loss: 0.283138
Train Epoch: 44 [26880/35339 (76%)]	Loss: 0.498732
Train Epoch: 44 [27520/35339 (78%)]	Loss: 0.395246
Train Epoch: 44 [28160/35339 (80%)]	Loss: 0.272770
Train Epoch: 44 [28800/35339 (81%)]	Loss: 0.324938
Train Epoch: 44 [29440/35339 (83%)]	Loss: 0.237482
Train Epoch: 44 [30080/35339 (85%)]	Loss: 0.281408
Train Epoch: 44 [30720/35339 (87%)]	Loss: 0.326553
Train Epoch: 44 [31360/35339 (89%)]	Loss: 0.328507
Train Epoch: 44 [32000/35339 (90%)]	Loss: 0.388881
Train Epoch: 44 [32640/35339 (92%)]	Loss: 0.247846
Train Epoch: 44 [33280/35339 (94%)]	Loss: 0.299225
Train Epoch: 44 [33920/35339 (96%)]	Loss: 0.562604
Train Epoch: 44 [34560/35339 (98%)]	Loss: 0.183767
Train Epoch: 44 [35200/35339 (99%)]	Loss: 0.329790

Validation set: Average loss: 1.7185, Accuracy: 2450/3870 (63%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 45 [0/35339 (0%)]	Loss: 0.355157
Train Epoch: 45 [640/35339 (2%)]	Loss: 0.244070
Train Epoch: 45 [1280/35339 (4%)]	Loss: 0.393571
Train Epoch: 45 [1920/35339 (5%)]	Loss: 0.356667
Train Epoch: 45 [2560/35339 (7%)]	Loss: 0.174609
Train Epoch: 45 [3200/35339 (9%)]	Loss: 0.347300
Train Epoch: 45 [3840/35339 (11%)]	Loss: 0.570329
Train Epoch: 45 [4480/35339 (13%)]	Loss: 0.261363
Train Epoch: 45 [5120/35339 (14%)]	Loss: 0.316711
Train Epoch: 45 [5760/35339 (16%)]	Loss: 0.226690
Train Epoch: 45 [6400/35339 (18%)]	Loss: 0.221592
Train Epoch: 45 [7040/35339 (20%)]	Loss: 0.214785
Train Epoch: 45 [7680/35339 (22%)]	Loss: 0.327776
Train Epoch: 45 [8320/35339 (24%)]	Loss: 0.261090
Train Epoch: 45 [8960/35339 (25%)]	Loss: 0.372950
Train Epoch: 45 [9600/35339 (27%)]	Loss: 0.421710
Train Epoch: 45 [10240/35339 (29%)]	Loss: 0.246359
Train Epoch: 45 [10880/35339 (31%)]	Loss: 0.222935
Train Epoch: 45 [11520/35339 (33%)]	Loss: 0.323831
Train Epoch: 45 [12160/35339 (34%)]	Loss: 0.188210
Train Epoch: 45 [12800/35339 (36%)]	Loss: 0.249880
Train Epoch: 45 [13440/35339 (38%)]	Loss: 0.302531
Train Epoch: 45 [14080/35339 (40%)]	Loss: 0.294739
Train Epoch: 45 [14720/35339 (42%)]	Loss: 0.357322
Train Epoch: 45 [15360/35339 (43%)]	Loss: 0.313089
Train Epoch: 45 [16000/35339 (45%)]	Loss: 0.314682
Train Epoch: 45 [16640/35339 (47%)]	Loss: 0.189748
Train Epoch: 45 [17280/35339 (49%)]	Loss: 0.195640
Train Epoch: 45 [17920/35339 (51%)]	Loss: 0.325143
Train Epoch: 45 [18560/35339 (52%)]	Loss: 0.176814
Train Epoch: 45 [19200/35339 (54%)]	Loss: 0.183646
Train Epoch: 45 [19840/35339 (56%)]	Loss: 0.286480
Train Epoch: 45 [20480/35339 (58%)]	Loss: 0.419616
Train Epoch: 45 [21120/35339 (60%)]	Loss: 0.392825
Train Epoch: 45 [21760/35339 (61%)]	Loss: 0.191553
Train Epoch: 45 [22400/35339 (63%)]	Loss: 0.266884
Train Epoch: 45 [23040/35339 (65%)]	Loss: 0.284723
Train Epoch: 45 [23680/35339 (67%)]	Loss: 0.496305
Train Epoch: 45 [24320/35339 (69%)]	Loss: 0.244909
Train Epoch: 45 [24960/35339 (71%)]	Loss: 0.405342
Train Epoch: 45 [25600/35339 (72%)]	Loss: 0.262821
Train Epoch: 45 [26240/35339 (74%)]	Loss: 0.384976
Train Epoch: 45 [26880/35339 (76%)]	Loss: 0.312394
Train Epoch: 45 [27520/35339 (78%)]	Loss: 0.297869
Train Epoch: 45 [28160/35339 (80%)]	Loss: 0.607912
Train Epoch: 45 [28800/35339 (81%)]	Loss: 0.301898
Train Epoch: 45 [29440/35339 (83%)]	Loss: 0.165391
Train Epoch: 45 [30080/35339 (85%)]	Loss: 0.566938
Train Epoch: 45 [30720/35339 (87%)]	Loss: 0.216097
Train Epoch: 45 [31360/35339 (89%)]	Loss: 0.425535
Train Epoch: 45 [32000/35339 (90%)]	Loss: 0.236316
Train Epoch: 45 [32640/35339 (92%)]	Loss: 0.422573
Train Epoch: 45 [33280/35339 (94%)]	Loss: 0.305962
Train Epoch: 45 [33920/35339 (96%)]	Loss: 0.307090
Train Epoch: 45 [34560/35339 (98%)]	Loss: 0.334242
Train Epoch: 45 [35200/35339 (99%)]	Loss: 0.372916

Validation set: Average loss: 1.6288, Accuracy: 2486/3870 (64%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 46 [0/35339 (0%)]	Loss: 0.466017
Train Epoch: 46 [640/35339 (2%)]	Loss: 0.414772
Train Epoch: 46 [1280/35339 (4%)]	Loss: 0.596828
Train Epoch: 46 [1920/35339 (5%)]	Loss: 0.185309
Train Epoch: 46 [2560/35339 (7%)]	Loss: 0.313339
Train Epoch: 46 [3200/35339 (9%)]	Loss: 0.363689
Train Epoch: 46 [3840/35339 (11%)]	Loss: 0.378709
Train Epoch: 46 [4480/35339 (13%)]	Loss: 0.137089
Train Epoch: 46 [5120/35339 (14%)]	Loss: 0.172185
Train Epoch: 46 [5760/35339 (16%)]	Loss: 0.262082
Train Epoch: 46 [6400/35339 (18%)]	Loss: 0.323163
Train Epoch: 46 [7040/35339 (20%)]	Loss: 0.230770
Train Epoch: 46 [7680/35339 (22%)]	Loss: 0.353996
Train Epoch: 46 [8320/35339 (24%)]	Loss: 0.274502
Train Epoch: 46 [8960/35339 (25%)]	Loss: 0.340104
Train Epoch: 46 [9600/35339 (27%)]	Loss: 0.211418
Train Epoch: 46 [10240/35339 (29%)]	Loss: 0.487174
Train Epoch: 46 [10880/35339 (31%)]	Loss: 0.526374
Train Epoch: 46 [11520/35339 (33%)]	Loss: 0.464312
Train Epoch: 46 [12160/35339 (34%)]	Loss: 0.242462
Train Epoch: 46 [12800/35339 (36%)]	Loss: 0.524596
Train Epoch: 46 [13440/35339 (38%)]	Loss: 0.352725
Train Epoch: 46 [14080/35339 (40%)]	Loss: 0.243170
Train Epoch: 46 [14720/35339 (42%)]	Loss: 0.279183
Train Epoch: 46 [15360/35339 (43%)]	Loss: 0.415381
Train Epoch: 46 [16000/35339 (45%)]	Loss: 0.245715
Train Epoch: 46 [16640/35339 (47%)]	Loss: 0.185930
Train Epoch: 46 [17280/35339 (49%)]	Loss: 0.336031
Train Epoch: 46 [17920/35339 (51%)]	Loss: 0.389446
Train Epoch: 46 [18560/35339 (52%)]	Loss: 0.296420
Train Epoch: 46 [19200/35339 (54%)]	Loss: 0.219420
Train Epoch: 46 [19840/35339 (56%)]	Loss: 0.499394
Train Epoch: 46 [20480/35339 (58%)]	Loss: 0.359917
Train Epoch: 46 [21120/35339 (60%)]	Loss: 0.253108
Train Epoch: 46 [21760/35339 (61%)]	Loss: 0.248389
Train Epoch: 46 [22400/35339 (63%)]	Loss: 0.215302
Train Epoch: 46 [23040/35339 (65%)]	Loss: 0.301498
Train Epoch: 46 [23680/35339 (67%)]	Loss: 0.391649
Train Epoch: 46 [24320/35339 (69%)]	Loss: 0.163388
Train Epoch: 46 [24960/35339 (71%)]	Loss: 0.261717
Train Epoch: 46 [25600/35339 (72%)]	Loss: 0.342143
Train Epoch: 46 [26240/35339 (74%)]	Loss: 0.203401
Train Epoch: 46 [26880/35339 (76%)]	Loss: 0.445374
Train Epoch: 46 [27520/35339 (78%)]	Loss: 0.329495
Train Epoch: 46 [28160/35339 (80%)]	Loss: 0.172713
Train Epoch: 46 [28800/35339 (81%)]	Loss: 0.435280
Train Epoch: 46 [29440/35339 (83%)]	Loss: 0.480984
Train Epoch: 46 [30080/35339 (85%)]	Loss: 0.282053
Train Epoch: 46 [30720/35339 (87%)]	Loss: 0.338727
Train Epoch: 46 [31360/35339 (89%)]	Loss: 0.154913
Train Epoch: 46 [32000/35339 (90%)]	Loss: 0.210099
Train Epoch: 46 [32640/35339 (92%)]	Loss: 0.275885
Train Epoch: 46 [33280/35339 (94%)]	Loss: 0.165983
Train Epoch: 46 [33920/35339 (96%)]	Loss: 0.206521
Train Epoch: 46 [34560/35339 (98%)]	Loss: 0.293217
Train Epoch: 46 [35200/35339 (99%)]	Loss: 0.400934

Validation set: Average loss: 1.6301, Accuracy: 2502/3870 (65%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 47 [0/35339 (0%)]	Loss: 0.196413
Train Epoch: 47 [640/35339 (2%)]	Loss: 0.298089
Train Epoch: 47 [1280/35339 (4%)]	Loss: 0.307556
Train Epoch: 47 [1920/35339 (5%)]	Loss: 0.279889
Train Epoch: 47 [2560/35339 (7%)]	Loss: 0.266301
Train Epoch: 47 [3200/35339 (9%)]	Loss: 0.411144
Train Epoch: 47 [3840/35339 (11%)]	Loss: 0.602136
Train Epoch: 47 [4480/35339 (13%)]	Loss: 0.255346
Train Epoch: 47 [5120/35339 (14%)]	Loss: 0.224577
Train Epoch: 47 [5760/35339 (16%)]	Loss: 0.304966
Train Epoch: 47 [6400/35339 (18%)]	Loss: 0.231154
Train Epoch: 47 [7040/35339 (20%)]	Loss: 0.245906
Train Epoch: 47 [7680/35339 (22%)]	Loss: 0.197923
Train Epoch: 47 [8320/35339 (24%)]	Loss: 0.310093
Train Epoch: 47 [8960/35339 (25%)]	Loss: 0.351007
Train Epoch: 47 [9600/35339 (27%)]	Loss: 0.215941
Train Epoch: 47 [10240/35339 (29%)]	Loss: 0.252433
Train Epoch: 47 [10880/35339 (31%)]	Loss: 0.461898
Train Epoch: 47 [11520/35339 (33%)]	Loss: 0.209069
Train Epoch: 47 [12160/35339 (34%)]	Loss: 0.383070
Train Epoch: 47 [12800/35339 (36%)]	Loss: 0.315589
Train Epoch: 47 [13440/35339 (38%)]	Loss: 0.554512
Train Epoch: 47 [14080/35339 (40%)]	Loss: 0.294666
Train Epoch: 47 [14720/35339 (42%)]	Loss: 0.318854
Train Epoch: 47 [15360/35339 (43%)]	Loss: 0.371364
Train Epoch: 47 [16000/35339 (45%)]	Loss: 0.317597
Train Epoch: 47 [16640/35339 (47%)]	Loss: 0.302904
Train Epoch: 47 [17280/35339 (49%)]	Loss: 0.246272
Train Epoch: 47 [17920/35339 (51%)]	Loss: 0.269636
Train Epoch: 47 [18560/35339 (52%)]	Loss: 0.212403
Train Epoch: 47 [19200/35339 (54%)]	Loss: 0.281415
Train Epoch: 47 [19840/35339 (56%)]	Loss: 0.269742
Train Epoch: 47 [20480/35339 (58%)]	Loss: 0.331242
Train Epoch: 47 [21120/35339 (60%)]	Loss: 0.310004
Train Epoch: 47 [21760/35339 (61%)]	Loss: 0.204066
Train Epoch: 47 [22400/35339 (63%)]	Loss: 0.410013
Train Epoch: 47 [23040/35339 (65%)]	Loss: 0.221516
Train Epoch: 47 [23680/35339 (67%)]	Loss: 0.291543
Train Epoch: 47 [24320/35339 (69%)]	Loss: 0.268355
Train Epoch: 47 [24960/35339 (71%)]	Loss: 0.372694
Train Epoch: 47 [25600/35339 (72%)]	Loss: 0.207248
Train Epoch: 47 [26240/35339 (74%)]	Loss: 0.472495
Train Epoch: 47 [26880/35339 (76%)]	Loss: 0.212464
Train Epoch: 47 [27520/35339 (78%)]	Loss: 0.235431
Train Epoch: 47 [28160/35339 (80%)]	Loss: 0.273338
Train Epoch: 47 [28800/35339 (81%)]	Loss: 0.167006
Train Epoch: 47 [29440/35339 (83%)]	Loss: 0.519720
Train Epoch: 47 [30080/35339 (85%)]	Loss: 0.273620
Train Epoch: 47 [30720/35339 (87%)]	Loss: 0.253801
Train Epoch: 47 [31360/35339 (89%)]	Loss: 0.508768
Train Epoch: 47 [32000/35339 (90%)]	Loss: 0.236788
Train Epoch: 47 [32640/35339 (92%)]	Loss: 0.432862
Train Epoch: 47 [33280/35339 (94%)]	Loss: 0.374802
Train Epoch: 47 [33920/35339 (96%)]	Loss: 0.280660
Train Epoch: 47 [34560/35339 (98%)]	Loss: 0.162273
Train Epoch: 47 [35200/35339 (99%)]	Loss: 0.391879

Validation set: Average loss: 1.6037, Accuracy: 2491/3870 (64%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 48 [0/35339 (0%)]	Loss: 0.375658
Train Epoch: 48 [640/35339 (2%)]	Loss: 0.294820
Train Epoch: 48 [1280/35339 (4%)]	Loss: 0.311092
Train Epoch: 48 [1920/35339 (5%)]	Loss: 0.178655
Train Epoch: 48 [2560/35339 (7%)]	Loss: 0.245644
Train Epoch: 48 [3200/35339 (9%)]	Loss: 0.200974
Train Epoch: 48 [3840/35339 (11%)]	Loss: 0.344309
Train Epoch: 48 [4480/35339 (13%)]	Loss: 0.404048
Train Epoch: 48 [5120/35339 (14%)]	Loss: 0.355572
Train Epoch: 48 [5760/35339 (16%)]	Loss: 0.322866
Train Epoch: 48 [6400/35339 (18%)]	Loss: 0.255044
Train Epoch: 48 [7040/35339 (20%)]	Loss: 0.370879
Train Epoch: 48 [7680/35339 (22%)]	Loss: 0.243873
Train Epoch: 48 [8320/35339 (24%)]	Loss: 0.283293
Train Epoch: 48 [8960/35339 (25%)]	Loss: 0.320674
Train Epoch: 48 [9600/35339 (27%)]	Loss: 0.232047
Train Epoch: 48 [10240/35339 (29%)]	Loss: 0.320155
Train Epoch: 48 [10880/35339 (31%)]	Loss: 0.253780
Train Epoch: 48 [11520/35339 (33%)]	Loss: 0.266352
Train Epoch: 48 [12160/35339 (34%)]	Loss: 0.358462
Train Epoch: 48 [12800/35339 (36%)]	Loss: 0.330097
Train Epoch: 48 [13440/35339 (38%)]	Loss: 0.414352
Train Epoch: 48 [14080/35339 (40%)]	Loss: 0.203809
Train Epoch: 48 [14720/35339 (42%)]	Loss: 0.367504
Train Epoch: 48 [15360/35339 (43%)]	Loss: 0.282442
Train Epoch: 48 [16000/35339 (45%)]	Loss: 0.381823
Train Epoch: 48 [16640/35339 (47%)]	Loss: 0.363914
Train Epoch: 48 [17280/35339 (49%)]	Loss: 0.199375
Train Epoch: 48 [17920/35339 (51%)]	Loss: 0.319766
Train Epoch: 48 [18560/35339 (52%)]	Loss: 0.414070
Train Epoch: 48 [19200/35339 (54%)]	Loss: 0.176908
Train Epoch: 48 [19840/35339 (56%)]	Loss: 0.180171
Train Epoch: 48 [20480/35339 (58%)]	Loss: 0.352443
Train Epoch: 48 [21120/35339 (60%)]	Loss: 0.258737
Train Epoch: 48 [21760/35339 (61%)]	Loss: 0.351952
Train Epoch: 48 [22400/35339 (63%)]	Loss: 0.306179
Train Epoch: 48 [23040/35339 (65%)]	Loss: 0.159582
Train Epoch: 48 [23680/35339 (67%)]	Loss: 0.433029
Train Epoch: 48 [24320/35339 (69%)]	Loss: 0.245086
Train Epoch: 48 [24960/35339 (71%)]	Loss: 0.273448
Train Epoch: 48 [25600/35339 (72%)]	Loss: 0.267466
Train Epoch: 48 [26240/35339 (74%)]	Loss: 0.232985
Train Epoch: 48 [26880/35339 (76%)]	Loss: 0.480840
Train Epoch: 48 [27520/35339 (78%)]	Loss: 0.342371
Train Epoch: 48 [28160/35339 (80%)]	Loss: 0.403269
Train Epoch: 48 [28800/35339 (81%)]	Loss: 0.219223
Train Epoch: 48 [29440/35339 (83%)]	Loss: 0.266685
Train Epoch: 48 [30080/35339 (85%)]	Loss: 0.211353
Train Epoch: 48 [30720/35339 (87%)]	Loss: 0.360103
Train Epoch: 48 [31360/35339 (89%)]	Loss: 0.489179
Train Epoch: 48 [32000/35339 (90%)]	Loss: 0.211435
Train Epoch: 48 [32640/35339 (92%)]	Loss: 0.197434
Train Epoch: 48 [33280/35339 (94%)]	Loss: 0.317092
Train Epoch: 48 [33920/35339 (96%)]	Loss: 0.234368
Train Epoch: 48 [34560/35339 (98%)]	Loss: 0.358469
Train Epoch: 48 [35200/35339 (99%)]	Loss: 0.185257

Validation set: Average loss: 1.5682, Accuracy: 2533/3870 (65%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 49 [0/35339 (0%)]	Loss: 0.306685
Train Epoch: 49 [640/35339 (2%)]	Loss: 0.278633
Train Epoch: 49 [1280/35339 (4%)]	Loss: 0.250600
Train Epoch: 49 [1920/35339 (5%)]	Loss: 0.298004
Train Epoch: 49 [2560/35339 (7%)]	Loss: 0.232260
Train Epoch: 49 [3200/35339 (9%)]	Loss: 0.477710
Train Epoch: 49 [3840/35339 (11%)]	Loss: 0.239962
Train Epoch: 49 [4480/35339 (13%)]	Loss: 0.337453
Train Epoch: 49 [5120/35339 (14%)]	Loss: 0.331312
Train Epoch: 49 [5760/35339 (16%)]	Loss: 0.281380
Train Epoch: 49 [6400/35339 (18%)]	Loss: 0.228756
Train Epoch: 49 [7040/35339 (20%)]	Loss: 0.244344
Train Epoch: 49 [7680/35339 (22%)]	Loss: 0.259968
Train Epoch: 49 [8320/35339 (24%)]	Loss: 0.394667
Train Epoch: 49 [8960/35339 (25%)]	Loss: 0.359199
Train Epoch: 49 [9600/35339 (27%)]	Loss: 0.369320
Train Epoch: 49 [10240/35339 (29%)]	Loss: 0.392267
Train Epoch: 49 [10880/35339 (31%)]	Loss: 0.264615
Train Epoch: 49 [11520/35339 (33%)]	Loss: 0.322995
Train Epoch: 49 [12160/35339 (34%)]	Loss: 0.252078
Train Epoch: 49 [12800/35339 (36%)]	Loss: 0.339467
Train Epoch: 49 [13440/35339 (38%)]	Loss: 0.358980
Train Epoch: 49 [14080/35339 (40%)]	Loss: 0.304957
Train Epoch: 49 [14720/35339 (42%)]	Loss: 0.316503
Train Epoch: 49 [15360/35339 (43%)]	Loss: 0.392546
Train Epoch: 49 [16000/35339 (45%)]	Loss: 0.238925
Train Epoch: 49 [16640/35339 (47%)]	Loss: 0.186214
Train Epoch: 49 [17280/35339 (49%)]	Loss: 0.281131
Train Epoch: 49 [17920/35339 (51%)]	Loss: 0.398481
Train Epoch: 49 [18560/35339 (52%)]	Loss: 0.276768
Train Epoch: 49 [19200/35339 (54%)]	Loss: 0.315742
Train Epoch: 49 [19840/35339 (56%)]	Loss: 0.210511
Train Epoch: 49 [20480/35339 (58%)]	Loss: 0.382277
Train Epoch: 49 [21120/35339 (60%)]	Loss: 0.273335
Train Epoch: 49 [21760/35339 (61%)]	Loss: 0.219985
Train Epoch: 49 [22400/35339 (63%)]	Loss: 0.366931
Train Epoch: 49 [23040/35339 (65%)]	Loss: 0.343409
Train Epoch: 49 [23680/35339 (67%)]	Loss: 0.388461
Train Epoch: 49 [24320/35339 (69%)]	Loss: 0.218448
Train Epoch: 49 [24960/35339 (71%)]	Loss: 0.282928
Train Epoch: 49 [25600/35339 (72%)]	Loss: 0.381897
Train Epoch: 49 [26240/35339 (74%)]	Loss: 0.432392
Train Epoch: 49 [26880/35339 (76%)]	Loss: 0.221484
Train Epoch: 49 [27520/35339 (78%)]	Loss: 0.310486
Train Epoch: 49 [28160/35339 (80%)]	Loss: 0.330822
Train Epoch: 49 [28800/35339 (81%)]	Loss: 0.207634
Train Epoch: 49 [29440/35339 (83%)]	Loss: 0.243114
Train Epoch: 49 [30080/35339 (85%)]	Loss: 0.291091
Train Epoch: 49 [30720/35339 (87%)]	Loss: 0.343389
Train Epoch: 49 [31360/35339 (89%)]	Loss: 0.398243
Train Epoch: 49 [32000/35339 (90%)]	Loss: 0.384794
Train Epoch: 49 [32640/35339 (92%)]	Loss: 0.373092
Train Epoch: 49 [33280/35339 (94%)]	Loss: 0.213384
Train Epoch: 49 [33920/35339 (96%)]	Loss: 0.230722
Train Epoch: 49 [34560/35339 (98%)]	Loss: 0.399889
Train Epoch: 49 [35200/35339 (99%)]	Loss: 0.264122

Validation set: Average loss: 1.6347, Accuracy: 2535/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 50 [0/35339 (0%)]	Loss: 0.263128
Train Epoch: 50 [640/35339 (2%)]	Loss: 0.428575
Train Epoch: 50 [1280/35339 (4%)]	Loss: 0.203296
Train Epoch: 50 [1920/35339 (5%)]	Loss: 0.447626
Train Epoch: 50 [2560/35339 (7%)]	Loss: 0.241671
Train Epoch: 50 [3200/35339 (9%)]	Loss: 0.291090
Train Epoch: 50 [3840/35339 (11%)]	Loss: 0.273939
Train Epoch: 50 [4480/35339 (13%)]	Loss: 0.570102
Train Epoch: 50 [5120/35339 (14%)]	Loss: 0.196674
Train Epoch: 50 [5760/35339 (16%)]	Loss: 0.435164
Train Epoch: 50 [6400/35339 (18%)]	Loss: 0.325932
Train Epoch: 50 [7040/35339 (20%)]	Loss: 0.350738
Train Epoch: 50 [7680/35339 (22%)]	Loss: 0.563499
Train Epoch: 50 [8320/35339 (24%)]	Loss: 0.259900
Train Epoch: 50 [8960/35339 (25%)]	Loss: 0.272852
Train Epoch: 50 [9600/35339 (27%)]	Loss: 0.250583
Train Epoch: 50 [10240/35339 (29%)]	Loss: 0.246177
Train Epoch: 50 [10880/35339 (31%)]	Loss: 0.173314
Train Epoch: 50 [11520/35339 (33%)]	Loss: 0.263986
Train Epoch: 50 [12160/35339 (34%)]	Loss: 0.260145
Train Epoch: 50 [12800/35339 (36%)]	Loss: 0.318555
Train Epoch: 50 [13440/35339 (38%)]	Loss: 0.292861
Train Epoch: 50 [14080/35339 (40%)]	Loss: 0.276967
Train Epoch: 50 [14720/35339 (42%)]	Loss: 0.283974
Train Epoch: 50 [15360/35339 (43%)]	Loss: 0.202592
Train Epoch: 50 [16000/35339 (45%)]	Loss: 0.300882
Train Epoch: 50 [16640/35339 (47%)]	Loss: 0.378369
Train Epoch: 50 [17280/35339 (49%)]	Loss: 0.297939
Train Epoch: 50 [17920/35339 (51%)]	Loss: 0.276309
Train Epoch: 50 [18560/35339 (52%)]	Loss: 0.271369
Train Epoch: 50 [19200/35339 (54%)]	Loss: 0.226588
Train Epoch: 50 [19840/35339 (56%)]	Loss: 0.266640
Train Epoch: 50 [20480/35339 (58%)]	Loss: 0.476159
Train Epoch: 50 [21120/35339 (60%)]	Loss: 0.229015
Train Epoch: 50 [21760/35339 (61%)]	Loss: 0.219898
Train Epoch: 50 [22400/35339 (63%)]	Loss: 0.292251
Train Epoch: 50 [23040/35339 (65%)]	Loss: 0.441798
Train Epoch: 50 [23680/35339 (67%)]	Loss: 0.205960
Train Epoch: 50 [24320/35339 (69%)]	Loss: 0.239368
Train Epoch: 50 [24960/35339 (71%)]	Loss: 0.219583
Train Epoch: 50 [25600/35339 (72%)]	Loss: 0.292701
Train Epoch: 50 [26240/35339 (74%)]	Loss: 0.231094
Train Epoch: 50 [26880/35339 (76%)]	Loss: 0.280126
Train Epoch: 50 [27520/35339 (78%)]	Loss: 0.371675
Train Epoch: 50 [28160/35339 (80%)]	Loss: 0.523337
Train Epoch: 50 [28800/35339 (81%)]	Loss: 0.235212
Train Epoch: 50 [29440/35339 (83%)]	Loss: 0.291803
Train Epoch: 50 [30080/35339 (85%)]	Loss: 0.418791
Train Epoch: 50 [30720/35339 (87%)]	Loss: 0.273162
Train Epoch: 50 [31360/35339 (89%)]	Loss: 0.308174
Train Epoch: 50 [32000/35339 (90%)]	Loss: 0.293061
Train Epoch: 50 [32640/35339 (92%)]	Loss: 0.307472
Train Epoch: 50 [33280/35339 (94%)]	Loss: 0.220116
Train Epoch: 50 [33920/35339 (96%)]	Loss: 0.216602
Train Epoch: 50 [34560/35339 (98%)]	Loss: 0.350184
Train Epoch: 50 [35200/35339 (99%)]	Loss: 0.322902

Validation set: Average loss: 1.6440, Accuracy: 2502/3870 (65%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 51 [0/35339 (0%)]	Loss: 0.586525
Train Epoch: 51 [640/35339 (2%)]	Loss: 0.408839
Train Epoch: 51 [1280/35339 (4%)]	Loss: 0.234602
Train Epoch: 51 [1920/35339 (5%)]	Loss: 0.312442
Train Epoch: 51 [2560/35339 (7%)]	Loss: 0.331518
Train Epoch: 51 [3200/35339 (9%)]	Loss: 0.310600
Train Epoch: 51 [3840/35339 (11%)]	Loss: 0.195390
Train Epoch: 51 [4480/35339 (13%)]	Loss: 0.453872
Train Epoch: 51 [5120/35339 (14%)]	Loss: 0.346912
Train Epoch: 51 [5760/35339 (16%)]	Loss: 0.438520
Train Epoch: 51 [6400/35339 (18%)]	Loss: 0.308683
Train Epoch: 51 [7040/35339 (20%)]	Loss: 0.304958
Train Epoch: 51 [7680/35339 (22%)]	Loss: 0.312564
Train Epoch: 51 [8320/35339 (24%)]	Loss: 0.252614
Train Epoch: 51 [8960/35339 (25%)]	Loss: 0.302074
Train Epoch: 51 [9600/35339 (27%)]	Loss: 0.370347
Train Epoch: 51 [10240/35339 (29%)]	Loss: 0.298053
Train Epoch: 51 [10880/35339 (31%)]	Loss: 0.448612
Train Epoch: 51 [11520/35339 (33%)]	Loss: 0.233428
Train Epoch: 51 [12160/35339 (34%)]	Loss: 0.327397
Train Epoch: 51 [12800/35339 (36%)]	Loss: 0.204761
Train Epoch: 51 [13440/35339 (38%)]	Loss: 0.271471
Train Epoch: 51 [14080/35339 (40%)]	Loss: 0.194600
Train Epoch: 51 [14720/35339 (42%)]	Loss: 0.238721
Train Epoch: 51 [15360/35339 (43%)]	Loss: 0.263241
Train Epoch: 51 [16000/35339 (45%)]	Loss: 0.342667
Train Epoch: 51 [16640/35339 (47%)]	Loss: 0.303589
Train Epoch: 51 [17280/35339 (49%)]	Loss: 0.168817
Train Epoch: 51 [17920/35339 (51%)]	Loss: 0.279150
Train Epoch: 51 [18560/35339 (52%)]	Loss: 0.405674
Train Epoch: 51 [19200/35339 (54%)]	Loss: 0.219816
Train Epoch: 51 [19840/35339 (56%)]	Loss: 0.291098
Train Epoch: 51 [20480/35339 (58%)]	Loss: 0.291775
Train Epoch: 51 [21120/35339 (60%)]	Loss: 0.292845
Train Epoch: 51 [21760/35339 (61%)]	Loss: 0.388668
Train Epoch: 51 [22400/35339 (63%)]	Loss: 0.256065
Train Epoch: 51 [23040/35339 (65%)]	Loss: 0.201123
Train Epoch: 51 [23680/35339 (67%)]	Loss: 0.284312
Train Epoch: 51 [24320/35339 (69%)]	Loss: 0.203728
Train Epoch: 51 [24960/35339 (71%)]	Loss: 0.251779
Train Epoch: 51 [25600/35339 (72%)]	Loss: 0.108270
Train Epoch: 51 [26240/35339 (74%)]	Loss: 0.284031
Train Epoch: 51 [26880/35339 (76%)]	Loss: 0.139689
Train Epoch: 51 [27520/35339 (78%)]	Loss: 0.253138
Train Epoch: 51 [28160/35339 (80%)]	Loss: 0.246261
Train Epoch: 51 [28800/35339 (81%)]	Loss: 0.119465
Train Epoch: 51 [29440/35339 (83%)]	Loss: 0.422487
Train Epoch: 51 [30080/35339 (85%)]	Loss: 0.482780
Train Epoch: 51 [30720/35339 (87%)]	Loss: 0.532662
Train Epoch: 51 [31360/35339 (89%)]	Loss: 0.394318
Train Epoch: 51 [32000/35339 (90%)]	Loss: 0.242257
Train Epoch: 51 [32640/35339 (92%)]	Loss: 0.454747
Train Epoch: 51 [33280/35339 (94%)]	Loss: 0.267622
Train Epoch: 51 [33920/35339 (96%)]	Loss: 0.247762
Train Epoch: 51 [34560/35339 (98%)]	Loss: 0.228496
Train Epoch: 51 [35200/35339 (99%)]	Loss: 0.275706

Validation set: Average loss: 1.5947, Accuracy: 2507/3870 (65%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 52 [0/35339 (0%)]	Loss: 0.365504
Train Epoch: 52 [640/35339 (2%)]	Loss: 0.155083
Train Epoch: 52 [1280/35339 (4%)]	Loss: 0.302021
Train Epoch: 52 [1920/35339 (5%)]	Loss: 0.224775
Train Epoch: 52 [2560/35339 (7%)]	Loss: 0.269167
Train Epoch: 52 [3200/35339 (9%)]	Loss: 0.260258
Train Epoch: 52 [3840/35339 (11%)]	Loss: 0.310596
Train Epoch: 52 [4480/35339 (13%)]	Loss: 0.652514
Train Epoch: 52 [5120/35339 (14%)]	Loss: 0.309326
Train Epoch: 52 [5760/35339 (16%)]	Loss: 0.195381
Train Epoch: 52 [6400/35339 (18%)]	Loss: 0.253116
Train Epoch: 52 [7040/35339 (20%)]	Loss: 0.269392
Train Epoch: 52 [7680/35339 (22%)]	Loss: 0.263587
Train Epoch: 52 [8320/35339 (24%)]	Loss: 0.579305
Train Epoch: 52 [8960/35339 (25%)]	Loss: 0.242275
Train Epoch: 52 [9600/35339 (27%)]	Loss: 0.258525
Train Epoch: 52 [10240/35339 (29%)]	Loss: 0.290964
Train Epoch: 52 [10880/35339 (31%)]	Loss: 0.305544
Train Epoch: 52 [11520/35339 (33%)]	Loss: 0.267803
Train Epoch: 52 [12160/35339 (34%)]	Loss: 0.235287
Train Epoch: 52 [12800/35339 (36%)]	Loss: 0.272673
Train Epoch: 52 [13440/35339 (38%)]	Loss: 0.259593
Train Epoch: 52 [14080/35339 (40%)]	Loss: 0.123443
Train Epoch: 52 [14720/35339 (42%)]	Loss: 0.379641
Train Epoch: 52 [15360/35339 (43%)]	Loss: 0.258696
Train Epoch: 52 [16000/35339 (45%)]	Loss: 0.260621
Train Epoch: 52 [16640/35339 (47%)]	Loss: 0.216544
Train Epoch: 52 [17280/35339 (49%)]	Loss: 0.278071
Train Epoch: 52 [17920/35339 (51%)]	Loss: 0.342586
Train Epoch: 52 [18560/35339 (52%)]	Loss: 0.130810
Train Epoch: 52 [19200/35339 (54%)]	Loss: 0.302089
Train Epoch: 52 [19840/35339 (56%)]	Loss: 0.249446
Train Epoch: 52 [20480/35339 (58%)]	Loss: 0.278250
Train Epoch: 52 [21120/35339 (60%)]	Loss: 0.378719
Train Epoch: 52 [21760/35339 (61%)]	Loss: 0.371472
Train Epoch: 52 [22400/35339 (63%)]	Loss: 0.428975
Train Epoch: 52 [23040/35339 (65%)]	Loss: 0.313504
Train Epoch: 52 [23680/35339 (67%)]	Loss: 0.397996
Train Epoch: 52 [24320/35339 (69%)]	Loss: 0.217495
Train Epoch: 52 [24960/35339 (71%)]	Loss: 0.288234
Train Epoch: 52 [25600/35339 (72%)]	Loss: 0.355638
Train Epoch: 52 [26240/35339 (74%)]	Loss: 0.363743
Train Epoch: 52 [26880/35339 (76%)]	Loss: 0.298478
Train Epoch: 52 [27520/35339 (78%)]	Loss: 0.303390
Train Epoch: 52 [28160/35339 (80%)]	Loss: 0.332747
Train Epoch: 52 [28800/35339 (81%)]	Loss: 0.343964
Train Epoch: 52 [29440/35339 (83%)]	Loss: 0.283847
Train Epoch: 52 [30080/35339 (85%)]	Loss: 0.254478
Train Epoch: 52 [30720/35339 (87%)]	Loss: 0.285840
Train Epoch: 52 [31360/35339 (89%)]	Loss: 0.383998
Train Epoch: 52 [32000/35339 (90%)]	Loss: 0.312868
Train Epoch: 52 [32640/35339 (92%)]	Loss: 0.347449
Train Epoch: 52 [33280/35339 (94%)]	Loss: 0.361954
Train Epoch: 52 [33920/35339 (96%)]	Loss: 0.234206
Train Epoch: 52 [34560/35339 (98%)]	Loss: 0.394423
Train Epoch: 52 [35200/35339 (99%)]	Loss: 0.239475

Validation set: Average loss: 1.6251, Accuracy: 2503/3870 (65%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 53 [0/35339 (0%)]	Loss: 0.320543
Train Epoch: 53 [640/35339 (2%)]	Loss: 0.378366
Train Epoch: 53 [1280/35339 (4%)]	Loss: 0.213103
Train Epoch: 53 [1920/35339 (5%)]	Loss: 0.243883
Train Epoch: 53 [2560/35339 (7%)]	Loss: 0.197112
Train Epoch: 53 [3200/35339 (9%)]	Loss: 0.322300
Train Epoch: 53 [3840/35339 (11%)]	Loss: 0.705346
Train Epoch: 53 [4480/35339 (13%)]	Loss: 0.143456
Train Epoch: 53 [5120/35339 (14%)]	Loss: 0.202328
Train Epoch: 53 [5760/35339 (16%)]	Loss: 0.324337
Train Epoch: 53 [6400/35339 (18%)]	Loss: 0.168921
Train Epoch: 53 [7040/35339 (20%)]	Loss: 0.337903
Train Epoch: 53 [7680/35339 (22%)]	Loss: 0.261190
Train Epoch: 53 [8320/35339 (24%)]	Loss: 0.627859
Train Epoch: 53 [8960/35339 (25%)]	Loss: 0.351663
Train Epoch: 53 [9600/35339 (27%)]	Loss: 0.413381
Train Epoch: 53 [10240/35339 (29%)]	Loss: 0.192886
Train Epoch: 53 [10880/35339 (31%)]	Loss: 0.229688
Train Epoch: 53 [11520/35339 (33%)]	Loss: 0.305922
Train Epoch: 53 [12160/35339 (34%)]	Loss: 0.286559
Train Epoch: 53 [12800/35339 (36%)]	Loss: 0.269019
Train Epoch: 53 [13440/35339 (38%)]	Loss: 0.494750
Train Epoch: 53 [14080/35339 (40%)]	Loss: 0.190431
Train Epoch: 53 [14720/35339 (42%)]	Loss: 0.299108
Train Epoch: 53 [15360/35339 (43%)]	Loss: 0.410785
Train Epoch: 53 [16000/35339 (45%)]	Loss: 0.410191
Train Epoch: 53 [16640/35339 (47%)]	Loss: 0.363945
Train Epoch: 53 [17280/35339 (49%)]	Loss: 0.309754
Train Epoch: 53 [17920/35339 (51%)]	Loss: 0.212538
Train Epoch: 53 [18560/35339 (52%)]	Loss: 0.215250
Train Epoch: 53 [19200/35339 (54%)]	Loss: 0.369116
Train Epoch: 53 [19840/35339 (56%)]	Loss: 0.318473
Train Epoch: 53 [20480/35339 (58%)]	Loss: 0.243523
Train Epoch: 53 [21120/35339 (60%)]	Loss: 0.319170
Train Epoch: 53 [21760/35339 (61%)]	Loss: 0.337034
Train Epoch: 53 [22400/35339 (63%)]	Loss: 0.324764
Train Epoch: 53 [23040/35339 (65%)]	Loss: 0.273048
Train Epoch: 53 [23680/35339 (67%)]	Loss: 0.274165
Train Epoch: 53 [24320/35339 (69%)]	Loss: 0.284754
Train Epoch: 53 [24960/35339 (71%)]	Loss: 0.327966
Train Epoch: 53 [25600/35339 (72%)]	Loss: 0.454944
Train Epoch: 53 [26240/35339 (74%)]	Loss: 0.295829
Train Epoch: 53 [26880/35339 (76%)]	Loss: 0.334750
Train Epoch: 53 [27520/35339 (78%)]	Loss: 0.274102
Train Epoch: 53 [28160/35339 (80%)]	Loss: 0.240918
Train Epoch: 53 [28800/35339 (81%)]	Loss: 0.324753
Train Epoch: 53 [29440/35339 (83%)]	Loss: 0.254439
Train Epoch: 53 [30080/35339 (85%)]	Loss: 0.381520
Train Epoch: 53 [30720/35339 (87%)]	Loss: 0.271832
Train Epoch: 53 [31360/35339 (89%)]	Loss: 0.241647
Train Epoch: 53 [32000/35339 (90%)]	Loss: 0.504150
Train Epoch: 53 [32640/35339 (92%)]	Loss: 0.241970
Train Epoch: 53 [33280/35339 (94%)]	Loss: 0.208434
Train Epoch: 53 [33920/35339 (96%)]	Loss: 0.282544
Train Epoch: 53 [34560/35339 (98%)]	Loss: 0.174962
Train Epoch: 53 [35200/35339 (99%)]	Loss: 0.429438

Validation set: Average loss: 1.5858, Accuracy: 2520/3870 (65%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 54 [0/35339 (0%)]	Loss: 0.217950
Train Epoch: 54 [640/35339 (2%)]	Loss: 0.322207
Train Epoch: 54 [1280/35339 (4%)]	Loss: 0.299814
Train Epoch: 54 [1920/35339 (5%)]	Loss: 0.466264
Train Epoch: 54 [2560/35339 (7%)]	Loss: 0.254441
Train Epoch: 54 [3200/35339 (9%)]	Loss: 0.362939
Train Epoch: 54 [3840/35339 (11%)]	Loss: 0.218878
Train Epoch: 54 [4480/35339 (13%)]	Loss: 0.198045
Train Epoch: 54 [5120/35339 (14%)]	Loss: 0.328111
Train Epoch: 54 [5760/35339 (16%)]	Loss: 0.227300
Train Epoch: 54 [6400/35339 (18%)]	Loss: 0.241156
Train Epoch: 54 [7040/35339 (20%)]	Loss: 0.290768
Train Epoch: 54 [7680/35339 (22%)]	Loss: 0.245188
Train Epoch: 54 [8320/35339 (24%)]	Loss: 0.392710
Train Epoch: 54 [8960/35339 (25%)]	Loss: 0.289345
Train Epoch: 54 [9600/35339 (27%)]	Loss: 0.210490
Train Epoch: 54 [10240/35339 (29%)]	Loss: 0.400233
Train Epoch: 54 [10880/35339 (31%)]	Loss: 0.185859
Train Epoch: 54 [11520/35339 (33%)]	Loss: 0.262526
Train Epoch: 54 [12160/35339 (34%)]	Loss: 0.281394
Train Epoch: 54 [12800/35339 (36%)]	Loss: 0.304843
Train Epoch: 54 [13440/35339 (38%)]	Loss: 0.186239
Train Epoch: 54 [14080/35339 (40%)]	Loss: 0.222501
Train Epoch: 54 [14720/35339 (42%)]	Loss: 0.284068
Train Epoch: 54 [15360/35339 (43%)]	Loss: 0.266988
Train Epoch: 54 [16000/35339 (45%)]	Loss: 0.342207
Train Epoch: 54 [16640/35339 (47%)]	Loss: 0.162379
Train Epoch: 54 [17280/35339 (49%)]	Loss: 0.338480
Train Epoch: 54 [17920/35339 (51%)]	Loss: 0.268899
Train Epoch: 54 [18560/35339 (52%)]	Loss: 0.243259
Train Epoch: 54 [19200/35339 (54%)]	Loss: 0.404672
Train Epoch: 54 [19840/35339 (56%)]	Loss: 0.285286
Train Epoch: 54 [20480/35339 (58%)]	Loss: 0.276702
Train Epoch: 54 [21120/35339 (60%)]	Loss: 0.301718
Train Epoch: 54 [21760/35339 (61%)]	Loss: 0.245050
Train Epoch: 54 [22400/35339 (63%)]	Loss: 0.142395
Train Epoch: 54 [23040/35339 (65%)]	Loss: 0.269989
Train Epoch: 54 [23680/35339 (67%)]	Loss: 0.292755
Train Epoch: 54 [24320/35339 (69%)]	Loss: 0.350730
Train Epoch: 54 [24960/35339 (71%)]	Loss: 0.513531
Train Epoch: 54 [25600/35339 (72%)]	Loss: 0.323460
Train Epoch: 54 [26240/35339 (74%)]	Loss: 0.185355
Train Epoch: 54 [26880/35339 (76%)]	Loss: 0.272553
Train Epoch: 54 [27520/35339 (78%)]	Loss: 0.279903
Train Epoch: 54 [28160/35339 (80%)]	Loss: 0.129932
Train Epoch: 54 [28800/35339 (81%)]	Loss: 0.230665
Train Epoch: 54 [29440/35339 (83%)]	Loss: 0.319403
Train Epoch: 54 [30080/35339 (85%)]	Loss: 0.291330
Train Epoch: 54 [30720/35339 (87%)]	Loss: 0.227831
Train Epoch: 54 [31360/35339 (89%)]	Loss: 0.351285
Train Epoch: 54 [32000/35339 (90%)]	Loss: 0.279872
Train Epoch: 54 [32640/35339 (92%)]	Loss: 0.248161
Train Epoch: 54 [33280/35339 (94%)]	Loss: 0.208659
Train Epoch: 54 [33920/35339 (96%)]	Loss: 0.254212
Train Epoch: 54 [34560/35339 (98%)]	Loss: 0.252224
Train Epoch: 54 [35200/35339 (99%)]	Loss: 0.339312

Validation set: Average loss: 1.5576, Accuracy: 2535/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 55 [0/35339 (0%)]	Loss: 0.384699
Train Epoch: 55 [640/35339 (2%)]	Loss: 0.314672
Train Epoch: 55 [1280/35339 (4%)]	Loss: 0.230843
Train Epoch: 55 [1920/35339 (5%)]	Loss: 0.529537
Train Epoch: 55 [2560/35339 (7%)]	Loss: 0.368907
Train Epoch: 55 [3200/35339 (9%)]	Loss: 0.296652
Train Epoch: 55 [3840/35339 (11%)]	Loss: 0.282972
Train Epoch: 55 [4480/35339 (13%)]	Loss: 0.301775
Train Epoch: 55 [5120/35339 (14%)]	Loss: 0.191769
Train Epoch: 55 [5760/35339 (16%)]	Loss: 0.282384
Train Epoch: 55 [6400/35339 (18%)]	Loss: 0.303664
Train Epoch: 55 [7040/35339 (20%)]	Loss: 0.235195
Train Epoch: 55 [7680/35339 (22%)]	Loss: 0.315100
Train Epoch: 55 [8320/35339 (24%)]	Loss: 0.266256
Train Epoch: 55 [8960/35339 (25%)]	Loss: 0.274374
Train Epoch: 55 [9600/35339 (27%)]	Loss: 0.548379
Train Epoch: 55 [10240/35339 (29%)]	Loss: 0.328437
Train Epoch: 55 [10880/35339 (31%)]	Loss: 0.251800
Train Epoch: 55 [11520/35339 (33%)]	Loss: 0.316692
Train Epoch: 55 [12160/35339 (34%)]	Loss: 0.184460
Train Epoch: 55 [12800/35339 (36%)]	Loss: 0.252685
Train Epoch: 55 [13440/35339 (38%)]	Loss: 0.159903
Train Epoch: 55 [14080/35339 (40%)]	Loss: 0.304915
Train Epoch: 55 [14720/35339 (42%)]	Loss: 0.538755
Train Epoch: 55 [15360/35339 (43%)]	Loss: 0.308595
Train Epoch: 55 [16000/35339 (45%)]	Loss: 0.318030
Train Epoch: 55 [16640/35339 (47%)]	Loss: 0.255888
Train Epoch: 55 [17280/35339 (49%)]	Loss: 0.218713
Train Epoch: 55 [17920/35339 (51%)]	Loss: 0.287360
Train Epoch: 55 [18560/35339 (52%)]	Loss: 0.291505
Train Epoch: 55 [19200/35339 (54%)]	Loss: 0.139417
Train Epoch: 55 [19840/35339 (56%)]	Loss: 0.134824
Train Epoch: 55 [20480/35339 (58%)]	Loss: 0.272850
Train Epoch: 55 [21120/35339 (60%)]	Loss: 0.187343
Train Epoch: 55 [21760/35339 (61%)]	Loss: 0.428947
Train Epoch: 55 [22400/35339 (63%)]	Loss: 0.280681
Train Epoch: 55 [23040/35339 (65%)]	Loss: 0.202038
Train Epoch: 55 [23680/35339 (67%)]	Loss: 0.268331
Train Epoch: 55 [24320/35339 (69%)]	Loss: 0.229118
Train Epoch: 55 [24960/35339 (71%)]	Loss: 0.278405
Train Epoch: 55 [25600/35339 (72%)]	Loss: 0.223338
Train Epoch: 55 [26240/35339 (74%)]	Loss: 0.203830
Train Epoch: 55 [26880/35339 (76%)]	Loss: 0.282645
Train Epoch: 55 [27520/35339 (78%)]	Loss: 0.584311
Train Epoch: 55 [28160/35339 (80%)]	Loss: 0.219897
Train Epoch: 55 [28800/35339 (81%)]	Loss: 0.304474
Train Epoch: 55 [29440/35339 (83%)]	Loss: 0.221937
Train Epoch: 55 [30080/35339 (85%)]	Loss: 0.391751
Train Epoch: 55 [30720/35339 (87%)]	Loss: 0.376847
Train Epoch: 55 [31360/35339 (89%)]	Loss: 0.285501
Train Epoch: 55 [32000/35339 (90%)]	Loss: 0.312785
Train Epoch: 55 [32640/35339 (92%)]	Loss: 0.432237
Train Epoch: 55 [33280/35339 (94%)]	Loss: 0.198058
Train Epoch: 55 [33920/35339 (96%)]	Loss: 0.283789
Train Epoch: 55 [34560/35339 (98%)]	Loss: 0.257324
Train Epoch: 55 [35200/35339 (99%)]	Loss: 0.313714

Validation set: Average loss: 1.6007, Accuracy: 2528/3870 (65%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 56 [0/35339 (0%)]	Loss: 0.246218
Train Epoch: 56 [640/35339 (2%)]	Loss: 0.282389
Train Epoch: 56 [1280/35339 (4%)]	Loss: 0.423582
Train Epoch: 56 [1920/35339 (5%)]	Loss: 0.291660
Train Epoch: 56 [2560/35339 (7%)]	Loss: 0.261831
Train Epoch: 56 [3200/35339 (9%)]	Loss: 0.200266
Train Epoch: 56 [3840/35339 (11%)]	Loss: 0.184507
Train Epoch: 56 [4480/35339 (13%)]	Loss: 0.292187
Train Epoch: 56 [5120/35339 (14%)]	Loss: 0.192390
Train Epoch: 56 [5760/35339 (16%)]	Loss: 0.615003
Train Epoch: 56 [6400/35339 (18%)]	Loss: 0.240446
Train Epoch: 56 [7040/35339 (20%)]	Loss: 0.367589
Train Epoch: 56 [7680/35339 (22%)]	Loss: 0.146532
Train Epoch: 56 [8320/35339 (24%)]	Loss: 0.263556
Train Epoch: 56 [8960/35339 (25%)]	Loss: 0.256774
Train Epoch: 56 [9600/35339 (27%)]	Loss: 0.327434
Train Epoch: 56 [10240/35339 (29%)]	Loss: 0.381579
Train Epoch: 56 [10880/35339 (31%)]	Loss: 0.368613
Train Epoch: 56 [11520/35339 (33%)]	Loss: 0.342732
Train Epoch: 56 [12160/35339 (34%)]	Loss: 0.211207
Train Epoch: 56 [12800/35339 (36%)]	Loss: 0.591051
Train Epoch: 56 [13440/35339 (38%)]	Loss: 0.257726
Train Epoch: 56 [14080/35339 (40%)]	Loss: 0.237863
Train Epoch: 56 [14720/35339 (42%)]	Loss: 0.284779
Train Epoch: 56 [15360/35339 (43%)]	Loss: 0.129878
Train Epoch: 56 [16000/35339 (45%)]	Loss: 0.408378
Train Epoch: 56 [16640/35339 (47%)]	Loss: 0.476690
Train Epoch: 56 [17280/35339 (49%)]	Loss: 0.305447
Train Epoch: 56 [17920/35339 (51%)]	Loss: 0.265653
Train Epoch: 56 [18560/35339 (52%)]	Loss: 0.181277
Train Epoch: 56 [19200/35339 (54%)]	Loss: 0.239051
Train Epoch: 56 [19840/35339 (56%)]	Loss: 0.113681
Train Epoch: 56 [20480/35339 (58%)]	Loss: 0.265257
Train Epoch: 56 [21120/35339 (60%)]	Loss: 0.229481
Train Epoch: 56 [21760/35339 (61%)]	Loss: 0.343731
Train Epoch: 56 [22400/35339 (63%)]	Loss: 0.402557
Train Epoch: 56 [23040/35339 (65%)]	Loss: 0.322478
Train Epoch: 56 [23680/35339 (67%)]	Loss: 0.249429
Train Epoch: 56 [24320/35339 (69%)]	Loss: 0.439927
Train Epoch: 56 [24960/35339 (71%)]	Loss: 0.224524
Train Epoch: 56 [25600/35339 (72%)]	Loss: 0.233992
Train Epoch: 56 [26240/35339 (74%)]	Loss: 0.250513
Train Epoch: 56 [26880/35339 (76%)]	Loss: 0.345929
Train Epoch: 56 [27520/35339 (78%)]	Loss: 0.315635
Train Epoch: 56 [28160/35339 (80%)]	Loss: 0.277509
Train Epoch: 56 [28800/35339 (81%)]	Loss: 0.344814
Train Epoch: 56 [29440/35339 (83%)]	Loss: 0.447438
Train Epoch: 56 [30080/35339 (85%)]	Loss: 0.243987
Train Epoch: 56 [30720/35339 (87%)]	Loss: 0.300296
Train Epoch: 56 [31360/35339 (89%)]	Loss: 0.280326
Train Epoch: 56 [32000/35339 (90%)]	Loss: 0.271332
Train Epoch: 56 [32640/35339 (92%)]	Loss: 0.208990
Train Epoch: 56 [33280/35339 (94%)]	Loss: 0.304543
Train Epoch: 56 [33920/35339 (96%)]	Loss: 0.222449
Train Epoch: 56 [34560/35339 (98%)]	Loss: 0.386611
Train Epoch: 56 [35200/35339 (99%)]	Loss: 0.268100

Validation set: Average loss: 1.5582, Accuracy: 2535/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 57 [0/35339 (0%)]	Loss: 0.140336
Train Epoch: 57 [640/35339 (2%)]	Loss: 0.357777
Train Epoch: 57 [1280/35339 (4%)]	Loss: 0.406772
Train Epoch: 57 [1920/35339 (5%)]	Loss: 0.168375
Train Epoch: 57 [2560/35339 (7%)]	Loss: 0.377933
Train Epoch: 57 [3200/35339 (9%)]	Loss: 0.216095
Train Epoch: 57 [3840/35339 (11%)]	Loss: 0.231441
Train Epoch: 57 [4480/35339 (13%)]	Loss: 0.417077
Train Epoch: 57 [5120/35339 (14%)]	Loss: 0.341499
Train Epoch: 57 [5760/35339 (16%)]	Loss: 0.263505
Train Epoch: 57 [6400/35339 (18%)]	Loss: 0.310175
Train Epoch: 57 [7040/35339 (20%)]	Loss: 0.367761
Train Epoch: 57 [7680/35339 (22%)]	Loss: 0.287287
Train Epoch: 57 [8320/35339 (24%)]	Loss: 0.307299
Train Epoch: 57 [8960/35339 (25%)]	Loss: 0.295823
Train Epoch: 57 [9600/35339 (27%)]	Loss: 0.399625
Train Epoch: 57 [10240/35339 (29%)]	Loss: 0.239623
Train Epoch: 57 [10880/35339 (31%)]	Loss: 0.149437
Train Epoch: 57 [11520/35339 (33%)]	Loss: 0.412662
Train Epoch: 57 [12160/35339 (34%)]	Loss: 0.188270
Train Epoch: 57 [12800/35339 (36%)]	Loss: 0.486992
Train Epoch: 57 [13440/35339 (38%)]	Loss: 0.392259
Train Epoch: 57 [14080/35339 (40%)]	Loss: 0.319413
Train Epoch: 57 [14720/35339 (42%)]	Loss: 0.280272
Train Epoch: 57 [15360/35339 (43%)]	Loss: 0.364628
Train Epoch: 57 [16000/35339 (45%)]	Loss: 0.223068
Train Epoch: 57 [16640/35339 (47%)]	Loss: 0.265918
Train Epoch: 57 [17280/35339 (49%)]	Loss: 0.983121
Train Epoch: 57 [17920/35339 (51%)]	Loss: 0.370309
Train Epoch: 57 [18560/35339 (52%)]	Loss: 0.264053
Train Epoch: 57 [19200/35339 (54%)]	Loss: 0.164518
Train Epoch: 57 [19840/35339 (56%)]	Loss: 0.326172
Train Epoch: 57 [20480/35339 (58%)]	Loss: 0.200585
Train Epoch: 57 [21120/35339 (60%)]	Loss: 0.157613
Train Epoch: 57 [21760/35339 (61%)]	Loss: 0.298906
Train Epoch: 57 [22400/35339 (63%)]	Loss: 0.216979
Train Epoch: 57 [23040/35339 (65%)]	Loss: 0.249599
Train Epoch: 57 [23680/35339 (67%)]	Loss: 0.304399
Train Epoch: 57 [24320/35339 (69%)]	Loss: 0.223289
Train Epoch: 57 [24960/35339 (71%)]	Loss: 0.320546
Train Epoch: 57 [25600/35339 (72%)]	Loss: 0.185478
Train Epoch: 57 [26240/35339 (74%)]	Loss: 0.260265
Train Epoch: 57 [26880/35339 (76%)]	Loss: 0.267879
Train Epoch: 57 [27520/35339 (78%)]	Loss: 0.521222
Train Epoch: 57 [28160/35339 (80%)]	Loss: 0.259409
Train Epoch: 57 [28800/35339 (81%)]	Loss: 0.182054
Train Epoch: 57 [29440/35339 (83%)]	Loss: 0.171009
Train Epoch: 57 [30080/35339 (85%)]	Loss: 0.485613
Train Epoch: 57 [30720/35339 (87%)]	Loss: 0.188318
Train Epoch: 57 [31360/35339 (89%)]	Loss: 0.245970
Train Epoch: 57 [32000/35339 (90%)]	Loss: 0.285989
Train Epoch: 57 [32640/35339 (92%)]	Loss: 0.443301
Train Epoch: 57 [33280/35339 (94%)]	Loss: 0.370948
Train Epoch: 57 [33920/35339 (96%)]	Loss: 0.216827
Train Epoch: 57 [34560/35339 (98%)]	Loss: 0.604959
Train Epoch: 57 [35200/35339 (99%)]	Loss: 0.383212

Validation set: Average loss: 1.5379, Accuracy: 2558/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 58 [0/35339 (0%)]	Loss: 0.259250
Train Epoch: 58 [640/35339 (2%)]	Loss: 0.243655
Train Epoch: 58 [1280/35339 (4%)]	Loss: 0.246011
Train Epoch: 58 [1920/35339 (5%)]	Loss: 0.205790
Train Epoch: 58 [2560/35339 (7%)]	Loss: 0.296888
Train Epoch: 58 [3200/35339 (9%)]	Loss: 0.306857
Train Epoch: 58 [3840/35339 (11%)]	Loss: 0.433864
Train Epoch: 58 [4480/35339 (13%)]	Loss: 0.392498
Train Epoch: 58 [5120/35339 (14%)]	Loss: 0.351410
Train Epoch: 58 [5760/35339 (16%)]	Loss: 0.160660
Train Epoch: 58 [6400/35339 (18%)]	Loss: 0.269128
Train Epoch: 58 [7040/35339 (20%)]	Loss: 0.394815
Train Epoch: 58 [7680/35339 (22%)]	Loss: 0.280541
Train Epoch: 58 [8320/35339 (24%)]	Loss: 0.449463
Train Epoch: 58 [8960/35339 (25%)]	Loss: 0.252383
Train Epoch: 58 [9600/35339 (27%)]	Loss: 0.158871
Train Epoch: 58 [10240/35339 (29%)]	Loss: 0.246000
Train Epoch: 58 [10880/35339 (31%)]	Loss: 0.172454
Train Epoch: 58 [11520/35339 (33%)]	Loss: 0.314138
Train Epoch: 58 [12160/35339 (34%)]	Loss: 0.205500
Train Epoch: 58 [12800/35339 (36%)]	Loss: 0.428127
Train Epoch: 58 [13440/35339 (38%)]	Loss: 0.303786
Train Epoch: 58 [14080/35339 (40%)]	Loss: 0.236934
Train Epoch: 58 [14720/35339 (42%)]	Loss: 0.259582
Train Epoch: 58 [15360/35339 (43%)]	Loss: 0.238652
Train Epoch: 58 [16000/35339 (45%)]	Loss: 0.323346
Train Epoch: 58 [16640/35339 (47%)]	Loss: 0.285838
Train Epoch: 58 [17280/35339 (49%)]	Loss: 0.307924
Train Epoch: 58 [17920/35339 (51%)]	Loss: 0.269322
Train Epoch: 58 [18560/35339 (52%)]	Loss: 0.192038
Train Epoch: 58 [19200/35339 (54%)]	Loss: 0.254666
Train Epoch: 58 [19840/35339 (56%)]	Loss: 0.425065
Train Epoch: 58 [20480/35339 (58%)]	Loss: 0.290699
Train Epoch: 58 [21120/35339 (60%)]	Loss: 0.272731
Train Epoch: 58 [21760/35339 (61%)]	Loss: 0.536507
Train Epoch: 58 [22400/35339 (63%)]	Loss: 0.447065
Train Epoch: 58 [23040/35339 (65%)]	Loss: 0.464450
Train Epoch: 58 [23680/35339 (67%)]	Loss: 0.335943
Train Epoch: 58 [24320/35339 (69%)]	Loss: 0.338013
Train Epoch: 58 [24960/35339 (71%)]	Loss: 0.231899
Train Epoch: 58 [25600/35339 (72%)]	Loss: 0.235015
Train Epoch: 58 [26240/35339 (74%)]	Loss: 0.363385
Train Epoch: 58 [26880/35339 (76%)]	Loss: 0.261787
Train Epoch: 58 [27520/35339 (78%)]	Loss: 0.427755
Train Epoch: 58 [28160/35339 (80%)]	Loss: 0.332101
Train Epoch: 58 [28800/35339 (81%)]	Loss: 0.256799
Train Epoch: 58 [29440/35339 (83%)]	Loss: 0.075945
Train Epoch: 58 [30080/35339 (85%)]	Loss: 0.281266
Train Epoch: 58 [30720/35339 (87%)]	Loss: 0.134702
Train Epoch: 58 [31360/35339 (89%)]	Loss: 0.286900
Train Epoch: 58 [32000/35339 (90%)]	Loss: 0.485800
Train Epoch: 58 [32640/35339 (92%)]	Loss: 0.258901
Train Epoch: 58 [33280/35339 (94%)]	Loss: 0.282576
Train Epoch: 58 [33920/35339 (96%)]	Loss: 0.143424
Train Epoch: 58 [34560/35339 (98%)]	Loss: 0.332565
Train Epoch: 58 [35200/35339 (99%)]	Loss: 0.509517

Validation set: Average loss: 1.5756, Accuracy: 2562/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 59 [0/35339 (0%)]	Loss: 0.293606
Train Epoch: 59 [640/35339 (2%)]	Loss: 0.194388
Train Epoch: 59 [1280/35339 (4%)]	Loss: 0.343201
Train Epoch: 59 [1920/35339 (5%)]	Loss: 0.419898
Train Epoch: 59 [2560/35339 (7%)]	Loss: 0.195704
Train Epoch: 59 [3200/35339 (9%)]	Loss: 0.301434
Train Epoch: 59 [3840/35339 (11%)]	Loss: 0.301501
Train Epoch: 59 [4480/35339 (13%)]	Loss: 0.352827
Train Epoch: 59 [5120/35339 (14%)]	Loss: 0.294858
Train Epoch: 59 [5760/35339 (16%)]	Loss: 0.229861
Train Epoch: 59 [6400/35339 (18%)]	Loss: 0.210373
Train Epoch: 59 [7040/35339 (20%)]	Loss: 0.244409
Train Epoch: 59 [7680/35339 (22%)]	Loss: 0.310663
Train Epoch: 59 [8320/35339 (24%)]	Loss: 0.343025
Train Epoch: 59 [8960/35339 (25%)]	Loss: 0.295135
Train Epoch: 59 [9600/35339 (27%)]	Loss: 0.154535
Train Epoch: 59 [10240/35339 (29%)]	Loss: 0.330468
Train Epoch: 59 [10880/35339 (31%)]	Loss: 0.283824
Train Epoch: 59 [11520/35339 (33%)]	Loss: 0.358909
Train Epoch: 59 [12160/35339 (34%)]	Loss: 0.241748
Train Epoch: 59 [12800/35339 (36%)]	Loss: 0.300751
Train Epoch: 59 [13440/35339 (38%)]	Loss: 0.194701
Train Epoch: 59 [14080/35339 (40%)]	Loss: 0.149930
Train Epoch: 59 [14720/35339 (42%)]	Loss: 0.295352
Train Epoch: 59 [15360/35339 (43%)]	Loss: 0.237364
Train Epoch: 59 [16000/35339 (45%)]	Loss: 0.256579
Train Epoch: 59 [16640/35339 (47%)]	Loss: 0.287067
Train Epoch: 59 [17280/35339 (49%)]	Loss: 0.353961
Train Epoch: 59 [17920/35339 (51%)]	Loss: 0.280990
Train Epoch: 59 [18560/35339 (52%)]	Loss: 0.394654
Train Epoch: 59 [19200/35339 (54%)]	Loss: 0.237911
Train Epoch: 59 [19840/35339 (56%)]	Loss: 0.141506
Train Epoch: 59 [20480/35339 (58%)]	Loss: 0.223727
Train Epoch: 59 [21120/35339 (60%)]	Loss: 0.238437
Train Epoch: 59 [21760/35339 (61%)]	Loss: 0.366799
Train Epoch: 59 [22400/35339 (63%)]	Loss: 0.346814
Train Epoch: 59 [23040/35339 (65%)]	Loss: 0.181404
Train Epoch: 59 [23680/35339 (67%)]	Loss: 0.182996
Train Epoch: 59 [24320/35339 (69%)]	Loss: 0.204963
Train Epoch: 59 [24960/35339 (71%)]	Loss: 0.255922
Train Epoch: 59 [25600/35339 (72%)]	Loss: 0.293059
Train Epoch: 59 [26240/35339 (74%)]	Loss: 0.324121
Train Epoch: 59 [26880/35339 (76%)]	Loss: 0.306252
Train Epoch: 59 [27520/35339 (78%)]	Loss: 0.285103
Train Epoch: 59 [28160/35339 (80%)]	Loss: 0.312472
Train Epoch: 59 [28800/35339 (81%)]	Loss: 0.247698
Train Epoch: 59 [29440/35339 (83%)]	Loss: 0.739996
Train Epoch: 59 [30080/35339 (85%)]	Loss: 0.241523
Train Epoch: 59 [30720/35339 (87%)]	Loss: 0.322227
Train Epoch: 59 [31360/35339 (89%)]	Loss: 0.255669
Train Epoch: 59 [32000/35339 (90%)]	Loss: 0.308115
Train Epoch: 59 [32640/35339 (92%)]	Loss: 0.196381
Train Epoch: 59 [33280/35339 (94%)]	Loss: 0.203687
Train Epoch: 59 [33920/35339 (96%)]	Loss: 0.431946
Train Epoch: 59 [34560/35339 (98%)]	Loss: 0.336491
Train Epoch: 59 [35200/35339 (99%)]	Loss: 0.304637

Validation set: Average loss: 1.5503, Accuracy: 2581/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 60 [0/35339 (0%)]	Loss: 0.431194
Train Epoch: 60 [640/35339 (2%)]	Loss: 0.222035
Train Epoch: 60 [1280/35339 (4%)]	Loss: 0.237376
Train Epoch: 60 [1920/35339 (5%)]	Loss: 0.291789
Train Epoch: 60 [2560/35339 (7%)]	Loss: 0.167984
Train Epoch: 60 [3200/35339 (9%)]	Loss: 0.217516
Train Epoch: 60 [3840/35339 (11%)]	Loss: 0.192748
Train Epoch: 60 [4480/35339 (13%)]	Loss: 0.216941
Train Epoch: 60 [5120/35339 (14%)]	Loss: 0.428168
Train Epoch: 60 [5760/35339 (16%)]	Loss: 0.265520
Train Epoch: 60 [6400/35339 (18%)]	Loss: 0.307884
Train Epoch: 60 [7040/35339 (20%)]	Loss: 0.233631
Train Epoch: 60 [7680/35339 (22%)]	Loss: 0.245475
Train Epoch: 60 [8320/35339 (24%)]	Loss: 0.159544
Train Epoch: 60 [8960/35339 (25%)]	Loss: 0.464964
Train Epoch: 60 [9600/35339 (27%)]	Loss: 0.290573
Train Epoch: 60 [10240/35339 (29%)]	Loss: 0.491382
Train Epoch: 60 [10880/35339 (31%)]	Loss: 0.232801
Train Epoch: 60 [11520/35339 (33%)]	Loss: 0.256878
Train Epoch: 60 [12160/35339 (34%)]	Loss: 0.510305
Train Epoch: 60 [12800/35339 (36%)]	Loss: 0.322036
Train Epoch: 60 [13440/35339 (38%)]	Loss: 0.244073
Train Epoch: 60 [14080/35339 (40%)]	Loss: 0.510306
Train Epoch: 60 [14720/35339 (42%)]	Loss: 0.202994
Train Epoch: 60 [15360/35339 (43%)]	Loss: 0.351080
Train Epoch: 60 [16000/35339 (45%)]	Loss: 0.255143
Train Epoch: 60 [16640/35339 (47%)]	Loss: 0.280203
Train Epoch: 60 [17280/35339 (49%)]	Loss: 0.240638
Train Epoch: 60 [17920/35339 (51%)]	Loss: 0.211360
Train Epoch: 60 [18560/35339 (52%)]	Loss: 0.241660
Train Epoch: 60 [19200/35339 (54%)]	Loss: 0.213339
Train Epoch: 60 [19840/35339 (56%)]	Loss: 0.336897
Train Epoch: 60 [20480/35339 (58%)]	Loss: 0.263667
Train Epoch: 60 [21120/35339 (60%)]	Loss: 0.212835
Train Epoch: 60 [21760/35339 (61%)]	Loss: 0.291273
Train Epoch: 60 [22400/35339 (63%)]	Loss: 0.298128
Train Epoch: 60 [23040/35339 (65%)]	Loss: 0.138122
Train Epoch: 60 [23680/35339 (67%)]	Loss: 0.293152
Train Epoch: 60 [24320/35339 (69%)]	Loss: 0.366690
Train Epoch: 60 [24960/35339 (71%)]	Loss: 0.173775
Train Epoch: 60 [25600/35339 (72%)]	Loss: 0.344572
Train Epoch: 60 [26240/35339 (74%)]	Loss: 0.355694
Train Epoch: 60 [26880/35339 (76%)]	Loss: 0.288142
Train Epoch: 60 [27520/35339 (78%)]	Loss: 0.312550
Train Epoch: 60 [28160/35339 (80%)]	Loss: 0.289977
Train Epoch: 60 [28800/35339 (81%)]	Loss: 0.222677
Train Epoch: 60 [29440/35339 (83%)]	Loss: 0.366818
Train Epoch: 60 [30080/35339 (85%)]	Loss: 0.179817
Train Epoch: 60 [30720/35339 (87%)]	Loss: 0.282209
Train Epoch: 60 [31360/35339 (89%)]	Loss: 0.188161
Train Epoch: 60 [32000/35339 (90%)]	Loss: 0.325571
Train Epoch: 60 [32640/35339 (92%)]	Loss: 0.336638
Train Epoch: 60 [33280/35339 (94%)]	Loss: 0.437812
Train Epoch: 60 [33920/35339 (96%)]	Loss: 0.291759
Train Epoch: 60 [34560/35339 (98%)]	Loss: 0.151051
Train Epoch: 60 [35200/35339 (99%)]	Loss: 0.442902

Validation set: Average loss: 1.5705, Accuracy: 2561/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 61 [0/35339 (0%)]	Loss: 0.216641
Train Epoch: 61 [640/35339 (2%)]	Loss: 0.250489
Train Epoch: 61 [1280/35339 (4%)]	Loss: 0.130035
Train Epoch: 61 [1920/35339 (5%)]	Loss: 0.178880
Train Epoch: 61 [2560/35339 (7%)]	Loss: 0.337534
Train Epoch: 61 [3200/35339 (9%)]	Loss: 0.171778
Train Epoch: 61 [3840/35339 (11%)]	Loss: 0.202771
Train Epoch: 61 [4480/35339 (13%)]	Loss: 0.258882
Train Epoch: 61 [5120/35339 (14%)]	Loss: 0.198109
Train Epoch: 61 [5760/35339 (16%)]	Loss: 0.297203
Train Epoch: 61 [6400/35339 (18%)]	Loss: 0.120260
Train Epoch: 61 [7040/35339 (20%)]	Loss: 0.179243
Train Epoch: 61 [7680/35339 (22%)]	Loss: 0.197560
Train Epoch: 61 [8320/35339 (24%)]	Loss: 0.313491
Train Epoch: 61 [8960/35339 (25%)]	Loss: 0.346041
Train Epoch: 61 [9600/35339 (27%)]	Loss: 0.195126
Train Epoch: 61 [10240/35339 (29%)]	Loss: 0.337000
Train Epoch: 61 [10880/35339 (31%)]	Loss: 0.173776
Train Epoch: 61 [11520/35339 (33%)]	Loss: 0.291999
Train Epoch: 61 [12160/35339 (34%)]	Loss: 0.217897
Train Epoch: 61 [12800/35339 (36%)]	Loss: 0.306328
Train Epoch: 61 [13440/35339 (38%)]	Loss: 0.199891
Train Epoch: 61 [14080/35339 (40%)]	Loss: 0.243511
Train Epoch: 61 [14720/35339 (42%)]	Loss: 0.296549
Train Epoch: 61 [15360/35339 (43%)]	Loss: 0.467499
Train Epoch: 61 [16000/35339 (45%)]	Loss: 0.185971
Train Epoch: 61 [16640/35339 (47%)]	Loss: 0.374555
Train Epoch: 61 [17280/35339 (49%)]	Loss: 0.343346
Train Epoch: 61 [17920/35339 (51%)]	Loss: 0.291014
Train Epoch: 61 [18560/35339 (52%)]	Loss: 0.422473
Train Epoch: 61 [19200/35339 (54%)]	Loss: 0.292442
Train Epoch: 61 [19840/35339 (56%)]	Loss: 0.264022
Train Epoch: 61 [20480/35339 (58%)]	Loss: 0.535791
Train Epoch: 61 [21120/35339 (60%)]	Loss: 0.293483
Train Epoch: 61 [21760/35339 (61%)]	Loss: 0.375086
Train Epoch: 61 [22400/35339 (63%)]	Loss: 0.381086
Train Epoch: 61 [23040/35339 (65%)]	Loss: 0.347266
Train Epoch: 61 [23680/35339 (67%)]	Loss: 0.173390
Train Epoch: 61 [24320/35339 (69%)]	Loss: 0.414523
Train Epoch: 61 [24960/35339 (71%)]	Loss: 0.402769
Train Epoch: 61 [25600/35339 (72%)]	Loss: 0.265796
Train Epoch: 61 [26240/35339 (74%)]	Loss: 0.420164
Train Epoch: 61 [26880/35339 (76%)]	Loss: 0.336248
Train Epoch: 61 [27520/35339 (78%)]	Loss: 0.353409
Train Epoch: 61 [28160/35339 (80%)]	Loss: 0.334244
Train Epoch: 61 [28800/35339 (81%)]	Loss: 0.204481
Train Epoch: 61 [29440/35339 (83%)]	Loss: 0.653549
Train Epoch: 61 [30080/35339 (85%)]	Loss: 0.194485
Train Epoch: 61 [30720/35339 (87%)]	Loss: 0.164275
Train Epoch: 61 [31360/35339 (89%)]	Loss: 0.214171
Train Epoch: 61 [32000/35339 (90%)]	Loss: 0.389257
Train Epoch: 61 [32640/35339 (92%)]	Loss: 0.244002
Train Epoch: 61 [33280/35339 (94%)]	Loss: 0.272087
Train Epoch: 61 [33920/35339 (96%)]	Loss: 0.321111
Train Epoch: 61 [34560/35339 (98%)]	Loss: 0.209608
Train Epoch: 61 [35200/35339 (99%)]	Loss: 0.296546

Validation set: Average loss: 1.5408, Accuracy: 2562/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 62 [0/35339 (0%)]	Loss: 0.349509
Train Epoch: 62 [640/35339 (2%)]	Loss: 0.327190
Train Epoch: 62 [1280/35339 (4%)]	Loss: 0.301616
Train Epoch: 62 [1920/35339 (5%)]	Loss: 0.268462
Train Epoch: 62 [2560/35339 (7%)]	Loss: 0.467794
Train Epoch: 62 [3200/35339 (9%)]	Loss: 0.156928
Train Epoch: 62 [3840/35339 (11%)]	Loss: 0.346767
Train Epoch: 62 [4480/35339 (13%)]	Loss: 0.430239
Train Epoch: 62 [5120/35339 (14%)]	Loss: 0.323182
Train Epoch: 62 [5760/35339 (16%)]	Loss: 0.170039
Train Epoch: 62 [6400/35339 (18%)]	Loss: 0.312967
Train Epoch: 62 [7040/35339 (20%)]	Loss: 0.346698
Train Epoch: 62 [7680/35339 (22%)]	Loss: 0.227245
Train Epoch: 62 [8320/35339 (24%)]	Loss: 0.406738
Train Epoch: 62 [8960/35339 (25%)]	Loss: 0.460094
Train Epoch: 62 [9600/35339 (27%)]	Loss: 0.182803
Train Epoch: 62 [10240/35339 (29%)]	Loss: 0.278760
Train Epoch: 62 [10880/35339 (31%)]	Loss: 0.607652
Train Epoch: 62 [11520/35339 (33%)]	Loss: 0.182344
Train Epoch: 62 [12160/35339 (34%)]	Loss: 0.164782
Train Epoch: 62 [12800/35339 (36%)]	Loss: 0.351308
Train Epoch: 62 [13440/35339 (38%)]	Loss: 0.229797
Train Epoch: 62 [14080/35339 (40%)]	Loss: 0.289692
Train Epoch: 62 [14720/35339 (42%)]	Loss: 0.183356
Train Epoch: 62 [15360/35339 (43%)]	Loss: 0.252855
Train Epoch: 62 [16000/35339 (45%)]	Loss: 0.208717
Train Epoch: 62 [16640/35339 (47%)]	Loss: 0.209645
Train Epoch: 62 [17280/35339 (49%)]	Loss: 0.227258
Train Epoch: 62 [17920/35339 (51%)]	Loss: 0.264464
Train Epoch: 62 [18560/35339 (52%)]	Loss: 0.121001
Train Epoch: 62 [19200/35339 (54%)]	Loss: 0.255256
Train Epoch: 62 [19840/35339 (56%)]	Loss: 0.190641
Train Epoch: 62 [20480/35339 (58%)]	Loss: 0.233502
Train Epoch: 62 [21120/35339 (60%)]	Loss: 0.403360
Train Epoch: 62 [21760/35339 (61%)]	Loss: 0.386531
Train Epoch: 62 [22400/35339 (63%)]	Loss: 0.255249
Train Epoch: 62 [23040/35339 (65%)]	Loss: 0.227635
Train Epoch: 62 [23680/35339 (67%)]	Loss: 0.412954
Train Epoch: 62 [24320/35339 (69%)]	Loss: 0.459469
Train Epoch: 62 [24960/35339 (71%)]	Loss: 0.439461
Train Epoch: 62 [25600/35339 (72%)]	Loss: 0.252459
Train Epoch: 62 [26240/35339 (74%)]	Loss: 0.266744
Train Epoch: 62 [26880/35339 (76%)]	Loss: 0.274282
Train Epoch: 62 [27520/35339 (78%)]	Loss: 0.239307
Train Epoch: 62 [28160/35339 (80%)]	Loss: 0.590856
Train Epoch: 62 [28800/35339 (81%)]	Loss: 0.205274
Train Epoch: 62 [29440/35339 (83%)]	Loss: 0.250169
Train Epoch: 62 [30080/35339 (85%)]	Loss: 0.193411
Train Epoch: 62 [30720/35339 (87%)]	Loss: 0.314783
Train Epoch: 62 [31360/35339 (89%)]	Loss: 0.332021
Train Epoch: 62 [32000/35339 (90%)]	Loss: 0.169335
Train Epoch: 62 [32640/35339 (92%)]	Loss: 0.244287
Train Epoch: 62 [33280/35339 (94%)]	Loss: 0.318899
Train Epoch: 62 [33920/35339 (96%)]	Loss: 0.255275
Train Epoch: 62 [34560/35339 (98%)]	Loss: 0.180599
Train Epoch: 62 [35200/35339 (99%)]	Loss: 0.305443

Validation set: Average loss: 1.5777, Accuracy: 2591/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 63 [0/35339 (0%)]	Loss: 0.291166
Train Epoch: 63 [640/35339 (2%)]	Loss: 0.241293
Train Epoch: 63 [1280/35339 (4%)]	Loss: 0.389023
Train Epoch: 63 [1920/35339 (5%)]	Loss: 0.567206
Train Epoch: 63 [2560/35339 (7%)]	Loss: 0.202631
Train Epoch: 63 [3200/35339 (9%)]	Loss: 0.355107
Train Epoch: 63 [3840/35339 (11%)]	Loss: 0.253043
Train Epoch: 63 [4480/35339 (13%)]	Loss: 0.303224
Train Epoch: 63 [5120/35339 (14%)]	Loss: 0.300440
Train Epoch: 63 [5760/35339 (16%)]	Loss: 0.351550
Train Epoch: 63 [6400/35339 (18%)]	Loss: 0.261787
Train Epoch: 63 [7040/35339 (20%)]	Loss: 0.390435
Train Epoch: 63 [7680/35339 (22%)]	Loss: 0.221124
Train Epoch: 63 [8320/35339 (24%)]	Loss: 0.336239
Train Epoch: 63 [8960/35339 (25%)]	Loss: 0.419305
Train Epoch: 63 [9600/35339 (27%)]	Loss: 0.334889
Train Epoch: 63 [10240/35339 (29%)]	Loss: 0.266685
Train Epoch: 63 [10880/35339 (31%)]	Loss: 0.356244
Train Epoch: 63 [11520/35339 (33%)]	Loss: 0.199303
Train Epoch: 63 [12160/35339 (34%)]	Loss: 0.384134
Train Epoch: 63 [12800/35339 (36%)]	Loss: 0.350603
Train Epoch: 63 [13440/35339 (38%)]	Loss: 0.399183
Train Epoch: 63 [14080/35339 (40%)]	Loss: 0.140492
Train Epoch: 63 [14720/35339 (42%)]	Loss: 0.318392
Train Epoch: 63 [15360/35339 (43%)]	Loss: 0.353560
Train Epoch: 63 [16000/35339 (45%)]	Loss: 0.195318
Train Epoch: 63 [16640/35339 (47%)]	Loss: 0.283500
Train Epoch: 63 [17280/35339 (49%)]	Loss: 0.269827
Train Epoch: 63 [17920/35339 (51%)]	Loss: 0.368642
Train Epoch: 63 [18560/35339 (52%)]	Loss: 0.405784
Train Epoch: 63 [19200/35339 (54%)]	Loss: 0.288247
Train Epoch: 63 [19840/35339 (56%)]	Loss: 0.445883
Train Epoch: 63 [20480/35339 (58%)]	Loss: 0.296714
Train Epoch: 63 [21120/35339 (60%)]	Loss: 0.289277
Train Epoch: 63 [21760/35339 (61%)]	Loss: 0.412250
Train Epoch: 63 [22400/35339 (63%)]	Loss: 0.406401
Train Epoch: 63 [23040/35339 (65%)]	Loss: 0.228539
Train Epoch: 63 [23680/35339 (67%)]	Loss: 0.261435
Train Epoch: 63 [24320/35339 (69%)]	Loss: 0.199931
Train Epoch: 63 [24960/35339 (71%)]	Loss: 0.209244
Train Epoch: 63 [25600/35339 (72%)]	Loss: 0.242892
Train Epoch: 63 [26240/35339 (74%)]	Loss: 0.332746
Train Epoch: 63 [26880/35339 (76%)]	Loss: 0.330338
Train Epoch: 63 [27520/35339 (78%)]	Loss: 0.266314
Train Epoch: 63 [28160/35339 (80%)]	Loss: 0.155721
Train Epoch: 63 [28800/35339 (81%)]	Loss: 0.250177
Train Epoch: 63 [29440/35339 (83%)]	Loss: 0.317472
Train Epoch: 63 [30080/35339 (85%)]	Loss: 0.225123
Train Epoch: 63 [30720/35339 (87%)]	Loss: 0.263505
Train Epoch: 63 [31360/35339 (89%)]	Loss: 0.218567
Train Epoch: 63 [32000/35339 (90%)]	Loss: 0.277659
Train Epoch: 63 [32640/35339 (92%)]	Loss: 0.367045
Train Epoch: 63 [33280/35339 (94%)]	Loss: 0.270809
Train Epoch: 63 [33920/35339 (96%)]	Loss: 0.167571
Train Epoch: 63 [34560/35339 (98%)]	Loss: 0.259529
Train Epoch: 63 [35200/35339 (99%)]	Loss: 0.448586

Validation set: Average loss: 1.5862, Accuracy: 2584/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 64 [0/35339 (0%)]	Loss: 0.259605
Train Epoch: 64 [640/35339 (2%)]	Loss: 0.207386
Train Epoch: 64 [1280/35339 (4%)]	Loss: 0.269550
Train Epoch: 64 [1920/35339 (5%)]	Loss: 0.155811
Train Epoch: 64 [2560/35339 (7%)]	Loss: 0.240073
Train Epoch: 64 [3200/35339 (9%)]	Loss: 0.369472
Train Epoch: 64 [3840/35339 (11%)]	Loss: 0.297053
Train Epoch: 64 [4480/35339 (13%)]	Loss: 0.228566
Train Epoch: 64 [5120/35339 (14%)]	Loss: 0.225967
Train Epoch: 64 [5760/35339 (16%)]	Loss: 0.232716
Train Epoch: 64 [6400/35339 (18%)]	Loss: 0.202758
Train Epoch: 64 [7040/35339 (20%)]	Loss: 0.251485
Train Epoch: 64 [7680/35339 (22%)]	Loss: 0.266315
Train Epoch: 64 [8320/35339 (24%)]	Loss: 0.238478
Train Epoch: 64 [8960/35339 (25%)]	Loss: 0.127142
Train Epoch: 64 [9600/35339 (27%)]	Loss: 0.289564
Train Epoch: 64 [10240/35339 (29%)]	Loss: 0.474856
Train Epoch: 64 [10880/35339 (31%)]	Loss: 0.200881
Train Epoch: 64 [11520/35339 (33%)]	Loss: 0.336392
Train Epoch: 64 [12160/35339 (34%)]	Loss: 0.394605
Train Epoch: 64 [12800/35339 (36%)]	Loss: 0.210926
Train Epoch: 64 [13440/35339 (38%)]	Loss: 0.182730
Train Epoch: 64 [14080/35339 (40%)]	Loss: 0.245512
Train Epoch: 64 [14720/35339 (42%)]	Loss: 0.163584
Train Epoch: 64 [15360/35339 (43%)]	Loss: 0.284814
Train Epoch: 64 [16000/35339 (45%)]	Loss: 0.282791
Train Epoch: 64 [16640/35339 (47%)]	Loss: 0.226346
Train Epoch: 64 [17280/35339 (49%)]	Loss: 0.212880
Train Epoch: 64 [17920/35339 (51%)]	Loss: 0.431259
Train Epoch: 64 [18560/35339 (52%)]	Loss: 0.417829
Train Epoch: 64 [19200/35339 (54%)]	Loss: 0.374897
Train Epoch: 64 [19840/35339 (56%)]	Loss: 0.380584
Train Epoch: 64 [20480/35339 (58%)]	Loss: 0.202850
Train Epoch: 64 [21120/35339 (60%)]	Loss: 0.217963
Train Epoch: 64 [21760/35339 (61%)]	Loss: 0.438725
Train Epoch: 64 [22400/35339 (63%)]	Loss: 0.250868
Train Epoch: 64 [23040/35339 (65%)]	Loss: 0.296625
Train Epoch: 64 [23680/35339 (67%)]	Loss: 0.292362
Train Epoch: 64 [24320/35339 (69%)]	Loss: 0.290495
Train Epoch: 64 [24960/35339 (71%)]	Loss: 0.286535
Train Epoch: 64 [25600/35339 (72%)]	Loss: 0.403040
Train Epoch: 64 [26240/35339 (74%)]	Loss: 0.194203
Train Epoch: 64 [26880/35339 (76%)]	Loss: 0.242599
Train Epoch: 64 [27520/35339 (78%)]	Loss: 0.291699
Train Epoch: 64 [28160/35339 (80%)]	Loss: 0.157171
Train Epoch: 64 [28800/35339 (81%)]	Loss: 0.377312
Train Epoch: 64 [29440/35339 (83%)]	Loss: 0.253081
Train Epoch: 64 [30080/35339 (85%)]	Loss: 0.137771
Train Epoch: 64 [30720/35339 (87%)]	Loss: 0.215902
Train Epoch: 64 [31360/35339 (89%)]	Loss: 0.247192
Train Epoch: 64 [32000/35339 (90%)]	Loss: 0.337935
Train Epoch: 64 [32640/35339 (92%)]	Loss: 0.475217
Train Epoch: 64 [33280/35339 (94%)]	Loss: 0.249666
Train Epoch: 64 [33920/35339 (96%)]	Loss: 0.304655
Train Epoch: 64 [34560/35339 (98%)]	Loss: 0.180752
Train Epoch: 64 [35200/35339 (99%)]	Loss: 0.330680

Validation set: Average loss: 1.5695, Accuracy: 2579/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 65 [0/35339 (0%)]	Loss: 0.342199
Train Epoch: 65 [640/35339 (2%)]	Loss: 0.346808
Train Epoch: 65 [1280/35339 (4%)]	Loss: 0.265037
Train Epoch: 65 [1920/35339 (5%)]	Loss: 0.198409
Train Epoch: 65 [2560/35339 (7%)]	Loss: 0.268549
Train Epoch: 65 [3200/35339 (9%)]	Loss: 0.227794
Train Epoch: 65 [3840/35339 (11%)]	Loss: 0.322549
Train Epoch: 65 [4480/35339 (13%)]	Loss: 0.452363
Train Epoch: 65 [5120/35339 (14%)]	Loss: 0.374534
Train Epoch: 65 [5760/35339 (16%)]	Loss: 0.316989
Train Epoch: 65 [6400/35339 (18%)]	Loss: 0.355215
Train Epoch: 65 [7040/35339 (20%)]	Loss: 0.394854
Train Epoch: 65 [7680/35339 (22%)]	Loss: 0.248500
Train Epoch: 65 [8320/35339 (24%)]	Loss: 0.281138
Train Epoch: 65 [8960/35339 (25%)]	Loss: 0.197906
Train Epoch: 65 [9600/35339 (27%)]	Loss: 0.329215
Train Epoch: 65 [10240/35339 (29%)]	Loss: 0.276039
Train Epoch: 65 [10880/35339 (31%)]	Loss: 0.256655
Train Epoch: 65 [11520/35339 (33%)]	Loss: 0.192648
Train Epoch: 65 [12160/35339 (34%)]	Loss: 0.425605
Train Epoch: 65 [12800/35339 (36%)]	Loss: 0.334776
Train Epoch: 65 [13440/35339 (38%)]	Loss: 0.200888
Train Epoch: 65 [14080/35339 (40%)]	Loss: 0.242082
Train Epoch: 65 [14720/35339 (42%)]	Loss: 0.266746
Train Epoch: 65 [15360/35339 (43%)]	Loss: 0.301607
Train Epoch: 65 [16000/35339 (45%)]	Loss: 0.296897
Train Epoch: 65 [16640/35339 (47%)]	Loss: 0.127415
Train Epoch: 65 [17280/35339 (49%)]	Loss: 0.224359
Train Epoch: 65 [17920/35339 (51%)]	Loss: 0.225985
Train Epoch: 65 [18560/35339 (52%)]	Loss: 0.441496
Train Epoch: 65 [19200/35339 (54%)]	Loss: 0.230665
Train Epoch: 65 [19840/35339 (56%)]	Loss: 0.309789
Train Epoch: 65 [20480/35339 (58%)]	Loss: 0.175414
Train Epoch: 65 [21120/35339 (60%)]	Loss: 0.150057
Train Epoch: 65 [21760/35339 (61%)]	Loss: 0.312280
Train Epoch: 65 [22400/35339 (63%)]	Loss: 0.346488
Train Epoch: 65 [23040/35339 (65%)]	Loss: 0.218868
Train Epoch: 65 [23680/35339 (67%)]	Loss: 0.330316
Train Epoch: 65 [24320/35339 (69%)]	Loss: 0.372960
Train Epoch: 65 [24960/35339 (71%)]	Loss: 0.146498
Train Epoch: 65 [25600/35339 (72%)]	Loss: 0.166526
Train Epoch: 65 [26240/35339 (74%)]	Loss: 0.190490
Train Epoch: 65 [26880/35339 (76%)]	Loss: 0.474564
Train Epoch: 65 [27520/35339 (78%)]	Loss: 0.253351
Train Epoch: 65 [28160/35339 (80%)]	Loss: 0.245685
Train Epoch: 65 [28800/35339 (81%)]	Loss: 0.246985
Train Epoch: 65 [29440/35339 (83%)]	Loss: 0.322178
Train Epoch: 65 [30080/35339 (85%)]	Loss: 0.381137
Train Epoch: 65 [30720/35339 (87%)]	Loss: 0.275555
Train Epoch: 65 [31360/35339 (89%)]	Loss: 0.280798
Train Epoch: 65 [32000/35339 (90%)]	Loss: 0.181730
Train Epoch: 65 [32640/35339 (92%)]	Loss: 0.349044
Train Epoch: 65 [33280/35339 (94%)]	Loss: 0.243371
Train Epoch: 65 [33920/35339 (96%)]	Loss: 0.510620
Train Epoch: 65 [34560/35339 (98%)]	Loss: 0.274872
Train Epoch: 65 [35200/35339 (99%)]	Loss: 0.376874

Validation set: Average loss: 1.5429, Accuracy: 2563/3870 (66%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 66 [0/35339 (0%)]	Loss: 0.281523
Train Epoch: 66 [640/35339 (2%)]	Loss: 0.275893
Train Epoch: 66 [1280/35339 (4%)]	Loss: 0.326911
Train Epoch: 66 [1920/35339 (5%)]	Loss: 0.358635
Train Epoch: 66 [2560/35339 (7%)]	Loss: 0.244644
Train Epoch: 66 [3200/35339 (9%)]	Loss: 0.239527
Train Epoch: 66 [3840/35339 (11%)]	Loss: 0.196695
Train Epoch: 66 [4480/35339 (13%)]	Loss: 0.269238
Train Epoch: 66 [5120/35339 (14%)]	Loss: 0.304334
Train Epoch: 66 [5760/35339 (16%)]	Loss: 0.151604
Train Epoch: 66 [6400/35339 (18%)]	Loss: 0.640372
Train Epoch: 66 [7040/35339 (20%)]	Loss: 0.733194
Train Epoch: 66 [7680/35339 (22%)]	Loss: 0.264235
Train Epoch: 66 [8320/35339 (24%)]	Loss: 0.357915
Train Epoch: 66 [8960/35339 (25%)]	Loss: 0.252749
Train Epoch: 66 [9600/35339 (27%)]	Loss: 0.235469
Train Epoch: 66 [10240/35339 (29%)]	Loss: 0.334071
Train Epoch: 66 [10880/35339 (31%)]	Loss: 0.236605
Train Epoch: 66 [11520/35339 (33%)]	Loss: 0.265478
Train Epoch: 66 [12160/35339 (34%)]	Loss: 0.268061
Train Epoch: 66 [12800/35339 (36%)]	Loss: 0.343944
Train Epoch: 66 [13440/35339 (38%)]	Loss: 0.209346
Train Epoch: 66 [14080/35339 (40%)]	Loss: 0.254569
Train Epoch: 66 [14720/35339 (42%)]	Loss: 0.236470
Train Epoch: 66 [15360/35339 (43%)]	Loss: 0.135170
Train Epoch: 66 [16000/35339 (45%)]	Loss: 0.422318
Train Epoch: 66 [16640/35339 (47%)]	Loss: 0.263450
Train Epoch: 66 [17280/35339 (49%)]	Loss: 0.215868
Train Epoch: 66 [17920/35339 (51%)]	Loss: 0.349281
Train Epoch: 66 [18560/35339 (52%)]	Loss: 0.287122
Train Epoch: 66 [19200/35339 (54%)]	Loss: 0.289057
Train Epoch: 66 [19840/35339 (56%)]	Loss: 0.188552
Train Epoch: 66 [20480/35339 (58%)]	Loss: 0.348857
Train Epoch: 66 [21120/35339 (60%)]	Loss: 0.174417
Train Epoch: 66 [21760/35339 (61%)]	Loss: 0.215331
Train Epoch: 66 [22400/35339 (63%)]	Loss: 0.196804
Train Epoch: 66 [23040/35339 (65%)]	Loss: 0.346491
Train Epoch: 66 [23680/35339 (67%)]	Loss: 0.274565
Train Epoch: 66 [24320/35339 (69%)]	Loss: 0.237535
Train Epoch: 66 [24960/35339 (71%)]	Loss: 0.254071
Train Epoch: 66 [25600/35339 (72%)]	Loss: 0.372468
Train Epoch: 66 [26240/35339 (74%)]	Loss: 0.285932
Train Epoch: 66 [26880/35339 (76%)]	Loss: 0.183310
Train Epoch: 66 [27520/35339 (78%)]	Loss: 0.289080
Train Epoch: 66 [28160/35339 (80%)]	Loss: 0.247851
Train Epoch: 66 [28800/35339 (81%)]	Loss: 0.155068
Train Epoch: 66 [29440/35339 (83%)]	Loss: 0.436861
Train Epoch: 66 [30080/35339 (85%)]	Loss: 0.300187
Train Epoch: 66 [30720/35339 (87%)]	Loss: 0.201094
Train Epoch: 66 [31360/35339 (89%)]	Loss: 0.241201
Train Epoch: 66 [32000/35339 (90%)]	Loss: 0.285828
Train Epoch: 66 [32640/35339 (92%)]	Loss: 0.505997
Train Epoch: 66 [33280/35339 (94%)]	Loss: 0.210129
Train Epoch: 66 [33920/35339 (96%)]	Loss: 0.306950
Train Epoch: 66 [34560/35339 (98%)]	Loss: 0.294104
Train Epoch: 66 [35200/35339 (99%)]	Loss: 0.321596

Validation set: Average loss: 1.4839, Accuracy: 2605/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 67 [0/35339 (0%)]	Loss: 0.255873
Train Epoch: 67 [640/35339 (2%)]	Loss: 0.329919
Train Epoch: 67 [1280/35339 (4%)]	Loss: 0.199053
Train Epoch: 67 [1920/35339 (5%)]	Loss: 0.232950
Train Epoch: 67 [2560/35339 (7%)]	Loss: 0.412443
Train Epoch: 67 [3200/35339 (9%)]	Loss: 0.237542
Train Epoch: 67 [3840/35339 (11%)]	Loss: 0.503490
Train Epoch: 67 [4480/35339 (13%)]	Loss: 0.279584
Train Epoch: 67 [5120/35339 (14%)]	Loss: 0.354404
Train Epoch: 67 [5760/35339 (16%)]	Loss: 0.318170
Train Epoch: 67 [6400/35339 (18%)]	Loss: 0.338438
Train Epoch: 67 [7040/35339 (20%)]	Loss: 0.295161
Train Epoch: 67 [7680/35339 (22%)]	Loss: 0.274603
Train Epoch: 67 [8320/35339 (24%)]	Loss: 0.298620
Train Epoch: 67 [8960/35339 (25%)]	Loss: 0.317599
Train Epoch: 67 [9600/35339 (27%)]	Loss: 0.323436
Train Epoch: 67 [10240/35339 (29%)]	Loss: 0.266003
Train Epoch: 67 [10880/35339 (31%)]	Loss: 0.243871
Train Epoch: 67 [11520/35339 (33%)]	Loss: 0.295140
Train Epoch: 67 [12160/35339 (34%)]	Loss: 0.677208
Train Epoch: 67 [12800/35339 (36%)]	Loss: 0.469152
Train Epoch: 67 [13440/35339 (38%)]	Loss: 0.241482
Train Epoch: 67 [14080/35339 (40%)]	Loss: 0.192227
Train Epoch: 67 [14720/35339 (42%)]	Loss: 0.266863
Train Epoch: 67 [15360/35339 (43%)]	Loss: 0.260909
Train Epoch: 67 [16000/35339 (45%)]	Loss: 0.286128
Train Epoch: 67 [16640/35339 (47%)]	Loss: 0.311311
Train Epoch: 67 [17280/35339 (49%)]	Loss: 0.256160
Train Epoch: 67 [17920/35339 (51%)]	Loss: 0.642058
Train Epoch: 67 [18560/35339 (52%)]	Loss: 0.206821
Train Epoch: 67 [19200/35339 (54%)]	Loss: 0.190336
Train Epoch: 67 [19840/35339 (56%)]	Loss: 0.307234
Train Epoch: 67 [20480/35339 (58%)]	Loss: 0.192083
Train Epoch: 67 [21120/35339 (60%)]	Loss: 0.148176
Train Epoch: 67 [21760/35339 (61%)]	Loss: 0.377299
Train Epoch: 67 [22400/35339 (63%)]	Loss: 0.568511
Train Epoch: 67 [23040/35339 (65%)]	Loss: 0.234565
Train Epoch: 67 [23680/35339 (67%)]	Loss: 0.368858
Train Epoch: 67 [24320/35339 (69%)]	Loss: 0.132668
Train Epoch: 67 [24960/35339 (71%)]	Loss: 0.210126
Train Epoch: 67 [25600/35339 (72%)]	Loss: 0.211549
Train Epoch: 67 [26240/35339 (74%)]	Loss: 0.107115
Train Epoch: 67 [26880/35339 (76%)]	Loss: 0.244684
Train Epoch: 67 [27520/35339 (78%)]	Loss: 0.315518
Train Epoch: 67 [28160/35339 (80%)]	Loss: 0.306812
Train Epoch: 67 [28800/35339 (81%)]	Loss: 0.174602
Train Epoch: 67 [29440/35339 (83%)]	Loss: 0.249400
Train Epoch: 67 [30080/35339 (85%)]	Loss: 0.357332
Train Epoch: 67 [30720/35339 (87%)]	Loss: 0.478798
Train Epoch: 67 [31360/35339 (89%)]	Loss: 0.312945
Train Epoch: 67 [32000/35339 (90%)]	Loss: 0.358783
Train Epoch: 67 [32640/35339 (92%)]	Loss: 0.167065
Train Epoch: 67 [33280/35339 (94%)]	Loss: 0.225313
Train Epoch: 67 [33920/35339 (96%)]	Loss: 0.242635
Train Epoch: 67 [34560/35339 (98%)]	Loss: 0.195720
Train Epoch: 67 [35200/35339 (99%)]	Loss: 0.223329

Validation set: Average loss: 1.5097, Accuracy: 2600/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 68 [0/35339 (0%)]	Loss: 0.398705
Train Epoch: 68 [640/35339 (2%)]	Loss: 0.249213
Train Epoch: 68 [1280/35339 (4%)]	Loss: 0.329549
Train Epoch: 68 [1920/35339 (5%)]	Loss: 0.233831
Train Epoch: 68 [2560/35339 (7%)]	Loss: 0.437569
Train Epoch: 68 [3200/35339 (9%)]	Loss: 0.160956
Train Epoch: 68 [3840/35339 (11%)]	Loss: 0.349113
Train Epoch: 68 [4480/35339 (13%)]	Loss: 0.228202
Train Epoch: 68 [5120/35339 (14%)]	Loss: 0.135935
Train Epoch: 68 [5760/35339 (16%)]	Loss: 0.381051
Train Epoch: 68 [6400/35339 (18%)]	Loss: 0.157153
Train Epoch: 68 [7040/35339 (20%)]	Loss: 0.210057
Train Epoch: 68 [7680/35339 (22%)]	Loss: 0.349496
Train Epoch: 68 [8320/35339 (24%)]	Loss: 0.217544
Train Epoch: 68 [8960/35339 (25%)]	Loss: 0.571054
Train Epoch: 68 [9600/35339 (27%)]	Loss: 0.193404
Train Epoch: 68 [10240/35339 (29%)]	Loss: 0.263621
Train Epoch: 68 [10880/35339 (31%)]	Loss: 0.318942
Train Epoch: 68 [11520/35339 (33%)]	Loss: 0.198306
Train Epoch: 68 [12160/35339 (34%)]	Loss: 0.143522
Train Epoch: 68 [12800/35339 (36%)]	Loss: 0.353214
Train Epoch: 68 [13440/35339 (38%)]	Loss: 0.336377
Train Epoch: 68 [14080/35339 (40%)]	Loss: 0.395514
Train Epoch: 68 [14720/35339 (42%)]	Loss: 0.870833
Train Epoch: 68 [15360/35339 (43%)]	Loss: 0.306676
Train Epoch: 68 [16000/35339 (45%)]	Loss: 0.191145
Train Epoch: 68 [16640/35339 (47%)]	Loss: 0.317967
Train Epoch: 68 [17280/35339 (49%)]	Loss: 0.284138
Train Epoch: 68 [17920/35339 (51%)]	Loss: 0.261848
Train Epoch: 68 [18560/35339 (52%)]	Loss: 0.328912
Train Epoch: 68 [19200/35339 (54%)]	Loss: 0.283547
Train Epoch: 68 [19840/35339 (56%)]	Loss: 0.271351
Train Epoch: 68 [20480/35339 (58%)]	Loss: 0.090214
Train Epoch: 68 [21120/35339 (60%)]	Loss: 0.150942
Train Epoch: 68 [21760/35339 (61%)]	Loss: 0.171204
Train Epoch: 68 [22400/35339 (63%)]	Loss: 0.380632
Train Epoch: 68 [23040/35339 (65%)]	Loss: 0.257448
Train Epoch: 68 [23680/35339 (67%)]	Loss: 0.379392
Train Epoch: 68 [24320/35339 (69%)]	Loss: 0.262461
Train Epoch: 68 [24960/35339 (71%)]	Loss: 0.205077
Train Epoch: 68 [25600/35339 (72%)]	Loss: 0.397179
Train Epoch: 68 [26240/35339 (74%)]	Loss: 0.440254
Train Epoch: 68 [26880/35339 (76%)]	Loss: 0.387218
Train Epoch: 68 [27520/35339 (78%)]	Loss: 0.252732
Train Epoch: 68 [28160/35339 (80%)]	Loss: 0.360539
Train Epoch: 68 [28800/35339 (81%)]	Loss: 0.221335
Train Epoch: 68 [29440/35339 (83%)]	Loss: 0.422338
Train Epoch: 68 [30080/35339 (85%)]	Loss: 0.191369
Train Epoch: 68 [30720/35339 (87%)]	Loss: 0.289806
Train Epoch: 68 [31360/35339 (89%)]	Loss: 0.254251
Train Epoch: 68 [32000/35339 (90%)]	Loss: 0.249125
Train Epoch: 68 [32640/35339 (92%)]	Loss: 0.213812
Train Epoch: 68 [33280/35339 (94%)]	Loss: 0.310382
Train Epoch: 68 [33920/35339 (96%)]	Loss: 0.153953
Train Epoch: 68 [34560/35339 (98%)]	Loss: 0.275117
Train Epoch: 68 [35200/35339 (99%)]	Loss: 0.291562

Validation set: Average loss: 1.5324, Accuracy: 2596/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 69 [0/35339 (0%)]	Loss: 0.269465
Train Epoch: 69 [640/35339 (2%)]	Loss: 0.329748
Train Epoch: 69 [1280/35339 (4%)]	Loss: 0.278468
Train Epoch: 69 [1920/35339 (5%)]	Loss: 0.414515
Train Epoch: 69 [2560/35339 (7%)]	Loss: 0.250999
Train Epoch: 69 [3200/35339 (9%)]	Loss: 0.313236
Train Epoch: 69 [3840/35339 (11%)]	Loss: 0.284302
Train Epoch: 69 [4480/35339 (13%)]	Loss: 0.422244
Train Epoch: 69 [5120/35339 (14%)]	Loss: 0.347605
Train Epoch: 69 [5760/35339 (16%)]	Loss: 0.180051
Train Epoch: 69 [6400/35339 (18%)]	Loss: 0.146438
Train Epoch: 69 [7040/35339 (20%)]	Loss: 0.199781
Train Epoch: 69 [7680/35339 (22%)]	Loss: 0.238673
Train Epoch: 69 [8320/35339 (24%)]	Loss: 0.490742
Train Epoch: 69 [8960/35339 (25%)]	Loss: 0.155602
Train Epoch: 69 [9600/35339 (27%)]	Loss: 0.161993
Train Epoch: 69 [10240/35339 (29%)]	Loss: 0.232512
Train Epoch: 69 [10880/35339 (31%)]	Loss: 0.296634
Train Epoch: 69 [11520/35339 (33%)]	Loss: 0.268769
Train Epoch: 69 [12160/35339 (34%)]	Loss: 0.380564
Train Epoch: 69 [12800/35339 (36%)]	Loss: 0.237950
Train Epoch: 69 [13440/35339 (38%)]	Loss: 0.102776
Train Epoch: 69 [14080/35339 (40%)]	Loss: 0.282491
Train Epoch: 69 [14720/35339 (42%)]	Loss: 0.248409
Train Epoch: 69 [15360/35339 (43%)]	Loss: 0.282996
Train Epoch: 69 [16000/35339 (45%)]	Loss: 0.282839
Train Epoch: 69 [16640/35339 (47%)]	Loss: 0.127195
Train Epoch: 69 [17280/35339 (49%)]	Loss: 0.362540
Train Epoch: 69 [17920/35339 (51%)]	Loss: 0.145942
Train Epoch: 69 [18560/35339 (52%)]	Loss: 0.136184
Train Epoch: 69 [19200/35339 (54%)]	Loss: 0.135131
Train Epoch: 69 [19840/35339 (56%)]	Loss: 0.291076
Train Epoch: 69 [20480/35339 (58%)]	Loss: 0.239541
Train Epoch: 69 [21120/35339 (60%)]	Loss: 0.162589
Train Epoch: 69 [21760/35339 (61%)]	Loss: 0.308218
Train Epoch: 69 [22400/35339 (63%)]	Loss: 0.523284
Train Epoch: 69 [23040/35339 (65%)]	Loss: 0.145692
Train Epoch: 69 [23680/35339 (67%)]	Loss: 0.241934
Train Epoch: 69 [24320/35339 (69%)]	Loss: 0.180914
Train Epoch: 69 [24960/35339 (71%)]	Loss: 0.182313
Train Epoch: 69 [25600/35339 (72%)]	Loss: 0.221117
Train Epoch: 69 [26240/35339 (74%)]	Loss: 0.283639
Train Epoch: 69 [26880/35339 (76%)]	Loss: 0.274484
Train Epoch: 69 [27520/35339 (78%)]	Loss: 0.305675
Train Epoch: 69 [28160/35339 (80%)]	Loss: 0.265779
Train Epoch: 69 [28800/35339 (81%)]	Loss: 0.230517
Train Epoch: 69 [29440/35339 (83%)]	Loss: 0.282963
Train Epoch: 69 [30080/35339 (85%)]	Loss: 0.295019
Train Epoch: 69 [30720/35339 (87%)]	Loss: 0.186059
Train Epoch: 69 [31360/35339 (89%)]	Loss: 0.396169
Train Epoch: 69 [32000/35339 (90%)]	Loss: 0.206449
Train Epoch: 69 [32640/35339 (92%)]	Loss: 0.221903
Train Epoch: 69 [33280/35339 (94%)]	Loss: 0.190435
Train Epoch: 69 [33920/35339 (96%)]	Loss: 0.348968
Train Epoch: 69 [34560/35339 (98%)]	Loss: 0.234317
Train Epoch: 69 [35200/35339 (99%)]	Loss: 0.245812

Validation set: Average loss: 1.4979, Accuracy: 2592/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 70 [0/35339 (0%)]	Loss: 0.253802
Train Epoch: 70 [640/35339 (2%)]	Loss: 0.316164
Train Epoch: 70 [1280/35339 (4%)]	Loss: 0.172906
Train Epoch: 70 [1920/35339 (5%)]	Loss: 0.239769
Train Epoch: 70 [2560/35339 (7%)]	Loss: 0.291441
Train Epoch: 70 [3200/35339 (9%)]	Loss: 0.233261
Train Epoch: 70 [3840/35339 (11%)]	Loss: 0.258118
Train Epoch: 70 [4480/35339 (13%)]	Loss: 0.349248
Train Epoch: 70 [5120/35339 (14%)]	Loss: 0.130909
Train Epoch: 70 [5760/35339 (16%)]	Loss: 0.369524
Train Epoch: 70 [6400/35339 (18%)]	Loss: 0.239423
Train Epoch: 70 [7040/35339 (20%)]	Loss: 0.306845
Train Epoch: 70 [7680/35339 (22%)]	Loss: 0.334068
Train Epoch: 70 [8320/35339 (24%)]	Loss: 0.289692
Train Epoch: 70 [8960/35339 (25%)]	Loss: 0.236874
Train Epoch: 70 [9600/35339 (27%)]	Loss: 0.213991
Train Epoch: 70 [10240/35339 (29%)]	Loss: 0.289384
Train Epoch: 70 [10880/35339 (31%)]	Loss: 0.228620
Train Epoch: 70 [11520/35339 (33%)]	Loss: 0.239027
Train Epoch: 70 [12160/35339 (34%)]	Loss: 0.375560
Train Epoch: 70 [12800/35339 (36%)]	Loss: 0.165634
Train Epoch: 70 [13440/35339 (38%)]	Loss: 0.257259
Train Epoch: 70 [14080/35339 (40%)]	Loss: 0.269163
Train Epoch: 70 [14720/35339 (42%)]	Loss: 0.361948
Train Epoch: 70 [15360/35339 (43%)]	Loss: 0.277583
Train Epoch: 70 [16000/35339 (45%)]	Loss: 0.220459
Train Epoch: 70 [16640/35339 (47%)]	Loss: 0.364756
Train Epoch: 70 [17280/35339 (49%)]	Loss: 0.225444
Train Epoch: 70 [17920/35339 (51%)]	Loss: 0.369063
Train Epoch: 70 [18560/35339 (52%)]	Loss: 0.282447
Train Epoch: 70 [19200/35339 (54%)]	Loss: 0.141301
Train Epoch: 70 [19840/35339 (56%)]	Loss: 0.158542
Train Epoch: 70 [20480/35339 (58%)]	Loss: 0.362138
Train Epoch: 70 [21120/35339 (60%)]	Loss: 0.207746
Train Epoch: 70 [21760/35339 (61%)]	Loss: 0.276507
Train Epoch: 70 [22400/35339 (63%)]	Loss: 0.240318
Train Epoch: 70 [23040/35339 (65%)]	Loss: 0.397260
Train Epoch: 70 [23680/35339 (67%)]	Loss: 0.236757
Train Epoch: 70 [24320/35339 (69%)]	Loss: 0.114048
Train Epoch: 70 [24960/35339 (71%)]	Loss: 0.380860
Train Epoch: 70 [25600/35339 (72%)]	Loss: 0.162754
Train Epoch: 70 [26240/35339 (74%)]	Loss: 0.218128
Train Epoch: 70 [26880/35339 (76%)]	Loss: 0.520739
Train Epoch: 70 [27520/35339 (78%)]	Loss: 0.196288
Train Epoch: 70 [28160/35339 (80%)]	Loss: 0.397750
Train Epoch: 70 [28800/35339 (81%)]	Loss: 0.261946
Train Epoch: 70 [29440/35339 (83%)]	Loss: 0.264179
Train Epoch: 70 [30080/35339 (85%)]	Loss: 0.184197
Train Epoch: 70 [30720/35339 (87%)]	Loss: 0.215881
Train Epoch: 70 [31360/35339 (89%)]	Loss: 0.368487
Train Epoch: 70 [32000/35339 (90%)]	Loss: 0.183797
Train Epoch: 70 [32640/35339 (92%)]	Loss: 0.193648
Train Epoch: 70 [33280/35339 (94%)]	Loss: 0.223135
Train Epoch: 70 [33920/35339 (96%)]	Loss: 0.268532
Train Epoch: 70 [34560/35339 (98%)]	Loss: 0.296751
Train Epoch: 70 [35200/35339 (99%)]	Loss: 0.147949

Validation set: Average loss: 1.4688, Accuracy: 2627/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 71 [0/35339 (0%)]	Loss: 0.191515
Train Epoch: 71 [640/35339 (2%)]	Loss: 0.188688
Train Epoch: 71 [1280/35339 (4%)]	Loss: 0.590430
Train Epoch: 71 [1920/35339 (5%)]	Loss: 0.274485
Train Epoch: 71 [2560/35339 (7%)]	Loss: 0.183826
Train Epoch: 71 [3200/35339 (9%)]	Loss: 0.320965
Train Epoch: 71 [3840/35339 (11%)]	Loss: 0.200111
Train Epoch: 71 [4480/35339 (13%)]	Loss: 0.303983
Train Epoch: 71 [5120/35339 (14%)]	Loss: 0.300533
Train Epoch: 71 [5760/35339 (16%)]	Loss: 0.362014
Train Epoch: 71 [6400/35339 (18%)]	Loss: 0.165235
Train Epoch: 71 [7040/35339 (20%)]	Loss: 0.189448
Train Epoch: 71 [7680/35339 (22%)]	Loss: 0.226831
Train Epoch: 71 [8320/35339 (24%)]	Loss: 0.109448
Train Epoch: 71 [8960/35339 (25%)]	Loss: 0.251470
Train Epoch: 71 [9600/35339 (27%)]	Loss: 0.135351
Train Epoch: 71 [10240/35339 (29%)]	Loss: 0.123279
Train Epoch: 71 [10880/35339 (31%)]	Loss: 0.251395
Train Epoch: 71 [11520/35339 (33%)]	Loss: 0.303179
Train Epoch: 71 [12160/35339 (34%)]	Loss: 0.359084
Train Epoch: 71 [12800/35339 (36%)]	Loss: 0.342367
Train Epoch: 71 [13440/35339 (38%)]	Loss: 0.274240
Train Epoch: 71 [14080/35339 (40%)]	Loss: 0.278953
Train Epoch: 71 [14720/35339 (42%)]	Loss: 0.211349
Train Epoch: 71 [15360/35339 (43%)]	Loss: 0.424855
Train Epoch: 71 [16000/35339 (45%)]	Loss: 0.224309
Train Epoch: 71 [16640/35339 (47%)]	Loss: 0.240370
Train Epoch: 71 [17280/35339 (49%)]	Loss: 0.256124
Train Epoch: 71 [17920/35339 (51%)]	Loss: 0.173682
Train Epoch: 71 [18560/35339 (52%)]	Loss: 0.325952
Train Epoch: 71 [19200/35339 (54%)]	Loss: 0.252437
Train Epoch: 71 [19840/35339 (56%)]	Loss: 0.154528
Train Epoch: 71 [20480/35339 (58%)]	Loss: 0.137656
Train Epoch: 71 [21120/35339 (60%)]	Loss: 0.130877
Train Epoch: 71 [21760/35339 (61%)]	Loss: 0.274072
Train Epoch: 71 [22400/35339 (63%)]	Loss: 0.247433
Train Epoch: 71 [23040/35339 (65%)]	Loss: 0.451567
Train Epoch: 71 [23680/35339 (67%)]	Loss: 0.104290
Train Epoch: 71 [24320/35339 (69%)]	Loss: 0.182439
Train Epoch: 71 [24960/35339 (71%)]	Loss: 0.277265
Train Epoch: 71 [25600/35339 (72%)]	Loss: 0.261482
Train Epoch: 71 [26240/35339 (74%)]	Loss: 0.366248
Train Epoch: 71 [26880/35339 (76%)]	Loss: 0.305307
Train Epoch: 71 [27520/35339 (78%)]	Loss: 0.164229
Train Epoch: 71 [28160/35339 (80%)]	Loss: 0.409747
Train Epoch: 71 [28800/35339 (81%)]	Loss: 0.227341
Train Epoch: 71 [29440/35339 (83%)]	Loss: 0.163304
Train Epoch: 71 [30080/35339 (85%)]	Loss: 0.135146
Train Epoch: 71 [30720/35339 (87%)]	Loss: 0.286146
Train Epoch: 71 [31360/35339 (89%)]	Loss: 0.270645
Train Epoch: 71 [32000/35339 (90%)]	Loss: 0.209507
Train Epoch: 71 [32640/35339 (92%)]	Loss: 0.274073
Train Epoch: 71 [33280/35339 (94%)]	Loss: 0.243414
Train Epoch: 71 [33920/35339 (96%)]	Loss: 0.100635
Train Epoch: 71 [34560/35339 (98%)]	Loss: 0.358225
Train Epoch: 71 [35200/35339 (99%)]	Loss: 0.281593

Validation set: Average loss: 1.4836, Accuracy: 2609/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 72 [0/35339 (0%)]	Loss: 0.303907
Train Epoch: 72 [640/35339 (2%)]	Loss: 0.314954
Train Epoch: 72 [1280/35339 (4%)]	Loss: 0.390481
Train Epoch: 72 [1920/35339 (5%)]	Loss: 0.341511
Train Epoch: 72 [2560/35339 (7%)]	Loss: 0.309230
Train Epoch: 72 [3200/35339 (9%)]	Loss: 0.214674
Train Epoch: 72 [3840/35339 (11%)]	Loss: 0.367898
Train Epoch: 72 [4480/35339 (13%)]	Loss: 0.239445
Train Epoch: 72 [5120/35339 (14%)]	Loss: 0.420652
Train Epoch: 72 [5760/35339 (16%)]	Loss: 0.445806
Train Epoch: 72 [6400/35339 (18%)]	Loss: 0.471330
Train Epoch: 72 [7040/35339 (20%)]	Loss: 0.274934
Train Epoch: 72 [7680/35339 (22%)]	Loss: 0.152357
Train Epoch: 72 [8320/35339 (24%)]	Loss: 0.307484
Train Epoch: 72 [8960/35339 (25%)]	Loss: 0.438576
Train Epoch: 72 [9600/35339 (27%)]	Loss: 0.271567
Train Epoch: 72 [10240/35339 (29%)]	Loss: 0.173588
Train Epoch: 72 [10880/35339 (31%)]	Loss: 0.279669
Train Epoch: 72 [11520/35339 (33%)]	Loss: 0.231976
Train Epoch: 72 [12160/35339 (34%)]	Loss: 0.318931
Train Epoch: 72 [12800/35339 (36%)]	Loss: 0.381588
Train Epoch: 72 [13440/35339 (38%)]	Loss: 0.190100
Train Epoch: 72 [14080/35339 (40%)]	Loss: 0.285661
Train Epoch: 72 [14720/35339 (42%)]	Loss: 0.186037
Train Epoch: 72 [15360/35339 (43%)]	Loss: 0.268765
Train Epoch: 72 [16000/35339 (45%)]	Loss: 0.398747
Train Epoch: 72 [16640/35339 (47%)]	Loss: 0.301139
Train Epoch: 72 [17280/35339 (49%)]	Loss: 0.168985
Train Epoch: 72 [17920/35339 (51%)]	Loss: 0.325960
Train Epoch: 72 [18560/35339 (52%)]	Loss: 0.387947
Train Epoch: 72 [19200/35339 (54%)]	Loss: 0.291465
Train Epoch: 72 [19840/35339 (56%)]	Loss: 0.164910
Train Epoch: 72 [20480/35339 (58%)]	Loss: 0.457017
Train Epoch: 72 [21120/35339 (60%)]	Loss: 0.272489
Train Epoch: 72 [21760/35339 (61%)]	Loss: 0.322312
Train Epoch: 72 [22400/35339 (63%)]	Loss: 0.347349
Train Epoch: 72 [23040/35339 (65%)]	Loss: 0.355024
Train Epoch: 72 [23680/35339 (67%)]	Loss: 0.203003
Train Epoch: 72 [24320/35339 (69%)]	Loss: 0.197274
Train Epoch: 72 [24960/35339 (71%)]	Loss: 0.407623
Train Epoch: 72 [25600/35339 (72%)]	Loss: 0.193999
Train Epoch: 72 [26240/35339 (74%)]	Loss: 0.261987
Train Epoch: 72 [26880/35339 (76%)]	Loss: 0.232408
Train Epoch: 72 [27520/35339 (78%)]	Loss: 0.184975
Train Epoch: 72 [28160/35339 (80%)]	Loss: 0.266607
Train Epoch: 72 [28800/35339 (81%)]	Loss: 0.182791
Train Epoch: 72 [29440/35339 (83%)]	Loss: 0.184208
Train Epoch: 72 [30080/35339 (85%)]	Loss: 0.381432
Train Epoch: 72 [30720/35339 (87%)]	Loss: 0.184398
Train Epoch: 72 [31360/35339 (89%)]	Loss: 0.346331
Train Epoch: 72 [32000/35339 (90%)]	Loss: 0.311752
Train Epoch: 72 [32640/35339 (92%)]	Loss: 0.227922
Train Epoch: 72 [33280/35339 (94%)]	Loss: 0.363292
Train Epoch: 72 [33920/35339 (96%)]	Loss: 0.306325
Train Epoch: 72 [34560/35339 (98%)]	Loss: 0.256963
Train Epoch: 72 [35200/35339 (99%)]	Loss: 0.329004

Validation set: Average loss: 1.4802, Accuracy: 2633/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 73 [0/35339 (0%)]	Loss: 0.300600
Train Epoch: 73 [640/35339 (2%)]	Loss: 0.396246
Train Epoch: 73 [1280/35339 (4%)]	Loss: 0.341259
Train Epoch: 73 [1920/35339 (5%)]	Loss: 0.227544
Train Epoch: 73 [2560/35339 (7%)]	Loss: 0.396823
Train Epoch: 73 [3200/35339 (9%)]	Loss: 0.277891
Train Epoch: 73 [3840/35339 (11%)]	Loss: 0.342538
Train Epoch: 73 [4480/35339 (13%)]	Loss: 0.268793
Train Epoch: 73 [5120/35339 (14%)]	Loss: 0.428365
Train Epoch: 73 [5760/35339 (16%)]	Loss: 0.190934
Train Epoch: 73 [6400/35339 (18%)]	Loss: 0.176244
Train Epoch: 73 [7040/35339 (20%)]	Loss: 0.236016
Train Epoch: 73 [7680/35339 (22%)]	Loss: 0.232407
Train Epoch: 73 [8320/35339 (24%)]	Loss: 0.446337
Train Epoch: 73 [8960/35339 (25%)]	Loss: 0.302316
Train Epoch: 73 [9600/35339 (27%)]	Loss: 0.272574
Train Epoch: 73 [10240/35339 (29%)]	Loss: 0.298339
Train Epoch: 73 [10880/35339 (31%)]	Loss: 0.325158
Train Epoch: 73 [11520/35339 (33%)]	Loss: 0.253766
Train Epoch: 73 [12160/35339 (34%)]	Loss: 0.409157
Train Epoch: 73 [12800/35339 (36%)]	Loss: 0.234195
Train Epoch: 73 [13440/35339 (38%)]	Loss: 0.239214
Train Epoch: 73 [14080/35339 (40%)]	Loss: 0.213125
Train Epoch: 73 [14720/35339 (42%)]	Loss: 0.239310
Train Epoch: 73 [15360/35339 (43%)]	Loss: 0.355732
Train Epoch: 73 [16000/35339 (45%)]	Loss: 0.130849
Train Epoch: 73 [16640/35339 (47%)]	Loss: 0.250744
Train Epoch: 73 [17280/35339 (49%)]	Loss: 0.310855
Train Epoch: 73 [17920/35339 (51%)]	Loss: 0.317452
Train Epoch: 73 [18560/35339 (52%)]	Loss: 0.176325
Train Epoch: 73 [19200/35339 (54%)]	Loss: 0.198853
Train Epoch: 73 [19840/35339 (56%)]	Loss: 0.239590
Train Epoch: 73 [20480/35339 (58%)]	Loss: 0.221495
Train Epoch: 73 [21120/35339 (60%)]	Loss: 0.232017
Train Epoch: 73 [21760/35339 (61%)]	Loss: 0.326266
Train Epoch: 73 [22400/35339 (63%)]	Loss: 0.359212
Train Epoch: 73 [23040/35339 (65%)]	Loss: 0.341348
Train Epoch: 73 [23680/35339 (67%)]	Loss: 0.244333
Train Epoch: 73 [24320/35339 (69%)]	Loss: 0.378785
Train Epoch: 73 [24960/35339 (71%)]	Loss: 0.234525
Train Epoch: 73 [25600/35339 (72%)]	Loss: 0.199351
Train Epoch: 73 [26240/35339 (74%)]	Loss: 0.181810
Train Epoch: 73 [26880/35339 (76%)]	Loss: 0.120529
Train Epoch: 73 [27520/35339 (78%)]	Loss: 0.149860
Train Epoch: 73 [28160/35339 (80%)]	Loss: 0.167680
Train Epoch: 73 [28800/35339 (81%)]	Loss: 0.246904
Train Epoch: 73 [29440/35339 (83%)]	Loss: 0.254202
Train Epoch: 73 [30080/35339 (85%)]	Loss: 0.219997
Train Epoch: 73 [30720/35339 (87%)]	Loss: 0.212507
Train Epoch: 73 [31360/35339 (89%)]	Loss: 0.186566
Train Epoch: 73 [32000/35339 (90%)]	Loss: 0.203565
Train Epoch: 73 [32640/35339 (92%)]	Loss: 0.173435
Train Epoch: 73 [33280/35339 (94%)]	Loss: 0.303194
Train Epoch: 73 [33920/35339 (96%)]	Loss: 0.358189
Train Epoch: 73 [34560/35339 (98%)]	Loss: 0.265294
Train Epoch: 73 [35200/35339 (99%)]	Loss: 0.389703

Validation set: Average loss: 1.6360, Accuracy: 2588/3870 (67%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 74 [0/35339 (0%)]	Loss: 0.367023
Train Epoch: 74 [640/35339 (2%)]	Loss: 0.287232
Train Epoch: 74 [1280/35339 (4%)]	Loss: 0.287691
Train Epoch: 74 [1920/35339 (5%)]	Loss: 0.238953
Train Epoch: 74 [2560/35339 (7%)]	Loss: 0.258383
Train Epoch: 74 [3200/35339 (9%)]	Loss: 0.187716
Train Epoch: 74 [3840/35339 (11%)]	Loss: 0.152526
Train Epoch: 74 [4480/35339 (13%)]	Loss: 0.226717
Train Epoch: 74 [5120/35339 (14%)]	Loss: 0.363991
Train Epoch: 74 [5760/35339 (16%)]	Loss: 0.306309
Train Epoch: 74 [6400/35339 (18%)]	Loss: 0.213218
Train Epoch: 74 [7040/35339 (20%)]	Loss: 0.307339
Train Epoch: 74 [7680/35339 (22%)]	Loss: 0.286386
Train Epoch: 74 [8320/35339 (24%)]	Loss: 0.238670
Train Epoch: 74 [8960/35339 (25%)]	Loss: 0.404190
Train Epoch: 74 [9600/35339 (27%)]	Loss: 0.218370
Train Epoch: 74 [10240/35339 (29%)]	Loss: 0.465952
Train Epoch: 74 [10880/35339 (31%)]	Loss: 0.508403
Train Epoch: 74 [11520/35339 (33%)]	Loss: 0.305909
Train Epoch: 74 [12160/35339 (34%)]	Loss: 0.194625
Train Epoch: 74 [12800/35339 (36%)]	Loss: 0.363798
Train Epoch: 74 [13440/35339 (38%)]	Loss: 0.205329
Train Epoch: 74 [14080/35339 (40%)]	Loss: 0.197435
Train Epoch: 74 [14720/35339 (42%)]	Loss: 0.364973
Train Epoch: 74 [15360/35339 (43%)]	Loss: 0.161713
Train Epoch: 74 [16000/35339 (45%)]	Loss: 0.339730
Train Epoch: 74 [16640/35339 (47%)]	Loss: 0.434093
Train Epoch: 74 [17280/35339 (49%)]	Loss: 0.284482
Train Epoch: 74 [17920/35339 (51%)]	Loss: 0.361360
Train Epoch: 74 [18560/35339 (52%)]	Loss: 0.218889
Train Epoch: 74 [19200/35339 (54%)]	Loss: 0.211519
Train Epoch: 74 [19840/35339 (56%)]	Loss: 0.337479
Train Epoch: 74 [20480/35339 (58%)]	Loss: 0.183620
Train Epoch: 74 [21120/35339 (60%)]	Loss: 0.261360
Train Epoch: 74 [21760/35339 (61%)]	Loss: 0.299035
Train Epoch: 74 [22400/35339 (63%)]	Loss: 0.226429
Train Epoch: 74 [23040/35339 (65%)]	Loss: 0.186180
Train Epoch: 74 [23680/35339 (67%)]	Loss: 0.175637
Train Epoch: 74 [24320/35339 (69%)]	Loss: 0.215365
Train Epoch: 74 [24960/35339 (71%)]	Loss: 0.252446
Train Epoch: 74 [25600/35339 (72%)]	Loss: 0.154412
Train Epoch: 74 [26240/35339 (74%)]	Loss: 0.193220
Train Epoch: 74 [26880/35339 (76%)]	Loss: 0.398308
Train Epoch: 74 [27520/35339 (78%)]	Loss: 0.215383
Train Epoch: 74 [28160/35339 (80%)]	Loss: 0.324428
Train Epoch: 74 [28800/35339 (81%)]	Loss: 0.162269
Train Epoch: 74 [29440/35339 (83%)]	Loss: 0.166577
Train Epoch: 74 [30080/35339 (85%)]	Loss: 0.321848
Train Epoch: 74 [30720/35339 (87%)]	Loss: 0.348405
Train Epoch: 74 [31360/35339 (89%)]	Loss: 0.335522
Train Epoch: 74 [32000/35339 (90%)]	Loss: 0.300395
Train Epoch: 74 [32640/35339 (92%)]	Loss: 0.227450
Train Epoch: 74 [33280/35339 (94%)]	Loss: 0.224539
Train Epoch: 74 [33920/35339 (96%)]	Loss: 0.235367
Train Epoch: 74 [34560/35339 (98%)]	Loss: 0.135952
Train Epoch: 74 [35200/35339 (99%)]	Loss: 0.360190

Validation set: Average loss: 1.5125, Accuracy: 2617/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 75 [0/35339 (0%)]	Loss: 0.179475
Train Epoch: 75 [640/35339 (2%)]	Loss: 0.189350
Train Epoch: 75 [1280/35339 (4%)]	Loss: 0.182403
Train Epoch: 75 [1920/35339 (5%)]	Loss: 0.202762
Train Epoch: 75 [2560/35339 (7%)]	Loss: 0.220639
Train Epoch: 75 [3200/35339 (9%)]	Loss: 0.407927
Train Epoch: 75 [3840/35339 (11%)]	Loss: 0.419144
Train Epoch: 75 [4480/35339 (13%)]	Loss: 0.367359
Train Epoch: 75 [5120/35339 (14%)]	Loss: 0.196469
Train Epoch: 75 [5760/35339 (16%)]	Loss: 0.205851
Train Epoch: 75 [6400/35339 (18%)]	Loss: 0.153683
Train Epoch: 75 [7040/35339 (20%)]	Loss: 0.413585
Train Epoch: 75 [7680/35339 (22%)]	Loss: 0.254390
Train Epoch: 75 [8320/35339 (24%)]	Loss: 0.320698
Train Epoch: 75 [8960/35339 (25%)]	Loss: 0.232907
Train Epoch: 75 [9600/35339 (27%)]	Loss: 0.224666
Train Epoch: 75 [10240/35339 (29%)]	Loss: 0.152109
Train Epoch: 75 [10880/35339 (31%)]	Loss: 0.458432
Train Epoch: 75 [11520/35339 (33%)]	Loss: 0.209702
Train Epoch: 75 [12160/35339 (34%)]	Loss: 0.254418
Train Epoch: 75 [12800/35339 (36%)]	Loss: 0.151781
Train Epoch: 75 [13440/35339 (38%)]	Loss: 0.159160
Train Epoch: 75 [14080/35339 (40%)]	Loss: 0.340596
Train Epoch: 75 [14720/35339 (42%)]	Loss: 0.187932
Train Epoch: 75 [15360/35339 (43%)]	Loss: 0.285427
Train Epoch: 75 [16000/35339 (45%)]	Loss: 0.185553
Train Epoch: 75 [16640/35339 (47%)]	Loss: 0.351116
Train Epoch: 75 [17280/35339 (49%)]	Loss: 0.263581
Train Epoch: 75 [17920/35339 (51%)]	Loss: 0.329143
Train Epoch: 75 [18560/35339 (52%)]	Loss: 0.326496
Train Epoch: 75 [19200/35339 (54%)]	Loss: 0.286885
Train Epoch: 75 [19840/35339 (56%)]	Loss: 0.263758
Train Epoch: 75 [20480/35339 (58%)]	Loss: 0.197977
Train Epoch: 75 [21120/35339 (60%)]	Loss: 0.397950
Train Epoch: 75 [21760/35339 (61%)]	Loss: 0.233016
Train Epoch: 75 [22400/35339 (63%)]	Loss: 0.268835
Train Epoch: 75 [23040/35339 (65%)]	Loss: 0.364077
Train Epoch: 75 [23680/35339 (67%)]	Loss: 0.217792
Train Epoch: 75 [24320/35339 (69%)]	Loss: 0.179646
Train Epoch: 75 [24960/35339 (71%)]	Loss: 0.130557
Train Epoch: 75 [25600/35339 (72%)]	Loss: 0.147184
Train Epoch: 75 [26240/35339 (74%)]	Loss: 0.321205
Train Epoch: 75 [26880/35339 (76%)]	Loss: 0.239471
Train Epoch: 75 [27520/35339 (78%)]	Loss: 0.370874
Train Epoch: 75 [28160/35339 (80%)]	Loss: 0.427548
Train Epoch: 75 [28800/35339 (81%)]	Loss: 0.213930
Train Epoch: 75 [29440/35339 (83%)]	Loss: 0.348808
Train Epoch: 75 [30080/35339 (85%)]	Loss: 0.308083
Train Epoch: 75 [30720/35339 (87%)]	Loss: 0.213805
Train Epoch: 75 [31360/35339 (89%)]	Loss: 0.244580
Train Epoch: 75 [32000/35339 (90%)]	Loss: 0.270393
Train Epoch: 75 [32640/35339 (92%)]	Loss: 0.270875
Train Epoch: 75 [33280/35339 (94%)]	Loss: 0.295009
Train Epoch: 75 [33920/35339 (96%)]	Loss: 0.226311
Train Epoch: 75 [34560/35339 (98%)]	Loss: 0.299291
Train Epoch: 75 [35200/35339 (99%)]	Loss: 0.253130

Validation set: Average loss: 1.4758, Accuracy: 2651/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 76 [0/35339 (0%)]	Loss: 0.181434
Train Epoch: 76 [640/35339 (2%)]	Loss: 0.286823
Train Epoch: 76 [1280/35339 (4%)]	Loss: 0.191917
Train Epoch: 76 [1920/35339 (5%)]	Loss: 0.399803
Train Epoch: 76 [2560/35339 (7%)]	Loss: 0.377004
Train Epoch: 76 [3200/35339 (9%)]	Loss: 0.294585
Train Epoch: 76 [3840/35339 (11%)]	Loss: 0.423825
Train Epoch: 76 [4480/35339 (13%)]	Loss: 0.608266
Train Epoch: 76 [5120/35339 (14%)]	Loss: 0.142956
Train Epoch: 76 [5760/35339 (16%)]	Loss: 0.237002
Train Epoch: 76 [6400/35339 (18%)]	Loss: 0.828872
Train Epoch: 76 [7040/35339 (20%)]	Loss: 0.170163
Train Epoch: 76 [7680/35339 (22%)]	Loss: 0.283786
Train Epoch: 76 [8320/35339 (24%)]	Loss: 0.342395
Train Epoch: 76 [8960/35339 (25%)]	Loss: 0.232181
Train Epoch: 76 [9600/35339 (27%)]	Loss: 0.455118
Train Epoch: 76 [10240/35339 (29%)]	Loss: 0.227027
Train Epoch: 76 [10880/35339 (31%)]	Loss: 0.270979
Train Epoch: 76 [11520/35339 (33%)]	Loss: 0.281091
Train Epoch: 76 [12160/35339 (34%)]	Loss: 0.270874
Train Epoch: 76 [12800/35339 (36%)]	Loss: 0.112928
Train Epoch: 76 [13440/35339 (38%)]	Loss: 0.207040
Train Epoch: 76 [14080/35339 (40%)]	Loss: 0.308940
Train Epoch: 76 [14720/35339 (42%)]	Loss: 0.165979
Train Epoch: 76 [15360/35339 (43%)]	Loss: 0.244366
Train Epoch: 76 [16000/35339 (45%)]	Loss: 0.231992
Train Epoch: 76 [16640/35339 (47%)]	Loss: 0.367071
Train Epoch: 76 [17280/35339 (49%)]	Loss: 0.166617
Train Epoch: 76 [17920/35339 (51%)]	Loss: 0.319723
Train Epoch: 76 [18560/35339 (52%)]	Loss: 0.219238
Train Epoch: 76 [19200/35339 (54%)]	Loss: 0.261431
Train Epoch: 76 [19840/35339 (56%)]	Loss: 0.217138
Train Epoch: 76 [20480/35339 (58%)]	Loss: 0.144061
Train Epoch: 76 [21120/35339 (60%)]	Loss: 0.329675
Train Epoch: 76 [21760/35339 (61%)]	Loss: 0.352339
Train Epoch: 76 [22400/35339 (63%)]	Loss: 0.223045
Train Epoch: 76 [23040/35339 (65%)]	Loss: 0.300072
Train Epoch: 76 [23680/35339 (67%)]	Loss: 0.135104
Train Epoch: 76 [24320/35339 (69%)]	Loss: 0.236577
Train Epoch: 76 [24960/35339 (71%)]	Loss: 0.185395
Train Epoch: 76 [25600/35339 (72%)]	Loss: 0.341098
Train Epoch: 76 [26240/35339 (74%)]	Loss: 0.121857
Train Epoch: 76 [26880/35339 (76%)]	Loss: 0.296450
Train Epoch: 76 [27520/35339 (78%)]	Loss: 0.464929
Train Epoch: 76 [28160/35339 (80%)]	Loss: 0.313141
Train Epoch: 76 [28800/35339 (81%)]	Loss: 0.252823
Train Epoch: 76 [29440/35339 (83%)]	Loss: 0.319201
Train Epoch: 76 [30080/35339 (85%)]	Loss: 0.161278
Train Epoch: 76 [30720/35339 (87%)]	Loss: 0.459447
Train Epoch: 76 [31360/35339 (89%)]	Loss: 0.369381
Train Epoch: 76 [32000/35339 (90%)]	Loss: 0.427499
Train Epoch: 76 [32640/35339 (92%)]	Loss: 0.372886
Train Epoch: 76 [33280/35339 (94%)]	Loss: 0.316436
Train Epoch: 76 [33920/35339 (96%)]	Loss: 0.247941
Train Epoch: 76 [34560/35339 (98%)]	Loss: 0.398969
Train Epoch: 76 [35200/35339 (99%)]	Loss: 0.157956

Validation set: Average loss: 1.4855, Accuracy: 2622/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 77 [0/35339 (0%)]	Loss: 0.247436
Train Epoch: 77 [640/35339 (2%)]	Loss: 0.155038
Train Epoch: 77 [1280/35339 (4%)]	Loss: 0.254073
Train Epoch: 77 [1920/35339 (5%)]	Loss: 0.345047
Train Epoch: 77 [2560/35339 (7%)]	Loss: 0.215222
Train Epoch: 77 [3200/35339 (9%)]	Loss: 0.201761
Train Epoch: 77 [3840/35339 (11%)]	Loss: 0.320984
Train Epoch: 77 [4480/35339 (13%)]	Loss: 0.211528
Train Epoch: 77 [5120/35339 (14%)]	Loss: 0.300496
Train Epoch: 77 [5760/35339 (16%)]	Loss: 0.187615
Train Epoch: 77 [6400/35339 (18%)]	Loss: 0.259001
Train Epoch: 77 [7040/35339 (20%)]	Loss: 0.286287
Train Epoch: 77 [7680/35339 (22%)]	Loss: 0.347073
Train Epoch: 77 [8320/35339 (24%)]	Loss: 0.481807
Train Epoch: 77 [8960/35339 (25%)]	Loss: 0.282526
Train Epoch: 77 [9600/35339 (27%)]	Loss: 0.228467
Train Epoch: 77 [10240/35339 (29%)]	Loss: 0.129957
Train Epoch: 77 [10880/35339 (31%)]	Loss: 0.263774
Train Epoch: 77 [11520/35339 (33%)]	Loss: 0.279372
Train Epoch: 77 [12160/35339 (34%)]	Loss: 0.255674
Train Epoch: 77 [12800/35339 (36%)]	Loss: 0.229645
Train Epoch: 77 [13440/35339 (38%)]	Loss: 0.376483
Train Epoch: 77 [14080/35339 (40%)]	Loss: 0.264430
Train Epoch: 77 [14720/35339 (42%)]	Loss: 0.129288
Train Epoch: 77 [15360/35339 (43%)]	Loss: 0.318234
Train Epoch: 77 [16000/35339 (45%)]	Loss: 0.252827
Train Epoch: 77 [16640/35339 (47%)]	Loss: 0.304694
Train Epoch: 77 [17280/35339 (49%)]	Loss: 0.237578
Train Epoch: 77 [17920/35339 (51%)]	Loss: 0.294060
Train Epoch: 77 [18560/35339 (52%)]	Loss: 0.279944
Train Epoch: 77 [19200/35339 (54%)]	Loss: 0.454442
Train Epoch: 77 [19840/35339 (56%)]	Loss: 0.173071
Train Epoch: 77 [20480/35339 (58%)]	Loss: 0.144218
Train Epoch: 77 [21120/35339 (60%)]	Loss: 0.242317
Train Epoch: 77 [21760/35339 (61%)]	Loss: 0.218097
Train Epoch: 77 [22400/35339 (63%)]	Loss: 0.213657
Train Epoch: 77 [23040/35339 (65%)]	Loss: 0.189991
Train Epoch: 77 [23680/35339 (67%)]	Loss: 0.240887
Train Epoch: 77 [24320/35339 (69%)]	Loss: 0.229299
Train Epoch: 77 [24960/35339 (71%)]	Loss: 0.210768
Train Epoch: 77 [25600/35339 (72%)]	Loss: 0.545119
Train Epoch: 77 [26240/35339 (74%)]	Loss: 0.314891
Train Epoch: 77 [26880/35339 (76%)]	Loss: 0.280545
Train Epoch: 77 [27520/35339 (78%)]	Loss: 0.286066
Train Epoch: 77 [28160/35339 (80%)]	Loss: 0.337314
Train Epoch: 77 [28800/35339 (81%)]	Loss: 0.211651
Train Epoch: 77 [29440/35339 (83%)]	Loss: 0.254680
Train Epoch: 77 [30080/35339 (85%)]	Loss: 0.108911
Train Epoch: 77 [30720/35339 (87%)]	Loss: 0.282508
Train Epoch: 77 [31360/35339 (89%)]	Loss: 0.177378
Train Epoch: 77 [32000/35339 (90%)]	Loss: 0.228073
Train Epoch: 77 [32640/35339 (92%)]	Loss: 0.166146
Train Epoch: 77 [33280/35339 (94%)]	Loss: 0.298892
Train Epoch: 77 [33920/35339 (96%)]	Loss: 0.249739
Train Epoch: 77 [34560/35339 (98%)]	Loss: 0.366398
Train Epoch: 77 [35200/35339 (99%)]	Loss: 0.486112

Validation set: Average loss: 1.4844, Accuracy: 2643/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 78 [0/35339 (0%)]	Loss: 0.243217
Train Epoch: 78 [640/35339 (2%)]	Loss: 0.241946
Train Epoch: 78 [1280/35339 (4%)]	Loss: 0.125233
Train Epoch: 78 [1920/35339 (5%)]	Loss: 0.247917
Train Epoch: 78 [2560/35339 (7%)]	Loss: 0.185250
Train Epoch: 78 [3200/35339 (9%)]	Loss: 0.242304
Train Epoch: 78 [3840/35339 (11%)]	Loss: 0.312919
Train Epoch: 78 [4480/35339 (13%)]	Loss: 0.385655
Train Epoch: 78 [5120/35339 (14%)]	Loss: 0.307178
Train Epoch: 78 [5760/35339 (16%)]	Loss: 0.941151
Train Epoch: 78 [6400/35339 (18%)]	Loss: 0.204896
Train Epoch: 78 [7040/35339 (20%)]	Loss: 0.196713
Train Epoch: 78 [7680/35339 (22%)]	Loss: 0.255613
Train Epoch: 78 [8320/35339 (24%)]	Loss: 0.339542
Train Epoch: 78 [8960/35339 (25%)]	Loss: 0.182893
Train Epoch: 78 [9600/35339 (27%)]	Loss: 0.170868
Train Epoch: 78 [10240/35339 (29%)]	Loss: 0.148336
Train Epoch: 78 [10880/35339 (31%)]	Loss: 0.258956
Train Epoch: 78 [11520/35339 (33%)]	Loss: 0.259836
Train Epoch: 78 [12160/35339 (34%)]	Loss: 0.494329
Train Epoch: 78 [12800/35339 (36%)]	Loss: 0.172612
Train Epoch: 78 [13440/35339 (38%)]	Loss: 0.279278
Train Epoch: 78 [14080/35339 (40%)]	Loss: 0.234817
Train Epoch: 78 [14720/35339 (42%)]	Loss: 0.427317
Train Epoch: 78 [15360/35339 (43%)]	Loss: 0.269844
Train Epoch: 78 [16000/35339 (45%)]	Loss: 0.235816
Train Epoch: 78 [16640/35339 (47%)]	Loss: 0.302003
Train Epoch: 78 [17280/35339 (49%)]	Loss: 0.349606
Train Epoch: 78 [17920/35339 (51%)]	Loss: 0.301181
Train Epoch: 78 [18560/35339 (52%)]	Loss: 0.264606
Train Epoch: 78 [19200/35339 (54%)]	Loss: 0.119302
Train Epoch: 78 [19840/35339 (56%)]	Loss: 0.351949
Train Epoch: 78 [20480/35339 (58%)]	Loss: 0.286869
Train Epoch: 78 [21120/35339 (60%)]	Loss: 0.215012
Train Epoch: 78 [21760/35339 (61%)]	Loss: 0.240520
Train Epoch: 78 [22400/35339 (63%)]	Loss: 0.337203
Train Epoch: 78 [23040/35339 (65%)]	Loss: 0.221491
Train Epoch: 78 [23680/35339 (67%)]	Loss: 0.268447
Train Epoch: 78 [24320/35339 (69%)]	Loss: 0.278142
Train Epoch: 78 [24960/35339 (71%)]	Loss: 0.201339
Train Epoch: 78 [25600/35339 (72%)]	Loss: 0.271588
Train Epoch: 78 [26240/35339 (74%)]	Loss: 0.183266
Train Epoch: 78 [26880/35339 (76%)]	Loss: 0.415634
Train Epoch: 78 [27520/35339 (78%)]	Loss: 0.227745
Train Epoch: 78 [28160/35339 (80%)]	Loss: 0.175930
Train Epoch: 78 [28800/35339 (81%)]	Loss: 0.345555
Train Epoch: 78 [29440/35339 (83%)]	Loss: 0.338023
Train Epoch: 78 [30080/35339 (85%)]	Loss: 0.245490
Train Epoch: 78 [30720/35339 (87%)]	Loss: 0.338516
Train Epoch: 78 [31360/35339 (89%)]	Loss: 0.255501
Train Epoch: 78 [32000/35339 (90%)]	Loss: 0.485046
Train Epoch: 78 [32640/35339 (92%)]	Loss: 0.179467
Train Epoch: 78 [33280/35339 (94%)]	Loss: 0.191878
Train Epoch: 78 [33920/35339 (96%)]	Loss: 0.390806
Train Epoch: 78 [34560/35339 (98%)]	Loss: 0.193946
Train Epoch: 78 [35200/35339 (99%)]	Loss: 0.388555

Validation set: Average loss: 1.5352, Accuracy: 2628/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 79 [0/35339 (0%)]	Loss: 0.157605
Train Epoch: 79 [640/35339 (2%)]	Loss: 0.264986
Train Epoch: 79 [1280/35339 (4%)]	Loss: 0.355678
Train Epoch: 79 [1920/35339 (5%)]	Loss: 0.383142
Train Epoch: 79 [2560/35339 (7%)]	Loss: 0.252466
Train Epoch: 79 [3200/35339 (9%)]	Loss: 0.432342
Train Epoch: 79 [3840/35339 (11%)]	Loss: 0.254787
Train Epoch: 79 [4480/35339 (13%)]	Loss: 0.292336
Train Epoch: 79 [5120/35339 (14%)]	Loss: 0.373237
Train Epoch: 79 [5760/35339 (16%)]	Loss: 0.178815
Train Epoch: 79 [6400/35339 (18%)]	Loss: 0.201822
Train Epoch: 79 [7040/35339 (20%)]	Loss: 0.088801
Train Epoch: 79 [7680/35339 (22%)]	Loss: 0.180889
Train Epoch: 79 [8320/35339 (24%)]	Loss: 0.229441
Train Epoch: 79 [8960/35339 (25%)]	Loss: 0.252114
Train Epoch: 79 [9600/35339 (27%)]	Loss: 0.173618
Train Epoch: 79 [10240/35339 (29%)]	Loss: 0.200742
Train Epoch: 79 [10880/35339 (31%)]	Loss: 0.486093
Train Epoch: 79 [11520/35339 (33%)]	Loss: 0.202796
Train Epoch: 79 [12160/35339 (34%)]	Loss: 0.373772
Train Epoch: 79 [12800/35339 (36%)]	Loss: 0.211604
Train Epoch: 79 [13440/35339 (38%)]	Loss: 0.633896
Train Epoch: 79 [14080/35339 (40%)]	Loss: 0.186515
Train Epoch: 79 [14720/35339 (42%)]	Loss: 0.149658
Train Epoch: 79 [15360/35339 (43%)]	Loss: 0.206887
Train Epoch: 79 [16000/35339 (45%)]	Loss: 0.250711
Train Epoch: 79 [16640/35339 (47%)]	Loss: 0.199517
Train Epoch: 79 [17280/35339 (49%)]	Loss: 0.275376
Train Epoch: 79 [17920/35339 (51%)]	Loss: 0.220469
Train Epoch: 79 [18560/35339 (52%)]	Loss: 0.137373
Train Epoch: 79 [19200/35339 (54%)]	Loss: 0.156944
Train Epoch: 79 [19840/35339 (56%)]	Loss: 0.235020
Train Epoch: 79 [20480/35339 (58%)]	Loss: 0.322959
Train Epoch: 79 [21120/35339 (60%)]	Loss: 0.105886
Train Epoch: 79 [21760/35339 (61%)]	Loss: 0.300238
Train Epoch: 79 [22400/35339 (63%)]	Loss: 0.169040
Train Epoch: 79 [23040/35339 (65%)]	Loss: 0.390066
Train Epoch: 79 [23680/35339 (67%)]	Loss: 0.320019
Train Epoch: 79 [24320/35339 (69%)]	Loss: 0.181198
Train Epoch: 79 [24960/35339 (71%)]	Loss: 0.262633
Train Epoch: 79 [25600/35339 (72%)]	Loss: 0.321970
Train Epoch: 79 [26240/35339 (74%)]	Loss: 0.217712
Train Epoch: 79 [26880/35339 (76%)]	Loss: 0.359708
Train Epoch: 79 [27520/35339 (78%)]	Loss: 0.271295
Train Epoch: 79 [28160/35339 (80%)]	Loss: 0.268266
Train Epoch: 79 [28800/35339 (81%)]	Loss: 0.213639
Train Epoch: 79 [29440/35339 (83%)]	Loss: 0.389238
Train Epoch: 79 [30080/35339 (85%)]	Loss: 0.280997
Train Epoch: 79 [30720/35339 (87%)]	Loss: 0.422719
Train Epoch: 79 [31360/35339 (89%)]	Loss: 0.279977
Train Epoch: 79 [32000/35339 (90%)]	Loss: 0.365231
Train Epoch: 79 [32640/35339 (92%)]	Loss: 0.146075
Train Epoch: 79 [33280/35339 (94%)]	Loss: 0.413427
Train Epoch: 79 [33920/35339 (96%)]	Loss: 0.199344
Train Epoch: 79 [34560/35339 (98%)]	Loss: 0.192506
Train Epoch: 79 [35200/35339 (99%)]	Loss: 0.265773

Validation set: Average loss: 1.4857, Accuracy: 2655/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 80 [0/35339 (0%)]	Loss: 0.278650
Train Epoch: 80 [640/35339 (2%)]	Loss: 0.214352
Train Epoch: 80 [1280/35339 (4%)]	Loss: 0.229317
Train Epoch: 80 [1920/35339 (5%)]	Loss: 0.410005
Train Epoch: 80 [2560/35339 (7%)]	Loss: 0.146441
Train Epoch: 80 [3200/35339 (9%)]	Loss: 0.190133
Train Epoch: 80 [3840/35339 (11%)]	Loss: 0.188967
Train Epoch: 80 [4480/35339 (13%)]	Loss: 0.239904
Train Epoch: 80 [5120/35339 (14%)]	Loss: 0.173787
Train Epoch: 80 [5760/35339 (16%)]	Loss: 0.247371
Train Epoch: 80 [6400/35339 (18%)]	Loss: 0.197847
Train Epoch: 80 [7040/35339 (20%)]	Loss: 0.145718
Train Epoch: 80 [7680/35339 (22%)]	Loss: 0.171115
Train Epoch: 80 [8320/35339 (24%)]	Loss: 0.302062
Train Epoch: 80 [8960/35339 (25%)]	Loss: 0.251248
Train Epoch: 80 [9600/35339 (27%)]	Loss: 0.358571
Train Epoch: 80 [10240/35339 (29%)]	Loss: 0.325215
Train Epoch: 80 [10880/35339 (31%)]	Loss: 0.481201
Train Epoch: 80 [11520/35339 (33%)]	Loss: 0.150225
Train Epoch: 80 [12160/35339 (34%)]	Loss: 0.169723
Train Epoch: 80 [12800/35339 (36%)]	Loss: 0.363364
Train Epoch: 80 [13440/35339 (38%)]	Loss: 0.150705
Train Epoch: 80 [14080/35339 (40%)]	Loss: 0.290632
Train Epoch: 80 [14720/35339 (42%)]	Loss: 0.132992
Train Epoch: 80 [15360/35339 (43%)]	Loss: 0.219216
Train Epoch: 80 [16000/35339 (45%)]	Loss: 0.180097
Train Epoch: 80 [16640/35339 (47%)]	Loss: 0.291052
Train Epoch: 80 [17280/35339 (49%)]	Loss: 0.415064
Train Epoch: 80 [17920/35339 (51%)]	Loss: 0.235261
Train Epoch: 80 [18560/35339 (52%)]	Loss: 0.408277
Train Epoch: 80 [19200/35339 (54%)]	Loss: 0.277636
Train Epoch: 80 [19840/35339 (56%)]	Loss: 0.182600
Train Epoch: 80 [20480/35339 (58%)]	Loss: 0.209714
Train Epoch: 80 [21120/35339 (60%)]	Loss: 0.454362
Train Epoch: 80 [21760/35339 (61%)]	Loss: 0.331575
Train Epoch: 80 [22400/35339 (63%)]	Loss: 0.237623
Train Epoch: 80 [23040/35339 (65%)]	Loss: 0.376904
Train Epoch: 80 [23680/35339 (67%)]	Loss: 0.321833
Train Epoch: 80 [24320/35339 (69%)]	Loss: 0.327136
Train Epoch: 80 [24960/35339 (71%)]	Loss: 0.310222
Train Epoch: 80 [25600/35339 (72%)]	Loss: 0.446536
Train Epoch: 80 [26240/35339 (74%)]	Loss: 0.220779
Train Epoch: 80 [26880/35339 (76%)]	Loss: 0.236960
Train Epoch: 80 [27520/35339 (78%)]	Loss: 0.329927
Train Epoch: 80 [28160/35339 (80%)]	Loss: 0.193980
Train Epoch: 80 [28800/35339 (81%)]	Loss: 0.475070
Train Epoch: 80 [29440/35339 (83%)]	Loss: 0.267601
Train Epoch: 80 [30080/35339 (85%)]	Loss: 0.214057
Train Epoch: 80 [30720/35339 (87%)]	Loss: 0.241110
Train Epoch: 80 [31360/35339 (89%)]	Loss: 0.269576
Train Epoch: 80 [32000/35339 (90%)]	Loss: 0.203208
Train Epoch: 80 [32640/35339 (92%)]	Loss: 0.348088
Train Epoch: 80 [33280/35339 (94%)]	Loss: 0.132101
Train Epoch: 80 [33920/35339 (96%)]	Loss: 0.273884
Train Epoch: 80 [34560/35339 (98%)]	Loss: 0.413263
Train Epoch: 80 [35200/35339 (99%)]	Loss: 0.086449

Validation set: Average loss: 1.4845, Accuracy: 2650/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 81 [0/35339 (0%)]	Loss: 0.337630
Train Epoch: 81 [640/35339 (2%)]	Loss: 0.223185
Train Epoch: 81 [1280/35339 (4%)]	Loss: 0.355862
Train Epoch: 81 [1920/35339 (5%)]	Loss: 0.277981
Train Epoch: 81 [2560/35339 (7%)]	Loss: 0.240629
Train Epoch: 81 [3200/35339 (9%)]	Loss: 0.298502
Train Epoch: 81 [3840/35339 (11%)]	Loss: 0.236612
Train Epoch: 81 [4480/35339 (13%)]	Loss: 0.452187
Train Epoch: 81 [5120/35339 (14%)]	Loss: 0.293374
Train Epoch: 81 [5760/35339 (16%)]	Loss: 0.390585
Train Epoch: 81 [6400/35339 (18%)]	Loss: 0.257402
Train Epoch: 81 [7040/35339 (20%)]	Loss: 0.218596
Train Epoch: 81 [7680/35339 (22%)]	Loss: 0.374577
Train Epoch: 81 [8320/35339 (24%)]	Loss: 0.119785
Train Epoch: 81 [8960/35339 (25%)]	Loss: 0.400973
Train Epoch: 81 [9600/35339 (27%)]	Loss: 0.302232
Train Epoch: 81 [10240/35339 (29%)]	Loss: 0.219991
Train Epoch: 81 [10880/35339 (31%)]	Loss: 0.355900
Train Epoch: 81 [11520/35339 (33%)]	Loss: 0.231781
Train Epoch: 81 [12160/35339 (34%)]	Loss: 0.183421
Train Epoch: 81 [12800/35339 (36%)]	Loss: 0.284505
Train Epoch: 81 [13440/35339 (38%)]	Loss: 0.265119
Train Epoch: 81 [14080/35339 (40%)]	Loss: 0.184385
Train Epoch: 81 [14720/35339 (42%)]	Loss: 0.370414
Train Epoch: 81 [15360/35339 (43%)]	Loss: 0.252098
Train Epoch: 81 [16000/35339 (45%)]	Loss: 0.330102
Train Epoch: 81 [16640/35339 (47%)]	Loss: 0.270276
Train Epoch: 81 [17280/35339 (49%)]	Loss: 0.269609
Train Epoch: 81 [17920/35339 (51%)]	Loss: 0.231481
Train Epoch: 81 [18560/35339 (52%)]	Loss: 0.327909
Train Epoch: 81 [19200/35339 (54%)]	Loss: 0.277334
Train Epoch: 81 [19840/35339 (56%)]	Loss: 0.307967
Train Epoch: 81 [20480/35339 (58%)]	Loss: 0.295670
Train Epoch: 81 [21120/35339 (60%)]	Loss: 0.192869
Train Epoch: 81 [21760/35339 (61%)]	Loss: 0.193147
Train Epoch: 81 [22400/35339 (63%)]	Loss: 0.329401
Train Epoch: 81 [23040/35339 (65%)]	Loss: 0.124420
Train Epoch: 81 [23680/35339 (67%)]	Loss: 0.399224
Train Epoch: 81 [24320/35339 (69%)]	Loss: 0.265886
Train Epoch: 81 [24960/35339 (71%)]	Loss: 0.320751
Train Epoch: 81 [25600/35339 (72%)]	Loss: 0.251820
Train Epoch: 81 [26240/35339 (74%)]	Loss: 0.281777
Train Epoch: 81 [26880/35339 (76%)]	Loss: 0.131539
Train Epoch: 81 [27520/35339 (78%)]	Loss: 0.190127
Train Epoch: 81 [28160/35339 (80%)]	Loss: 0.279966
Train Epoch: 81 [28800/35339 (81%)]	Loss: 0.125283
Train Epoch: 81 [29440/35339 (83%)]	Loss: 0.290234
Train Epoch: 81 [30080/35339 (85%)]	Loss: 0.303489
Train Epoch: 81 [30720/35339 (87%)]	Loss: 0.302813
Train Epoch: 81 [31360/35339 (89%)]	Loss: 0.254896
Train Epoch: 81 [32000/35339 (90%)]	Loss: 0.172674
Train Epoch: 81 [32640/35339 (92%)]	Loss: 0.304764
Train Epoch: 81 [33280/35339 (94%)]	Loss: 0.413462
Train Epoch: 81 [33920/35339 (96%)]	Loss: 0.301376
Train Epoch: 81 [34560/35339 (98%)]	Loss: 0.205398
Train Epoch: 81 [35200/35339 (99%)]	Loss: 0.419841

Validation set: Average loss: 1.4745, Accuracy: 2625/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 82 [0/35339 (0%)]	Loss: 0.526679
Train Epoch: 82 [640/35339 (2%)]	Loss: 0.247296
Train Epoch: 82 [1280/35339 (4%)]	Loss: 0.332474
Train Epoch: 82 [1920/35339 (5%)]	Loss: 0.255342
Train Epoch: 82 [2560/35339 (7%)]	Loss: 0.122195
Train Epoch: 82 [3200/35339 (9%)]	Loss: 0.197693
Train Epoch: 82 [3840/35339 (11%)]	Loss: 0.106548
Train Epoch: 82 [4480/35339 (13%)]	Loss: 0.286530
Train Epoch: 82 [5120/35339 (14%)]	Loss: 0.235013
Train Epoch: 82 [5760/35339 (16%)]	Loss: 0.362654
Train Epoch: 82 [6400/35339 (18%)]	Loss: 0.195040
Train Epoch: 82 [7040/35339 (20%)]	Loss: 0.293337
Train Epoch: 82 [7680/35339 (22%)]	Loss: 0.371269
Train Epoch: 82 [8320/35339 (24%)]	Loss: 0.260699
Train Epoch: 82 [8960/35339 (25%)]	Loss: 0.375619
Train Epoch: 82 [9600/35339 (27%)]	Loss: 0.216014
Train Epoch: 82 [10240/35339 (29%)]	Loss: 0.244484
Train Epoch: 82 [10880/35339 (31%)]	Loss: 0.329501
Train Epoch: 82 [11520/35339 (33%)]	Loss: 0.313489
Train Epoch: 82 [12160/35339 (34%)]	Loss: 0.234751
Train Epoch: 82 [12800/35339 (36%)]	Loss: 0.315522
Train Epoch: 82 [13440/35339 (38%)]	Loss: 0.253243
Train Epoch: 82 [14080/35339 (40%)]	Loss: 0.280463
Train Epoch: 82 [14720/35339 (42%)]	Loss: 0.219482
Train Epoch: 82 [15360/35339 (43%)]	Loss: 0.254791
Train Epoch: 82 [16000/35339 (45%)]	Loss: 0.194394
Train Epoch: 82 [16640/35339 (47%)]	Loss: 0.293877
Train Epoch: 82 [17280/35339 (49%)]	Loss: 0.217938
Train Epoch: 82 [17920/35339 (51%)]	Loss: 0.181753
Train Epoch: 82 [18560/35339 (52%)]	Loss: 0.227297
Train Epoch: 82 [19200/35339 (54%)]	Loss: 0.232794
Train Epoch: 82 [19840/35339 (56%)]	Loss: 0.265583
Train Epoch: 82 [20480/35339 (58%)]	Loss: 0.319332
Train Epoch: 82 [21120/35339 (60%)]	Loss: 0.608199
Train Epoch: 82 [21760/35339 (61%)]	Loss: 0.192196
Train Epoch: 82 [22400/35339 (63%)]	Loss: 0.358438
Train Epoch: 82 [23040/35339 (65%)]	Loss: 0.207361
Train Epoch: 82 [23680/35339 (67%)]	Loss: 0.550055
Train Epoch: 82 [24320/35339 (69%)]	Loss: 0.207040
Train Epoch: 82 [24960/35339 (71%)]	Loss: 0.374994
Train Epoch: 82 [25600/35339 (72%)]	Loss: 0.168309
Train Epoch: 82 [26240/35339 (74%)]	Loss: 0.221088
Train Epoch: 82 [26880/35339 (76%)]	Loss: 0.148453
Train Epoch: 82 [27520/35339 (78%)]	Loss: 0.253769
Train Epoch: 82 [28160/35339 (80%)]	Loss: 0.263341
Train Epoch: 82 [28800/35339 (81%)]	Loss: 0.187181
Train Epoch: 82 [29440/35339 (83%)]	Loss: 0.203793
Train Epoch: 82 [30080/35339 (85%)]	Loss: 0.134379
Train Epoch: 82 [30720/35339 (87%)]	Loss: 0.338882
Train Epoch: 82 [31360/35339 (89%)]	Loss: 0.145583
Train Epoch: 82 [32000/35339 (90%)]	Loss: 0.233717
Train Epoch: 82 [32640/35339 (92%)]	Loss: 0.225578
Train Epoch: 82 [33280/35339 (94%)]	Loss: 0.249396
Train Epoch: 82 [33920/35339 (96%)]	Loss: 0.332834
Train Epoch: 82 [34560/35339 (98%)]	Loss: 0.416868
Train Epoch: 82 [35200/35339 (99%)]	Loss: 0.127921

Validation set: Average loss: 1.5403, Accuracy: 2628/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 83 [0/35339 (0%)]	Loss: 0.230522
Train Epoch: 83 [640/35339 (2%)]	Loss: 0.137499
Train Epoch: 83 [1280/35339 (4%)]	Loss: 0.223088
Train Epoch: 83 [1920/35339 (5%)]	Loss: 0.299188
Train Epoch: 83 [2560/35339 (7%)]	Loss: 0.379824
Train Epoch: 83 [3200/35339 (9%)]	Loss: 0.313607
Train Epoch: 83 [3840/35339 (11%)]	Loss: 0.478183
Train Epoch: 83 [4480/35339 (13%)]	Loss: 0.213093
Train Epoch: 83 [5120/35339 (14%)]	Loss: 0.377248
Train Epoch: 83 [5760/35339 (16%)]	Loss: 0.425983
Train Epoch: 83 [6400/35339 (18%)]	Loss: 0.307614
Train Epoch: 83 [7040/35339 (20%)]	Loss: 0.386499
Train Epoch: 83 [7680/35339 (22%)]	Loss: 0.213731
Train Epoch: 83 [8320/35339 (24%)]	Loss: 0.238348
Train Epoch: 83 [8960/35339 (25%)]	Loss: 0.314682
Train Epoch: 83 [9600/35339 (27%)]	Loss: 0.439064
Train Epoch: 83 [10240/35339 (29%)]	Loss: 0.535639
Train Epoch: 83 [10880/35339 (31%)]	Loss: 0.402979
Train Epoch: 83 [11520/35339 (33%)]	Loss: 0.192721
Train Epoch: 83 [12160/35339 (34%)]	Loss: 0.370332
Train Epoch: 83 [12800/35339 (36%)]	Loss: 0.210892
Train Epoch: 83 [13440/35339 (38%)]	Loss: 0.182069
Train Epoch: 83 [14080/35339 (40%)]	Loss: 0.146937
Train Epoch: 83 [14720/35339 (42%)]	Loss: 0.257451
Train Epoch: 83 [15360/35339 (43%)]	Loss: 0.341648
Train Epoch: 83 [16000/35339 (45%)]	Loss: 0.309984
Train Epoch: 83 [16640/35339 (47%)]	Loss: 0.336051
Train Epoch: 83 [17280/35339 (49%)]	Loss: 0.236629
Train Epoch: 83 [17920/35339 (51%)]	Loss: 0.303177
Train Epoch: 83 [18560/35339 (52%)]	Loss: 0.110053
Train Epoch: 83 [19200/35339 (54%)]	Loss: 0.379179
Train Epoch: 83 [19840/35339 (56%)]	Loss: 0.247757
Train Epoch: 83 [20480/35339 (58%)]	Loss: 0.288101
Train Epoch: 83 [21120/35339 (60%)]	Loss: 0.241955
Train Epoch: 83 [21760/35339 (61%)]	Loss: 0.467149
Train Epoch: 83 [22400/35339 (63%)]	Loss: 0.537115
Train Epoch: 83 [23040/35339 (65%)]	Loss: 0.643204
Train Epoch: 83 [23680/35339 (67%)]	Loss: 0.275058
Train Epoch: 83 [24320/35339 (69%)]	Loss: 0.279714
Train Epoch: 83 [24960/35339 (71%)]	Loss: 0.233304
Train Epoch: 83 [25600/35339 (72%)]	Loss: 0.373127
Train Epoch: 83 [26240/35339 (74%)]	Loss: 0.228574
Train Epoch: 83 [26880/35339 (76%)]	Loss: 0.358596
Train Epoch: 83 [27520/35339 (78%)]	Loss: 0.322057
Train Epoch: 83 [28160/35339 (80%)]	Loss: 0.193217
Train Epoch: 83 [28800/35339 (81%)]	Loss: 0.407002
Train Epoch: 83 [29440/35339 (83%)]	Loss: 0.168850
Train Epoch: 83 [30080/35339 (85%)]	Loss: 0.212215
Train Epoch: 83 [30720/35339 (87%)]	Loss: 0.297760
Train Epoch: 83 [31360/35339 (89%)]	Loss: 0.196443
Train Epoch: 83 [32000/35339 (90%)]	Loss: 0.182745
Train Epoch: 83 [32640/35339 (92%)]	Loss: 0.423162
Train Epoch: 83 [33280/35339 (94%)]	Loss: 0.344802
Train Epoch: 83 [33920/35339 (96%)]	Loss: 0.271911
Train Epoch: 83 [34560/35339 (98%)]	Loss: 0.239855
Train Epoch: 83 [35200/35339 (99%)]	Loss: 0.217403

Validation set: Average loss: 1.5142, Accuracy: 2629/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 84 [0/35339 (0%)]	Loss: 0.267553
Train Epoch: 84 [640/35339 (2%)]	Loss: 0.240745
Train Epoch: 84 [1280/35339 (4%)]	Loss: 0.263693
Train Epoch: 84 [1920/35339 (5%)]	Loss: 0.259050
Train Epoch: 84 [2560/35339 (7%)]	Loss: 0.195431
Train Epoch: 84 [3200/35339 (9%)]	Loss: 0.175406
Train Epoch: 84 [3840/35339 (11%)]	Loss: 0.155829
Train Epoch: 84 [4480/35339 (13%)]	Loss: 0.429778
Train Epoch: 84 [5120/35339 (14%)]	Loss: 0.331358
Train Epoch: 84 [5760/35339 (16%)]	Loss: 0.164338
Train Epoch: 84 [6400/35339 (18%)]	Loss: 0.204767
Train Epoch: 84 [7040/35339 (20%)]	Loss: 0.302977
Train Epoch: 84 [7680/35339 (22%)]	Loss: 0.149543
Train Epoch: 84 [8320/35339 (24%)]	Loss: 0.336651
Train Epoch: 84 [8960/35339 (25%)]	Loss: 0.213279
Train Epoch: 84 [9600/35339 (27%)]	Loss: 0.519301
Train Epoch: 84 [10240/35339 (29%)]	Loss: 0.414791
Train Epoch: 84 [10880/35339 (31%)]	Loss: 0.281089
Train Epoch: 84 [11520/35339 (33%)]	Loss: 0.186442
Train Epoch: 84 [12160/35339 (34%)]	Loss: 0.131043
Train Epoch: 84 [12800/35339 (36%)]	Loss: 0.136283
Train Epoch: 84 [13440/35339 (38%)]	Loss: 0.318076
Train Epoch: 84 [14080/35339 (40%)]	Loss: 0.216107
Train Epoch: 84 [14720/35339 (42%)]	Loss: 0.225841
Train Epoch: 84 [15360/35339 (43%)]	Loss: 0.272933
Train Epoch: 84 [16000/35339 (45%)]	Loss: 0.255211
Train Epoch: 84 [16640/35339 (47%)]	Loss: 0.262671
Train Epoch: 84 [17280/35339 (49%)]	Loss: 0.404672
Train Epoch: 84 [17920/35339 (51%)]	Loss: 0.189852
Train Epoch: 84 [18560/35339 (52%)]	Loss: 0.236928
Train Epoch: 84 [19200/35339 (54%)]	Loss: 0.299571
Train Epoch: 84 [19840/35339 (56%)]	Loss: 0.298592
Train Epoch: 84 [20480/35339 (58%)]	Loss: 0.241068
Train Epoch: 84 [21120/35339 (60%)]	Loss: 0.232373
Train Epoch: 84 [21760/35339 (61%)]	Loss: 0.343759
Train Epoch: 84 [22400/35339 (63%)]	Loss: 0.203690
Train Epoch: 84 [23040/35339 (65%)]	Loss: 0.314585
Train Epoch: 84 [23680/35339 (67%)]	Loss: 0.243243
Train Epoch: 84 [24320/35339 (69%)]	Loss: 0.228002
Train Epoch: 84 [24960/35339 (71%)]	Loss: 0.269919
Train Epoch: 84 [25600/35339 (72%)]	Loss: 0.360152
Train Epoch: 84 [26240/35339 (74%)]	Loss: 0.228338
Train Epoch: 84 [26880/35339 (76%)]	Loss: 0.406754
Train Epoch: 84 [27520/35339 (78%)]	Loss: 0.291299
Train Epoch: 84 [28160/35339 (80%)]	Loss: 0.289285
Train Epoch: 84 [28800/35339 (81%)]	Loss: 0.401220
Train Epoch: 84 [29440/35339 (83%)]	Loss: 0.203737
Train Epoch: 84 [30080/35339 (85%)]	Loss: 0.398079
Train Epoch: 84 [30720/35339 (87%)]	Loss: 0.406028
Train Epoch: 84 [31360/35339 (89%)]	Loss: 0.263851
Train Epoch: 84 [32000/35339 (90%)]	Loss: 0.274157
Train Epoch: 84 [32640/35339 (92%)]	Loss: 0.311852
Train Epoch: 84 [33280/35339 (94%)]	Loss: 0.207741
Train Epoch: 84 [33920/35339 (96%)]	Loss: 0.302432
Train Epoch: 84 [34560/35339 (98%)]	Loss: 0.250119
Train Epoch: 84 [35200/35339 (99%)]	Loss: 0.250655

Validation set: Average loss: 1.4531, Accuracy: 2652/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 85 [0/35339 (0%)]	Loss: 0.195065
Train Epoch: 85 [640/35339 (2%)]	Loss: 0.217557
Train Epoch: 85 [1280/35339 (4%)]	Loss: 0.429038
Train Epoch: 85 [1920/35339 (5%)]	Loss: 0.150185
Train Epoch: 85 [2560/35339 (7%)]	Loss: 0.221192
Train Epoch: 85 [3200/35339 (9%)]	Loss: 0.187256
Train Epoch: 85 [3840/35339 (11%)]	Loss: 0.314130
Train Epoch: 85 [4480/35339 (13%)]	Loss: 0.381374
Train Epoch: 85 [5120/35339 (14%)]	Loss: 0.236363
Train Epoch: 85 [5760/35339 (16%)]	Loss: 0.262715
Train Epoch: 85 [6400/35339 (18%)]	Loss: 0.134577
Train Epoch: 85 [7040/35339 (20%)]	Loss: 0.204906
Train Epoch: 85 [7680/35339 (22%)]	Loss: 0.277364
Train Epoch: 85 [8320/35339 (24%)]	Loss: 0.100596
Train Epoch: 85 [8960/35339 (25%)]	Loss: 0.178529
Train Epoch: 85 [9600/35339 (27%)]	Loss: 0.292096
Train Epoch: 85 [10240/35339 (29%)]	Loss: 0.231941
Train Epoch: 85 [10880/35339 (31%)]	Loss: 0.168085
Train Epoch: 85 [11520/35339 (33%)]	Loss: 0.176669
Train Epoch: 85 [12160/35339 (34%)]	Loss: 0.238482
Train Epoch: 85 [12800/35339 (36%)]	Loss: 0.376263
Train Epoch: 85 [13440/35339 (38%)]	Loss: 0.272807
Train Epoch: 85 [14080/35339 (40%)]	Loss: 0.230200
Train Epoch: 85 [14720/35339 (42%)]	Loss: 0.154495
Train Epoch: 85 [15360/35339 (43%)]	Loss: 0.137086
Train Epoch: 85 [16000/35339 (45%)]	Loss: 0.357425
Train Epoch: 85 [16640/35339 (47%)]	Loss: 0.360375
Train Epoch: 85 [17280/35339 (49%)]	Loss: 0.280634
Train Epoch: 85 [17920/35339 (51%)]	Loss: 0.377955
Train Epoch: 85 [18560/35339 (52%)]	Loss: 0.357576
Train Epoch: 85 [19200/35339 (54%)]	Loss: 0.566562
Train Epoch: 85 [19840/35339 (56%)]	Loss: 0.365842
Train Epoch: 85 [20480/35339 (58%)]	Loss: 0.181853
Train Epoch: 85 [21120/35339 (60%)]	Loss: 0.342844
Train Epoch: 85 [21760/35339 (61%)]	Loss: 0.218323
Train Epoch: 85 [22400/35339 (63%)]	Loss: 0.169196
Train Epoch: 85 [23040/35339 (65%)]	Loss: 0.381640
Train Epoch: 85 [23680/35339 (67%)]	Loss: 0.246747
Train Epoch: 85 [24320/35339 (69%)]	Loss: 0.723902
Train Epoch: 85 [24960/35339 (71%)]	Loss: 0.150874
Train Epoch: 85 [25600/35339 (72%)]	Loss: 0.438821
Train Epoch: 85 [26240/35339 (74%)]	Loss: 0.153720
Train Epoch: 85 [26880/35339 (76%)]	Loss: 0.183825
Train Epoch: 85 [27520/35339 (78%)]	Loss: 0.277571
Train Epoch: 85 [28160/35339 (80%)]	Loss: 0.233230
Train Epoch: 85 [28800/35339 (81%)]	Loss: 0.342524
Train Epoch: 85 [29440/35339 (83%)]	Loss: 0.391811
Train Epoch: 85 [30080/35339 (85%)]	Loss: 0.379230
Train Epoch: 85 [30720/35339 (87%)]	Loss: 0.210766
Train Epoch: 85 [31360/35339 (89%)]	Loss: 0.159526
Train Epoch: 85 [32000/35339 (90%)]	Loss: 0.255843
Train Epoch: 85 [32640/35339 (92%)]	Loss: 0.255732
Train Epoch: 85 [33280/35339 (94%)]	Loss: 0.117882
Train Epoch: 85 [33920/35339 (96%)]	Loss: 0.316312
Train Epoch: 85 [34560/35339 (98%)]	Loss: 0.320703
Train Epoch: 85 [35200/35339 (99%)]	Loss: 0.389331

Validation set: Average loss: 1.4876, Accuracy: 2633/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 86 [0/35339 (0%)]	Loss: 0.181096
Train Epoch: 86 [640/35339 (2%)]	Loss: 0.172759
Train Epoch: 86 [1280/35339 (4%)]	Loss: 0.145303
Train Epoch: 86 [1920/35339 (5%)]	Loss: 0.330043
Train Epoch: 86 [2560/35339 (7%)]	Loss: 0.347399
Train Epoch: 86 [3200/35339 (9%)]	Loss: 0.316169
Train Epoch: 86 [3840/35339 (11%)]	Loss: 0.305070
Train Epoch: 86 [4480/35339 (13%)]	Loss: 0.320472
Train Epoch: 86 [5120/35339 (14%)]	Loss: 0.265018
Train Epoch: 86 [5760/35339 (16%)]	Loss: 0.311908
Train Epoch: 86 [6400/35339 (18%)]	Loss: 0.258688
Train Epoch: 86 [7040/35339 (20%)]	Loss: 0.406194
Train Epoch: 86 [7680/35339 (22%)]	Loss: 0.178593
Train Epoch: 86 [8320/35339 (24%)]	Loss: 0.181819
Train Epoch: 86 [8960/35339 (25%)]	Loss: 0.220260
Train Epoch: 86 [9600/35339 (27%)]	Loss: 0.225059
Train Epoch: 86 [10240/35339 (29%)]	Loss: 0.156287
Train Epoch: 86 [10880/35339 (31%)]	Loss: 0.365658
Train Epoch: 86 [11520/35339 (33%)]	Loss: 0.310892
Train Epoch: 86 [12160/35339 (34%)]	Loss: 0.212573
Train Epoch: 86 [12800/35339 (36%)]	Loss: 0.418542
Train Epoch: 86 [13440/35339 (38%)]	Loss: 0.281169
Train Epoch: 86 [14080/35339 (40%)]	Loss: 0.135771
Train Epoch: 86 [14720/35339 (42%)]	Loss: 0.303563
Train Epoch: 86 [15360/35339 (43%)]	Loss: 0.309432
Train Epoch: 86 [16000/35339 (45%)]	Loss: 0.177631
Train Epoch: 86 [16640/35339 (47%)]	Loss: 0.160267
Train Epoch: 86 [17280/35339 (49%)]	Loss: 0.201318
Train Epoch: 86 [17920/35339 (51%)]	Loss: 0.352965
Train Epoch: 86 [18560/35339 (52%)]	Loss: 0.200838
Train Epoch: 86 [19200/35339 (54%)]	Loss: 0.167207
Train Epoch: 86 [19840/35339 (56%)]	Loss: 0.164082
Train Epoch: 86 [20480/35339 (58%)]	Loss: 0.226380
Train Epoch: 86 [21120/35339 (60%)]	Loss: 0.291624
Train Epoch: 86 [21760/35339 (61%)]	Loss: 0.285511
Train Epoch: 86 [22400/35339 (63%)]	Loss: 0.215284
Train Epoch: 86 [23040/35339 (65%)]	Loss: 0.153995
Train Epoch: 86 [23680/35339 (67%)]	Loss: 0.348077
Train Epoch: 86 [24320/35339 (69%)]	Loss: 0.276330
Train Epoch: 86 [24960/35339 (71%)]	Loss: 0.162715
Train Epoch: 86 [25600/35339 (72%)]	Loss: 0.265260
Train Epoch: 86 [26240/35339 (74%)]	Loss: 0.261810
Train Epoch: 86 [26880/35339 (76%)]	Loss: 0.117787
Train Epoch: 86 [27520/35339 (78%)]	Loss: 0.217796
Train Epoch: 86 [28160/35339 (80%)]	Loss: 0.269105
Train Epoch: 86 [28800/35339 (81%)]	Loss: 0.166699
Train Epoch: 86 [29440/35339 (83%)]	Loss: 0.243885
Train Epoch: 86 [30080/35339 (85%)]	Loss: 0.282218
Train Epoch: 86 [30720/35339 (87%)]	Loss: 0.430874
Train Epoch: 86 [31360/35339 (89%)]	Loss: 0.234629
Train Epoch: 86 [32000/35339 (90%)]	Loss: 0.126206
Train Epoch: 86 [32640/35339 (92%)]	Loss: 0.366185
Train Epoch: 86 [33280/35339 (94%)]	Loss: 0.315256
Train Epoch: 86 [33920/35339 (96%)]	Loss: 0.478962
Train Epoch: 86 [34560/35339 (98%)]	Loss: 0.280338
Train Epoch: 86 [35200/35339 (99%)]	Loss: 0.245310

Validation set: Average loss: 1.4552, Accuracy: 2652/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 87 [0/35339 (0%)]	Loss: 0.239764
Train Epoch: 87 [640/35339 (2%)]	Loss: 0.163037
Train Epoch: 87 [1280/35339 (4%)]	Loss: 0.276608
Train Epoch: 87 [1920/35339 (5%)]	Loss: 0.210329
Train Epoch: 87 [2560/35339 (7%)]	Loss: 0.215113
Train Epoch: 87 [3200/35339 (9%)]	Loss: 0.233386
Train Epoch: 87 [3840/35339 (11%)]	Loss: 0.238721
Train Epoch: 87 [4480/35339 (13%)]	Loss: 0.146695
Train Epoch: 87 [5120/35339 (14%)]	Loss: 0.250942
Train Epoch: 87 [5760/35339 (16%)]	Loss: 0.263962
Train Epoch: 87 [6400/35339 (18%)]	Loss: 0.314975
Train Epoch: 87 [7040/35339 (20%)]	Loss: 0.667413
Train Epoch: 87 [7680/35339 (22%)]	Loss: 0.421153
Train Epoch: 87 [8320/35339 (24%)]	Loss: 0.251316
Train Epoch: 87 [8960/35339 (25%)]	Loss: 0.373494
Train Epoch: 87 [9600/35339 (27%)]	Loss: 0.249839
Train Epoch: 87 [10240/35339 (29%)]	Loss: 0.316558
Train Epoch: 87 [10880/35339 (31%)]	Loss: 0.407697
Train Epoch: 87 [11520/35339 (33%)]	Loss: 0.203270
Train Epoch: 87 [12160/35339 (34%)]	Loss: 0.207492
Train Epoch: 87 [12800/35339 (36%)]	Loss: 0.280056
Train Epoch: 87 [13440/35339 (38%)]	Loss: 0.358790
Train Epoch: 87 [14080/35339 (40%)]	Loss: 0.257665
Train Epoch: 87 [14720/35339 (42%)]	Loss: 0.216911
Train Epoch: 87 [15360/35339 (43%)]	Loss: 0.215538
Train Epoch: 87 [16000/35339 (45%)]	Loss: 0.189415
Train Epoch: 87 [16640/35339 (47%)]	Loss: 0.257193
Train Epoch: 87 [17280/35339 (49%)]	Loss: 0.253696
Train Epoch: 87 [17920/35339 (51%)]	Loss: 0.256598
Train Epoch: 87 [18560/35339 (52%)]	Loss: 0.426629
Train Epoch: 87 [19200/35339 (54%)]	Loss: 0.311431
Train Epoch: 87 [19840/35339 (56%)]	Loss: 0.430958
Train Epoch: 87 [20480/35339 (58%)]	Loss: 0.151951
Train Epoch: 87 [21120/35339 (60%)]	Loss: 0.310679
Train Epoch: 87 [21760/35339 (61%)]	Loss: 0.304291
Train Epoch: 87 [22400/35339 (63%)]	Loss: 0.429668
Train Epoch: 87 [23040/35339 (65%)]	Loss: 0.366149
Train Epoch: 87 [23680/35339 (67%)]	Loss: 0.229434
Train Epoch: 87 [24320/35339 (69%)]	Loss: 0.115330
Train Epoch: 87 [24960/35339 (71%)]	Loss: 0.228750
Train Epoch: 87 [25600/35339 (72%)]	Loss: 0.209134
Train Epoch: 87 [26240/35339 (74%)]	Loss: 0.177692
Train Epoch: 87 [26880/35339 (76%)]	Loss: 0.182791
Train Epoch: 87 [27520/35339 (78%)]	Loss: 0.265086
Train Epoch: 87 [28160/35339 (80%)]	Loss: 0.177860
Train Epoch: 87 [28800/35339 (81%)]	Loss: 0.349757
Train Epoch: 87 [29440/35339 (83%)]	Loss: 0.254293
Train Epoch: 87 [30080/35339 (85%)]	Loss: 0.293671
Train Epoch: 87 [30720/35339 (87%)]	Loss: 0.282445
Train Epoch: 87 [31360/35339 (89%)]	Loss: 0.527325
Train Epoch: 87 [32000/35339 (90%)]	Loss: 0.267051
Train Epoch: 87 [32640/35339 (92%)]	Loss: 0.404974
Train Epoch: 87 [33280/35339 (94%)]	Loss: 0.194155
Train Epoch: 87 [33920/35339 (96%)]	Loss: 0.150827
Train Epoch: 87 [34560/35339 (98%)]	Loss: 0.156259
Train Epoch: 87 [35200/35339 (99%)]	Loss: 0.317421

Validation set: Average loss: 1.5382, Accuracy: 2632/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 88 [0/35339 (0%)]	Loss: 0.216852
Train Epoch: 88 [640/35339 (2%)]	Loss: 0.452543
Train Epoch: 88 [1280/35339 (4%)]	Loss: 0.225605
Train Epoch: 88 [1920/35339 (5%)]	Loss: 0.191301
Train Epoch: 88 [2560/35339 (7%)]	Loss: 0.153764
Train Epoch: 88 [3200/35339 (9%)]	Loss: 0.287038
Train Epoch: 88 [3840/35339 (11%)]	Loss: 0.235621
Train Epoch: 88 [4480/35339 (13%)]	Loss: 0.182327
Train Epoch: 88 [5120/35339 (14%)]	Loss: 0.115719
Train Epoch: 88 [5760/35339 (16%)]	Loss: 0.219903
Train Epoch: 88 [6400/35339 (18%)]	Loss: 0.405629
Train Epoch: 88 [7040/35339 (20%)]	Loss: 0.225065
Train Epoch: 88 [7680/35339 (22%)]	Loss: 0.173202
Train Epoch: 88 [8320/35339 (24%)]	Loss: 0.434911
Train Epoch: 88 [8960/35339 (25%)]	Loss: 0.248961
Train Epoch: 88 [9600/35339 (27%)]	Loss: 0.263825
Train Epoch: 88 [10240/35339 (29%)]	Loss: 0.261765
Train Epoch: 88 [10880/35339 (31%)]	Loss: 0.269891
Train Epoch: 88 [11520/35339 (33%)]	Loss: 0.354106
Train Epoch: 88 [12160/35339 (34%)]	Loss: 0.239085
Train Epoch: 88 [12800/35339 (36%)]	Loss: 0.333226
Train Epoch: 88 [13440/35339 (38%)]	Loss: 0.190769
Train Epoch: 88 [14080/35339 (40%)]	Loss: 0.334829
Train Epoch: 88 [14720/35339 (42%)]	Loss: 0.122711
Train Epoch: 88 [15360/35339 (43%)]	Loss: 0.275867
Train Epoch: 88 [16000/35339 (45%)]	Loss: 0.151353
Train Epoch: 88 [16640/35339 (47%)]	Loss: 0.349411
Train Epoch: 88 [17280/35339 (49%)]	Loss: 0.327695
Train Epoch: 88 [17920/35339 (51%)]	Loss: 0.169419
Train Epoch: 88 [18560/35339 (52%)]	Loss: 0.234462
Train Epoch: 88 [19200/35339 (54%)]	Loss: 0.192783
Train Epoch: 88 [19840/35339 (56%)]	Loss: 0.221097
Train Epoch: 88 [20480/35339 (58%)]	Loss: 0.178477
Train Epoch: 88 [21120/35339 (60%)]	Loss: 0.380189
Train Epoch: 88 [21760/35339 (61%)]	Loss: 0.234138
Train Epoch: 88 [22400/35339 (63%)]	Loss: 0.262697
Train Epoch: 88 [23040/35339 (65%)]	Loss: 0.231539
Train Epoch: 88 [23680/35339 (67%)]	Loss: 0.255960
Train Epoch: 88 [24320/35339 (69%)]	Loss: 0.344792
Train Epoch: 88 [24960/35339 (71%)]	Loss: 0.185454
Train Epoch: 88 [25600/35339 (72%)]	Loss: 0.255465
Train Epoch: 88 [26240/35339 (74%)]	Loss: 0.144464
Train Epoch: 88 [26880/35339 (76%)]	Loss: 0.200027
Train Epoch: 88 [27520/35339 (78%)]	Loss: 0.312250
Train Epoch: 88 [28160/35339 (80%)]	Loss: 0.314636
Train Epoch: 88 [28800/35339 (81%)]	Loss: 0.172547
Train Epoch: 88 [29440/35339 (83%)]	Loss: 0.208995
Train Epoch: 88 [30080/35339 (85%)]	Loss: 0.226909
Train Epoch: 88 [30720/35339 (87%)]	Loss: 0.394841
Train Epoch: 88 [31360/35339 (89%)]	Loss: 0.269556
Train Epoch: 88 [32000/35339 (90%)]	Loss: 0.272584
Train Epoch: 88 [32640/35339 (92%)]	Loss: 0.121036
Train Epoch: 88 [33280/35339 (94%)]	Loss: 0.205175
Train Epoch: 88 [33920/35339 (96%)]	Loss: 0.227452
Train Epoch: 88 [34560/35339 (98%)]	Loss: 0.241693
Train Epoch: 88 [35200/35339 (99%)]	Loss: 0.201477

Validation set: Average loss: 1.5185, Accuracy: 2622/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 89 [0/35339 (0%)]	Loss: 0.717415
Train Epoch: 89 [640/35339 (2%)]	Loss: 0.202747
Train Epoch: 89 [1280/35339 (4%)]	Loss: 0.236484
Train Epoch: 89 [1920/35339 (5%)]	Loss: 0.639755
Train Epoch: 89 [2560/35339 (7%)]	Loss: 0.167344
Train Epoch: 89 [3200/35339 (9%)]	Loss: 0.356450
Train Epoch: 89 [3840/35339 (11%)]	Loss: 0.443850
Train Epoch: 89 [4480/35339 (13%)]	Loss: 0.185415
Train Epoch: 89 [5120/35339 (14%)]	Loss: 0.346142
Train Epoch: 89 [5760/35339 (16%)]	Loss: 0.338158
Train Epoch: 89 [6400/35339 (18%)]	Loss: 0.317121
Train Epoch: 89 [7040/35339 (20%)]	Loss: 0.352127
Train Epoch: 89 [7680/35339 (22%)]	Loss: 0.292244
Train Epoch: 89 [8320/35339 (24%)]	Loss: 0.157084
Train Epoch: 89 [8960/35339 (25%)]	Loss: 0.403242
Train Epoch: 89 [9600/35339 (27%)]	Loss: 0.143067
Train Epoch: 89 [10240/35339 (29%)]	Loss: 0.149469
Train Epoch: 89 [10880/35339 (31%)]	Loss: 0.314607
Train Epoch: 89 [11520/35339 (33%)]	Loss: 0.256770
Train Epoch: 89 [12160/35339 (34%)]	Loss: 0.274122
Train Epoch: 89 [12800/35339 (36%)]	Loss: 0.203363
Train Epoch: 89 [13440/35339 (38%)]	Loss: 0.278228
Train Epoch: 89 [14080/35339 (40%)]	Loss: 0.197426
Train Epoch: 89 [14720/35339 (42%)]	Loss: 0.212786
Train Epoch: 89 [15360/35339 (43%)]	Loss: 0.209211
Train Epoch: 89 [16000/35339 (45%)]	Loss: 0.362423
Train Epoch: 89 [16640/35339 (47%)]	Loss: 0.317361
Train Epoch: 89 [17280/35339 (49%)]	Loss: 0.316119
Train Epoch: 89 [17920/35339 (51%)]	Loss: 0.214758
Train Epoch: 89 [18560/35339 (52%)]	Loss: 0.181949
Train Epoch: 89 [19200/35339 (54%)]	Loss: 0.293009
Train Epoch: 89 [19840/35339 (56%)]	Loss: 0.367224
Train Epoch: 89 [20480/35339 (58%)]	Loss: 0.180706
Train Epoch: 89 [21120/35339 (60%)]	Loss: 0.151561
Train Epoch: 89 [21760/35339 (61%)]	Loss: 0.290616
Train Epoch: 89 [22400/35339 (63%)]	Loss: 0.119129
Train Epoch: 89 [23040/35339 (65%)]	Loss: 0.247379
Train Epoch: 89 [23680/35339 (67%)]	Loss: 0.239974
Train Epoch: 89 [24320/35339 (69%)]	Loss: 0.162368
Train Epoch: 89 [24960/35339 (71%)]	Loss: 0.417925
Train Epoch: 89 [25600/35339 (72%)]	Loss: 0.105055
Train Epoch: 89 [26240/35339 (74%)]	Loss: 0.287055
Train Epoch: 89 [26880/35339 (76%)]	Loss: 0.240833
Train Epoch: 89 [27520/35339 (78%)]	Loss: 0.350578
Train Epoch: 89 [28160/35339 (80%)]	Loss: 0.305265
Train Epoch: 89 [28800/35339 (81%)]	Loss: 0.352216
Train Epoch: 89 [29440/35339 (83%)]	Loss: 0.448383
Train Epoch: 89 [30080/35339 (85%)]	Loss: 0.386505
Train Epoch: 89 [30720/35339 (87%)]	Loss: 0.249939
Train Epoch: 89 [31360/35339 (89%)]	Loss: 0.226534
Train Epoch: 89 [32000/35339 (90%)]	Loss: 0.201766
Train Epoch: 89 [32640/35339 (92%)]	Loss: 0.298595
Train Epoch: 89 [33280/35339 (94%)]	Loss: 0.375140
Train Epoch: 89 [33920/35339 (96%)]	Loss: 0.138153
Train Epoch: 89 [34560/35339 (98%)]	Loss: 0.329938
Train Epoch: 89 [35200/35339 (99%)]	Loss: 0.277650

Validation set: Average loss: 1.4982, Accuracy: 2646/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 90 [0/35339 (0%)]	Loss: 0.121043
Train Epoch: 90 [640/35339 (2%)]	Loss: 0.268188
Train Epoch: 90 [1280/35339 (4%)]	Loss: 0.421696
Train Epoch: 90 [1920/35339 (5%)]	Loss: 0.232492
Train Epoch: 90 [2560/35339 (7%)]	Loss: 0.373729
Train Epoch: 90 [3200/35339 (9%)]	Loss: 0.296073
Train Epoch: 90 [3840/35339 (11%)]	Loss: 0.258464
Train Epoch: 90 [4480/35339 (13%)]	Loss: 0.391550
Train Epoch: 90 [5120/35339 (14%)]	Loss: 0.340212
Train Epoch: 90 [5760/35339 (16%)]	Loss: 0.324476
Train Epoch: 90 [6400/35339 (18%)]	Loss: 0.296657
Train Epoch: 90 [7040/35339 (20%)]	Loss: 0.226792
Train Epoch: 90 [7680/35339 (22%)]	Loss: 0.159940
Train Epoch: 90 [8320/35339 (24%)]	Loss: 0.214727
Train Epoch: 90 [8960/35339 (25%)]	Loss: 0.322290
Train Epoch: 90 [9600/35339 (27%)]	Loss: 0.178522
Train Epoch: 90 [10240/35339 (29%)]	Loss: 0.244964
Train Epoch: 90 [10880/35339 (31%)]	Loss: 0.252825
Train Epoch: 90 [11520/35339 (33%)]	Loss: 0.151726
Train Epoch: 90 [12160/35339 (34%)]	Loss: 0.240439
Train Epoch: 90 [12800/35339 (36%)]	Loss: 0.393735
Train Epoch: 90 [13440/35339 (38%)]	Loss: 0.411871
Train Epoch: 90 [14080/35339 (40%)]	Loss: 0.462182
Train Epoch: 90 [14720/35339 (42%)]	Loss: 0.244187
Train Epoch: 90 [15360/35339 (43%)]	Loss: 0.141377
Train Epoch: 90 [16000/35339 (45%)]	Loss: 0.255379
Train Epoch: 90 [16640/35339 (47%)]	Loss: 0.282722
Train Epoch: 90 [17280/35339 (49%)]	Loss: 0.156754
Train Epoch: 90 [17920/35339 (51%)]	Loss: 0.173339
Train Epoch: 90 [18560/35339 (52%)]	Loss: 0.336000
Train Epoch: 90 [19200/35339 (54%)]	Loss: 0.200304
Train Epoch: 90 [19840/35339 (56%)]	Loss: 0.224878
Train Epoch: 90 [20480/35339 (58%)]	Loss: 0.240149
Train Epoch: 90 [21120/35339 (60%)]	Loss: 0.277407
Train Epoch: 90 [21760/35339 (61%)]	Loss: 0.205426
Train Epoch: 90 [22400/35339 (63%)]	Loss: 0.241143
Train Epoch: 90 [23040/35339 (65%)]	Loss: 0.201833
Train Epoch: 90 [23680/35339 (67%)]	Loss: 0.327024
Train Epoch: 90 [24320/35339 (69%)]	Loss: 0.198807
Train Epoch: 90 [24960/35339 (71%)]	Loss: 0.254993
Train Epoch: 90 [25600/35339 (72%)]	Loss: 0.233741
Train Epoch: 90 [26240/35339 (74%)]	Loss: 0.258293
Train Epoch: 90 [26880/35339 (76%)]	Loss: 0.589999
Train Epoch: 90 [27520/35339 (78%)]	Loss: 0.402592
Train Epoch: 90 [28160/35339 (80%)]	Loss: 0.218355
Train Epoch: 90 [28800/35339 (81%)]	Loss: 0.347886
Train Epoch: 90 [29440/35339 (83%)]	Loss: 0.154666
Train Epoch: 90 [30080/35339 (85%)]	Loss: 0.153333
Train Epoch: 90 [30720/35339 (87%)]	Loss: 0.280247
Train Epoch: 90 [31360/35339 (89%)]	Loss: 0.231504
Train Epoch: 90 [32000/35339 (90%)]	Loss: 0.329513
Train Epoch: 90 [32640/35339 (92%)]	Loss: 0.244644
Train Epoch: 90 [33280/35339 (94%)]	Loss: 0.292369
Train Epoch: 90 [33920/35339 (96%)]	Loss: 0.143645
Train Epoch: 90 [34560/35339 (98%)]	Loss: 0.282006
Train Epoch: 90 [35200/35339 (99%)]	Loss: 0.159659

Validation set: Average loss: 1.5293, Accuracy: 2645/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 91 [0/35339 (0%)]	Loss: 0.140442
Train Epoch: 91 [640/35339 (2%)]	Loss: 0.206867
Train Epoch: 91 [1280/35339 (4%)]	Loss: 0.354506
Train Epoch: 91 [1920/35339 (5%)]	Loss: 0.211575
Train Epoch: 91 [2560/35339 (7%)]	Loss: 0.395179
Train Epoch: 91 [3200/35339 (9%)]	Loss: 0.220806
Train Epoch: 91 [3840/35339 (11%)]	Loss: 0.363449
Train Epoch: 91 [4480/35339 (13%)]	Loss: 0.332788
Train Epoch: 91 [5120/35339 (14%)]	Loss: 0.275143
Train Epoch: 91 [5760/35339 (16%)]	Loss: 0.283268
Train Epoch: 91 [6400/35339 (18%)]	Loss: 0.339249
Train Epoch: 91 [7040/35339 (20%)]	Loss: 0.445139
Train Epoch: 91 [7680/35339 (22%)]	Loss: 0.174804
Train Epoch: 91 [8320/35339 (24%)]	Loss: 0.282456
Train Epoch: 91 [8960/35339 (25%)]	Loss: 0.185892
Train Epoch: 91 [9600/35339 (27%)]	Loss: 0.227483
Train Epoch: 91 [10240/35339 (29%)]	Loss: 0.247857
Train Epoch: 91 [10880/35339 (31%)]	Loss: 0.194852
Train Epoch: 91 [11520/35339 (33%)]	Loss: 0.333160
Train Epoch: 91 [12160/35339 (34%)]	Loss: 0.438183
Train Epoch: 91 [12800/35339 (36%)]	Loss: 0.249000
Train Epoch: 91 [13440/35339 (38%)]	Loss: 0.358156
Train Epoch: 91 [14080/35339 (40%)]	Loss: 0.351412
Train Epoch: 91 [14720/35339 (42%)]	Loss: 0.262820
Train Epoch: 91 [15360/35339 (43%)]	Loss: 0.110177
Train Epoch: 91 [16000/35339 (45%)]	Loss: 0.139814
Train Epoch: 91 [16640/35339 (47%)]	Loss: 0.185249
Train Epoch: 91 [17280/35339 (49%)]	Loss: 0.405905
Train Epoch: 91 [17920/35339 (51%)]	Loss: 0.237412
Train Epoch: 91 [18560/35339 (52%)]	Loss: 0.223226
Train Epoch: 91 [19200/35339 (54%)]	Loss: 0.188306
Train Epoch: 91 [19840/35339 (56%)]	Loss: 0.257117
Train Epoch: 91 [20480/35339 (58%)]	Loss: 0.217391
Train Epoch: 91 [21120/35339 (60%)]	Loss: 0.223598
Train Epoch: 91 [21760/35339 (61%)]	Loss: 0.217936
Train Epoch: 91 [22400/35339 (63%)]	Loss: 0.228244
Train Epoch: 91 [23040/35339 (65%)]	Loss: 0.294178
Train Epoch: 91 [23680/35339 (67%)]	Loss: 0.238747
Train Epoch: 91 [24320/35339 (69%)]	Loss: 0.284166
Train Epoch: 91 [24960/35339 (71%)]	Loss: 0.149444
Train Epoch: 91 [25600/35339 (72%)]	Loss: 0.399829
Train Epoch: 91 [26240/35339 (74%)]	Loss: 0.218016
Train Epoch: 91 [26880/35339 (76%)]	Loss: 0.288698
Train Epoch: 91 [27520/35339 (78%)]	Loss: 0.329113
Train Epoch: 91 [28160/35339 (80%)]	Loss: 0.206811
Train Epoch: 91 [28800/35339 (81%)]	Loss: 0.173847
Train Epoch: 91 [29440/35339 (83%)]	Loss: 0.303528
Train Epoch: 91 [30080/35339 (85%)]	Loss: 0.223016
Train Epoch: 91 [30720/35339 (87%)]	Loss: 0.166320
Train Epoch: 91 [31360/35339 (89%)]	Loss: 0.224622
Train Epoch: 91 [32000/35339 (90%)]	Loss: 0.174789
Train Epoch: 91 [32640/35339 (92%)]	Loss: 0.237677
Train Epoch: 91 [33280/35339 (94%)]	Loss: 0.267083
Train Epoch: 91 [33920/35339 (96%)]	Loss: 0.180990
Train Epoch: 91 [34560/35339 (98%)]	Loss: 0.256758
Train Epoch: 91 [35200/35339 (99%)]	Loss: 0.164464

Validation set: Average loss: 1.4282, Accuracy: 2658/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 92 [0/35339 (0%)]	Loss: 0.230813
Train Epoch: 92 [640/35339 (2%)]	Loss: 0.382511
Train Epoch: 92 [1280/35339 (4%)]	Loss: 0.182113
Train Epoch: 92 [1920/35339 (5%)]	Loss: 0.293767
Train Epoch: 92 [2560/35339 (7%)]	Loss: 0.144941
Train Epoch: 92 [3200/35339 (9%)]	Loss: 0.342753
Train Epoch: 92 [3840/35339 (11%)]	Loss: 0.399721
Train Epoch: 92 [4480/35339 (13%)]	Loss: 0.311680
Train Epoch: 92 [5120/35339 (14%)]	Loss: 0.291105
Train Epoch: 92 [5760/35339 (16%)]	Loss: 0.253473
Train Epoch: 92 [6400/35339 (18%)]	Loss: 0.164266
Train Epoch: 92 [7040/35339 (20%)]	Loss: 0.201094
Train Epoch: 92 [7680/35339 (22%)]	Loss: 0.252494
Train Epoch: 92 [8320/35339 (24%)]	Loss: 0.330146
Train Epoch: 92 [8960/35339 (25%)]	Loss: 0.262754
Train Epoch: 92 [9600/35339 (27%)]	Loss: 0.376255
Train Epoch: 92 [10240/35339 (29%)]	Loss: 0.282983
Train Epoch: 92 [10880/35339 (31%)]	Loss: 0.205356
Train Epoch: 92 [11520/35339 (33%)]	Loss: 0.250699
Train Epoch: 92 [12160/35339 (34%)]	Loss: 0.163878
Train Epoch: 92 [12800/35339 (36%)]	Loss: 0.187507
Train Epoch: 92 [13440/35339 (38%)]	Loss: 0.425776
Train Epoch: 92 [14080/35339 (40%)]	Loss: 0.341151
Train Epoch: 92 [14720/35339 (42%)]	Loss: 0.272624
Train Epoch: 92 [15360/35339 (43%)]	Loss: 0.176281
Train Epoch: 92 [16000/35339 (45%)]	Loss: 0.221021
Train Epoch: 92 [16640/35339 (47%)]	Loss: 0.265086
Train Epoch: 92 [17280/35339 (49%)]	Loss: 0.405392
Train Epoch: 92 [17920/35339 (51%)]	Loss: 0.234392
Train Epoch: 92 [18560/35339 (52%)]	Loss: 0.235345
Train Epoch: 92 [19200/35339 (54%)]	Loss: 0.238402
Train Epoch: 92 [19840/35339 (56%)]	Loss: 0.081990
Train Epoch: 92 [20480/35339 (58%)]	Loss: 0.184729
Train Epoch: 92 [21120/35339 (60%)]	Loss: 0.162086
Train Epoch: 92 [21760/35339 (61%)]	Loss: 0.164958
Train Epoch: 92 [22400/35339 (63%)]	Loss: 0.216809
Train Epoch: 92 [23040/35339 (65%)]	Loss: 0.227334
Train Epoch: 92 [23680/35339 (67%)]	Loss: 0.207645
Train Epoch: 92 [24320/35339 (69%)]	Loss: 0.083747
Train Epoch: 92 [24960/35339 (71%)]	Loss: 0.311995
Train Epoch: 92 [25600/35339 (72%)]	Loss: 0.329344
Train Epoch: 92 [26240/35339 (74%)]	Loss: 0.184637
Train Epoch: 92 [26880/35339 (76%)]	Loss: 0.302228
Train Epoch: 92 [27520/35339 (78%)]	Loss: 0.282283
Train Epoch: 92 [28160/35339 (80%)]	Loss: 0.377734
Train Epoch: 92 [28800/35339 (81%)]	Loss: 0.338738
Train Epoch: 92 [29440/35339 (83%)]	Loss: 0.300317
Train Epoch: 92 [30080/35339 (85%)]	Loss: 0.163807
Train Epoch: 92 [30720/35339 (87%)]	Loss: 0.175345
Train Epoch: 92 [31360/35339 (89%)]	Loss: 0.270119
Train Epoch: 92 [32000/35339 (90%)]	Loss: 0.194919
Train Epoch: 92 [32640/35339 (92%)]	Loss: 0.203142
Train Epoch: 92 [33280/35339 (94%)]	Loss: 0.137617
Train Epoch: 92 [33920/35339 (96%)]	Loss: 0.269568
Train Epoch: 92 [34560/35339 (98%)]	Loss: 0.353401
Train Epoch: 92 [35200/35339 (99%)]	Loss: 0.190508

Validation set: Average loss: 1.4650, Accuracy: 2668/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 93 [0/35339 (0%)]	Loss: 0.385780
Train Epoch: 93 [640/35339 (2%)]	Loss: 0.303011
Train Epoch: 93 [1280/35339 (4%)]	Loss: 0.164464
Train Epoch: 93 [1920/35339 (5%)]	Loss: 0.182081
Train Epoch: 93 [2560/35339 (7%)]	Loss: 0.327843
Train Epoch: 93 [3200/35339 (9%)]	Loss: 0.281936
Train Epoch: 93 [3840/35339 (11%)]	Loss: 0.118423
Train Epoch: 93 [4480/35339 (13%)]	Loss: 0.221227
Train Epoch: 93 [5120/35339 (14%)]	Loss: 0.157365
Train Epoch: 93 [5760/35339 (16%)]	Loss: 0.299383
Train Epoch: 93 [6400/35339 (18%)]	Loss: 0.341174
Train Epoch: 93 [7040/35339 (20%)]	Loss: 0.241651
Train Epoch: 93 [7680/35339 (22%)]	Loss: 0.325172
Train Epoch: 93 [8320/35339 (24%)]	Loss: 0.369337
Train Epoch: 93 [8960/35339 (25%)]	Loss: 0.392132
Train Epoch: 93 [9600/35339 (27%)]	Loss: 0.148709
Train Epoch: 93 [10240/35339 (29%)]	Loss: 0.333384
Train Epoch: 93 [10880/35339 (31%)]	Loss: 0.305926
Train Epoch: 93 [11520/35339 (33%)]	Loss: 0.228894
Train Epoch: 93 [12160/35339 (34%)]	Loss: 0.165927
Train Epoch: 93 [12800/35339 (36%)]	Loss: 0.240086
Train Epoch: 93 [13440/35339 (38%)]	Loss: 0.417772
Train Epoch: 93 [14080/35339 (40%)]	Loss: 0.156345
Train Epoch: 93 [14720/35339 (42%)]	Loss: 0.234768
Train Epoch: 93 [15360/35339 (43%)]	Loss: 0.193955
Train Epoch: 93 [16000/35339 (45%)]	Loss: 0.264184
Train Epoch: 93 [16640/35339 (47%)]	Loss: 0.354730
Train Epoch: 93 [17280/35339 (49%)]	Loss: 0.250991
Train Epoch: 93 [17920/35339 (51%)]	Loss: 0.190675
Train Epoch: 93 [18560/35339 (52%)]	Loss: 0.254919
Train Epoch: 93 [19200/35339 (54%)]	Loss: 0.263109
Train Epoch: 93 [19840/35339 (56%)]	Loss: 0.235139
Train Epoch: 93 [20480/35339 (58%)]	Loss: 0.186759
Train Epoch: 93 [21120/35339 (60%)]	Loss: 0.170654
Train Epoch: 93 [21760/35339 (61%)]	Loss: 0.259352
Train Epoch: 93 [22400/35339 (63%)]	Loss: 0.287421
Train Epoch: 93 [23040/35339 (65%)]	Loss: 0.201563
Train Epoch: 93 [23680/35339 (67%)]	Loss: 0.238658
Train Epoch: 93 [24320/35339 (69%)]	Loss: 0.230397
Train Epoch: 93 [24960/35339 (71%)]	Loss: 0.112108
Train Epoch: 93 [25600/35339 (72%)]	Loss: 0.162233
Train Epoch: 93 [26240/35339 (74%)]	Loss: 0.152295
Train Epoch: 93 [26880/35339 (76%)]	Loss: 0.329673
Train Epoch: 93 [27520/35339 (78%)]	Loss: 0.185748
Train Epoch: 93 [28160/35339 (80%)]	Loss: 0.250135
Train Epoch: 93 [28800/35339 (81%)]	Loss: 0.239286
Train Epoch: 93 [29440/35339 (83%)]	Loss: 0.325343
Train Epoch: 93 [30080/35339 (85%)]	Loss: 0.310321
Train Epoch: 93 [30720/35339 (87%)]	Loss: 0.378510
Train Epoch: 93 [31360/35339 (89%)]	Loss: 0.279032
Train Epoch: 93 [32000/35339 (90%)]	Loss: 0.179671
Train Epoch: 93 [32640/35339 (92%)]	Loss: 0.249746
Train Epoch: 93 [33280/35339 (94%)]	Loss: 0.181086
Train Epoch: 93 [33920/35339 (96%)]	Loss: 0.176809
Train Epoch: 93 [34560/35339 (98%)]	Loss: 0.352424
Train Epoch: 93 [35200/35339 (99%)]	Loss: 0.301925

Validation set: Average loss: 1.5533, Accuracy: 2636/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 94 [0/35339 (0%)]	Loss: 0.368631
Train Epoch: 94 [640/35339 (2%)]	Loss: 0.450079
Train Epoch: 94 [1280/35339 (4%)]	Loss: 0.095638
Train Epoch: 94 [1920/35339 (5%)]	Loss: 0.176978
Train Epoch: 94 [2560/35339 (7%)]	Loss: 0.270751
Train Epoch: 94 [3200/35339 (9%)]	Loss: 0.516662
Train Epoch: 94 [3840/35339 (11%)]	Loss: 0.351045
Train Epoch: 94 [4480/35339 (13%)]	Loss: 0.390203
Train Epoch: 94 [5120/35339 (14%)]	Loss: 0.312727
Train Epoch: 94 [5760/35339 (16%)]	Loss: 0.243792
Train Epoch: 94 [6400/35339 (18%)]	Loss: 0.213927
Train Epoch: 94 [7040/35339 (20%)]	Loss: 0.209721
Train Epoch: 94 [7680/35339 (22%)]	Loss: 0.186214
Train Epoch: 94 [8320/35339 (24%)]	Loss: 0.248551
Train Epoch: 94 [8960/35339 (25%)]	Loss: 0.380938
Train Epoch: 94 [9600/35339 (27%)]	Loss: 0.282349
Train Epoch: 94 [10240/35339 (29%)]	Loss: 0.275235
Train Epoch: 94 [10880/35339 (31%)]	Loss: 0.134300
Train Epoch: 94 [11520/35339 (33%)]	Loss: 0.165858
Train Epoch: 94 [12160/35339 (34%)]	Loss: 0.301174
Train Epoch: 94 [12800/35339 (36%)]	Loss: 0.242842
Train Epoch: 94 [13440/35339 (38%)]	Loss: 0.401593
Train Epoch: 94 [14080/35339 (40%)]	Loss: 0.285086
Train Epoch: 94 [14720/35339 (42%)]	Loss: 0.150555
Train Epoch: 94 [15360/35339 (43%)]	Loss: 0.262788
Train Epoch: 94 [16000/35339 (45%)]	Loss: 0.130263
Train Epoch: 94 [16640/35339 (47%)]	Loss: 0.237875
Train Epoch: 94 [17280/35339 (49%)]	Loss: 0.275941
Train Epoch: 94 [17920/35339 (51%)]	Loss: 0.203422
Train Epoch: 94 [18560/35339 (52%)]	Loss: 0.178995
Train Epoch: 94 [19200/35339 (54%)]	Loss: 0.263585
Train Epoch: 94 [19840/35339 (56%)]	Loss: 0.349537
Train Epoch: 94 [20480/35339 (58%)]	Loss: 0.254618
Train Epoch: 94 [21120/35339 (60%)]	Loss: 0.284103
Train Epoch: 94 [21760/35339 (61%)]	Loss: 0.198134
Train Epoch: 94 [22400/35339 (63%)]	Loss: 0.216408
Train Epoch: 94 [23040/35339 (65%)]	Loss: 0.289287
Train Epoch: 94 [23680/35339 (67%)]	Loss: 0.257885
Train Epoch: 94 [24320/35339 (69%)]	Loss: 0.387990
Train Epoch: 94 [24960/35339 (71%)]	Loss: 0.268397
Train Epoch: 94 [25600/35339 (72%)]	Loss: 0.236946
Train Epoch: 94 [26240/35339 (74%)]	Loss: 0.292248
Train Epoch: 94 [26880/35339 (76%)]	Loss: 0.267071
Train Epoch: 94 [27520/35339 (78%)]	Loss: 0.248062
Train Epoch: 94 [28160/35339 (80%)]	Loss: 0.151840
Train Epoch: 94 [28800/35339 (81%)]	Loss: 0.314537
Train Epoch: 94 [29440/35339 (83%)]	Loss: 0.167482
Train Epoch: 94 [30080/35339 (85%)]	Loss: 0.233424
Train Epoch: 94 [30720/35339 (87%)]	Loss: 0.257487
Train Epoch: 94 [31360/35339 (89%)]	Loss: 0.345795
Train Epoch: 94 [32000/35339 (90%)]	Loss: 0.274924
Train Epoch: 94 [32640/35339 (92%)]	Loss: 0.395533
Train Epoch: 94 [33280/35339 (94%)]	Loss: 0.217391
Train Epoch: 94 [33920/35339 (96%)]	Loss: 0.244601
Train Epoch: 94 [34560/35339 (98%)]	Loss: 0.299865
Train Epoch: 94 [35200/35339 (99%)]	Loss: 0.386827

Validation set: Average loss: 1.4800, Accuracy: 2663/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 95 [0/35339 (0%)]	Loss: 0.256739
Train Epoch: 95 [640/35339 (2%)]	Loss: 0.292569
Train Epoch: 95 [1280/35339 (4%)]	Loss: 0.350747
Train Epoch: 95 [1920/35339 (5%)]	Loss: 0.285266
Train Epoch: 95 [2560/35339 (7%)]	Loss: 0.289810
Train Epoch: 95 [3200/35339 (9%)]	Loss: 0.246906
Train Epoch: 95 [3840/35339 (11%)]	Loss: 0.208017
Train Epoch: 95 [4480/35339 (13%)]	Loss: 0.268804
Train Epoch: 95 [5120/35339 (14%)]	Loss: 0.195461
Train Epoch: 95 [5760/35339 (16%)]	Loss: 0.232495
Train Epoch: 95 [6400/35339 (18%)]	Loss: 0.269164
Train Epoch: 95 [7040/35339 (20%)]	Loss: 0.305182
Train Epoch: 95 [7680/35339 (22%)]	Loss: 0.246053
Train Epoch: 95 [8320/35339 (24%)]	Loss: 0.354003
Train Epoch: 95 [8960/35339 (25%)]	Loss: 0.291818
Train Epoch: 95 [9600/35339 (27%)]	Loss: 0.220034
Train Epoch: 95 [10240/35339 (29%)]	Loss: 0.331706
Train Epoch: 95 [10880/35339 (31%)]	Loss: 0.485122
Train Epoch: 95 [11520/35339 (33%)]	Loss: 0.225918
Train Epoch: 95 [12160/35339 (34%)]	Loss: 0.258208
Train Epoch: 95 [12800/35339 (36%)]	Loss: 0.775966
Train Epoch: 95 [13440/35339 (38%)]	Loss: 0.306684
Train Epoch: 95 [14080/35339 (40%)]	Loss: 0.351628
Train Epoch: 95 [14720/35339 (42%)]	Loss: 0.284425
Train Epoch: 95 [15360/35339 (43%)]	Loss: 0.229019
Train Epoch: 95 [16000/35339 (45%)]	Loss: 0.401542
Train Epoch: 95 [16640/35339 (47%)]	Loss: 0.219888
Train Epoch: 95 [17280/35339 (49%)]	Loss: 0.189107
Train Epoch: 95 [17920/35339 (51%)]	Loss: 0.135438
Train Epoch: 95 [18560/35339 (52%)]	Loss: 0.296452
Train Epoch: 95 [19200/35339 (54%)]	Loss: 0.436313
Train Epoch: 95 [19840/35339 (56%)]	Loss: 0.241759
Train Epoch: 95 [20480/35339 (58%)]	Loss: 0.305079
Train Epoch: 95 [21120/35339 (60%)]	Loss: 0.255792
Train Epoch: 95 [21760/35339 (61%)]	Loss: 0.441129
Train Epoch: 95 [22400/35339 (63%)]	Loss: 0.168900
Train Epoch: 95 [23040/35339 (65%)]	Loss: 0.436366
Train Epoch: 95 [23680/35339 (67%)]	Loss: 0.276478
Train Epoch: 95 [24320/35339 (69%)]	Loss: 0.227522
Train Epoch: 95 [24960/35339 (71%)]	Loss: 0.303127
Train Epoch: 95 [25600/35339 (72%)]	Loss: 0.348001
Train Epoch: 95 [26240/35339 (74%)]	Loss: 0.296545
Train Epoch: 95 [26880/35339 (76%)]	Loss: 0.406191
Train Epoch: 95 [27520/35339 (78%)]	Loss: 0.248865
Train Epoch: 95 [28160/35339 (80%)]	Loss: 0.144007
Train Epoch: 95 [28800/35339 (81%)]	Loss: 0.233804
Train Epoch: 95 [29440/35339 (83%)]	Loss: 0.373014
Train Epoch: 95 [30080/35339 (85%)]	Loss: 0.220628
Train Epoch: 95 [30720/35339 (87%)]	Loss: 0.273360
Train Epoch: 95 [31360/35339 (89%)]	Loss: 0.203484
Train Epoch: 95 [32000/35339 (90%)]	Loss: 0.172571
Train Epoch: 95 [32640/35339 (92%)]	Loss: 0.131224
Train Epoch: 95 [33280/35339 (94%)]	Loss: 0.277479
Train Epoch: 95 [33920/35339 (96%)]	Loss: 0.282924
Train Epoch: 95 [34560/35339 (98%)]	Loss: 0.294621
Train Epoch: 95 [35200/35339 (99%)]	Loss: 0.220658

Validation set: Average loss: 1.4677, Accuracy: 2656/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 96 [0/35339 (0%)]	Loss: 0.295875
Train Epoch: 96 [640/35339 (2%)]	Loss: 0.251276
Train Epoch: 96 [1280/35339 (4%)]	Loss: 0.412353
Train Epoch: 96 [1920/35339 (5%)]	Loss: 0.194032
Train Epoch: 96 [2560/35339 (7%)]	Loss: 0.316595
Train Epoch: 96 [3200/35339 (9%)]	Loss: 0.229771
Train Epoch: 96 [3840/35339 (11%)]	Loss: 0.273715
Train Epoch: 96 [4480/35339 (13%)]	Loss: 0.171087
Train Epoch: 96 [5120/35339 (14%)]	Loss: 0.265853
Train Epoch: 96 [5760/35339 (16%)]	Loss: 0.247677
Train Epoch: 96 [6400/35339 (18%)]	Loss: 0.322806
Train Epoch: 96 [7040/35339 (20%)]	Loss: 0.245244
Train Epoch: 96 [7680/35339 (22%)]	Loss: 0.272643
Train Epoch: 96 [8320/35339 (24%)]	Loss: 0.133782
Train Epoch: 96 [8960/35339 (25%)]	Loss: 0.241832
Train Epoch: 96 [9600/35339 (27%)]	Loss: 0.181886
Train Epoch: 96 [10240/35339 (29%)]	Loss: 0.153818
Train Epoch: 96 [10880/35339 (31%)]	Loss: 0.153760
Train Epoch: 96 [11520/35339 (33%)]	Loss: 0.133370
Train Epoch: 96 [12160/35339 (34%)]	Loss: 0.290754
Train Epoch: 96 [12800/35339 (36%)]	Loss: 0.215992
Train Epoch: 96 [13440/35339 (38%)]	Loss: 0.169634
Train Epoch: 96 [14080/35339 (40%)]	Loss: 0.244913
Train Epoch: 96 [14720/35339 (42%)]	Loss: 0.256660
Train Epoch: 96 [15360/35339 (43%)]	Loss: 0.219280
Train Epoch: 96 [16000/35339 (45%)]	Loss: 0.376771
Train Epoch: 96 [16640/35339 (47%)]	Loss: 0.257945
Train Epoch: 96 [17280/35339 (49%)]	Loss: 0.251143
Train Epoch: 96 [17920/35339 (51%)]	Loss: 0.298554
Train Epoch: 96 [18560/35339 (52%)]	Loss: 0.200280
Train Epoch: 96 [19200/35339 (54%)]	Loss: 0.188326
Train Epoch: 96 [19840/35339 (56%)]	Loss: 0.244440
Train Epoch: 96 [20480/35339 (58%)]	Loss: 0.289335
Train Epoch: 96 [21120/35339 (60%)]	Loss: 0.197375
Train Epoch: 96 [21760/35339 (61%)]	Loss: 0.235273
Train Epoch: 96 [22400/35339 (63%)]	Loss: 0.294892
Train Epoch: 96 [23040/35339 (65%)]	Loss: 0.265289
Train Epoch: 96 [23680/35339 (67%)]	Loss: 0.248800
Train Epoch: 96 [24320/35339 (69%)]	Loss: 0.182605
Train Epoch: 96 [24960/35339 (71%)]	Loss: 0.360097
Train Epoch: 96 [25600/35339 (72%)]	Loss: 0.230395
Train Epoch: 96 [26240/35339 (74%)]	Loss: 0.206593
Train Epoch: 96 [26880/35339 (76%)]	Loss: 0.264402
Train Epoch: 96 [27520/35339 (78%)]	Loss: 0.210240
Train Epoch: 96 [28160/35339 (80%)]	Loss: 0.179830
Train Epoch: 96 [28800/35339 (81%)]	Loss: 0.151523
Train Epoch: 96 [29440/35339 (83%)]	Loss: 0.214657
Train Epoch: 96 [30080/35339 (85%)]	Loss: 0.297922
Train Epoch: 96 [30720/35339 (87%)]	Loss: 0.160593
Train Epoch: 96 [31360/35339 (89%)]	Loss: 0.246962
Train Epoch: 96 [32000/35339 (90%)]	Loss: 0.150049
Train Epoch: 96 [32640/35339 (92%)]	Loss: 0.203298
Train Epoch: 96 [33280/35339 (94%)]	Loss: 0.339469
Train Epoch: 96 [33920/35339 (96%)]	Loss: 0.268906
Train Epoch: 96 [34560/35339 (98%)]	Loss: 0.199233
Train Epoch: 96 [35200/35339 (99%)]	Loss: 0.131503

Validation set: Average loss: 1.4250, Accuracy: 2664/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 97 [0/35339 (0%)]	Loss: 0.260953
Train Epoch: 97 [640/35339 (2%)]	Loss: 0.279694
Train Epoch: 97 [1280/35339 (4%)]	Loss: 0.193434
Train Epoch: 97 [1920/35339 (5%)]	Loss: 0.221071
Train Epoch: 97 [2560/35339 (7%)]	Loss: 0.427724
Train Epoch: 97 [3200/35339 (9%)]	Loss: 0.246621
Train Epoch: 97 [3840/35339 (11%)]	Loss: 0.232349
Train Epoch: 97 [4480/35339 (13%)]	Loss: 0.193049
Train Epoch: 97 [5120/35339 (14%)]	Loss: 0.304585
Train Epoch: 97 [5760/35339 (16%)]	Loss: 0.364754
Train Epoch: 97 [6400/35339 (18%)]	Loss: 0.381477
Train Epoch: 97 [7040/35339 (20%)]	Loss: 0.222830
Train Epoch: 97 [7680/35339 (22%)]	Loss: 0.483662
Train Epoch: 97 [8320/35339 (24%)]	Loss: 0.234005
Train Epoch: 97 [8960/35339 (25%)]	Loss: 0.117194
Train Epoch: 97 [9600/35339 (27%)]	Loss: 0.182584
Train Epoch: 97 [10240/35339 (29%)]	Loss: 0.312550
Train Epoch: 97 [10880/35339 (31%)]	Loss: 0.361286
Train Epoch: 97 [11520/35339 (33%)]	Loss: 0.219327
Train Epoch: 97 [12160/35339 (34%)]	Loss: 0.149757
Train Epoch: 97 [12800/35339 (36%)]	Loss: 0.331760
Train Epoch: 97 [13440/35339 (38%)]	Loss: 0.444339
Train Epoch: 97 [14080/35339 (40%)]	Loss: 0.254134
Train Epoch: 97 [14720/35339 (42%)]	Loss: 0.196594
Train Epoch: 97 [15360/35339 (43%)]	Loss: 0.279465
Train Epoch: 97 [16000/35339 (45%)]	Loss: 0.210426
Train Epoch: 97 [16640/35339 (47%)]	Loss: 0.334774
Train Epoch: 97 [17280/35339 (49%)]	Loss: 0.256074
Train Epoch: 97 [17920/35339 (51%)]	Loss: 0.277574
Train Epoch: 97 [18560/35339 (52%)]	Loss: 0.306096
Train Epoch: 97 [19200/35339 (54%)]	Loss: 0.309231
Train Epoch: 97 [19840/35339 (56%)]	Loss: 0.348690
Train Epoch: 97 [20480/35339 (58%)]	Loss: 0.381539
Train Epoch: 97 [21120/35339 (60%)]	Loss: 0.218200
Train Epoch: 97 [21760/35339 (61%)]	Loss: 0.421165
Train Epoch: 97 [22400/35339 (63%)]	Loss: 0.270349
Train Epoch: 97 [23040/35339 (65%)]	Loss: 0.246234
Train Epoch: 97 [23680/35339 (67%)]	Loss: 0.381645
Train Epoch: 97 [24320/35339 (69%)]	Loss: 0.312515
Train Epoch: 97 [24960/35339 (71%)]	Loss: 0.214688
Train Epoch: 97 [25600/35339 (72%)]	Loss: 0.250405
Train Epoch: 97 [26240/35339 (74%)]	Loss: 0.268478
Train Epoch: 97 [26880/35339 (76%)]	Loss: 0.276075
Train Epoch: 97 [27520/35339 (78%)]	Loss: 0.218754
Train Epoch: 97 [28160/35339 (80%)]	Loss: 0.233149
Train Epoch: 97 [28800/35339 (81%)]	Loss: 0.500015
Train Epoch: 97 [29440/35339 (83%)]	Loss: 0.239141
Train Epoch: 97 [30080/35339 (85%)]	Loss: 0.195552
Train Epoch: 97 [30720/35339 (87%)]	Loss: 0.292591
Train Epoch: 97 [31360/35339 (89%)]	Loss: 0.251888
Train Epoch: 97 [32000/35339 (90%)]	Loss: 0.240226
Train Epoch: 97 [32640/35339 (92%)]	Loss: 0.244919
Train Epoch: 97 [33280/35339 (94%)]	Loss: 0.167787
Train Epoch: 97 [33920/35339 (96%)]	Loss: 0.143824
Train Epoch: 97 [34560/35339 (98%)]	Loss: 0.165618
Train Epoch: 97 [35200/35339 (99%)]	Loss: 0.092152

Validation set: Average loss: 1.4915, Accuracy: 2641/3870 (68%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 98 [0/35339 (0%)]	Loss: 0.348825
Train Epoch: 98 [640/35339 (2%)]	Loss: 0.186921
Train Epoch: 98 [1280/35339 (4%)]	Loss: 0.411442
Train Epoch: 98 [1920/35339 (5%)]	Loss: 0.338710
Train Epoch: 98 [2560/35339 (7%)]	Loss: 0.336555
Train Epoch: 98 [3200/35339 (9%)]	Loss: 0.326373
Train Epoch: 98 [3840/35339 (11%)]	Loss: 0.209102
Train Epoch: 98 [4480/35339 (13%)]	Loss: 0.393268
Train Epoch: 98 [5120/35339 (14%)]	Loss: 0.226476
Train Epoch: 98 [5760/35339 (16%)]	Loss: 0.125594
Train Epoch: 98 [6400/35339 (18%)]	Loss: 0.168628
Train Epoch: 98 [7040/35339 (20%)]	Loss: 0.374149
Train Epoch: 98 [7680/35339 (22%)]	Loss: 0.242434
Train Epoch: 98 [8320/35339 (24%)]	Loss: 0.234696
Train Epoch: 98 [8960/35339 (25%)]	Loss: 0.327757
Train Epoch: 98 [9600/35339 (27%)]	Loss: 0.151042
Train Epoch: 98 [10240/35339 (29%)]	Loss: 0.364504
Train Epoch: 98 [10880/35339 (31%)]	Loss: 0.341292
Train Epoch: 98 [11520/35339 (33%)]	Loss: 0.158103
Train Epoch: 98 [12160/35339 (34%)]	Loss: 0.212304
Train Epoch: 98 [12800/35339 (36%)]	Loss: 0.232396
Train Epoch: 98 [13440/35339 (38%)]	Loss: 0.296011
Train Epoch: 98 [14080/35339 (40%)]	Loss: 0.426693
Train Epoch: 98 [14720/35339 (42%)]	Loss: 0.223675
Train Epoch: 98 [15360/35339 (43%)]	Loss: 0.105946
Train Epoch: 98 [16000/35339 (45%)]	Loss: 0.197750
Train Epoch: 98 [16640/35339 (47%)]	Loss: 0.263991
Train Epoch: 98 [17280/35339 (49%)]	Loss: 0.165717
Train Epoch: 98 [17920/35339 (51%)]	Loss: 0.168482
Train Epoch: 98 [18560/35339 (52%)]	Loss: 0.172782
Train Epoch: 98 [19200/35339 (54%)]	Loss: 0.392163
Train Epoch: 98 [19840/35339 (56%)]	Loss: 0.303824
Train Epoch: 98 [20480/35339 (58%)]	Loss: 0.319181
Train Epoch: 98 [21120/35339 (60%)]	Loss: 0.293807
Train Epoch: 98 [21760/35339 (61%)]	Loss: 0.306237
Train Epoch: 98 [22400/35339 (63%)]	Loss: 0.229942
Train Epoch: 98 [23040/35339 (65%)]	Loss: 0.201318
Train Epoch: 98 [23680/35339 (67%)]	Loss: 0.220176
Train Epoch: 98 [24320/35339 (69%)]	Loss: 0.198549
Train Epoch: 98 [24960/35339 (71%)]	Loss: 0.246687
Train Epoch: 98 [25600/35339 (72%)]	Loss: 0.131082
Train Epoch: 98 [26240/35339 (74%)]	Loss: 0.310239
Train Epoch: 98 [26880/35339 (76%)]	Loss: 0.143265
Train Epoch: 98 [27520/35339 (78%)]	Loss: 0.141698
Train Epoch: 98 [28160/35339 (80%)]	Loss: 0.206776
Train Epoch: 98 [28800/35339 (81%)]	Loss: 0.180036
Train Epoch: 98 [29440/35339 (83%)]	Loss: 0.154677
Train Epoch: 98 [30080/35339 (85%)]	Loss: 0.288153
Train Epoch: 98 [30720/35339 (87%)]	Loss: 0.306024
Train Epoch: 98 [31360/35339 (89%)]	Loss: 0.139086
Train Epoch: 98 [32000/35339 (90%)]	Loss: 0.258760
Train Epoch: 98 [32640/35339 (92%)]	Loss: 0.304858
Train Epoch: 98 [33280/35339 (94%)]	Loss: 0.205323
Train Epoch: 98 [33920/35339 (96%)]	Loss: 0.198278
Train Epoch: 98 [34560/35339 (98%)]	Loss: 0.259006
Train Epoch: 98 [35200/35339 (99%)]	Loss: 0.252537

Validation set: Average loss: 1.5010, Accuracy: 2658/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 99 [0/35339 (0%)]	Loss: 0.188861
Train Epoch: 99 [640/35339 (2%)]	Loss: 0.332621
Train Epoch: 99 [1280/35339 (4%)]	Loss: 0.267879
Train Epoch: 99 [1920/35339 (5%)]	Loss: 0.199962
Train Epoch: 99 [2560/35339 (7%)]	Loss: 0.068377
Train Epoch: 99 [3200/35339 (9%)]	Loss: 0.163068
Train Epoch: 99 [3840/35339 (11%)]	Loss: 0.182360
Train Epoch: 99 [4480/35339 (13%)]	Loss: 0.324609
Train Epoch: 99 [5120/35339 (14%)]	Loss: 0.239290
Train Epoch: 99 [5760/35339 (16%)]	Loss: 0.356379
Train Epoch: 99 [6400/35339 (18%)]	Loss: 0.228283
Train Epoch: 99 [7040/35339 (20%)]	Loss: 0.230787
Train Epoch: 99 [7680/35339 (22%)]	Loss: 0.714819
Train Epoch: 99 [8320/35339 (24%)]	Loss: 0.310319
Train Epoch: 99 [8960/35339 (25%)]	Loss: 0.288393
Train Epoch: 99 [9600/35339 (27%)]	Loss: 0.151488
Train Epoch: 99 [10240/35339 (29%)]	Loss: 0.375894
Train Epoch: 99 [10880/35339 (31%)]	Loss: 0.246575
Train Epoch: 99 [11520/35339 (33%)]	Loss: 0.501573
Train Epoch: 99 [12160/35339 (34%)]	Loss: 0.204915
Train Epoch: 99 [12800/35339 (36%)]	Loss: 0.194874
Train Epoch: 99 [13440/35339 (38%)]	Loss: 0.166346
Train Epoch: 99 [14080/35339 (40%)]	Loss: 0.253534
Train Epoch: 99 [14720/35339 (42%)]	Loss: 0.188826
Train Epoch: 99 [15360/35339 (43%)]	Loss: 0.321700
Train Epoch: 99 [16000/35339 (45%)]	Loss: 0.230019
Train Epoch: 99 [16640/35339 (47%)]	Loss: 0.211171
Train Epoch: 99 [17280/35339 (49%)]	Loss: 0.246860
Train Epoch: 99 [17920/35339 (51%)]	Loss: 0.224771
Train Epoch: 99 [18560/35339 (52%)]	Loss: 0.377257
Train Epoch: 99 [19200/35339 (54%)]	Loss: 0.187657
Train Epoch: 99 [19840/35339 (56%)]	Loss: 0.270176
Train Epoch: 99 [20480/35339 (58%)]	Loss: 0.223090
Train Epoch: 99 [21120/35339 (60%)]	Loss: 0.191548
Train Epoch: 99 [21760/35339 (61%)]	Loss: 0.235484
Train Epoch: 99 [22400/35339 (63%)]	Loss: 0.195789
Train Epoch: 99 [23040/35339 (65%)]	Loss: 0.161489
Train Epoch: 99 [23680/35339 (67%)]	Loss: 0.651596
Train Epoch: 99 [24320/35339 (69%)]	Loss: 0.222508
Train Epoch: 99 [24960/35339 (71%)]	Loss: 0.251321
Train Epoch: 99 [25600/35339 (72%)]	Loss: 0.154703
Train Epoch: 99 [26240/35339 (74%)]	Loss: 0.370165
Train Epoch: 99 [26880/35339 (76%)]	Loss: 0.246463
Train Epoch: 99 [27520/35339 (78%)]	Loss: 0.237956
Train Epoch: 99 [28160/35339 (80%)]	Loss: 0.205804
Train Epoch: 99 [28800/35339 (81%)]	Loss: 0.224943
Train Epoch: 99 [29440/35339 (83%)]	Loss: 0.307308
Train Epoch: 99 [30080/35339 (85%)]	Loss: 0.291246
Train Epoch: 99 [30720/35339 (87%)]	Loss: 0.350756
Train Epoch: 99 [31360/35339 (89%)]	Loss: 0.253869
Train Epoch: 99 [32000/35339 (90%)]	Loss: 0.401247
Train Epoch: 99 [32640/35339 (92%)]	Loss: 0.216802
Train Epoch: 99 [33280/35339 (94%)]	Loss: 0.292251
Train Epoch: 99 [33920/35339 (96%)]	Loss: 0.228034
Train Epoch: 99 [34560/35339 (98%)]	Loss: 0.252452
Train Epoch: 99 [35200/35339 (99%)]	Loss: 0.281915

Validation set: Average loss: 1.4646, Accuracy: 2658/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 100 [0/35339 (0%)]	Loss: 0.099589
Train Epoch: 100 [640/35339 (2%)]	Loss: 0.132346
Train Epoch: 100 [1280/35339 (4%)]	Loss: 0.345547
Train Epoch: 100 [1920/35339 (5%)]	Loss: 0.172835
Train Epoch: 100 [2560/35339 (7%)]	Loss: 0.160415
Train Epoch: 100 [3200/35339 (9%)]	Loss: 0.148727
Train Epoch: 100 [3840/35339 (11%)]	Loss: 0.239407
Train Epoch: 100 [4480/35339 (13%)]	Loss: 0.147598
Train Epoch: 100 [5120/35339 (14%)]	Loss: 0.143647
Train Epoch: 100 [5760/35339 (16%)]	Loss: 0.223095
Train Epoch: 100 [6400/35339 (18%)]	Loss: 0.192854
Train Epoch: 100 [7040/35339 (20%)]	Loss: 0.124836
Train Epoch: 100 [7680/35339 (22%)]	Loss: 0.256489
Train Epoch: 100 [8320/35339 (24%)]	Loss: 0.313703
Train Epoch: 100 [8960/35339 (25%)]	Loss: 0.354095
Train Epoch: 100 [9600/35339 (27%)]	Loss: 0.289594
Train Epoch: 100 [10240/35339 (29%)]	Loss: 0.360671
Train Epoch: 100 [10880/35339 (31%)]	Loss: 0.210073
Train Epoch: 100 [11520/35339 (33%)]	Loss: 0.209702
Train Epoch: 100 [12160/35339 (34%)]	Loss: 0.279975
Train Epoch: 100 [12800/35339 (36%)]	Loss: 0.182998
Train Epoch: 100 [13440/35339 (38%)]	Loss: 0.126469
Train Epoch: 100 [14080/35339 (40%)]	Loss: 0.263677
Train Epoch: 100 [14720/35339 (42%)]	Loss: 0.326100
Train Epoch: 100 [15360/35339 (43%)]	Loss: 0.178971
Train Epoch: 100 [16000/35339 (45%)]	Loss: 0.191149
Train Epoch: 100 [16640/35339 (47%)]	Loss: 0.204710
Train Epoch: 100 [17280/35339 (49%)]	Loss: 0.208617
Train Epoch: 100 [17920/35339 (51%)]	Loss: 0.177216
Train Epoch: 100 [18560/35339 (52%)]	Loss: 0.375015
Train Epoch: 100 [19200/35339 (54%)]	Loss: 0.271253
Train Epoch: 100 [19840/35339 (56%)]	Loss: 0.181529
Train Epoch: 100 [20480/35339 (58%)]	Loss: 0.218652
Train Epoch: 100 [21120/35339 (60%)]	Loss: 0.135340
Train Epoch: 100 [21760/35339 (61%)]	Loss: 0.154042
Train Epoch: 100 [22400/35339 (63%)]	Loss: 0.122608
Train Epoch: 100 [23040/35339 (65%)]	Loss: 0.264838
Train Epoch: 100 [23680/35339 (67%)]	Loss: 0.304502
Train Epoch: 100 [24320/35339 (69%)]	Loss: 0.301800
Train Epoch: 100 [24960/35339 (71%)]	Loss: 0.304792
Train Epoch: 100 [25600/35339 (72%)]	Loss: 0.277650
Train Epoch: 100 [26240/35339 (74%)]	Loss: 0.173590
Train Epoch: 100 [26880/35339 (76%)]	Loss: 0.227117
Train Epoch: 100 [27520/35339 (78%)]	Loss: 0.268082
Train Epoch: 100 [28160/35339 (80%)]	Loss: 0.232805
Train Epoch: 100 [28800/35339 (81%)]	Loss: 0.216947
Train Epoch: 100 [29440/35339 (83%)]	Loss: 0.228442
Train Epoch: 100 [30080/35339 (85%)]	Loss: 0.184224
Train Epoch: 100 [30720/35339 (87%)]	Loss: 0.291476
Train Epoch: 100 [31360/35339 (89%)]	Loss: 0.126245
Train Epoch: 100 [32000/35339 (90%)]	Loss: 0.272221
Train Epoch: 100 [32640/35339 (92%)]	Loss: 0.221811
Train Epoch: 100 [33280/35339 (94%)]	Loss: 0.380413
Train Epoch: 100 [33920/35339 (96%)]	Loss: 0.349210
Train Epoch: 100 [34560/35339 (98%)]	Loss: 0.374945
Train Epoch: 100 [35200/35339 (99%)]	Loss: 0.392408

Validation set: Average loss: 1.4713, Accuracy: 2678/3870 (69%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
  0%|          | 0/12631 [00:00<?, ?it/s]  0%|          | 46/12631 [00:00<00:27, 459.35it/s]  1%|          | 94/12631 [00:00<00:27, 464.23it/s]  1%|1         | 142/12631 [00:00<00:26, 467.89it/s]  1%|1         | 186/12631 [00:00<00:27, 456.97it/s]  2%|1         | 226/12631 [00:00<00:28, 436.70it/s]  2%|2         | 267/12631 [00:00<00:29, 424.80it/s]  2%|2         | 309/12631 [00:00<00:29, 420.93it/s]  3%|2         | 350/12631 [00:00<00:29, 416.91it/s]  3%|3         | 390/12631 [00:00<00:30, 406.61it/s]  3%|3         | 431/12631 [00:01<00:30, 405.49it/s]  4%|3         | 474/12631 [00:01<00:29, 411.35it/s]  4%|4         | 520/12631 [00:01<00:28, 423.29it/s]  4%|4         | 563/12631 [00:01<00:28, 423.43it/s]  5%|4         | 606/12631 [00:01<00:28, 418.06it/s]  5%|5         | 648/12631 [00:01<00:29, 412.30it/s]  5%|5         | 690/12631 [00:01<00:29, 405.80it/s]  6%|5         | 734/12631 [00:01<00:28, 413.78it/s]  6%|6         | 776/12631 [00:01<00:29, 404.94it/s]  6%|6         | 817/12631 [00:01<00:29, 400.47it/s]  7%|6         | 858/12631 [00:02<00:29, 397.12it/s]  7%|7         | 898/12631 [00:02<00:29, 392.81it/s]  7%|7         | 939/12631 [00:02<00:29, 397.79it/s]  8%|7         | 979/12631 [00:02<00:30, 388.19it/s]  8%|8         | 1018/12631 [00:02<00:30, 375.22it/s]  8%|8         | 1056/12631 [00:02<00:31, 367.91it/s]  9%|8         | 1096/12631 [00:02<00:30, 375.06it/s]  9%|9         | 1137/12631 [00:02<00:30, 381.39it/s]  9%|9         | 1176/12631 [00:02<00:30, 372.84it/s] 10%|9         | 1214/12631 [00:03<00:30, 373.37it/s] 10%|9         | 1252/12631 [00:03<00:30, 370.24it/s] 10%|#         | 1292/12631 [00:03<00:30, 376.70it/s] 11%|#         | 1330/12631 [00:03<00:29, 377.43it/s] 11%|#         | 1368/12631 [00:03<00:30, 369.77it/s] 11%|#1        | 1406/12631 [00:03<00:30, 364.98it/s] 11%|#1        | 1443/12631 [00:03<00:30, 364.15it/s] 12%|#1        | 1483/12631 [00:03<00:29, 372.99it/s] 12%|#2        | 1522/12631 [00:03<00:29, 376.29it/s] 12%|#2        | 1560/12631 [00:03<00:29, 369.31it/s] 13%|#2        | 1599/12631 [00:04<00:29, 373.02it/s] 13%|#2        | 1638/12631 [00:04<00:29, 376.59it/s] 13%|#3        | 1682/12631 [00:04<00:27, 392.71it/s] 14%|#3        | 1730/12631 [00:04<00:26, 414.62it/s] 14%|#4        | 1782/12631 [00:04<00:24, 440.44it/s] 15%|#4        | 1834/12631 [00:04<00:23, 460.96it/s] 15%|#4        | 1884/12631 [00:04<00:22, 470.61it/s] 15%|#5        | 1932/12631 [00:04<00:22, 468.77it/s] 16%|#5        | 1980/12631 [00:04<00:23, 458.57it/s] 16%|#6        | 2027/12631 [00:04<00:24, 441.17it/s] 16%|#6        | 2072/12631 [00:05<00:24, 428.35it/s] 17%|#6        | 2116/12631 [00:05<00:24, 425.20it/s] 17%|#7        | 2161/12631 [00:05<00:24, 431.40it/s] 17%|#7        | 2206/12631 [00:05<00:24, 434.35it/s] 18%|#7        | 2250/12631 [00:05<00:24, 423.52it/s] 18%|#8        | 2293/12631 [00:05<00:24, 416.12it/s] 18%|#8        | 2335/12631 [00:05<00:25, 411.22it/s] 19%|#8        | 2377/12631 [00:05<00:25, 405.95it/s] 19%|#9        | 2418/12631 [00:05<00:25, 404.52it/s] 19%|#9        | 2459/12631 [00:06<00:25, 396.83it/s] 20%|#9        | 2499/12631 [00:06<00:26, 388.92it/s] 20%|##        | 2542/12631 [00:06<00:25, 397.94it/s] 20%|##        | 2582/12631 [00:06<00:25, 388.59it/s] 21%|##        | 2621/12631 [00:06<00:26, 377.46it/s] 21%|##1       | 2659/12631 [00:06<00:27, 369.25it/s] 21%|##1       | 2699/12631 [00:06<00:26, 375.81it/s] 22%|##1       | 2740/12631 [00:06<00:25, 383.43it/s] 22%|##2       | 2779/12631 [00:06<00:26, 377.23it/s] 22%|##2       | 2817/12631 [00:06<00:26, 370.62it/s] 23%|##2       | 2855/12631 [00:07<00:26, 363.74it/s] 23%|##2       | 2895/12631 [00:07<00:26, 372.16it/s] 23%|##3       | 2934/12631 [00:07<00:25, 374.93it/s] 24%|##3       | 2972/12631 [00:07<00:26, 370.04it/s] 24%|##3       | 3010/12631 [00:07<00:26, 364.36it/s] 24%|##4       | 3047/12631 [00:07<00:26, 363.90it/s] 24%|##4       | 3087/12631 [00:07<00:25, 373.71it/s] 25%|##4       | 3125/12631 [00:07<00:25, 370.22it/s] 25%|##5       | 3163/12631 [00:07<00:25, 369.12it/s] 25%|##5       | 3202/12631 [00:08<00:25, 374.53it/s] 26%|##5       | 3242/12631 [00:08<00:24, 381.81it/s] 26%|##6       | 3287/12631 [00:08<00:23, 398.18it/s] 26%|##6       | 3331/12631 [00:08<00:22, 407.90it/s] 27%|##6       | 3375/12631 [00:08<00:22, 416.68it/s] 27%|##7       | 3421/12631 [00:08<00:21, 427.87it/s] 27%|##7       | 3470/12631 [00:08<00:20, 444.45it/s] 28%|##7       | 3515/12631 [00:08<00:20, 445.29it/s] 28%|##8       | 3560/12631 [00:08<00:20, 435.29it/s] 29%|##8       | 3604/12631 [00:08<00:21, 419.82it/s] 29%|##8       | 3647/12631 [00:09<00:21, 408.70it/s] 29%|##9       | 3689/12631 [00:09<00:21, 406.55it/s] 30%|##9       | 3733/12631 [00:09<00:21, 415.39it/s] 30%|##9       | 3775/12631 [00:09<00:21, 410.38it/s] 30%|###       | 3817/12631 [00:09<00:21, 408.60it/s] 31%|###       | 3858/12631 [00:09<00:21, 402.64it/s] 31%|###       | 3900/12631 [00:09<00:21, 407.10it/s] 31%|###1      | 3942/12631 [00:09<00:21, 409.17it/s] 32%|###1      | 3983/12631 [00:09<00:21, 404.97it/s] 32%|###1      | 4024/12631 [00:10<00:21, 398.65it/s] 32%|###2      | 4064/12631 [00:10<00:21, 393.30it/s] 33%|###2      | 4108/12631 [00:10<00:21, 405.74it/s] 33%|###2      | 4152/12631 [00:10<00:20, 413.63it/s] 33%|###3      | 4195/12631 [00:10<00:20, 416.52it/s] 34%|###3      | 4237/12631 [00:10<00:20, 414.09it/s] 34%|###3      | 4279/12631 [00:10<00:20, 403.27it/s] 34%|###4      | 4321/12631 [00:10<00:20, 406.88it/s] 35%|###4      | 4362/12631 [00:10<00:20, 401.44it/s] 35%|###4      | 4403/12631 [00:10<00:20, 392.28it/s] 35%|###5      | 4443/12631 [00:11<00:20, 390.38it/s] 35%|###5      | 4483/12631 [00:11<00:21, 386.07it/s] 36%|###5      | 4524/12631 [00:11<00:20, 392.43it/s] 36%|###6      | 4564/12631 [00:11<00:20, 387.57it/s] 36%|###6      | 4603/12631 [00:11<00:21, 380.44it/s] 37%|###6      | 4642/12631 [00:11<00:21, 366.57it/s] 37%|###7      | 4682/12631 [00:11<00:21, 373.69it/s] 37%|###7      | 4726/12631 [00:11<00:20, 391.03it/s] 38%|###7      | 4766/12631 [00:11<00:20, 392.33it/s] 38%|###8      | 4806/12631 [00:11<00:20, 390.55it/s] 38%|###8      | 4846/12631 [00:12<00:20, 387.58it/s] 39%|###8      | 4887/12631 [00:12<00:19, 392.69it/s] 39%|###9      | 4930/12631 [00:12<00:19, 402.25it/s] 39%|###9      | 4971/12631 [00:12<00:18, 403.19it/s] 40%|###9      | 5013/12631 [00:12<00:18, 405.57it/s] 40%|####      | 5054/12631 [00:12<00:18, 399.28it/s] 40%|####      | 5096/12631 [00:12<00:18, 404.30it/s] 41%|####      | 5141/12631 [00:12<00:17, 416.93it/s] 41%|####1     | 5193/12631 [00:12<00:16, 442.44it/s] 42%|####1     | 5246/12631 [00:13<00:15, 463.44it/s] 42%|####1     | 5295/12631 [00:13<00:15, 470.59it/s] 42%|####2     | 5343/12631 [00:13<00:15, 467.76it/s] 43%|####2     | 5391/12631 [00:13<00:15, 456.14it/s] 43%|####3     | 5437/12631 [00:13<00:16, 444.59it/s] 43%|####3     | 5482/12631 [00:13<00:16, 430.44it/s] 44%|####3     | 5526/12631 [00:13<00:17, 417.20it/s] 44%|####4     | 5569/12631 [00:13<00:16, 417.52it/s] 44%|####4     | 5611/12631 [00:13<00:17, 410.91it/s] 45%|####4     | 5653/12631 [00:13<00:17, 405.36it/s] 45%|####5     | 5694/12631 [00:14<00:17, 394.56it/s] 45%|####5     | 5736/12631 [00:14<00:17, 401.25it/s] 46%|####5     | 5777/12631 [00:14<00:16, 403.58it/s] 46%|####6     | 5818/12631 [00:14<00:17, 393.89it/s] 46%|####6     | 5858/12631 [00:14<00:17, 380.32it/s] 47%|####6     | 5897/12631 [00:14<00:18, 364.89it/s] 47%|####7     | 5939/12631 [00:14<00:17, 377.83it/s] 47%|####7     | 5980/12631 [00:14<00:17, 385.27it/s] 48%|####7     | 6019/12631 [00:14<00:17, 379.54it/s] 48%|####7     | 6058/12631 [00:15<00:17, 367.22it/s] 48%|####8     | 6095/12631 [00:15<00:17, 365.84it/s] 49%|####8     | 6137/12631 [00:15<00:17, 380.56it/s] 49%|####8     | 6176/12631 [00:15<00:16, 381.64it/s] 49%|####9     | 6215/12631 [00:15<00:16, 381.51it/s] 50%|####9     | 6254/12631 [00:15<00:16, 381.69it/s] 50%|####9     | 6293/12631 [00:15<00:16, 383.71it/s] 50%|#####     | 6332/12631 [00:15<00:16, 385.31it/s] 50%|#####     | 6371/12631 [00:15<00:16, 380.68it/s] 51%|#####     | 6410/12631 [00:15<00:16, 379.74it/s] 51%|#####1    | 6449/12631 [00:16<00:16, 377.25it/s] 51%|#####1    | 6488/12631 [00:16<00:16, 378.78it/s] 52%|#####1    | 6532/12631 [00:16<00:15, 394.61it/s] 52%|#####2    | 6576/12631 [00:16<00:14, 405.52it/s] 52%|#####2    | 6620/12631 [00:16<00:14, 413.15it/s] 53%|#####2    | 6662/12631 [00:16<00:14, 412.65it/s] 53%|#####3    | 6704/12631 [00:16<00:14, 410.44it/s] 53%|#####3    | 6746/12631 [00:16<00:14, 408.84it/s] 54%|#####3    | 6787/12631 [00:16<00:14, 402.91it/s] 54%|#####4    | 6828/12631 [00:16<00:14, 396.18it/s] 54%|#####4    | 6868/12631 [00:17<00:14, 391.72it/s] 55%|#####4    | 6910/12631 [00:17<00:14, 399.74it/s] 55%|#####5    | 6954/12631 [00:17<00:13, 408.95it/s] 55%|#####5    | 6996/12631 [00:17<00:14, 386.08it/s] 56%|#####5    | 7035/12631 [00:17<00:14, 375.98it/s] 56%|#####5    | 7073/12631 [00:17<00:14, 374.19it/s] 56%|#####6    | 7113/12631 [00:17<00:14, 379.29it/s] 57%|#####6    | 7152/12631 [00:17<00:14, 372.41it/s] 57%|#####6    | 7190/12631 [00:17<00:14, 370.24it/s] 57%|#####7    | 7228/12631 [00:18<00:14, 365.68it/s] 58%|#####7    | 7266/12631 [00:18<00:14, 369.01it/s] 58%|#####7    | 7310/12631 [00:18<00:13, 387.42it/s] 58%|#####8    | 7351/12631 [00:18<00:13, 392.74it/s] 59%|#####8    | 7391/12631 [00:18<00:13, 385.68it/s] 59%|#####8    | 7430/12631 [00:18<00:13, 375.88it/s] 59%|#####9    | 7469/12631 [00:18<00:13, 377.64it/s] 59%|#####9    | 7511/12631 [00:18<00:13, 387.65it/s] 60%|#####9    | 7550/12631 [00:18<00:13, 383.59it/s] 60%|######    | 7589/12631 [00:19<00:13, 374.38it/s] 60%|######    | 7627/12631 [00:19<00:13, 368.56it/s] 61%|######    | 7666/12631 [00:19<00:13, 373.51it/s] 61%|######1   | 7705/12631 [00:19<00:13, 376.10it/s] 61%|######1   | 7743/12631 [00:19<00:13, 372.86it/s] 62%|######1   | 7781/12631 [00:19<00:13, 369.48it/s] 62%|######1   | 7818/12631 [00:19<00:13, 367.16it/s] 62%|######2   | 7858/12631 [00:19<00:12, 375.16it/s] 63%|######2   | 7896/12631 [00:19<00:12, 372.43it/s] 63%|######2   | 7936/12631 [00:19<00:12, 377.65it/s] 63%|######3   | 7974/12631 [00:20<00:12, 376.97it/s] 63%|######3   | 8013/12631 [00:20<00:12, 380.76it/s] 64%|######3   | 8056/12631 [00:20<00:11, 394.14it/s] 64%|######4   | 8097/12631 [00:20<00:11, 396.34it/s] 64%|######4   | 8137/12631 [00:20<00:11, 395.26it/s] 65%|######4   | 8177/12631 [00:20<00:11, 388.75it/s] 65%|######5   | 8216/12631 [00:20<00:11, 374.61it/s] 65%|######5   | 8258/12631 [00:20<00:11, 386.56it/s] 66%|######5   | 8297/12631 [00:20<00:11, 380.66it/s] 66%|######5   | 8336/12631 [00:20<00:11, 369.55it/s] 66%|######6   | 8374/12631 [00:21<00:11, 369.04it/s] 67%|######6   | 8414/12631 [00:21<00:11, 377.33it/s] 67%|######6   | 8458/12631 [00:21<00:10, 391.92it/s] 67%|######7   | 8501/12631 [00:21<00:10, 400.99it/s] 68%|######7   | 8542/12631 [00:21<00:10, 393.59it/s] 68%|######7   | 8582/12631 [00:21<00:10, 394.72it/s] 68%|######8   | 8625/12631 [00:21<00:09, 404.25it/s] 69%|######8   | 8669/12631 [00:21<00:09, 414.28it/s] 69%|######8   | 8711/12631 [00:21<00:09, 410.83it/s] 69%|######9   | 8753/12631 [00:22<00:09, 405.83it/s] 70%|######9   | 8794/12631 [00:22<00:09, 391.90it/s] 70%|######9   | 8835/12631 [00:22<00:09, 396.03it/s] 70%|#######   | 8875/12631 [00:22<00:09, 394.42it/s] 71%|#######   | 8915/12631 [00:22<00:09, 386.45it/s] 71%|#######   | 8954/12631 [00:22<00:09, 378.86it/s] 71%|#######1  | 8992/12631 [00:22<00:09, 367.75it/s] 72%|#######1  | 9032/12631 [00:22<00:09, 374.77it/s] 72%|#######1  | 9070/12631 [00:22<00:09, 371.30it/s] 72%|#######2  | 9108/12631 [00:22<00:09, 365.11it/s] 72%|#######2  | 9145/12631 [00:23<00:09, 363.75it/s] 73%|#######2  | 9183/12631 [00:23<00:09, 366.54it/s] 73%|#######3  | 9221/12631 [00:23<00:09, 369.37it/s] 73%|#######3  | 9258/12631 [00:23<00:09, 368.46it/s] 74%|#######3  | 9295/12631 [00:23<00:09, 362.48it/s] 74%|#######3  | 9332/12631 [00:23<00:09, 357.22it/s] 74%|#######4  | 9368/12631 [00:23<00:09, 355.04it/s] 74%|#######4  | 9404/12631 [00:23<00:09, 354.74it/s] 75%|#######4  | 9442/12631 [00:23<00:08, 361.03it/s] 75%|#######5  | 9480/12631 [00:23<00:08, 364.75it/s] 75%|#######5  | 9517/12631 [00:24<00:08, 366.31it/s] 76%|#######5  | 9557/12631 [00:24<00:08, 375.80it/s] 76%|#######5  | 9599/12631 [00:24<00:07, 387.69it/s] 76%|#######6  | 9649/12631 [00:24<00:07, 414.29it/s] 77%|#######6  | 9697/12631 [00:24<00:06, 429.76it/s] 77%|#######7  | 9748/12631 [00:24<00:06, 450.23it/s] 78%|#######7  | 9797/12631 [00:24<00:06, 460.18it/s] 78%|#######7  | 9844/12631 [00:24<00:06, 440.96it/s] 78%|#######8  | 9889/12631 [00:24<00:06, 441.56it/s] 79%|#######8  | 9934/12631 [00:25<00:06, 441.86it/s] 79%|#######9  | 9979/12631 [00:25<00:06, 440.96it/s] 79%|#######9  | 10024/12631 [00:25<00:05, 441.09it/s] 80%|#######9  | 10069/12631 [00:25<00:05, 434.54it/s] 80%|########  | 10113/12631 [00:25<00:05, 432.39it/s] 80%|########  | 10157/12631 [00:25<00:05, 417.55it/s] 81%|########  | 10199/12631 [00:25<00:05, 409.07it/s] 81%|########1 | 10242/12631 [00:25<00:05, 413.48it/s] 81%|########1 | 10284/12631 [00:25<00:05, 407.74it/s] 82%|########1 | 10325/12631 [00:25<00:05, 399.86it/s] 82%|########2 | 10367/12631 [00:26<00:05, 404.38it/s] 82%|########2 | 10409/12631 [00:26<00:05, 407.96it/s] 83%|########2 | 10452/12631 [00:26<00:05, 411.94it/s] 83%|########3 | 10494/12631 [00:26<00:05, 412.77it/s] 83%|########3 | 10536/12631 [00:26<00:05, 405.55it/s] 84%|########3 | 10577/12631 [00:26<00:05, 388.82it/s] 84%|########4 | 10617/12631 [00:26<00:05, 382.99it/s] 84%|########4 | 10656/12631 [00:26<00:05, 381.65it/s] 85%|########4 | 10695/12631 [00:26<00:05, 372.94it/s] 85%|########4 | 10733/12631 [00:27<00:05, 363.89it/s] 85%|########5 | 10770/12631 [00:27<00:05, 353.20it/s] 86%|########5 | 10809/12631 [00:27<00:05, 361.76it/s] 86%|########5 | 10846/12631 [00:27<00:04, 360.84it/s] 86%|########6 | 10883/12631 [00:27<00:04, 358.35it/s] 86%|########6 | 10919/12631 [00:27<00:04, 354.19it/s] 87%|########6 | 10955/12631 [00:27<00:04, 350.27it/s] 87%|########7 | 10993/12631 [00:27<00:04, 356.92it/s] 87%|########7 | 11029/12631 [00:27<00:04, 357.19it/s] 88%|########7 | 11066/12631 [00:27<00:04, 358.44it/s] 88%|########7 | 11103/12631 [00:28<00:04, 360.26it/s] 88%|########8 | 11142/12631 [00:28<00:04, 366.40it/s] 89%|########8 | 11183/12631 [00:28<00:03, 378.09it/s] 89%|########8 | 11221/12631 [00:28<00:03, 378.17it/s] 89%|########9 | 11259/12631 [00:28<00:03, 373.06it/s] 89%|########9 | 11297/12631 [00:28<00:03, 368.60it/s] 90%|########9 | 11337/12631 [00:28<00:03, 375.13it/s] 90%|######### | 11377/12631 [00:28<00:03, 381.85it/s] 90%|######### | 11417/12631 [00:28<00:03, 384.60it/s] 91%|######### | 11457/12631 [00:28<00:03, 387.74it/s] 91%|#########1| 11496/12631 [00:29<00:02, 386.93it/s] 91%|#########1| 11536/12631 [00:29<00:02, 389.81it/s] 92%|#########1| 11576/12631 [00:29<00:02, 390.62it/s] 92%|#########1| 11616/12631 [00:29<00:02, 391.11it/s] 92%|#########2| 11656/12631 [00:29<00:02, 381.12it/s] 93%|#########2| 11695/12631 [00:29<00:02, 375.05it/s] 93%|#########2| 11735/12631 [00:29<00:02, 380.69it/s] 93%|#########3| 11774/12631 [00:29<00:02, 381.25it/s] 94%|#########3| 11813/12631 [00:29<00:02, 380.49it/s] 94%|#########3| 11852/12631 [00:30<00:02, 376.22it/s] 94%|#########4| 11890/12631 [00:30<00:01, 372.88it/s] 94%|#########4| 11932/12631 [00:30<00:01, 384.03it/s] 95%|#########4| 11975/12631 [00:30<00:01, 396.75it/s] 95%|#########5| 12015/12631 [00:30<00:01, 393.15it/s] 95%|#########5| 12055/12631 [00:30<00:01, 382.70it/s] 96%|#########5| 12094/12631 [00:30<00:01, 376.38it/s] 96%|#########6| 12137/12631 [00:30<00:01, 389.25it/s] 96%|#########6| 12177/12631 [00:30<00:01, 389.72it/s] 97%|#########6| 12217/12631 [00:30<00:01, 379.97it/s] 97%|#########7| 12256/12631 [00:31<00:01, 371.36it/s] 97%|#########7| 12294/12631 [00:31<00:00, 373.21it/s] 98%|#########7| 12336/12631 [00:31<00:00, 385.55it/s] 98%|#########7| 12375/12631 [00:31<00:00, 378.43it/s] 98%|#########8| 12413/12631 [00:31<00:00, 372.74it/s] 99%|#########8| 12451/12631 [00:31<00:00, 367.53it/s] 99%|#########8| 12489/12631 [00:31<00:00, 369.17it/s] 99%|#########9| 12527/12631 [00:31<00:00, 371.22it/s] 99%|#########9| 12565/12631 [00:31<00:00, 370.82it/s]100%|#########9| 12603/12631 [00:32<00:00, 368.88it/s]100%|##########| 12631/12631 [00:32<00:00, 393.66it/s]
Succesfully wrote out_latest_Adagrad.csv, you can upload this file to the kaggle competition at https://www.kaggle.com/c/nyu-cv-fall-2017/
