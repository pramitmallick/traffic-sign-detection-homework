Lmod has detected the following error: You can only have one PYTORCH  module
loaded at a time.
You already have pytorch/python2.7  loaded.
To correct the situation, please enter the following command:

  module swap pytorch/python2.7  pytorch/0.2.0_1


While processing the following module(s):

Module fullname  Module Filename
---------------  ---------------
pytorch/0.2.0_1  /share/apps/modulefiles/pytorch/0.2.0_1.lua
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
Train Epoch: 1 [0/35339 (0%)]	Loss: 3.785155
Train Epoch: 1 [640/35339 (2%)]	Loss: 3.820907
Train Epoch: 1 [1280/35339 (4%)]	Loss: 3.750383
Train Epoch: 1 [1920/35339 (5%)]	Loss: 3.693743
Train Epoch: 1 [2560/35339 (7%)]	Loss: 3.694709
Train Epoch: 1 [3200/35339 (9%)]	Loss: 3.631568
Train Epoch: 1 [3840/35339 (11%)]	Loss: 3.527786
Train Epoch: 1 [4480/35339 (13%)]	Loss: 3.642114
Train Epoch: 1 [5120/35339 (14%)]	Loss: 3.567919
Train Epoch: 1 [5760/35339 (16%)]	Loss: 3.430686
Train Epoch: 1 [6400/35339 (18%)]	Loss: 3.513217
Train Epoch: 1 [7040/35339 (20%)]	Loss: 3.340333
Train Epoch: 1 [7680/35339 (22%)]	Loss: 3.399417
Train Epoch: 1 [8320/35339 (24%)]	Loss: 3.254588
Train Epoch: 1 [8960/35339 (25%)]	Loss: 3.110131
Train Epoch: 1 [9600/35339 (27%)]	Loss: 3.159304
Train Epoch: 1 [10240/35339 (29%)]	Loss: 3.160528
Train Epoch: 1 [10880/35339 (31%)]	Loss: 3.032307
Train Epoch: 1 [11520/35339 (33%)]	Loss: 3.010733
Train Epoch: 1 [12160/35339 (34%)]	Loss: 2.794804
Train Epoch: 1 [12800/35339 (36%)]	Loss: 3.070604
Train Epoch: 1 [13440/35339 (38%)]	Loss: 2.835196
Train Epoch: 1 [14080/35339 (40%)]	Loss: 2.799660
Train Epoch: 1 [14720/35339 (42%)]	Loss: 2.635936
Train Epoch: 1 [15360/35339 (43%)]	Loss: 2.795011
Train Epoch: 1 [16000/35339 (45%)]	Loss: 2.670745
Train Epoch: 1 [16640/35339 (47%)]	Loss: 2.278208
Train Epoch: 1 [17280/35339 (49%)]	Loss: 2.576794
Train Epoch: 1 [17920/35339 (51%)]	Loss: 2.369422
Train Epoch: 1 [18560/35339 (52%)]	Loss: 2.606153
Train Epoch: 1 [19200/35339 (54%)]	Loss: 2.596641
Train Epoch: 1 [19840/35339 (56%)]	Loss: 2.149110
Train Epoch: 1 [20480/35339 (58%)]	Loss: 2.547146
Train Epoch: 1 [21120/35339 (60%)]	Loss: 2.359550
Train Epoch: 1 [21760/35339 (61%)]	Loss: 2.336212
Train Epoch: 1 [22400/35339 (63%)]	Loss: 1.938989
Train Epoch: 1 [23040/35339 (65%)]	Loss: 2.170416
Train Epoch: 1 [23680/35339 (67%)]	Loss: 2.054845
Train Epoch: 1 [24320/35339 (69%)]	Loss: 2.132219
Train Epoch: 1 [24960/35339 (71%)]	Loss: 2.058206
Train Epoch: 1 [25600/35339 (72%)]	Loss: 2.022622
Train Epoch: 1 [26240/35339 (74%)]	Loss: 2.161269
Train Epoch: 1 [26880/35339 (76%)]	Loss: 2.063041
Train Epoch: 1 [27520/35339 (78%)]	Loss: 1.782834
Train Epoch: 1 [28160/35339 (80%)]	Loss: 1.958578
Train Epoch: 1 [28800/35339 (81%)]	Loss: 1.660834
Train Epoch: 1 [29440/35339 (83%)]	Loss: 2.152040
Train Epoch: 1 [30080/35339 (85%)]	Loss: 1.823348
Train Epoch: 1 [30720/35339 (87%)]	Loss: 1.909632
Train Epoch: 1 [31360/35339 (89%)]	Loss: 1.632647
Train Epoch: 1 [32000/35339 (90%)]	Loss: 1.912698
Train Epoch: 1 [32640/35339 (92%)]	Loss: 2.023901
Train Epoch: 1 [33280/35339 (94%)]	Loss: 1.681669
Train Epoch: 1 [33920/35339 (96%)]	Loss: 1.918159
Train Epoch: 1 [34560/35339 (98%)]	Loss: 1.661371
Train Epoch: 1 [35200/35339 (99%)]	Loss: 1.674383

Validation set: Average loss: 3.8078, Accuracy: 407/3870 (11%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 2 [0/35339 (0%)]	Loss: 1.535742
Train Epoch: 2 [640/35339 (2%)]	Loss: 1.571225
Train Epoch: 2 [1280/35339 (4%)]	Loss: 1.687301
Train Epoch: 2 [1920/35339 (5%)]	Loss: 1.677103
Train Epoch: 2 [2560/35339 (7%)]	Loss: 1.677863
Train Epoch: 2 [3200/35339 (9%)]	Loss: 1.703711
Train Epoch: 2 [3840/35339 (11%)]	Loss: 1.489025
Train Epoch: 2 [4480/35339 (13%)]	Loss: 1.596985
Train Epoch: 2 [5120/35339 (14%)]	Loss: 1.547470
Train Epoch: 2 [5760/35339 (16%)]	Loss: 1.590609
Train Epoch: 2 [6400/35339 (18%)]	Loss: 1.451873
Train Epoch: 2 [7040/35339 (20%)]	Loss: 1.477328
Train Epoch: 2 [7680/35339 (22%)]	Loss: 1.761829
Train Epoch: 2 [8320/35339 (24%)]	Loss: 1.520479
Train Epoch: 2 [8960/35339 (25%)]	Loss: 1.412741
Train Epoch: 2 [9600/35339 (27%)]	Loss: 1.509451
Train Epoch: 2 [10240/35339 (29%)]	Loss: 1.286680
Train Epoch: 2 [10880/35339 (31%)]	Loss: 1.425648
Train Epoch: 2 [11520/35339 (33%)]	Loss: 1.284612
Train Epoch: 2 [12160/35339 (34%)]	Loss: 1.395005
Train Epoch: 2 [12800/35339 (36%)]	Loss: 1.291731
Train Epoch: 2 [13440/35339 (38%)]	Loss: 1.196307
Train Epoch: 2 [14080/35339 (40%)]	Loss: 1.527521
Train Epoch: 2 [14720/35339 (42%)]	Loss: 1.291878
Train Epoch: 2 [15360/35339 (43%)]	Loss: 1.144803
Train Epoch: 2 [16000/35339 (45%)]	Loss: 1.057872
Train Epoch: 2 [16640/35339 (47%)]	Loss: 1.324381
Train Epoch: 2 [17280/35339 (49%)]	Loss: 1.288601
Train Epoch: 2 [17920/35339 (51%)]	Loss: 1.009152
Train Epoch: 2 [18560/35339 (52%)]	Loss: 1.090531
Train Epoch: 2 [19200/35339 (54%)]	Loss: 1.291939
Train Epoch: 2 [19840/35339 (56%)]	Loss: 0.997323
Train Epoch: 2 [20480/35339 (58%)]	Loss: 1.389693
Train Epoch: 2 [21120/35339 (60%)]	Loss: 1.093212
Train Epoch: 2 [21760/35339 (61%)]	Loss: 1.235721
Train Epoch: 2 [22400/35339 (63%)]	Loss: 1.237432
Train Epoch: 2 [23040/35339 (65%)]	Loss: 1.044611
Train Epoch: 2 [23680/35339 (67%)]	Loss: 1.087622
Train Epoch: 2 [24320/35339 (69%)]	Loss: 1.001021
Train Epoch: 2 [24960/35339 (71%)]	Loss: 0.993928
Train Epoch: 2 [25600/35339 (72%)]	Loss: 1.083707
Train Epoch: 2 [26240/35339 (74%)]	Loss: 1.057153
Train Epoch: 2 [26880/35339 (76%)]	Loss: 1.031713
Train Epoch: 2 [27520/35339 (78%)]	Loss: 1.169599
Train Epoch: 2 [28160/35339 (80%)]	Loss: 1.113097
Train Epoch: 2 [28800/35339 (81%)]	Loss: 0.950785
Train Epoch: 2 [29440/35339 (83%)]	Loss: 1.080800
Train Epoch: 2 [30080/35339 (85%)]	Loss: 1.041165
Train Epoch: 2 [30720/35339 (87%)]	Loss: 0.831434
Train Epoch: 2 [31360/35339 (89%)]	Loss: 0.828261
Train Epoch: 2 [32000/35339 (90%)]	Loss: 0.992407
Train Epoch: 2 [32640/35339 (92%)]	Loss: 0.926782
Train Epoch: 2 [33280/35339 (94%)]	Loss: 0.903807
Train Epoch: 2 [33920/35339 (96%)]	Loss: 0.960171
Train Epoch: 2 [34560/35339 (98%)]	Loss: 1.013825
Train Epoch: 2 [35200/35339 (99%)]	Loss: 0.958390

Validation set: Average loss: 3.7718, Accuracy: 531/3870 (14%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 3 [0/35339 (0%)]	Loss: 0.923619
Train Epoch: 3 [640/35339 (2%)]	Loss: 0.851340
Train Epoch: 3 [1280/35339 (4%)]	Loss: 0.926172
Train Epoch: 3 [1920/35339 (5%)]	Loss: 0.955181
Train Epoch: 3 [2560/35339 (7%)]	Loss: 0.892601
Train Epoch: 3 [3200/35339 (9%)]	Loss: 0.722826
Train Epoch: 3 [3840/35339 (11%)]	Loss: 0.819195
Train Epoch: 3 [4480/35339 (13%)]	Loss: 0.893967
Train Epoch: 3 [5120/35339 (14%)]	Loss: 0.865855
Train Epoch: 3 [5760/35339 (16%)]	Loss: 0.779707
Train Epoch: 3 [6400/35339 (18%)]	Loss: 1.010704
Train Epoch: 3 [7040/35339 (20%)]	Loss: 0.716270
Train Epoch: 3 [7680/35339 (22%)]	Loss: 0.818819
Train Epoch: 3 [8320/35339 (24%)]	Loss: 0.615061
Train Epoch: 3 [8960/35339 (25%)]	Loss: 0.971893
Train Epoch: 3 [9600/35339 (27%)]	Loss: 0.869051
Train Epoch: 3 [10240/35339 (29%)]	Loss: 0.898274
Train Epoch: 3 [10880/35339 (31%)]	Loss: 0.809996
Train Epoch: 3 [11520/35339 (33%)]	Loss: 0.905978
Train Epoch: 3 [12160/35339 (34%)]	Loss: 0.543024
Train Epoch: 3 [12800/35339 (36%)]	Loss: 0.792819
Train Epoch: 3 [13440/35339 (38%)]	Loss: 0.957699
Train Epoch: 3 [14080/35339 (40%)]	Loss: 0.913488
Train Epoch: 3 [14720/35339 (42%)]	Loss: 0.632686
Train Epoch: 3 [15360/35339 (43%)]	Loss: 0.814675
Train Epoch: 3 [16000/35339 (45%)]	Loss: 0.844248
Train Epoch: 3 [16640/35339 (47%)]	Loss: 0.977588
Train Epoch: 3 [17280/35339 (49%)]	Loss: 0.723460
Train Epoch: 3 [17920/35339 (51%)]	Loss: 1.073627
Train Epoch: 3 [18560/35339 (52%)]	Loss: 0.822535
Train Epoch: 3 [19200/35339 (54%)]	Loss: 0.898134
Train Epoch: 3 [19840/35339 (56%)]	Loss: 0.773785
Train Epoch: 3 [20480/35339 (58%)]	Loss: 1.059977
Train Epoch: 3 [21120/35339 (60%)]	Loss: 0.606011
Train Epoch: 3 [21760/35339 (61%)]	Loss: 0.664422
Train Epoch: 3 [22400/35339 (63%)]	Loss: 0.755200
Train Epoch: 3 [23040/35339 (65%)]	Loss: 0.670183
Train Epoch: 3 [23680/35339 (67%)]	Loss: 0.660921
Train Epoch: 3 [24320/35339 (69%)]	Loss: 1.010888
Train Epoch: 3 [24960/35339 (71%)]	Loss: 0.784282
Train Epoch: 3 [25600/35339 (72%)]	Loss: 0.626740
Train Epoch: 3 [26240/35339 (74%)]	Loss: 0.617848
Train Epoch: 3 [26880/35339 (76%)]	Loss: 0.758051
Train Epoch: 3 [27520/35339 (78%)]	Loss: 0.658888
Train Epoch: 3 [28160/35339 (80%)]	Loss: 0.693625
Train Epoch: 3 [28800/35339 (81%)]	Loss: 0.709049
Train Epoch: 3 [29440/35339 (83%)]	Loss: 0.628041
Train Epoch: 3 [30080/35339 (85%)]	Loss: 0.696133
Train Epoch: 3 [30720/35339 (87%)]	Loss: 0.643474
Train Epoch: 3 [31360/35339 (89%)]	Loss: 0.698080
Train Epoch: 3 [32000/35339 (90%)]	Loss: 0.609506
Train Epoch: 3 [32640/35339 (92%)]	Loss: 0.486520
Train Epoch: 3 [33280/35339 (94%)]	Loss: 0.702114
Train Epoch: 3 [33920/35339 (96%)]	Loss: 0.845315
Train Epoch: 3 [34560/35339 (98%)]	Loss: 0.533580
Train Epoch: 3 [35200/35339 (99%)]	Loss: 0.861441

Validation set: Average loss: 3.7767, Accuracy: 644/3870 (17%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 4 [0/35339 (0%)]	Loss: 0.740454
Train Epoch: 4 [640/35339 (2%)]	Loss: 0.622499
Train Epoch: 4 [1280/35339 (4%)]	Loss: 0.596192
Train Epoch: 4 [1920/35339 (5%)]	Loss: 0.718862
Train Epoch: 4 [2560/35339 (7%)]	Loss: 0.619332
Train Epoch: 4 [3200/35339 (9%)]	Loss: 0.617078
Train Epoch: 4 [3840/35339 (11%)]	Loss: 0.885088
Train Epoch: 4 [4480/35339 (13%)]	Loss: 0.763359
Train Epoch: 4 [5120/35339 (14%)]	Loss: 0.705709
Train Epoch: 4 [5760/35339 (16%)]	Loss: 0.607625
Train Epoch: 4 [6400/35339 (18%)]	Loss: 0.490804
Train Epoch: 4 [7040/35339 (20%)]	Loss: 0.516185
Train Epoch: 4 [7680/35339 (22%)]	Loss: 0.654065
Train Epoch: 4 [8320/35339 (24%)]	Loss: 0.646223
Train Epoch: 4 [8960/35339 (25%)]	Loss: 0.971841
Train Epoch: 4 [9600/35339 (27%)]	Loss: 0.617355
Train Epoch: 4 [10240/35339 (29%)]	Loss: 0.677961
Train Epoch: 4 [10880/35339 (31%)]	Loss: 0.597516
Train Epoch: 4 [11520/35339 (33%)]	Loss: 0.489003
Train Epoch: 4 [12160/35339 (34%)]	Loss: 0.617128
Train Epoch: 4 [12800/35339 (36%)]	Loss: 0.396691
Train Epoch: 4 [13440/35339 (38%)]	Loss: 0.511267
Train Epoch: 4 [14080/35339 (40%)]	Loss: 0.498695
Train Epoch: 4 [14720/35339 (42%)]	Loss: 0.440885
Train Epoch: 4 [15360/35339 (43%)]	Loss: 0.619224
Train Epoch: 4 [16000/35339 (45%)]	Loss: 0.464936
Train Epoch: 4 [16640/35339 (47%)]	Loss: 0.594704
Train Epoch: 4 [17280/35339 (49%)]	Loss: 0.686424
Train Epoch: 4 [17920/35339 (51%)]	Loss: 0.656344
Train Epoch: 4 [18560/35339 (52%)]	Loss: 0.675095
Train Epoch: 4 [19200/35339 (54%)]	Loss: 0.733890
Train Epoch: 4 [19840/35339 (56%)]	Loss: 0.599429
Train Epoch: 4 [20480/35339 (58%)]	Loss: 0.581271
Train Epoch: 4 [21120/35339 (60%)]	Loss: 0.607685
Train Epoch: 4 [21760/35339 (61%)]	Loss: 0.597740
Train Epoch: 4 [22400/35339 (63%)]	Loss: 0.622277
Train Epoch: 4 [23040/35339 (65%)]	Loss: 0.943970
Train Epoch: 4 [23680/35339 (67%)]	Loss: 0.594710
Train Epoch: 4 [24320/35339 (69%)]	Loss: 0.538667
Train Epoch: 4 [24960/35339 (71%)]	Loss: 0.432139
Train Epoch: 4 [25600/35339 (72%)]	Loss: 0.568042
Train Epoch: 4 [26240/35339 (74%)]	Loss: 0.556992
Train Epoch: 4 [26880/35339 (76%)]	Loss: 0.477257
Train Epoch: 4 [27520/35339 (78%)]	Loss: 0.637684
Train Epoch: 4 [28160/35339 (80%)]	Loss: 0.527769
Train Epoch: 4 [28800/35339 (81%)]	Loss: 0.551754
Train Epoch: 4 [29440/35339 (83%)]	Loss: 0.560856
Train Epoch: 4 [30080/35339 (85%)]	Loss: 0.561630
Train Epoch: 4 [30720/35339 (87%)]	Loss: 0.455494
Train Epoch: 4 [31360/35339 (89%)]	Loss: 0.553752
Train Epoch: 4 [32000/35339 (90%)]	Loss: 0.544631
Train Epoch: 4 [32640/35339 (92%)]	Loss: 0.359666
Train Epoch: 4 [33280/35339 (94%)]	Loss: 0.521180
Train Epoch: 4 [33920/35339 (96%)]	Loss: 0.522352
Train Epoch: 4 [34560/35339 (98%)]	Loss: 0.678087
Train Epoch: 4 [35200/35339 (99%)]	Loss: 0.627346

Validation set: Average loss: 3.6603, Accuracy: 716/3870 (19%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 5 [0/35339 (0%)]	Loss: 0.586469
Train Epoch: 5 [640/35339 (2%)]	Loss: 0.412538
Train Epoch: 5 [1280/35339 (4%)]	Loss: 0.525642
Train Epoch: 5 [1920/35339 (5%)]	Loss: 0.404257
Train Epoch: 5 [2560/35339 (7%)]	Loss: 0.424566
Train Epoch: 5 [3200/35339 (9%)]	Loss: 0.443583
Train Epoch: 5 [3840/35339 (11%)]	Loss: 0.465596
Train Epoch: 5 [4480/35339 (13%)]	Loss: 0.515147
Train Epoch: 5 [5120/35339 (14%)]	Loss: 0.610383
Train Epoch: 5 [5760/35339 (16%)]	Loss: 0.300471
Train Epoch: 5 [6400/35339 (18%)]	Loss: 0.591388
Train Epoch: 5 [7040/35339 (20%)]	Loss: 0.603902
Train Epoch: 5 [7680/35339 (22%)]	Loss: 0.457104
Train Epoch: 5 [8320/35339 (24%)]	Loss: 0.522143
Train Epoch: 5 [8960/35339 (25%)]	Loss: 0.591110
Train Epoch: 5 [9600/35339 (27%)]	Loss: 0.365357
Train Epoch: 5 [10240/35339 (29%)]	Loss: 0.439077
Train Epoch: 5 [10880/35339 (31%)]	Loss: 0.497037
Train Epoch: 5 [11520/35339 (33%)]	Loss: 0.439526
Train Epoch: 5 [12160/35339 (34%)]	Loss: 0.407370
Train Epoch: 5 [12800/35339 (36%)]	Loss: 0.555923
Train Epoch: 5 [13440/35339 (38%)]	Loss: 0.427470
Train Epoch: 5 [14080/35339 (40%)]	Loss: 0.606789
Train Epoch: 5 [14720/35339 (42%)]	Loss: 0.435663
Train Epoch: 5 [15360/35339 (43%)]	Loss: 0.321334
Train Epoch: 5 [16000/35339 (45%)]	Loss: 0.482917
Train Epoch: 5 [16640/35339 (47%)]	Loss: 0.389738
Train Epoch: 5 [17280/35339 (49%)]	Loss: 0.515847
Train Epoch: 5 [17920/35339 (51%)]	Loss: 0.403274
Train Epoch: 5 [18560/35339 (52%)]	Loss: 0.523073
Train Epoch: 5 [19200/35339 (54%)]	Loss: 0.443784
Train Epoch: 5 [19840/35339 (56%)]	Loss: 0.408562
Train Epoch: 5 [20480/35339 (58%)]	Loss: 0.265844
Train Epoch: 5 [21120/35339 (60%)]	Loss: 0.323061
Train Epoch: 5 [21760/35339 (61%)]	Loss: 0.370802
Train Epoch: 5 [22400/35339 (63%)]	Loss: 0.497320
Train Epoch: 5 [23040/35339 (65%)]	Loss: 0.681745
Train Epoch: 5 [23680/35339 (67%)]	Loss: 0.492859
Train Epoch: 5 [24320/35339 (69%)]	Loss: 0.583629
Train Epoch: 5 [24960/35339 (71%)]	Loss: 0.477557
Train Epoch: 5 [25600/35339 (72%)]	Loss: 0.478279
Train Epoch: 5 [26240/35339 (74%)]	Loss: 0.625478
Train Epoch: 5 [26880/35339 (76%)]	Loss: 0.513034
Train Epoch: 5 [27520/35339 (78%)]	Loss: 0.697950
Train Epoch: 5 [28160/35339 (80%)]	Loss: 0.309931
Train Epoch: 5 [28800/35339 (81%)]	Loss: 0.522628
Train Epoch: 5 [29440/35339 (83%)]	Loss: 0.337451
Train Epoch: 5 [30080/35339 (85%)]	Loss: 0.480480
Train Epoch: 5 [30720/35339 (87%)]	Loss: 0.432986
Train Epoch: 5 [31360/35339 (89%)]	Loss: 0.380145
Train Epoch: 5 [32000/35339 (90%)]	Loss: 0.491585
Train Epoch: 5 [32640/35339 (92%)]	Loss: 0.402840
Train Epoch: 5 [33280/35339 (94%)]	Loss: 0.321032
Train Epoch: 5 [33920/35339 (96%)]	Loss: 0.577590
Train Epoch: 5 [34560/35339 (98%)]	Loss: 0.347091
Train Epoch: 5 [35200/35339 (99%)]	Loss: 0.334921

Validation set: Average loss: 3.6228, Accuracy: 886/3870 (23%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 6 [0/35339 (0%)]	Loss: 0.338593
Train Epoch: 6 [640/35339 (2%)]	Loss: 0.461651
Train Epoch: 6 [1280/35339 (4%)]	Loss: 0.498972
Train Epoch: 6 [1920/35339 (5%)]	Loss: 0.464696
Train Epoch: 6 [2560/35339 (7%)]	Loss: 0.358039
Train Epoch: 6 [3200/35339 (9%)]	Loss: 0.414632
Train Epoch: 6 [3840/35339 (11%)]	Loss: 0.214563
Train Epoch: 6 [4480/35339 (13%)]	Loss: 0.375537
Train Epoch: 6 [5120/35339 (14%)]	Loss: 0.618469
Train Epoch: 6 [5760/35339 (16%)]	Loss: 0.419999
Train Epoch: 6 [6400/35339 (18%)]	Loss: 0.501945
Train Epoch: 6 [7040/35339 (20%)]	Loss: 0.397544
Train Epoch: 6 [7680/35339 (22%)]	Loss: 0.495063
Train Epoch: 6 [8320/35339 (24%)]	Loss: 0.385376
Train Epoch: 6 [8960/35339 (25%)]	Loss: 0.335270
Train Epoch: 6 [9600/35339 (27%)]	Loss: 0.478732
Train Epoch: 6 [10240/35339 (29%)]	Loss: 0.304932
Train Epoch: 6 [10880/35339 (31%)]	Loss: 0.369400
Train Epoch: 6 [11520/35339 (33%)]	Loss: 0.460321
Train Epoch: 6 [12160/35339 (34%)]	Loss: 0.458012
Train Epoch: 6 [12800/35339 (36%)]	Loss: 0.471002
Train Epoch: 6 [13440/35339 (38%)]	Loss: 0.304466
Train Epoch: 6 [14080/35339 (40%)]	Loss: 0.616486
Train Epoch: 6 [14720/35339 (42%)]	Loss: 0.447667
Train Epoch: 6 [15360/35339 (43%)]	Loss: 0.386017
Train Epoch: 6 [16000/35339 (45%)]	Loss: 0.401749
Train Epoch: 6 [16640/35339 (47%)]	Loss: 0.251150
Train Epoch: 6 [17280/35339 (49%)]	Loss: 0.287940
Train Epoch: 6 [17920/35339 (51%)]	Loss: 0.370113
Train Epoch: 6 [18560/35339 (52%)]	Loss: 0.461613
Train Epoch: 6 [19200/35339 (54%)]	Loss: 0.294448
Train Epoch: 6 [19840/35339 (56%)]	Loss: 0.398146
Train Epoch: 6 [20480/35339 (58%)]	Loss: 0.395189
Train Epoch: 6 [21120/35339 (60%)]	Loss: 0.384313
Train Epoch: 6 [21760/35339 (61%)]	Loss: 0.399778
Train Epoch: 6 [22400/35339 (63%)]	Loss: 0.313046
Train Epoch: 6 [23040/35339 (65%)]	Loss: 0.355611
Train Epoch: 6 [23680/35339 (67%)]	Loss: 0.459450
Train Epoch: 6 [24320/35339 (69%)]	Loss: 0.246795
Train Epoch: 6 [24960/35339 (71%)]	Loss: 0.366637
Train Epoch: 6 [25600/35339 (72%)]	Loss: 0.244635
Train Epoch: 6 [26240/35339 (74%)]	Loss: 0.379840
Train Epoch: 6 [26880/35339 (76%)]	Loss: 0.392040
Train Epoch: 6 [27520/35339 (78%)]	Loss: 0.370687
Train Epoch: 6 [28160/35339 (80%)]	Loss: 0.404399
Train Epoch: 6 [28800/35339 (81%)]	Loss: 0.271237
Train Epoch: 6 [29440/35339 (83%)]	Loss: 0.534643
Train Epoch: 6 [30080/35339 (85%)]	Loss: 0.249859
Train Epoch: 6 [30720/35339 (87%)]	Loss: 0.264110
Train Epoch: 6 [31360/35339 (89%)]	Loss: 0.245536
Train Epoch: 6 [32000/35339 (90%)]	Loss: 0.453287
Train Epoch: 6 [32640/35339 (92%)]	Loss: 0.460732
Train Epoch: 6 [33280/35339 (94%)]	Loss: 0.286660
Train Epoch: 6 [33920/35339 (96%)]	Loss: 0.450391
Train Epoch: 6 [34560/35339 (98%)]	Loss: 0.383681
Train Epoch: 6 [35200/35339 (99%)]	Loss: 0.352383

Validation set: Average loss: 3.4951, Accuracy: 1015/3870 (26%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 7 [0/35339 (0%)]	Loss: 0.329234
Train Epoch: 7 [640/35339 (2%)]	Loss: 0.309891
Train Epoch: 7 [1280/35339 (4%)]	Loss: 0.430657
Train Epoch: 7 [1920/35339 (5%)]	Loss: 0.402685
Train Epoch: 7 [2560/35339 (7%)]	Loss: 0.314196
Train Epoch: 7 [3200/35339 (9%)]	Loss: 0.593482
Train Epoch: 7 [3840/35339 (11%)]	Loss: 0.241049
Train Epoch: 7 [4480/35339 (13%)]	Loss: 0.538131
Train Epoch: 7 [5120/35339 (14%)]	Loss: 0.370592
Train Epoch: 7 [5760/35339 (16%)]	Loss: 0.397611
Train Epoch: 7 [6400/35339 (18%)]	Loss: 0.352918
Train Epoch: 7 [7040/35339 (20%)]	Loss: 0.345918
Train Epoch: 7 [7680/35339 (22%)]	Loss: 0.462235
Train Epoch: 7 [8320/35339 (24%)]	Loss: 0.490657
Train Epoch: 7 [8960/35339 (25%)]	Loss: 0.238593
Train Epoch: 7 [9600/35339 (27%)]	Loss: 0.343189
Train Epoch: 7 [10240/35339 (29%)]	Loss: 0.397764
Train Epoch: 7 [10880/35339 (31%)]	Loss: 0.439565
Train Epoch: 7 [11520/35339 (33%)]	Loss: 0.287148
Train Epoch: 7 [12160/35339 (34%)]	Loss: 0.600656
Train Epoch: 7 [12800/35339 (36%)]	Loss: 0.383635
Train Epoch: 7 [13440/35339 (38%)]	Loss: 0.332717
Train Epoch: 7 [14080/35339 (40%)]	Loss: 0.435034
Train Epoch: 7 [14720/35339 (42%)]	Loss: 0.343329
Train Epoch: 7 [15360/35339 (43%)]	Loss: 0.412460
Train Epoch: 7 [16000/35339 (45%)]	Loss: 0.258432
Train Epoch: 7 [16640/35339 (47%)]	Loss: 0.405294
Train Epoch: 7 [17280/35339 (49%)]	Loss: 0.424979
Train Epoch: 7 [17920/35339 (51%)]	Loss: 0.386981
Train Epoch: 7 [18560/35339 (52%)]	Loss: 0.360666
Train Epoch: 7 [19200/35339 (54%)]	Loss: 0.449107
Train Epoch: 7 [19840/35339 (56%)]	Loss: 0.397048
Train Epoch: 7 [20480/35339 (58%)]	Loss: 0.299241
Train Epoch: 7 [21120/35339 (60%)]	Loss: 0.497611
Train Epoch: 7 [21760/35339 (61%)]	Loss: 0.350814
Train Epoch: 7 [22400/35339 (63%)]	Loss: 0.403707
Train Epoch: 7 [23040/35339 (65%)]	Loss: 0.303961
Train Epoch: 7 [23680/35339 (67%)]	Loss: 0.525332
Train Epoch: 7 [24320/35339 (69%)]	Loss: 0.311993
Train Epoch: 7 [24960/35339 (71%)]	Loss: 0.310070
Train Epoch: 7 [25600/35339 (72%)]	Loss: 0.311249
Train Epoch: 7 [26240/35339 (74%)]	Loss: 0.405554
Train Epoch: 7 [26880/35339 (76%)]	Loss: 0.418998
Train Epoch: 7 [27520/35339 (78%)]	Loss: 0.419714
Train Epoch: 7 [28160/35339 (80%)]	Loss: 0.273451
Train Epoch: 7 [28800/35339 (81%)]	Loss: 0.215522
Train Epoch: 7 [29440/35339 (83%)]	Loss: 0.360361
Train Epoch: 7 [30080/35339 (85%)]	Loss: 0.352094
Train Epoch: 7 [30720/35339 (87%)]	Loss: 0.357223
Train Epoch: 7 [31360/35339 (89%)]	Loss: 0.384340
Train Epoch: 7 [32000/35339 (90%)]	Loss: 0.351961
Train Epoch: 7 [32640/35339 (92%)]	Loss: 0.365087
Train Epoch: 7 [33280/35339 (94%)]	Loss: 0.336010
Train Epoch: 7 [33920/35339 (96%)]	Loss: 0.284401
Train Epoch: 7 [34560/35339 (98%)]	Loss: 0.389809
Train Epoch: 7 [35200/35339 (99%)]	Loss: 0.278193

Validation set: Average loss: 3.5063, Accuracy: 1085/3870 (28%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 8 [0/35339 (0%)]	Loss: 0.348429
Train Epoch: 8 [640/35339 (2%)]	Loss: 0.240371
Train Epoch: 8 [1280/35339 (4%)]	Loss: 0.303066
Train Epoch: 8 [1920/35339 (5%)]	Loss: 0.366891
Train Epoch: 8 [2560/35339 (7%)]	Loss: 0.312461
Train Epoch: 8 [3200/35339 (9%)]	Loss: 0.415931
Train Epoch: 8 [3840/35339 (11%)]	Loss: 0.328906
Train Epoch: 8 [4480/35339 (13%)]	Loss: 0.410854
Train Epoch: 8 [5120/35339 (14%)]	Loss: 0.464509
Train Epoch: 8 [5760/35339 (16%)]	Loss: 0.206408
Train Epoch: 8 [6400/35339 (18%)]	Loss: 0.210103
Train Epoch: 8 [7040/35339 (20%)]	Loss: 0.214010
Train Epoch: 8 [7680/35339 (22%)]	Loss: 0.501132
Train Epoch: 8 [8320/35339 (24%)]	Loss: 0.305614
Train Epoch: 8 [8960/35339 (25%)]	Loss: 0.290744
Train Epoch: 8 [9600/35339 (27%)]	Loss: 0.255571
Train Epoch: 8 [10240/35339 (29%)]	Loss: 0.318321
Train Epoch: 8 [10880/35339 (31%)]	Loss: 0.287876
Train Epoch: 8 [11520/35339 (33%)]	Loss: 0.186799
Train Epoch: 8 [12160/35339 (34%)]	Loss: 0.328646
Train Epoch: 8 [12800/35339 (36%)]	Loss: 0.638707
Train Epoch: 8 [13440/35339 (38%)]	Loss: 0.548550
Train Epoch: 8 [14080/35339 (40%)]	Loss: 0.332900
Train Epoch: 8 [14720/35339 (42%)]	Loss: 0.287251
Train Epoch: 8 [15360/35339 (43%)]	Loss: 0.301040
Train Epoch: 8 [16000/35339 (45%)]	Loss: 0.383060
Train Epoch: 8 [16640/35339 (47%)]	Loss: 0.306854
Train Epoch: 8 [17280/35339 (49%)]	Loss: 0.377060
Train Epoch: 8 [17920/35339 (51%)]	Loss: 0.414412
Train Epoch: 8 [18560/35339 (52%)]	Loss: 0.425810
Train Epoch: 8 [19200/35339 (54%)]	Loss: 0.268959
Train Epoch: 8 [19840/35339 (56%)]	Loss: 0.492226
Train Epoch: 8 [20480/35339 (58%)]	Loss: 0.192192
Train Epoch: 8 [21120/35339 (60%)]	Loss: 0.452967
Train Epoch: 8 [21760/35339 (61%)]	Loss: 0.335175
Train Epoch: 8 [22400/35339 (63%)]	Loss: 0.306275
Train Epoch: 8 [23040/35339 (65%)]	Loss: 0.312299
Train Epoch: 8 [23680/35339 (67%)]	Loss: 0.247176
Train Epoch: 8 [24320/35339 (69%)]	Loss: 0.265950
Train Epoch: 8 [24960/35339 (71%)]	Loss: 0.303099
Train Epoch: 8 [25600/35339 (72%)]	Loss: 0.269017
Train Epoch: 8 [26240/35339 (74%)]	Loss: 0.516775
Train Epoch: 8 [26880/35339 (76%)]	Loss: 0.278899
Train Epoch: 8 [27520/35339 (78%)]	Loss: 0.356464
Train Epoch: 8 [28160/35339 (80%)]	Loss: 0.332509
Train Epoch: 8 [28800/35339 (81%)]	Loss: 0.443593
Train Epoch: 8 [29440/35339 (83%)]	Loss: 0.139554
Train Epoch: 8 [30080/35339 (85%)]	Loss: 0.368023
Train Epoch: 8 [30720/35339 (87%)]	Loss: 0.216535
Train Epoch: 8 [31360/35339 (89%)]	Loss: 0.137335
Train Epoch: 8 [32000/35339 (90%)]	Loss: 0.195670
Train Epoch: 8 [32640/35339 (92%)]	Loss: 0.382794
Train Epoch: 8 [33280/35339 (94%)]	Loss: 0.210712
Train Epoch: 8 [33920/35339 (96%)]	Loss: 0.165109
Train Epoch: 8 [34560/35339 (98%)]	Loss: 0.483206
Train Epoch: 8 [35200/35339 (99%)]	Loss: 0.526770

Validation set: Average loss: 3.5585, Accuracy: 1008/3870 (26%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 9 [0/35339 (0%)]	Loss: 0.262360
Train Epoch: 9 [640/35339 (2%)]	Loss: 0.342195
Train Epoch: 9 [1280/35339 (4%)]	Loss: 0.230236
Train Epoch: 9 [1920/35339 (5%)]	Loss: 0.171153
Train Epoch: 9 [2560/35339 (7%)]	Loss: 0.263424
Train Epoch: 9 [3200/35339 (9%)]	Loss: 0.387172
Train Epoch: 9 [3840/35339 (11%)]	Loss: 0.260292
Train Epoch: 9 [4480/35339 (13%)]	Loss: 0.294016
Train Epoch: 9 [5120/35339 (14%)]	Loss: 0.359078
Train Epoch: 9 [5760/35339 (16%)]	Loss: 0.465184
Train Epoch: 9 [6400/35339 (18%)]	Loss: 0.547043
Train Epoch: 9 [7040/35339 (20%)]	Loss: 0.303091
Train Epoch: 9 [7680/35339 (22%)]	Loss: 0.355728
Train Epoch: 9 [8320/35339 (24%)]	Loss: 0.424627
Train Epoch: 9 [8960/35339 (25%)]	Loss: 0.263517
Train Epoch: 9 [9600/35339 (27%)]	Loss: 0.193913
Train Epoch: 9 [10240/35339 (29%)]	Loss: 0.272800
Train Epoch: 9 [10880/35339 (31%)]	Loss: 0.367736
Train Epoch: 9 [11520/35339 (33%)]	Loss: 0.200113
Train Epoch: 9 [12160/35339 (34%)]	Loss: 0.280756
Train Epoch: 9 [12800/35339 (36%)]	Loss: 0.265315
Train Epoch: 9 [13440/35339 (38%)]	Loss: 0.406100
Train Epoch: 9 [14080/35339 (40%)]	Loss: 0.216169
Train Epoch: 9 [14720/35339 (42%)]	Loss: 0.272786
Train Epoch: 9 [15360/35339 (43%)]	Loss: 0.311371
Train Epoch: 9 [16000/35339 (45%)]	Loss: 0.203179
Train Epoch: 9 [16640/35339 (47%)]	Loss: 0.303809
Train Epoch: 9 [17280/35339 (49%)]	Loss: 0.419987
Train Epoch: 9 [17920/35339 (51%)]	Loss: 0.221975
Train Epoch: 9 [18560/35339 (52%)]	Loss: 0.197295
Train Epoch: 9 [19200/35339 (54%)]	Loss: 0.480610
Train Epoch: 9 [19840/35339 (56%)]	Loss: 0.400369
Train Epoch: 9 [20480/35339 (58%)]	Loss: 0.267621
Train Epoch: 9 [21120/35339 (60%)]	Loss: 0.155350
Train Epoch: 9 [21760/35339 (61%)]	Loss: 0.175474
Train Epoch: 9 [22400/35339 (63%)]	Loss: 0.222226
Train Epoch: 9 [23040/35339 (65%)]	Loss: 0.387630
Train Epoch: 9 [23680/35339 (67%)]	Loss: 0.445587
Train Epoch: 9 [24320/35339 (69%)]	Loss: 0.257093
Train Epoch: 9 [24960/35339 (71%)]	Loss: 0.337876
Train Epoch: 9 [25600/35339 (72%)]	Loss: 0.513418
Train Epoch: 9 [26240/35339 (74%)]	Loss: 0.389372
Train Epoch: 9 [26880/35339 (76%)]	Loss: 0.218903
Train Epoch: 9 [27520/35339 (78%)]	Loss: 0.220026
Train Epoch: 9 [28160/35339 (80%)]	Loss: 0.415958
Train Epoch: 9 [28800/35339 (81%)]	Loss: 0.263231
Train Epoch: 9 [29440/35339 (83%)]	Loss: 0.332838
Train Epoch: 9 [30080/35339 (85%)]	Loss: 0.218426
Train Epoch: 9 [30720/35339 (87%)]	Loss: 0.277863
Train Epoch: 9 [31360/35339 (89%)]	Loss: 0.276992
Train Epoch: 9 [32000/35339 (90%)]	Loss: 0.205353
Train Epoch: 9 [32640/35339 (92%)]	Loss: 0.300666
Train Epoch: 9 [33280/35339 (94%)]	Loss: 0.164285
Train Epoch: 9 [33920/35339 (96%)]	Loss: 0.207474
Train Epoch: 9 [34560/35339 (98%)]	Loss: 0.249046
Train Epoch: 9 [35200/35339 (99%)]	Loss: 0.306133

Validation set: Average loss: 3.4766, Accuracy: 1086/3870 (28%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 10 [0/35339 (0%)]	Loss: 0.338970
Train Epoch: 10 [640/35339 (2%)]	Loss: 0.295900
Train Epoch: 10 [1280/35339 (4%)]	Loss: 0.212413
Train Epoch: 10 [1920/35339 (5%)]	Loss: 0.383233
Train Epoch: 10 [2560/35339 (7%)]	Loss: 0.191858
Train Epoch: 10 [3200/35339 (9%)]	Loss: 0.194527
Train Epoch: 10 [3840/35339 (11%)]	Loss: 0.472761
Train Epoch: 10 [4480/35339 (13%)]	Loss: 0.282126
Train Epoch: 10 [5120/35339 (14%)]	Loss: 0.496692
Train Epoch: 10 [5760/35339 (16%)]	Loss: 0.287652
Train Epoch: 10 [6400/35339 (18%)]	Loss: 0.277471
Train Epoch: 10 [7040/35339 (20%)]	Loss: 0.595033
Train Epoch: 10 [7680/35339 (22%)]	Loss: 0.566036
Train Epoch: 10 [8320/35339 (24%)]	Loss: 0.361010
Train Epoch: 10 [8960/35339 (25%)]	Loss: 0.332082
Train Epoch: 10 [9600/35339 (27%)]	Loss: 0.242639
Train Epoch: 10 [10240/35339 (29%)]	Loss: 0.298918
Train Epoch: 10 [10880/35339 (31%)]	Loss: 0.200763
Train Epoch: 10 [11520/35339 (33%)]	Loss: 0.194789
Train Epoch: 10 [12160/35339 (34%)]	Loss: 0.246256
Train Epoch: 10 [12800/35339 (36%)]	Loss: 0.519413
Train Epoch: 10 [13440/35339 (38%)]	Loss: 0.377352
Train Epoch: 10 [14080/35339 (40%)]	Loss: 0.332432
Train Epoch: 10 [14720/35339 (42%)]	Loss: 0.376060
Train Epoch: 10 [15360/35339 (43%)]	Loss: 0.257163
Train Epoch: 10 [16000/35339 (45%)]	Loss: 0.427070
Train Epoch: 10 [16640/35339 (47%)]	Loss: 0.284916
Train Epoch: 10 [17280/35339 (49%)]	Loss: 0.308192
Train Epoch: 10 [17920/35339 (51%)]	Loss: 0.380404
Train Epoch: 10 [18560/35339 (52%)]	Loss: 0.276500
Train Epoch: 10 [19200/35339 (54%)]	Loss: 0.242677
Train Epoch: 10 [19840/35339 (56%)]	Loss: 0.198479
Train Epoch: 10 [20480/35339 (58%)]	Loss: 0.186120
Train Epoch: 10 [21120/35339 (60%)]	Loss: 0.222484
Train Epoch: 10 [21760/35339 (61%)]	Loss: 0.320855
Train Epoch: 10 [22400/35339 (63%)]	Loss: 0.265344
Train Epoch: 10 [23040/35339 (65%)]	Loss: 0.261598
Train Epoch: 10 [23680/35339 (67%)]	Loss: 0.232737
Train Epoch: 10 [24320/35339 (69%)]	Loss: 0.243891
Train Epoch: 10 [24960/35339 (71%)]	Loss: 0.196604
Train Epoch: 10 [25600/35339 (72%)]	Loss: 0.178140
Train Epoch: 10 [26240/35339 (74%)]	Loss: 0.190723
Train Epoch: 10 [26880/35339 (76%)]	Loss: 0.388417
Train Epoch: 10 [27520/35339 (78%)]	Loss: 0.110511
Train Epoch: 10 [28160/35339 (80%)]	Loss: 0.137503
Train Epoch: 10 [28800/35339 (81%)]	Loss: 0.401864
Train Epoch: 10 [29440/35339 (83%)]	Loss: 0.257530
Train Epoch: 10 [30080/35339 (85%)]	Loss: 0.253241
Train Epoch: 10 [30720/35339 (87%)]	Loss: 0.277352
Train Epoch: 10 [31360/35339 (89%)]	Loss: 0.348598
Train Epoch: 10 [32000/35339 (90%)]	Loss: 0.528832
Train Epoch: 10 [32640/35339 (92%)]	Loss: 0.332612
Train Epoch: 10 [33280/35339 (94%)]	Loss: 0.340025
Train Epoch: 10 [33920/35339 (96%)]	Loss: 0.407793
Train Epoch: 10 [34560/35339 (98%)]	Loss: 0.262920
Train Epoch: 10 [35200/35339 (99%)]	Loss: 0.280676

Validation set: Average loss: 3.3954, Accuracy: 1199/3870 (31%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 11 [0/35339 (0%)]	Loss: 0.433977
Train Epoch: 11 [640/35339 (2%)]	Loss: 0.343028
Train Epoch: 11 [1280/35339 (4%)]	Loss: 0.313752
Train Epoch: 11 [1920/35339 (5%)]	Loss: 0.215019
Train Epoch: 11 [2560/35339 (7%)]	Loss: 0.304402
Train Epoch: 11 [3200/35339 (9%)]	Loss: 0.333572
Train Epoch: 11 [3840/35339 (11%)]	Loss: 0.244056
Train Epoch: 11 [4480/35339 (13%)]	Loss: 0.324650
Train Epoch: 11 [5120/35339 (14%)]	Loss: 0.197514
Train Epoch: 11 [5760/35339 (16%)]	Loss: 0.437454
Train Epoch: 11 [6400/35339 (18%)]	Loss: 0.173323
Train Epoch: 11 [7040/35339 (20%)]	Loss: 0.215021
Train Epoch: 11 [7680/35339 (22%)]	Loss: 0.372580
Train Epoch: 11 [8320/35339 (24%)]	Loss: 0.192325
Train Epoch: 11 [8960/35339 (25%)]	Loss: 0.246339
Train Epoch: 11 [9600/35339 (27%)]	Loss: 0.371819
Train Epoch: 11 [10240/35339 (29%)]	Loss: 0.252109
Train Epoch: 11 [10880/35339 (31%)]	Loss: 0.239360
Train Epoch: 11 [11520/35339 (33%)]	Loss: 0.363398
Train Epoch: 11 [12160/35339 (34%)]	Loss: 0.169945
Train Epoch: 11 [12800/35339 (36%)]	Loss: 0.348558
Train Epoch: 11 [13440/35339 (38%)]	Loss: 0.356907
Train Epoch: 11 [14080/35339 (40%)]	Loss: 0.264052
Train Epoch: 11 [14720/35339 (42%)]	Loss: 0.162525
Train Epoch: 11 [15360/35339 (43%)]	Loss: 0.195784
Train Epoch: 11 [16000/35339 (45%)]	Loss: 0.351338
Train Epoch: 11 [16640/35339 (47%)]	Loss: 0.240016
Train Epoch: 11 [17280/35339 (49%)]	Loss: 0.276232
Train Epoch: 11 [17920/35339 (51%)]	Loss: 0.204055
Train Epoch: 11 [18560/35339 (52%)]	Loss: 0.229253
Train Epoch: 11 [19200/35339 (54%)]	Loss: 0.277205
Train Epoch: 11 [19840/35339 (56%)]	Loss: 0.458976
Train Epoch: 11 [20480/35339 (58%)]	Loss: 0.223490
Train Epoch: 11 [21120/35339 (60%)]	Loss: 0.336382
Train Epoch: 11 [21760/35339 (61%)]	Loss: 0.221555
Train Epoch: 11 [22400/35339 (63%)]	Loss: 0.234580
Train Epoch: 11 [23040/35339 (65%)]	Loss: 0.152501
Train Epoch: 11 [23680/35339 (67%)]	Loss: 0.318277
Train Epoch: 11 [24320/35339 (69%)]	Loss: 0.219933
Train Epoch: 11 [24960/35339 (71%)]	Loss: 0.232215
Train Epoch: 11 [25600/35339 (72%)]	Loss: 0.133007
Train Epoch: 11 [26240/35339 (74%)]	Loss: 0.212236
Train Epoch: 11 [26880/35339 (76%)]	Loss: 0.201709
Train Epoch: 11 [27520/35339 (78%)]	Loss: 0.307199
Train Epoch: 11 [28160/35339 (80%)]	Loss: 0.293044
Train Epoch: 11 [28800/35339 (81%)]	Loss: 0.296128
Train Epoch: 11 [29440/35339 (83%)]	Loss: 0.276977
Train Epoch: 11 [30080/35339 (85%)]	Loss: 0.290119
Train Epoch: 11 [30720/35339 (87%)]	Loss: 0.255008
Train Epoch: 11 [31360/35339 (89%)]	Loss: 0.569938
Train Epoch: 11 [32000/35339 (90%)]	Loss: 0.352167
Train Epoch: 11 [32640/35339 (92%)]	Loss: 0.202967
Train Epoch: 11 [33280/35339 (94%)]	Loss: 0.209998
Train Epoch: 11 [33920/35339 (96%)]	Loss: 0.165424
Train Epoch: 11 [34560/35339 (98%)]	Loss: 0.218487
Train Epoch: 11 [35200/35339 (99%)]	Loss: 0.222248

Validation set: Average loss: 3.3506, Accuracy: 1264/3870 (33%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 12 [0/35339 (0%)]	Loss: 0.247481
Train Epoch: 12 [640/35339 (2%)]	Loss: 0.289117
Train Epoch: 12 [1280/35339 (4%)]	Loss: 0.260815
Train Epoch: 12 [1920/35339 (5%)]	Loss: 0.258431
Train Epoch: 12 [2560/35339 (7%)]	Loss: 0.203798
Train Epoch: 12 [3200/35339 (9%)]	Loss: 0.378118
Train Epoch: 12 [3840/35339 (11%)]	Loss: 0.432150
Train Epoch: 12 [4480/35339 (13%)]	Loss: 0.209741
Train Epoch: 12 [5120/35339 (14%)]	Loss: 0.210819
Train Epoch: 12 [5760/35339 (16%)]	Loss: 0.261515
Train Epoch: 12 [6400/35339 (18%)]	Loss: 0.182703
Train Epoch: 12 [7040/35339 (20%)]	Loss: 0.167537
Train Epoch: 12 [7680/35339 (22%)]	Loss: 0.166053
Train Epoch: 12 [8320/35339 (24%)]	Loss: 0.252271
Train Epoch: 12 [8960/35339 (25%)]	Loss: 0.234211
Train Epoch: 12 [9600/35339 (27%)]	Loss: 0.225969
Train Epoch: 12 [10240/35339 (29%)]	Loss: 0.185384
Train Epoch: 12 [10880/35339 (31%)]	Loss: 0.233414
Train Epoch: 12 [11520/35339 (33%)]	Loss: 0.162509
Train Epoch: 12 [12160/35339 (34%)]	Loss: 0.142419
Train Epoch: 12 [12800/35339 (36%)]	Loss: 0.252991
Train Epoch: 12 [13440/35339 (38%)]	Loss: 0.245901
Train Epoch: 12 [14080/35339 (40%)]	Loss: 0.186003
Train Epoch: 12 [14720/35339 (42%)]	Loss: 0.324979
Train Epoch: 12 [15360/35339 (43%)]	Loss: 0.347506
Train Epoch: 12 [16000/35339 (45%)]	Loss: 0.338444
Train Epoch: 12 [16640/35339 (47%)]	Loss: 0.171271
Train Epoch: 12 [17280/35339 (49%)]	Loss: 0.415806
Train Epoch: 12 [17920/35339 (51%)]	Loss: 0.253319
Train Epoch: 12 [18560/35339 (52%)]	Loss: 0.241773
Train Epoch: 12 [19200/35339 (54%)]	Loss: 0.239589
Train Epoch: 12 [19840/35339 (56%)]	Loss: 0.253035
Train Epoch: 12 [20480/35339 (58%)]	Loss: 0.271731
Train Epoch: 12 [21120/35339 (60%)]	Loss: 0.288562
Train Epoch: 12 [21760/35339 (61%)]	Loss: 0.241530
Train Epoch: 12 [22400/35339 (63%)]	Loss: 0.114187
Train Epoch: 12 [23040/35339 (65%)]	Loss: 0.256493
Train Epoch: 12 [23680/35339 (67%)]	Loss: 0.182360
Train Epoch: 12 [24320/35339 (69%)]	Loss: 0.269585
Train Epoch: 12 [24960/35339 (71%)]	Loss: 0.142117
Train Epoch: 12 [25600/35339 (72%)]	Loss: 0.331981
Train Epoch: 12 [26240/35339 (74%)]	Loss: 0.155365
Train Epoch: 12 [26880/35339 (76%)]	Loss: 0.215407
Train Epoch: 12 [27520/35339 (78%)]	Loss: 0.330091
Train Epoch: 12 [28160/35339 (80%)]	Loss: 0.144737
Train Epoch: 12 [28800/35339 (81%)]	Loss: 0.238081
Train Epoch: 12 [29440/35339 (83%)]	Loss: 0.186031
Train Epoch: 12 [30080/35339 (85%)]	Loss: 0.180824
Train Epoch: 12 [30720/35339 (87%)]	Loss: 0.220135
Train Epoch: 12 [31360/35339 (89%)]	Loss: 0.277652
Train Epoch: 12 [32000/35339 (90%)]	Loss: 0.330085
Train Epoch: 12 [32640/35339 (92%)]	Loss: 0.186915
Train Epoch: 12 [33280/35339 (94%)]	Loss: 0.246746
Train Epoch: 12 [33920/35339 (96%)]	Loss: 0.172666
Train Epoch: 12 [34560/35339 (98%)]	Loss: 0.191420
Train Epoch: 12 [35200/35339 (99%)]	Loss: 0.261557

Validation set: Average loss: 3.3277, Accuracy: 1290/3870 (33%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 13 [0/35339 (0%)]	Loss: 0.267261
Train Epoch: 13 [640/35339 (2%)]	Loss: 0.306562
Train Epoch: 13 [1280/35339 (4%)]	Loss: 0.259672
Train Epoch: 13 [1920/35339 (5%)]	Loss: 0.195486
Train Epoch: 13 [2560/35339 (7%)]	Loss: 0.252410
Train Epoch: 13 [3200/35339 (9%)]	Loss: 0.339846
Train Epoch: 13 [3840/35339 (11%)]	Loss: 0.183023
Train Epoch: 13 [4480/35339 (13%)]	Loss: 0.119972
Train Epoch: 13 [5120/35339 (14%)]	Loss: 0.373968
Train Epoch: 13 [5760/35339 (16%)]	Loss: 0.378012
Train Epoch: 13 [6400/35339 (18%)]	Loss: 0.335803
Train Epoch: 13 [7040/35339 (20%)]	Loss: 0.214114
Train Epoch: 13 [7680/35339 (22%)]	Loss: 0.201056
Train Epoch: 13 [8320/35339 (24%)]	Loss: 0.195384
Train Epoch: 13 [8960/35339 (25%)]	Loss: 0.233988
Train Epoch: 13 [9600/35339 (27%)]	Loss: 0.293366
Train Epoch: 13 [10240/35339 (29%)]	Loss: 0.246412
Train Epoch: 13 [10880/35339 (31%)]	Loss: 0.161534
Train Epoch: 13 [11520/35339 (33%)]	Loss: 0.208150
Train Epoch: 13 [12160/35339 (34%)]	Loss: 0.291330
Train Epoch: 13 [12800/35339 (36%)]	Loss: 0.233378
Train Epoch: 13 [13440/35339 (38%)]	Loss: 0.193502
Train Epoch: 13 [14080/35339 (40%)]	Loss: 0.525757
Train Epoch: 13 [14720/35339 (42%)]	Loss: 0.176580
Train Epoch: 13 [15360/35339 (43%)]	Loss: 0.211705
Train Epoch: 13 [16000/35339 (45%)]	Loss: 0.231748
Train Epoch: 13 [16640/35339 (47%)]	Loss: 0.181637
Train Epoch: 13 [17280/35339 (49%)]	Loss: 0.274301
Train Epoch: 13 [17920/35339 (51%)]	Loss: 0.316923
Train Epoch: 13 [18560/35339 (52%)]	Loss: 0.278565
Train Epoch: 13 [19200/35339 (54%)]	Loss: 0.368588
Train Epoch: 13 [19840/35339 (56%)]	Loss: 0.189577
Train Epoch: 13 [20480/35339 (58%)]	Loss: 0.188363
Train Epoch: 13 [21120/35339 (60%)]	Loss: 0.608377
Train Epoch: 13 [21760/35339 (61%)]	Loss: 0.185562
Train Epoch: 13 [22400/35339 (63%)]	Loss: 0.251562
Train Epoch: 13 [23040/35339 (65%)]	Loss: 0.146718
Train Epoch: 13 [23680/35339 (67%)]	Loss: 0.220653
Train Epoch: 13 [24320/35339 (69%)]	Loss: 0.314829
Train Epoch: 13 [24960/35339 (71%)]	Loss: 0.194403
Train Epoch: 13 [25600/35339 (72%)]	Loss: 0.239578
Train Epoch: 13 [26240/35339 (74%)]	Loss: 0.120194
Train Epoch: 13 [26880/35339 (76%)]	Loss: 0.312848
Train Epoch: 13 [27520/35339 (78%)]	Loss: 0.224960
Train Epoch: 13 [28160/35339 (80%)]	Loss: 0.235189
Train Epoch: 13 [28800/35339 (81%)]	Loss: 0.203172
Train Epoch: 13 [29440/35339 (83%)]	Loss: 0.154288
Train Epoch: 13 [30080/35339 (85%)]	Loss: 0.231121
Train Epoch: 13 [30720/35339 (87%)]	Loss: 0.182575
Train Epoch: 13 [31360/35339 (89%)]	Loss: 0.262925
Train Epoch: 13 [32000/35339 (90%)]	Loss: 0.226007
Train Epoch: 13 [32640/35339 (92%)]	Loss: 0.248673
Train Epoch: 13 [33280/35339 (94%)]	Loss: 0.221254
Train Epoch: 13 [33920/35339 (96%)]	Loss: 0.151330
Train Epoch: 13 [34560/35339 (98%)]	Loss: 0.210908
Train Epoch: 13 [35200/35339 (99%)]	Loss: 0.179029

Validation set: Average loss: 3.3819, Accuracy: 1277/3870 (33%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 14 [0/35339 (0%)]	Loss: 0.208839
Train Epoch: 14 [640/35339 (2%)]	Loss: 0.165328
Train Epoch: 14 [1280/35339 (4%)]	Loss: 0.192052
Train Epoch: 14 [1920/35339 (5%)]	Loss: 0.170467
Train Epoch: 14 [2560/35339 (7%)]	Loss: 0.191456
Train Epoch: 14 [3200/35339 (9%)]	Loss: 0.104784
Train Epoch: 14 [3840/35339 (11%)]	Loss: 0.278982
Train Epoch: 14 [4480/35339 (13%)]	Loss: 0.274567
Train Epoch: 14 [5120/35339 (14%)]	Loss: 0.160776
Train Epoch: 14 [5760/35339 (16%)]	Loss: 0.329976
Train Epoch: 14 [6400/35339 (18%)]	Loss: 0.266736
Train Epoch: 14 [7040/35339 (20%)]	Loss: 0.111842
Train Epoch: 14 [7680/35339 (22%)]	Loss: 0.235895
Train Epoch: 14 [8320/35339 (24%)]	Loss: 0.285747
Train Epoch: 14 [8960/35339 (25%)]	Loss: 0.242244
Train Epoch: 14 [9600/35339 (27%)]	Loss: 0.195652
Train Epoch: 14 [10240/35339 (29%)]	Loss: 0.228058
Train Epoch: 14 [10880/35339 (31%)]	Loss: 0.232985
Train Epoch: 14 [11520/35339 (33%)]	Loss: 0.085683
Train Epoch: 14 [12160/35339 (34%)]	Loss: 0.296770
Train Epoch: 14 [12800/35339 (36%)]	Loss: 0.387512
Train Epoch: 14 [13440/35339 (38%)]	Loss: 0.319346
Train Epoch: 14 [14080/35339 (40%)]	Loss: 0.234847
Train Epoch: 14 [14720/35339 (42%)]	Loss: 0.159161
Train Epoch: 14 [15360/35339 (43%)]	Loss: 0.219723
Train Epoch: 14 [16000/35339 (45%)]	Loss: 0.353849
Train Epoch: 14 [16640/35339 (47%)]	Loss: 0.219181
Train Epoch: 14 [17280/35339 (49%)]	Loss: 0.295996
Train Epoch: 14 [17920/35339 (51%)]	Loss: 0.243552
Train Epoch: 14 [18560/35339 (52%)]	Loss: 0.342706
Train Epoch: 14 [19200/35339 (54%)]	Loss: 0.203804
Train Epoch: 14 [19840/35339 (56%)]	Loss: 0.252342
Train Epoch: 14 [20480/35339 (58%)]	Loss: 0.147873
Train Epoch: 14 [21120/35339 (60%)]	Loss: 0.158872
Train Epoch: 14 [21760/35339 (61%)]	Loss: 0.144154
Train Epoch: 14 [22400/35339 (63%)]	Loss: 0.141494
Train Epoch: 14 [23040/35339 (65%)]	Loss: 0.185147
Train Epoch: 14 [23680/35339 (67%)]	Loss: 0.173335
Train Epoch: 14 [24320/35339 (69%)]	Loss: 0.185685
Train Epoch: 14 [24960/35339 (71%)]	Loss: 0.214561
Train Epoch: 14 [25600/35339 (72%)]	Loss: 0.326041
Train Epoch: 14 [26240/35339 (74%)]	Loss: 0.170989
Train Epoch: 14 [26880/35339 (76%)]	Loss: 0.178006
Train Epoch: 14 [27520/35339 (78%)]	Loss: 0.166500
Train Epoch: 14 [28160/35339 (80%)]	Loss: 0.130811
Train Epoch: 14 [28800/35339 (81%)]	Loss: 0.113366
Train Epoch: 14 [29440/35339 (83%)]	Loss: 0.356567
Train Epoch: 14 [30080/35339 (85%)]	Loss: 0.140379
Train Epoch: 14 [30720/35339 (87%)]	Loss: 0.122626
Train Epoch: 14 [31360/35339 (89%)]	Loss: 0.267957
Train Epoch: 14 [32000/35339 (90%)]	Loss: 0.301404
Train Epoch: 14 [32640/35339 (92%)]	Loss: 0.235755
Train Epoch: 14 [33280/35339 (94%)]	Loss: 0.256441
Train Epoch: 14 [33920/35339 (96%)]	Loss: 0.241408
Train Epoch: 14 [34560/35339 (98%)]	Loss: 0.164923
Train Epoch: 14 [35200/35339 (99%)]	Loss: 0.227905

Validation set: Average loss: 3.2808, Accuracy: 1345/3870 (35%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 15 [0/35339 (0%)]	Loss: 0.224878
Train Epoch: 15 [640/35339 (2%)]	Loss: 0.212641
Train Epoch: 15 [1280/35339 (4%)]	Loss: 0.336526
Train Epoch: 15 [1920/35339 (5%)]	Loss: 0.252834
Train Epoch: 15 [2560/35339 (7%)]	Loss: 0.277925
Train Epoch: 15 [3200/35339 (9%)]	Loss: 0.184995
Train Epoch: 15 [3840/35339 (11%)]	Loss: 0.313896
Train Epoch: 15 [4480/35339 (13%)]	Loss: 0.278593
Train Epoch: 15 [5120/35339 (14%)]	Loss: 0.167024
Train Epoch: 15 [5760/35339 (16%)]	Loss: 0.114746
Train Epoch: 15 [6400/35339 (18%)]	Loss: 0.229326
Train Epoch: 15 [7040/35339 (20%)]	Loss: 0.160642
Train Epoch: 15 [7680/35339 (22%)]	Loss: 0.420055
Train Epoch: 15 [8320/35339 (24%)]	Loss: 0.105496
Train Epoch: 15 [8960/35339 (25%)]	Loss: 0.216630
Train Epoch: 15 [9600/35339 (27%)]	Loss: 0.103478
Train Epoch: 15 [10240/35339 (29%)]	Loss: 0.228593
Train Epoch: 15 [10880/35339 (31%)]	Loss: 0.248542
Train Epoch: 15 [11520/35339 (33%)]	Loss: 0.124314
Train Epoch: 15 [12160/35339 (34%)]	Loss: 0.210087
Train Epoch: 15 [12800/35339 (36%)]	Loss: 0.205345
Train Epoch: 15 [13440/35339 (38%)]	Loss: 0.178192
Train Epoch: 15 [14080/35339 (40%)]	Loss: 0.148084
Train Epoch: 15 [14720/35339 (42%)]	Loss: 0.128624
Train Epoch: 15 [15360/35339 (43%)]	Loss: 0.113428
Train Epoch: 15 [16000/35339 (45%)]	Loss: 0.195528
Train Epoch: 15 [16640/35339 (47%)]	Loss: 0.135576
Train Epoch: 15 [17280/35339 (49%)]	Loss: 0.132019
Train Epoch: 15 [17920/35339 (51%)]	Loss: 0.149420
Train Epoch: 15 [18560/35339 (52%)]	Loss: 0.261039
Train Epoch: 15 [19200/35339 (54%)]	Loss: 0.208207
Train Epoch: 15 [19840/35339 (56%)]	Loss: 0.179402
Train Epoch: 15 [20480/35339 (58%)]	Loss: 0.242765
Train Epoch: 15 [21120/35339 (60%)]	Loss: 0.192670
Train Epoch: 15 [21760/35339 (61%)]	Loss: 0.291850
Train Epoch: 15 [22400/35339 (63%)]	Loss: 0.248805
Train Epoch: 15 [23040/35339 (65%)]	Loss: 0.267176
Train Epoch: 15 [23680/35339 (67%)]	Loss: 0.255136
Train Epoch: 15 [24320/35339 (69%)]	Loss: 0.204164
Train Epoch: 15 [24960/35339 (71%)]	Loss: 0.235352
Train Epoch: 15 [25600/35339 (72%)]	Loss: 0.188641
Train Epoch: 15 [26240/35339 (74%)]	Loss: 0.189965
Train Epoch: 15 [26880/35339 (76%)]	Loss: 0.332917
Train Epoch: 15 [27520/35339 (78%)]	Loss: 0.161991
Train Epoch: 15 [28160/35339 (80%)]	Loss: 0.277339
Train Epoch: 15 [28800/35339 (81%)]	Loss: 0.253933
Train Epoch: 15 [29440/35339 (83%)]	Loss: 0.168759
Train Epoch: 15 [30080/35339 (85%)]	Loss: 0.187643
Train Epoch: 15 [30720/35339 (87%)]	Loss: 0.354281
Train Epoch: 15 [31360/35339 (89%)]	Loss: 0.225640
Train Epoch: 15 [32000/35339 (90%)]	Loss: 0.143417
Train Epoch: 15 [32640/35339 (92%)]	Loss: 0.187468
Train Epoch: 15 [33280/35339 (94%)]	Loss: 0.121730
Train Epoch: 15 [33920/35339 (96%)]	Loss: 0.234132
Train Epoch: 15 [34560/35339 (98%)]	Loss: 0.284779
Train Epoch: 15 [35200/35339 (99%)]	Loss: 0.140186

Validation set: Average loss: 3.1862, Accuracy: 1408/3870 (36%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 16 [0/35339 (0%)]	Loss: 0.271831
Train Epoch: 16 [640/35339 (2%)]	Loss: 0.198079
Train Epoch: 16 [1280/35339 (4%)]	Loss: 0.195410
Train Epoch: 16 [1920/35339 (5%)]	Loss: 0.216400
Train Epoch: 16 [2560/35339 (7%)]	Loss: 0.255003
Train Epoch: 16 [3200/35339 (9%)]	Loss: 0.443058
Train Epoch: 16 [3840/35339 (11%)]	Loss: 0.320734
Train Epoch: 16 [4480/35339 (13%)]	Loss: 0.218479
Train Epoch: 16 [5120/35339 (14%)]	Loss: 0.271255
Train Epoch: 16 [5760/35339 (16%)]	Loss: 0.200282
Train Epoch: 16 [6400/35339 (18%)]	Loss: 0.201184
Train Epoch: 16 [7040/35339 (20%)]	Loss: 0.429581
Train Epoch: 16 [7680/35339 (22%)]	Loss: 0.113374
Train Epoch: 16 [8320/35339 (24%)]	Loss: 0.218227
Train Epoch: 16 [8960/35339 (25%)]	Loss: 0.260960
Train Epoch: 16 [9600/35339 (27%)]	Loss: 0.238954
Train Epoch: 16 [10240/35339 (29%)]	Loss: 0.235180
Train Epoch: 16 [10880/35339 (31%)]	Loss: 0.225950
Train Epoch: 16 [11520/35339 (33%)]	Loss: 0.296031
Train Epoch: 16 [12160/35339 (34%)]	Loss: 0.219385
Train Epoch: 16 [12800/35339 (36%)]	Loss: 0.237943
Train Epoch: 16 [13440/35339 (38%)]	Loss: 0.131727
Train Epoch: 16 [14080/35339 (40%)]	Loss: 0.191646
Train Epoch: 16 [14720/35339 (42%)]	Loss: 0.257110
Train Epoch: 16 [15360/35339 (43%)]	Loss: 0.219705
Train Epoch: 16 [16000/35339 (45%)]	Loss: 0.228259
Train Epoch: 16 [16640/35339 (47%)]	Loss: 0.174683
Train Epoch: 16 [17280/35339 (49%)]	Loss: 0.210859
Train Epoch: 16 [17920/35339 (51%)]	Loss: 0.265081
Train Epoch: 16 [18560/35339 (52%)]	Loss: 0.204879
Train Epoch: 16 [19200/35339 (54%)]	Loss: 0.128454
Train Epoch: 16 [19840/35339 (56%)]	Loss: 0.147529
Train Epoch: 16 [20480/35339 (58%)]	Loss: 0.279664
Train Epoch: 16 [21120/35339 (60%)]	Loss: 0.148692
Train Epoch: 16 [21760/35339 (61%)]	Loss: 0.293731
Train Epoch: 16 [22400/35339 (63%)]	Loss: 0.115309
Train Epoch: 16 [23040/35339 (65%)]	Loss: 0.195088
Train Epoch: 16 [23680/35339 (67%)]	Loss: 0.151531
Train Epoch: 16 [24320/35339 (69%)]	Loss: 0.318427
Train Epoch: 16 [24960/35339 (71%)]	Loss: 0.212890
Train Epoch: 16 [25600/35339 (72%)]	Loss: 0.357142
Train Epoch: 16 [26240/35339 (74%)]	Loss: 0.127649
Train Epoch: 16 [26880/35339 (76%)]	Loss: 0.187205
Train Epoch: 16 [27520/35339 (78%)]	Loss: 0.258780
Train Epoch: 16 [28160/35339 (80%)]	Loss: 0.174946
Train Epoch: 16 [28800/35339 (81%)]	Loss: 0.174463
Train Epoch: 16 [29440/35339 (83%)]	Loss: 0.328681
Train Epoch: 16 [30080/35339 (85%)]	Loss: 0.219622
Train Epoch: 16 [30720/35339 (87%)]	Loss: 0.282003
Train Epoch: 16 [31360/35339 (89%)]	Loss: 0.195402
Train Epoch: 16 [32000/35339 (90%)]	Loss: 0.236684
Train Epoch: 16 [32640/35339 (92%)]	Loss: 0.165869
Train Epoch: 16 [33280/35339 (94%)]	Loss: 0.133417
Train Epoch: 16 [33920/35339 (96%)]	Loss: 0.195474
Train Epoch: 16 [34560/35339 (98%)]	Loss: 0.178458
Train Epoch: 16 [35200/35339 (99%)]	Loss: 0.113808

Validation set: Average loss: 3.1519, Accuracy: 1449/3870 (37%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 17 [0/35339 (0%)]	Loss: 0.229353
Train Epoch: 17 [640/35339 (2%)]	Loss: 0.204105
Train Epoch: 17 [1280/35339 (4%)]	Loss: 0.307641
Train Epoch: 17 [1920/35339 (5%)]	Loss: 0.240749
Train Epoch: 17 [2560/35339 (7%)]	Loss: 0.238783
Train Epoch: 17 [3200/35339 (9%)]	Loss: 0.297828
Train Epoch: 17 [3840/35339 (11%)]	Loss: 0.153799
Train Epoch: 17 [4480/35339 (13%)]	Loss: 0.187071
Train Epoch: 17 [5120/35339 (14%)]	Loss: 0.220726
Train Epoch: 17 [5760/35339 (16%)]	Loss: 0.117079
Train Epoch: 17 [6400/35339 (18%)]	Loss: 0.157143
Train Epoch: 17 [7040/35339 (20%)]	Loss: 0.230036
Train Epoch: 17 [7680/35339 (22%)]	Loss: 0.234675
Train Epoch: 17 [8320/35339 (24%)]	Loss: 0.199801
Train Epoch: 17 [8960/35339 (25%)]	Loss: 0.260030
Train Epoch: 17 [9600/35339 (27%)]	Loss: 0.114821
Train Epoch: 17 [10240/35339 (29%)]	Loss: 0.196784
Train Epoch: 17 [10880/35339 (31%)]	Loss: 0.245730
Train Epoch: 17 [11520/35339 (33%)]	Loss: 0.154099
Train Epoch: 17 [12160/35339 (34%)]	Loss: 0.196226
Train Epoch: 17 [12800/35339 (36%)]	Loss: 0.270568
Train Epoch: 17 [13440/35339 (38%)]	Loss: 0.221884
Train Epoch: 17 [14080/35339 (40%)]	Loss: 0.114547
Train Epoch: 17 [14720/35339 (42%)]	Loss: 0.223175
Train Epoch: 17 [15360/35339 (43%)]	Loss: 0.139619
Train Epoch: 17 [16000/35339 (45%)]	Loss: 0.203150
Train Epoch: 17 [16640/35339 (47%)]	Loss: 0.177741
Train Epoch: 17 [17280/35339 (49%)]	Loss: 0.164285
Train Epoch: 17 [17920/35339 (51%)]	Loss: 0.130088
Train Epoch: 17 [18560/35339 (52%)]	Loss: 0.171001
Train Epoch: 17 [19200/35339 (54%)]	Loss: 0.163304
Train Epoch: 17 [19840/35339 (56%)]	Loss: 0.180744
Train Epoch: 17 [20480/35339 (58%)]	Loss: 0.139982
Train Epoch: 17 [21120/35339 (60%)]	Loss: 0.148434
Train Epoch: 17 [21760/35339 (61%)]	Loss: 0.230435
Train Epoch: 17 [22400/35339 (63%)]	Loss: 0.363992
Train Epoch: 17 [23040/35339 (65%)]	Loss: 0.160638
Train Epoch: 17 [23680/35339 (67%)]	Loss: 0.204789
Train Epoch: 17 [24320/35339 (69%)]	Loss: 0.108183
Train Epoch: 17 [24960/35339 (71%)]	Loss: 0.186255
Train Epoch: 17 [25600/35339 (72%)]	Loss: 0.225938
Train Epoch: 17 [26240/35339 (74%)]	Loss: 0.203720
Train Epoch: 17 [26880/35339 (76%)]	Loss: 0.352926
Train Epoch: 17 [27520/35339 (78%)]	Loss: 0.245446
Train Epoch: 17 [28160/35339 (80%)]	Loss: 0.174706
Train Epoch: 17 [28800/35339 (81%)]	Loss: 0.132522
Train Epoch: 17 [29440/35339 (83%)]	Loss: 0.256522
Train Epoch: 17 [30080/35339 (85%)]	Loss: 0.227196
Train Epoch: 17 [30720/35339 (87%)]	Loss: 0.224638
Train Epoch: 17 [31360/35339 (89%)]	Loss: 0.207459
Train Epoch: 17 [32000/35339 (90%)]	Loss: 0.211929
Train Epoch: 17 [32640/35339 (92%)]	Loss: 0.154700
Train Epoch: 17 [33280/35339 (94%)]	Loss: 0.206302
Train Epoch: 17 [33920/35339 (96%)]	Loss: 0.249066
Train Epoch: 17 [34560/35339 (98%)]	Loss: 0.117254
Train Epoch: 17 [35200/35339 (99%)]	Loss: 0.140336

Validation set: Average loss: 3.2140, Accuracy: 1426/3870 (37%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 18 [0/35339 (0%)]	Loss: 0.189575
Train Epoch: 18 [640/35339 (2%)]	Loss: 0.247735
Train Epoch: 18 [1280/35339 (4%)]	Loss: 0.074055
Train Epoch: 18 [1920/35339 (5%)]	Loss: 0.234199
Train Epoch: 18 [2560/35339 (7%)]	Loss: 0.146756
Train Epoch: 18 [3200/35339 (9%)]	Loss: 0.107357
Train Epoch: 18 [3840/35339 (11%)]	Loss: 0.171773
Train Epoch: 18 [4480/35339 (13%)]	Loss: 0.331379
Train Epoch: 18 [5120/35339 (14%)]	Loss: 0.273728
Train Epoch: 18 [5760/35339 (16%)]	Loss: 0.286427
Train Epoch: 18 [6400/35339 (18%)]	Loss: 0.214852
Train Epoch: 18 [7040/35339 (20%)]	Loss: 0.168879
Train Epoch: 18 [7680/35339 (22%)]	Loss: 0.209537
Train Epoch: 18 [8320/35339 (24%)]	Loss: 0.147920
Train Epoch: 18 [8960/35339 (25%)]	Loss: 0.240267
Train Epoch: 18 [9600/35339 (27%)]	Loss: 0.286687
Train Epoch: 18 [10240/35339 (29%)]	Loss: 0.263288
Train Epoch: 18 [10880/35339 (31%)]	Loss: 0.171142
Train Epoch: 18 [11520/35339 (33%)]	Loss: 0.187731
Train Epoch: 18 [12160/35339 (34%)]	Loss: 0.130790
Train Epoch: 18 [12800/35339 (36%)]	Loss: 0.173115
Train Epoch: 18 [13440/35339 (38%)]	Loss: 0.219153
Train Epoch: 18 [14080/35339 (40%)]	Loss: 0.144433
Train Epoch: 18 [14720/35339 (42%)]	Loss: 0.146013
Train Epoch: 18 [15360/35339 (43%)]	Loss: 0.293666
Train Epoch: 18 [16000/35339 (45%)]	Loss: 0.112699
Train Epoch: 18 [16640/35339 (47%)]	Loss: 0.132871
Train Epoch: 18 [17280/35339 (49%)]	Loss: 0.271971
Train Epoch: 18 [17920/35339 (51%)]	Loss: 0.230748
Train Epoch: 18 [18560/35339 (52%)]	Loss: 0.232711
Train Epoch: 18 [19200/35339 (54%)]	Loss: 0.122879
Train Epoch: 18 [19840/35339 (56%)]	Loss: 0.135960
Train Epoch: 18 [20480/35339 (58%)]	Loss: 0.104009
Train Epoch: 18 [21120/35339 (60%)]	Loss: 0.173546
Train Epoch: 18 [21760/35339 (61%)]	Loss: 0.237849
Train Epoch: 18 [22400/35339 (63%)]	Loss: 0.307033
Train Epoch: 18 [23040/35339 (65%)]	Loss: 0.170514
Train Epoch: 18 [23680/35339 (67%)]	Loss: 0.197188
Train Epoch: 18 [24320/35339 (69%)]	Loss: 0.406955
Train Epoch: 18 [24960/35339 (71%)]	Loss: 0.203126
Train Epoch: 18 [25600/35339 (72%)]	Loss: 0.253626
Train Epoch: 18 [26240/35339 (74%)]	Loss: 0.104412
Train Epoch: 18 [26880/35339 (76%)]	Loss: 0.407235
Train Epoch: 18 [27520/35339 (78%)]	Loss: 0.167274
Train Epoch: 18 [28160/35339 (80%)]	Loss: 0.249701
Train Epoch: 18 [28800/35339 (81%)]	Loss: 0.099867
Train Epoch: 18 [29440/35339 (83%)]	Loss: 0.179101
Train Epoch: 18 [30080/35339 (85%)]	Loss: 0.251385
Train Epoch: 18 [30720/35339 (87%)]	Loss: 0.110709
Train Epoch: 18 [31360/35339 (89%)]	Loss: 0.217603
Train Epoch: 18 [32000/35339 (90%)]	Loss: 0.261974
Train Epoch: 18 [32640/35339 (92%)]	Loss: 0.141841
Train Epoch: 18 [33280/35339 (94%)]	Loss: 0.147220
Train Epoch: 18 [33920/35339 (96%)]	Loss: 0.140412
Train Epoch: 18 [34560/35339 (98%)]	Loss: 0.105910
Train Epoch: 18 [35200/35339 (99%)]	Loss: 0.177874

Validation set: Average loss: 3.2356, Accuracy: 1384/3870 (36%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 19 [0/35339 (0%)]	Loss: 0.151119
Train Epoch: 19 [640/35339 (2%)]	Loss: 0.312105
Train Epoch: 19 [1280/35339 (4%)]	Loss: 0.198288
Train Epoch: 19 [1920/35339 (5%)]	Loss: 0.096069
Train Epoch: 19 [2560/35339 (7%)]	Loss: 0.153393
Train Epoch: 19 [3200/35339 (9%)]	Loss: 0.240541
Train Epoch: 19 [3840/35339 (11%)]	Loss: 0.185949
Train Epoch: 19 [4480/35339 (13%)]	Loss: 0.156651
Train Epoch: 19 [5120/35339 (14%)]	Loss: 0.170979
Train Epoch: 19 [5760/35339 (16%)]	Loss: 0.147055
Train Epoch: 19 [6400/35339 (18%)]	Loss: 0.195262
Train Epoch: 19 [7040/35339 (20%)]	Loss: 0.203707
Train Epoch: 19 [7680/35339 (22%)]	Loss: 0.284457
Train Epoch: 19 [8320/35339 (24%)]	Loss: 0.111234
Train Epoch: 19 [8960/35339 (25%)]	Loss: 0.118024
Train Epoch: 19 [9600/35339 (27%)]	Loss: 0.148758
Train Epoch: 19 [10240/35339 (29%)]	Loss: 0.152907
Train Epoch: 19 [10880/35339 (31%)]	Loss: 0.134535
Train Epoch: 19 [11520/35339 (33%)]	Loss: 0.094648
Train Epoch: 19 [12160/35339 (34%)]	Loss: 0.177303
Train Epoch: 19 [12800/35339 (36%)]	Loss: 0.196411
Train Epoch: 19 [13440/35339 (38%)]	Loss: 0.367979
Train Epoch: 19 [14080/35339 (40%)]	Loss: 0.167169
Train Epoch: 19 [14720/35339 (42%)]	Loss: 0.141462
Train Epoch: 19 [15360/35339 (43%)]	Loss: 0.202776
Train Epoch: 19 [16000/35339 (45%)]	Loss: 0.207764
Train Epoch: 19 [16640/35339 (47%)]	Loss: 0.168438
Train Epoch: 19 [17280/35339 (49%)]	Loss: 0.382500
Train Epoch: 19 [17920/35339 (51%)]	Loss: 0.203439
Train Epoch: 19 [18560/35339 (52%)]	Loss: 0.207823
Train Epoch: 19 [19200/35339 (54%)]	Loss: 0.230324
Train Epoch: 19 [19840/35339 (56%)]	Loss: 0.231805
Train Epoch: 19 [20480/35339 (58%)]	Loss: 0.234552
Train Epoch: 19 [21120/35339 (60%)]	Loss: 0.217853
Train Epoch: 19 [21760/35339 (61%)]	Loss: 0.308115
Train Epoch: 19 [22400/35339 (63%)]	Loss: 0.224151
Train Epoch: 19 [23040/35339 (65%)]	Loss: 0.111864
Train Epoch: 19 [23680/35339 (67%)]	Loss: 0.336322
Train Epoch: 19 [24320/35339 (69%)]	Loss: 0.168599
Train Epoch: 19 [24960/35339 (71%)]	Loss: 0.254710
Train Epoch: 19 [25600/35339 (72%)]	Loss: 0.359385
Train Epoch: 19 [26240/35339 (74%)]	Loss: 0.272590
Train Epoch: 19 [26880/35339 (76%)]	Loss: 0.215779
Train Epoch: 19 [27520/35339 (78%)]	Loss: 0.297329
Train Epoch: 19 [28160/35339 (80%)]	Loss: 0.139308
Train Epoch: 19 [28800/35339 (81%)]	Loss: 0.107963
Train Epoch: 19 [29440/35339 (83%)]	Loss: 0.140218
Train Epoch: 19 [30080/35339 (85%)]	Loss: 0.079916
Train Epoch: 19 [30720/35339 (87%)]	Loss: 0.205438
Train Epoch: 19 [31360/35339 (89%)]	Loss: 0.134770
Train Epoch: 19 [32000/35339 (90%)]	Loss: 0.119927
Train Epoch: 19 [32640/35339 (92%)]	Loss: 0.088587
Train Epoch: 19 [33280/35339 (94%)]	Loss: 0.155263
Train Epoch: 19 [33920/35339 (96%)]	Loss: 0.261356
Train Epoch: 19 [34560/35339 (98%)]	Loss: 0.237671
Train Epoch: 19 [35200/35339 (99%)]	Loss: 0.322720

Validation set: Average loss: 3.1914, Accuracy: 1433/3870 (37%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 20 [0/35339 (0%)]	Loss: 0.235130
Train Epoch: 20 [640/35339 (2%)]	Loss: 0.098999
Train Epoch: 20 [1280/35339 (4%)]	Loss: 0.282848
Train Epoch: 20 [1920/35339 (5%)]	Loss: 0.195137
Train Epoch: 20 [2560/35339 (7%)]	Loss: 0.234233
Train Epoch: 20 [3200/35339 (9%)]	Loss: 0.184108
Train Epoch: 20 [3840/35339 (11%)]	Loss: 0.221410
Train Epoch: 20 [4480/35339 (13%)]	Loss: 0.336228
Train Epoch: 20 [5120/35339 (14%)]	Loss: 0.337338
Train Epoch: 20 [5760/35339 (16%)]	Loss: 0.134918
Train Epoch: 20 [6400/35339 (18%)]	Loss: 0.211681
Train Epoch: 20 [7040/35339 (20%)]	Loss: 0.157184
Train Epoch: 20 [7680/35339 (22%)]	Loss: 0.178764
Train Epoch: 20 [8320/35339 (24%)]	Loss: 0.197982
Train Epoch: 20 [8960/35339 (25%)]	Loss: 0.107064
Train Epoch: 20 [9600/35339 (27%)]	Loss: 0.232844
Train Epoch: 20 [10240/35339 (29%)]	Loss: 0.191619
Train Epoch: 20 [10880/35339 (31%)]	Loss: 0.286638
Train Epoch: 20 [11520/35339 (33%)]	Loss: 0.149578
Train Epoch: 20 [12160/35339 (34%)]	Loss: 0.240960
Train Epoch: 20 [12800/35339 (36%)]	Loss: 0.112366
Train Epoch: 20 [13440/35339 (38%)]	Loss: 0.281591
Train Epoch: 20 [14080/35339 (40%)]	Loss: 0.152169
Train Epoch: 20 [14720/35339 (42%)]	Loss: 0.084298
Train Epoch: 20 [15360/35339 (43%)]	Loss: 0.194578
Train Epoch: 20 [16000/35339 (45%)]	Loss: 0.336485
Train Epoch: 20 [16640/35339 (47%)]	Loss: 0.187346
Train Epoch: 20 [17280/35339 (49%)]	Loss: 0.135975
Train Epoch: 20 [17920/35339 (51%)]	Loss: 0.187173
Train Epoch: 20 [18560/35339 (52%)]	Loss: 0.166446
Train Epoch: 20 [19200/35339 (54%)]	Loss: 0.342541
Train Epoch: 20 [19840/35339 (56%)]	Loss: 0.121641
Train Epoch: 20 [20480/35339 (58%)]	Loss: 0.153324
Train Epoch: 20 [21120/35339 (60%)]	Loss: 0.099330
Train Epoch: 20 [21760/35339 (61%)]	Loss: 0.132574
Train Epoch: 20 [22400/35339 (63%)]	Loss: 0.198821
Train Epoch: 20 [23040/35339 (65%)]	Loss: 0.175937
Train Epoch: 20 [23680/35339 (67%)]	Loss: 0.131279
Train Epoch: 20 [24320/35339 (69%)]	Loss: 0.120099
Train Epoch: 20 [24960/35339 (71%)]	Loss: 0.218204
Train Epoch: 20 [25600/35339 (72%)]	Loss: 0.247408
Train Epoch: 20 [26240/35339 (74%)]	Loss: 0.156627
Train Epoch: 20 [26880/35339 (76%)]	Loss: 0.202883
Train Epoch: 20 [27520/35339 (78%)]	Loss: 0.114828
Train Epoch: 20 [28160/35339 (80%)]	Loss: 0.127140
Train Epoch: 20 [28800/35339 (81%)]	Loss: 0.193883
Train Epoch: 20 [29440/35339 (83%)]	Loss: 0.272757
Train Epoch: 20 [30080/35339 (85%)]	Loss: 0.134933
Train Epoch: 20 [30720/35339 (87%)]	Loss: 0.148789
Train Epoch: 20 [31360/35339 (89%)]	Loss: 0.196098
Train Epoch: 20 [32000/35339 (90%)]	Loss: 0.146800
Train Epoch: 20 [32640/35339 (92%)]	Loss: 0.129442
Train Epoch: 20 [33280/35339 (94%)]	Loss: 0.124543
Train Epoch: 20 [33920/35339 (96%)]	Loss: 0.131581
Train Epoch: 20 [34560/35339 (98%)]	Loss: 0.204041
Train Epoch: 20 [35200/35339 (99%)]	Loss: 0.191913

Validation set: Average loss: 3.1508, Accuracy: 1507/3870 (39%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 21 [0/35339 (0%)]	Loss: 0.193758
Train Epoch: 21 [640/35339 (2%)]	Loss: 0.234158
Train Epoch: 21 [1280/35339 (4%)]	Loss: 0.155223
Train Epoch: 21 [1920/35339 (5%)]	Loss: 0.092575
Train Epoch: 21 [2560/35339 (7%)]	Loss: 0.124356
Train Epoch: 21 [3200/35339 (9%)]	Loss: 0.549461
Train Epoch: 21 [3840/35339 (11%)]	Loss: 0.181465
Train Epoch: 21 [4480/35339 (13%)]	Loss: 0.148009
Train Epoch: 21 [5120/35339 (14%)]	Loss: 0.168222
Train Epoch: 21 [5760/35339 (16%)]	Loss: 0.124015
Train Epoch: 21 [6400/35339 (18%)]	Loss: 0.136951
Train Epoch: 21 [7040/35339 (20%)]	Loss: 0.110208
Train Epoch: 21 [7680/35339 (22%)]	Loss: 0.432201
Train Epoch: 21 [8320/35339 (24%)]	Loss: 0.215835
Train Epoch: 21 [8960/35339 (25%)]	Loss: 0.107306
Train Epoch: 21 [9600/35339 (27%)]	Loss: 0.138607
Train Epoch: 21 [10240/35339 (29%)]	Loss: 0.218908
Train Epoch: 21 [10880/35339 (31%)]	Loss: 0.132522
Train Epoch: 21 [11520/35339 (33%)]	Loss: 0.266036
Train Epoch: 21 [12160/35339 (34%)]	Loss: 0.174851
Train Epoch: 21 [12800/35339 (36%)]	Loss: 0.136766
Train Epoch: 21 [13440/35339 (38%)]	Loss: 0.131524
Train Epoch: 21 [14080/35339 (40%)]	Loss: 0.167436
Train Epoch: 21 [14720/35339 (42%)]	Loss: 0.210448
Train Epoch: 21 [15360/35339 (43%)]	Loss: 0.214077
Train Epoch: 21 [16000/35339 (45%)]	Loss: 0.285143
Train Epoch: 21 [16640/35339 (47%)]	Loss: 0.123482
Train Epoch: 21 [17280/35339 (49%)]	Loss: 0.167316
Train Epoch: 21 [17920/35339 (51%)]	Loss: 0.147686
Train Epoch: 21 [18560/35339 (52%)]	Loss: 0.099833
Train Epoch: 21 [19200/35339 (54%)]	Loss: 0.183782
Train Epoch: 21 [19840/35339 (56%)]	Loss: 0.203135
Train Epoch: 21 [20480/35339 (58%)]	Loss: 0.093039
Train Epoch: 21 [21120/35339 (60%)]	Loss: 0.196787
Train Epoch: 21 [21760/35339 (61%)]	Loss: 0.108815
Train Epoch: 21 [22400/35339 (63%)]	Loss: 0.144812
Train Epoch: 21 [23040/35339 (65%)]	Loss: 0.121297
Train Epoch: 21 [23680/35339 (67%)]	Loss: 0.197007
Train Epoch: 21 [24320/35339 (69%)]	Loss: 0.171908
Train Epoch: 21 [24960/35339 (71%)]	Loss: 0.371921
Train Epoch: 21 [25600/35339 (72%)]	Loss: 0.143127
Train Epoch: 21 [26240/35339 (74%)]	Loss: 0.155150
Train Epoch: 21 [26880/35339 (76%)]	Loss: 0.125197
Train Epoch: 21 [27520/35339 (78%)]	Loss: 0.177182
Train Epoch: 21 [28160/35339 (80%)]	Loss: 0.164631
Train Epoch: 21 [28800/35339 (81%)]	Loss: 0.104955
Train Epoch: 21 [29440/35339 (83%)]	Loss: 0.096159
Train Epoch: 21 [30080/35339 (85%)]	Loss: 0.136231
Train Epoch: 21 [30720/35339 (87%)]	Loss: 0.386856
Train Epoch: 21 [31360/35339 (89%)]	Loss: 0.237241
Train Epoch: 21 [32000/35339 (90%)]	Loss: 0.118877
Train Epoch: 21 [32640/35339 (92%)]	Loss: 0.155372
Train Epoch: 21 [33280/35339 (94%)]	Loss: 0.093787
Train Epoch: 21 [33920/35339 (96%)]	Loss: 0.224988
Train Epoch: 21 [34560/35339 (98%)]	Loss: 0.295397
Train Epoch: 21 [35200/35339 (99%)]	Loss: 0.132730

Validation set: Average loss: 3.0843, Accuracy: 1527/3870 (39%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 22 [0/35339 (0%)]	Loss: 0.239852
Train Epoch: 22 [640/35339 (2%)]	Loss: 0.265318
Train Epoch: 22 [1280/35339 (4%)]	Loss: 0.098537
Train Epoch: 22 [1920/35339 (5%)]	Loss: 0.200873
Train Epoch: 22 [2560/35339 (7%)]	Loss: 0.104426
Train Epoch: 22 [3200/35339 (9%)]	Loss: 0.114154
Train Epoch: 22 [3840/35339 (11%)]	Loss: 0.218877
Train Epoch: 22 [4480/35339 (13%)]	Loss: 0.096747
Train Epoch: 22 [5120/35339 (14%)]	Loss: 0.157122
Train Epoch: 22 [5760/35339 (16%)]	Loss: 0.106238
Train Epoch: 22 [6400/35339 (18%)]	Loss: 0.136204
Train Epoch: 22 [7040/35339 (20%)]	Loss: 0.142083
Train Epoch: 22 [7680/35339 (22%)]	Loss: 0.301131
Train Epoch: 22 [8320/35339 (24%)]	Loss: 0.087589
Train Epoch: 22 [8960/35339 (25%)]	Loss: 0.125851
Train Epoch: 22 [9600/35339 (27%)]	Loss: 0.192631
Train Epoch: 22 [10240/35339 (29%)]	Loss: 0.170101
Train Epoch: 22 [10880/35339 (31%)]	Loss: 0.099930
Train Epoch: 22 [11520/35339 (33%)]	Loss: 0.177912
Train Epoch: 22 [12160/35339 (34%)]	Loss: 0.207330
Train Epoch: 22 [12800/35339 (36%)]	Loss: 0.128347
Train Epoch: 22 [13440/35339 (38%)]	Loss: 0.177140
Train Epoch: 22 [14080/35339 (40%)]	Loss: 0.205460
Train Epoch: 22 [14720/35339 (42%)]	Loss: 0.124465
Train Epoch: 22 [15360/35339 (43%)]	Loss: 0.186828
Train Epoch: 22 [16000/35339 (45%)]	Loss: 0.147588
Train Epoch: 22 [16640/35339 (47%)]	Loss: 0.183374
Train Epoch: 22 [17280/35339 (49%)]	Loss: 0.156399
Train Epoch: 22 [17920/35339 (51%)]	Loss: 0.252832
Train Epoch: 22 [18560/35339 (52%)]	Loss: 0.172717
Train Epoch: 22 [19200/35339 (54%)]	Loss: 0.137513
Train Epoch: 22 [19840/35339 (56%)]	Loss: 0.163193
Train Epoch: 22 [20480/35339 (58%)]	Loss: 0.127354
Train Epoch: 22 [21120/35339 (60%)]	Loss: 0.262646
Train Epoch: 22 [21760/35339 (61%)]	Loss: 0.199119
Train Epoch: 22 [22400/35339 (63%)]	Loss: 0.132558
Train Epoch: 22 [23040/35339 (65%)]	Loss: 0.277864
Train Epoch: 22 [23680/35339 (67%)]	Loss: 0.138099
Train Epoch: 22 [24320/35339 (69%)]	Loss: 0.191138
Train Epoch: 22 [24960/35339 (71%)]	Loss: 0.146119
Train Epoch: 22 [25600/35339 (72%)]	Loss: 0.074470
Train Epoch: 22 [26240/35339 (74%)]	Loss: 0.127086
Train Epoch: 22 [26880/35339 (76%)]	Loss: 0.246256
Train Epoch: 22 [27520/35339 (78%)]	Loss: 0.191113
Train Epoch: 22 [28160/35339 (80%)]	Loss: 0.147444
Train Epoch: 22 [28800/35339 (81%)]	Loss: 0.097944
Train Epoch: 22 [29440/35339 (83%)]	Loss: 0.146299
Train Epoch: 22 [30080/35339 (85%)]	Loss: 0.269273
Train Epoch: 22 [30720/35339 (87%)]	Loss: 0.178173
Train Epoch: 22 [31360/35339 (89%)]	Loss: 0.244803
Train Epoch: 22 [32000/35339 (90%)]	Loss: 0.186105
Train Epoch: 22 [32640/35339 (92%)]	Loss: 0.196279
Train Epoch: 22 [33280/35339 (94%)]	Loss: 0.186381
Train Epoch: 22 [33920/35339 (96%)]	Loss: 0.200719
Train Epoch: 22 [34560/35339 (98%)]	Loss: 0.192780
Train Epoch: 22 [35200/35339 (99%)]	Loss: 0.242209

Validation set: Average loss: 3.1233, Accuracy: 1496/3870 (39%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 23 [0/35339 (0%)]	Loss: 0.120178
Train Epoch: 23 [640/35339 (2%)]	Loss: 0.223823
Train Epoch: 23 [1280/35339 (4%)]	Loss: 0.189070
Train Epoch: 23 [1920/35339 (5%)]	Loss: 0.086400
Train Epoch: 23 [2560/35339 (7%)]	Loss: 0.186421
Train Epoch: 23 [3200/35339 (9%)]	Loss: 0.136023
Train Epoch: 23 [3840/35339 (11%)]	Loss: 0.148788
Train Epoch: 23 [4480/35339 (13%)]	Loss: 0.164833
Train Epoch: 23 [5120/35339 (14%)]	Loss: 0.200965
Train Epoch: 23 [5760/35339 (16%)]	Loss: 0.195194
Train Epoch: 23 [6400/35339 (18%)]	Loss: 0.207774
Train Epoch: 23 [7040/35339 (20%)]	Loss: 0.216998
Train Epoch: 23 [7680/35339 (22%)]	Loss: 0.189608
Train Epoch: 23 [8320/35339 (24%)]	Loss: 0.226466
Train Epoch: 23 [8960/35339 (25%)]	Loss: 0.115343
Train Epoch: 23 [9600/35339 (27%)]	Loss: 0.159508
Train Epoch: 23 [10240/35339 (29%)]	Loss: 0.139158
Train Epoch: 23 [10880/35339 (31%)]	Loss: 0.175523
Train Epoch: 23 [11520/35339 (33%)]	Loss: 0.151548
Train Epoch: 23 [12160/35339 (34%)]	Loss: 0.116260
Train Epoch: 23 [12800/35339 (36%)]	Loss: 0.149466
Train Epoch: 23 [13440/35339 (38%)]	Loss: 0.129741
Train Epoch: 23 [14080/35339 (40%)]	Loss: 0.312431
Train Epoch: 23 [14720/35339 (42%)]	Loss: 0.261602
Train Epoch: 23 [15360/35339 (43%)]	Loss: 0.078281
Train Epoch: 23 [16000/35339 (45%)]	Loss: 0.223126
Train Epoch: 23 [16640/35339 (47%)]	Loss: 0.157726
Train Epoch: 23 [17280/35339 (49%)]	Loss: 0.082103
Train Epoch: 23 [17920/35339 (51%)]	Loss: 0.146186
Train Epoch: 23 [18560/35339 (52%)]	Loss: 0.131874
Train Epoch: 23 [19200/35339 (54%)]	Loss: 0.261096
Train Epoch: 23 [19840/35339 (56%)]	Loss: 0.133306
Train Epoch: 23 [20480/35339 (58%)]	Loss: 0.135742
Train Epoch: 23 [21120/35339 (60%)]	Loss: 0.158444
Train Epoch: 23 [21760/35339 (61%)]	Loss: 0.096940
Train Epoch: 23 [22400/35339 (63%)]	Loss: 0.144708
Train Epoch: 23 [23040/35339 (65%)]	Loss: 0.091468
Train Epoch: 23 [23680/35339 (67%)]	Loss: 0.130789
Train Epoch: 23 [24320/35339 (69%)]	Loss: 0.229908
Train Epoch: 23 [24960/35339 (71%)]	Loss: 0.126708
Train Epoch: 23 [25600/35339 (72%)]	Loss: 0.125345
Train Epoch: 23 [26240/35339 (74%)]	Loss: 0.276636
Train Epoch: 23 [26880/35339 (76%)]	Loss: 0.134087
Train Epoch: 23 [27520/35339 (78%)]	Loss: 0.157934
Train Epoch: 23 [28160/35339 (80%)]	Loss: 0.188904
Train Epoch: 23 [28800/35339 (81%)]	Loss: 0.217020
Train Epoch: 23 [29440/35339 (83%)]	Loss: 0.207432
Train Epoch: 23 [30080/35339 (85%)]	Loss: 0.144172
Train Epoch: 23 [30720/35339 (87%)]	Loss: 0.152206
Train Epoch: 23 [31360/35339 (89%)]	Loss: 0.166861
Train Epoch: 23 [32000/35339 (90%)]	Loss: 0.339545
Train Epoch: 23 [32640/35339 (92%)]	Loss: 0.138234
Train Epoch: 23 [33280/35339 (94%)]	Loss: 0.139594
Train Epoch: 23 [33920/35339 (96%)]	Loss: 0.210254
Train Epoch: 23 [34560/35339 (98%)]	Loss: 0.123991
Train Epoch: 23 [35200/35339 (99%)]	Loss: 0.321976

Validation set: Average loss: 3.0977, Accuracy: 1533/3870 (40%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 24 [0/35339 (0%)]	Loss: 0.127720
Train Epoch: 24 [640/35339 (2%)]	Loss: 0.119940
Train Epoch: 24 [1280/35339 (4%)]	Loss: 0.320893
Train Epoch: 24 [1920/35339 (5%)]	Loss: 0.114609
Train Epoch: 24 [2560/35339 (7%)]	Loss: 0.070773
Train Epoch: 24 [3200/35339 (9%)]	Loss: 0.201246
Train Epoch: 24 [3840/35339 (11%)]	Loss: 0.253432
Train Epoch: 24 [4480/35339 (13%)]	Loss: 0.123213
Train Epoch: 24 [5120/35339 (14%)]	Loss: 0.135109
Train Epoch: 24 [5760/35339 (16%)]	Loss: 0.166555
Train Epoch: 24 [6400/35339 (18%)]	Loss: 0.260035
Train Epoch: 24 [7040/35339 (20%)]	Loss: 0.242528
Train Epoch: 24 [7680/35339 (22%)]	Loss: 0.245883
Train Epoch: 24 [8320/35339 (24%)]	Loss: 0.102158
Train Epoch: 24 [8960/35339 (25%)]	Loss: 0.175025
Train Epoch: 24 [9600/35339 (27%)]	Loss: 0.109064
Train Epoch: 24 [10240/35339 (29%)]	Loss: 0.062632
Train Epoch: 24 [10880/35339 (31%)]	Loss: 0.099557
Train Epoch: 24 [11520/35339 (33%)]	Loss: 0.090450
Train Epoch: 24 [12160/35339 (34%)]	Loss: 0.176259
Train Epoch: 24 [12800/35339 (36%)]	Loss: 0.114904
Train Epoch: 24 [13440/35339 (38%)]	Loss: 0.188256
Train Epoch: 24 [14080/35339 (40%)]	Loss: 0.150836
Train Epoch: 24 [14720/35339 (42%)]	Loss: 0.202633
Train Epoch: 24 [15360/35339 (43%)]	Loss: 0.238730
Train Epoch: 24 [16000/35339 (45%)]	Loss: 0.181341
Train Epoch: 24 [16640/35339 (47%)]	Loss: 0.191252
Train Epoch: 24 [17280/35339 (49%)]	Loss: 0.128557
Train Epoch: 24 [17920/35339 (51%)]	Loss: 0.099717
Train Epoch: 24 [18560/35339 (52%)]	Loss: 0.154624
Train Epoch: 24 [19200/35339 (54%)]	Loss: 0.171062
Train Epoch: 24 [19840/35339 (56%)]	Loss: 0.146373
Train Epoch: 24 [20480/35339 (58%)]	Loss: 0.376352
Train Epoch: 24 [21120/35339 (60%)]	Loss: 0.107982
Train Epoch: 24 [21760/35339 (61%)]	Loss: 0.126285
Train Epoch: 24 [22400/35339 (63%)]	Loss: 0.091006
Train Epoch: 24 [23040/35339 (65%)]	Loss: 0.218140
Train Epoch: 24 [23680/35339 (67%)]	Loss: 0.171191
Train Epoch: 24 [24320/35339 (69%)]	Loss: 0.137631
Train Epoch: 24 [24960/35339 (71%)]	Loss: 0.137500
Train Epoch: 24 [25600/35339 (72%)]	Loss: 0.114159
Train Epoch: 24 [26240/35339 (74%)]	Loss: 0.114223
Train Epoch: 24 [26880/35339 (76%)]	Loss: 0.142261
Train Epoch: 24 [27520/35339 (78%)]	Loss: 0.145746
Train Epoch: 24 [28160/35339 (80%)]	Loss: 0.122232
Train Epoch: 24 [28800/35339 (81%)]	Loss: 0.157383
Train Epoch: 24 [29440/35339 (83%)]	Loss: 0.227138
Train Epoch: 24 [30080/35339 (85%)]	Loss: 0.247615
Train Epoch: 24 [30720/35339 (87%)]	Loss: 0.150542
Train Epoch: 24 [31360/35339 (89%)]	Loss: 0.123409
Train Epoch: 24 [32000/35339 (90%)]	Loss: 0.121251
Train Epoch: 24 [32640/35339 (92%)]	Loss: 0.238654
Train Epoch: 24 [33280/35339 (94%)]	Loss: 0.130609
Train Epoch: 24 [33920/35339 (96%)]	Loss: 0.163180
Train Epoch: 24 [34560/35339 (98%)]	Loss: 0.130368
Train Epoch: 24 [35200/35339 (99%)]	Loss: 0.252790

Validation set: Average loss: 3.1017, Accuracy: 1549/3870 (40%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 25 [0/35339 (0%)]	Loss: 0.093244
Train Epoch: 25 [640/35339 (2%)]	Loss: 0.172727
Train Epoch: 25 [1280/35339 (4%)]	Loss: 0.196245
Train Epoch: 25 [1920/35339 (5%)]	Loss: 0.120197
Train Epoch: 25 [2560/35339 (7%)]	Loss: 0.077269
Train Epoch: 25 [3200/35339 (9%)]	Loss: 0.139495
Train Epoch: 25 [3840/35339 (11%)]	Loss: 0.290098
Train Epoch: 25 [4480/35339 (13%)]	Loss: 0.207386
Train Epoch: 25 [5120/35339 (14%)]	Loss: 0.159086
Train Epoch: 25 [5760/35339 (16%)]	Loss: 0.221477
Train Epoch: 25 [6400/35339 (18%)]	Loss: 0.156977
Train Epoch: 25 [7040/35339 (20%)]	Loss: 0.121928
Train Epoch: 25 [7680/35339 (22%)]	Loss: 0.185396
Train Epoch: 25 [8320/35339 (24%)]	Loss: 0.190071
Train Epoch: 25 [8960/35339 (25%)]	Loss: 0.389025
Train Epoch: 25 [9600/35339 (27%)]	Loss: 0.140630
Train Epoch: 25 [10240/35339 (29%)]	Loss: 0.133206
Train Epoch: 25 [10880/35339 (31%)]	Loss: 0.307628
Train Epoch: 25 [11520/35339 (33%)]	Loss: 0.096871
Train Epoch: 25 [12160/35339 (34%)]	Loss: 0.180290
Train Epoch: 25 [12800/35339 (36%)]	Loss: 0.216670
Train Epoch: 25 [13440/35339 (38%)]	Loss: 0.158850
Train Epoch: 25 [14080/35339 (40%)]	Loss: 0.119936
Train Epoch: 25 [14720/35339 (42%)]	Loss: 0.076315
Train Epoch: 25 [15360/35339 (43%)]	Loss: 0.175025
Train Epoch: 25 [16000/35339 (45%)]	Loss: 0.372445
Train Epoch: 25 [16640/35339 (47%)]	Loss: 0.065448
Train Epoch: 25 [17280/35339 (49%)]	Loss: 0.101246
Train Epoch: 25 [17920/35339 (51%)]	Loss: 0.211735
Train Epoch: 25 [18560/35339 (52%)]	Loss: 0.269539
Train Epoch: 25 [19200/35339 (54%)]	Loss: 0.074730
Train Epoch: 25 [19840/35339 (56%)]	Loss: 0.204851
Train Epoch: 25 [20480/35339 (58%)]	Loss: 0.227924
Train Epoch: 25 [21120/35339 (60%)]	Loss: 0.092676
Train Epoch: 25 [21760/35339 (61%)]	Loss: 0.162862
Train Epoch: 25 [22400/35339 (63%)]	Loss: 0.195872
Train Epoch: 25 [23040/35339 (65%)]	Loss: 0.205640
Train Epoch: 25 [23680/35339 (67%)]	Loss: 0.248235
Train Epoch: 25 [24320/35339 (69%)]	Loss: 0.174686
Train Epoch: 25 [24960/35339 (71%)]	Loss: 0.179263
Train Epoch: 25 [25600/35339 (72%)]	Loss: 0.209830
Train Epoch: 25 [26240/35339 (74%)]	Loss: 0.121461
Train Epoch: 25 [26880/35339 (76%)]	Loss: 0.158629
Train Epoch: 25 [27520/35339 (78%)]	Loss: 0.116688
Train Epoch: 25 [28160/35339 (80%)]	Loss: 0.097677
Train Epoch: 25 [28800/35339 (81%)]	Loss: 0.121632
Train Epoch: 25 [29440/35339 (83%)]	Loss: 0.085296
Train Epoch: 25 [30080/35339 (85%)]	Loss: 0.127012
Train Epoch: 25 [30720/35339 (87%)]	Loss: 0.230089
Train Epoch: 25 [31360/35339 (89%)]	Loss: 0.147311
Train Epoch: 25 [32000/35339 (90%)]	Loss: 0.087927
Train Epoch: 25 [32640/35339 (92%)]	Loss: 0.174249
Train Epoch: 25 [33280/35339 (94%)]	Loss: 0.183271
Train Epoch: 25 [33920/35339 (96%)]	Loss: 0.157266
Train Epoch: 25 [34560/35339 (98%)]	Loss: 0.136665
Train Epoch: 25 [35200/35339 (99%)]	Loss: 0.106715

Validation set: Average loss: 3.0719, Accuracy: 1578/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 26 [0/35339 (0%)]	Loss: 0.274142
Train Epoch: 26 [640/35339 (2%)]	Loss: 0.189169
Train Epoch: 26 [1280/35339 (4%)]	Loss: 0.653360
Train Epoch: 26 [1920/35339 (5%)]	Loss: 0.322592
Train Epoch: 26 [2560/35339 (7%)]	Loss: 0.128385
Train Epoch: 26 [3200/35339 (9%)]	Loss: 0.178380
Train Epoch: 26 [3840/35339 (11%)]	Loss: 0.138891
Train Epoch: 26 [4480/35339 (13%)]	Loss: 0.072875
Train Epoch: 26 [5120/35339 (14%)]	Loss: 0.114479
Train Epoch: 26 [5760/35339 (16%)]	Loss: 0.215965
Train Epoch: 26 [6400/35339 (18%)]	Loss: 0.136254
Train Epoch: 26 [7040/35339 (20%)]	Loss: 0.146763
Train Epoch: 26 [7680/35339 (22%)]	Loss: 0.165755
Train Epoch: 26 [8320/35339 (24%)]	Loss: 0.391796
Train Epoch: 26 [8960/35339 (25%)]	Loss: 0.188996
Train Epoch: 26 [9600/35339 (27%)]	Loss: 0.149375
Train Epoch: 26 [10240/35339 (29%)]	Loss: 0.136784
Train Epoch: 26 [10880/35339 (31%)]	Loss: 0.097858
Train Epoch: 26 [11520/35339 (33%)]	Loss: 0.233179
Train Epoch: 26 [12160/35339 (34%)]	Loss: 0.154569
Train Epoch: 26 [12800/35339 (36%)]	Loss: 0.115841
Train Epoch: 26 [13440/35339 (38%)]	Loss: 0.158026
Train Epoch: 26 [14080/35339 (40%)]	Loss: 0.121104
Train Epoch: 26 [14720/35339 (42%)]	Loss: 0.179120
Train Epoch: 26 [15360/35339 (43%)]	Loss: 0.094386
Train Epoch: 26 [16000/35339 (45%)]	Loss: 0.184831
Train Epoch: 26 [16640/35339 (47%)]	Loss: 0.180009
Train Epoch: 26 [17280/35339 (49%)]	Loss: 0.096418
Train Epoch: 26 [17920/35339 (51%)]	Loss: 0.115387
Train Epoch: 26 [18560/35339 (52%)]	Loss: 0.088065
Train Epoch: 26 [19200/35339 (54%)]	Loss: 0.164723
Train Epoch: 26 [19840/35339 (56%)]	Loss: 0.194914
Train Epoch: 26 [20480/35339 (58%)]	Loss: 0.192589
Train Epoch: 26 [21120/35339 (60%)]	Loss: 0.153636
Train Epoch: 26 [21760/35339 (61%)]	Loss: 0.082508
Train Epoch: 26 [22400/35339 (63%)]	Loss: 0.128415
Train Epoch: 26 [23040/35339 (65%)]	Loss: 0.139918
Train Epoch: 26 [23680/35339 (67%)]	Loss: 0.084950
Train Epoch: 26 [24320/35339 (69%)]	Loss: 0.153107
Train Epoch: 26 [24960/35339 (71%)]	Loss: 0.089866
Train Epoch: 26 [25600/35339 (72%)]	Loss: 0.180189
Train Epoch: 26 [26240/35339 (74%)]	Loss: 0.218171
Train Epoch: 26 [26880/35339 (76%)]	Loss: 0.185738
Train Epoch: 26 [27520/35339 (78%)]	Loss: 0.137637
Train Epoch: 26 [28160/35339 (80%)]	Loss: 0.106708
Train Epoch: 26 [28800/35339 (81%)]	Loss: 0.174114
Train Epoch: 26 [29440/35339 (83%)]	Loss: 0.160388
Train Epoch: 26 [30080/35339 (85%)]	Loss: 0.117382
Train Epoch: 26 [30720/35339 (87%)]	Loss: 0.196240
Train Epoch: 26 [31360/35339 (89%)]	Loss: 0.210913
Train Epoch: 26 [32000/35339 (90%)]	Loss: 0.170169
Train Epoch: 26 [32640/35339 (92%)]	Loss: 0.149834
Train Epoch: 26 [33280/35339 (94%)]	Loss: 0.167352
Train Epoch: 26 [33920/35339 (96%)]	Loss: 0.153114
Train Epoch: 26 [34560/35339 (98%)]	Loss: 0.259790
Train Epoch: 26 [35200/35339 (99%)]	Loss: 0.211539

Validation set: Average loss: 3.0415, Accuracy: 1590/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 27 [0/35339 (0%)]	Loss: 0.305958
Train Epoch: 27 [640/35339 (2%)]	Loss: 0.223126
Train Epoch: 27 [1280/35339 (4%)]	Loss: 0.142816
Train Epoch: 27 [1920/35339 (5%)]	Loss: 0.159244
Train Epoch: 27 [2560/35339 (7%)]	Loss: 0.118663
Train Epoch: 27 [3200/35339 (9%)]	Loss: 0.149207
Train Epoch: 27 [3840/35339 (11%)]	Loss: 0.074784
Train Epoch: 27 [4480/35339 (13%)]	Loss: 0.121373
Train Epoch: 27 [5120/35339 (14%)]	Loss: 0.133015
Train Epoch: 27 [5760/35339 (16%)]	Loss: 0.101839
Train Epoch: 27 [6400/35339 (18%)]	Loss: 0.103217
Train Epoch: 27 [7040/35339 (20%)]	Loss: 0.296831
Train Epoch: 27 [7680/35339 (22%)]	Loss: 0.104950
Train Epoch: 27 [8320/35339 (24%)]	Loss: 0.156370
Train Epoch: 27 [8960/35339 (25%)]	Loss: 0.203192
Train Epoch: 27 [9600/35339 (27%)]	Loss: 0.187513
Train Epoch: 27 [10240/35339 (29%)]	Loss: 0.169498
Train Epoch: 27 [10880/35339 (31%)]	Loss: 0.140744
Train Epoch: 27 [11520/35339 (33%)]	Loss: 0.165688
Train Epoch: 27 [12160/35339 (34%)]	Loss: 0.180815
Train Epoch: 27 [12800/35339 (36%)]	Loss: 0.157147
Train Epoch: 27 [13440/35339 (38%)]	Loss: 0.148762
Train Epoch: 27 [14080/35339 (40%)]	Loss: 0.135323
Train Epoch: 27 [14720/35339 (42%)]	Loss: 0.151088
Train Epoch: 27 [15360/35339 (43%)]	Loss: 0.210811
Train Epoch: 27 [16000/35339 (45%)]	Loss: 0.130030
Train Epoch: 27 [16640/35339 (47%)]	Loss: 0.111582
Train Epoch: 27 [17280/35339 (49%)]	Loss: 0.151243
Train Epoch: 27 [17920/35339 (51%)]	Loss: 0.185691
Train Epoch: 27 [18560/35339 (52%)]	Loss: 0.141740
Train Epoch: 27 [19200/35339 (54%)]	Loss: 0.123084
Train Epoch: 27 [19840/35339 (56%)]	Loss: 0.138824
Train Epoch: 27 [20480/35339 (58%)]	Loss: 0.082447
Train Epoch: 27 [21120/35339 (60%)]	Loss: 0.161217
Train Epoch: 27 [21760/35339 (61%)]	Loss: 0.155760
Train Epoch: 27 [22400/35339 (63%)]	Loss: 0.223822
Train Epoch: 27 [23040/35339 (65%)]	Loss: 0.105106
Train Epoch: 27 [23680/35339 (67%)]	Loss: 0.202990
Train Epoch: 27 [24320/35339 (69%)]	Loss: 0.161863
Train Epoch: 27 [24960/35339 (71%)]	Loss: 0.189645
Train Epoch: 27 [25600/35339 (72%)]	Loss: 0.182468
Train Epoch: 27 [26240/35339 (74%)]	Loss: 0.225857
Train Epoch: 27 [26880/35339 (76%)]	Loss: 0.164491
Train Epoch: 27 [27520/35339 (78%)]	Loss: 0.136554
Train Epoch: 27 [28160/35339 (80%)]	Loss: 0.088558
Train Epoch: 27 [28800/35339 (81%)]	Loss: 0.202904
Train Epoch: 27 [29440/35339 (83%)]	Loss: 0.120085
Train Epoch: 27 [30080/35339 (85%)]	Loss: 0.208202
Train Epoch: 27 [30720/35339 (87%)]	Loss: 0.298801
Train Epoch: 27 [31360/35339 (89%)]	Loss: 0.107454
Train Epoch: 27 [32000/35339 (90%)]	Loss: 0.261596
Train Epoch: 27 [32640/35339 (92%)]	Loss: 0.151067
Train Epoch: 27 [33280/35339 (94%)]	Loss: 0.173203
Train Epoch: 27 [33920/35339 (96%)]	Loss: 0.175056
Train Epoch: 27 [34560/35339 (98%)]	Loss: 0.138260
Train Epoch: 27 [35200/35339 (99%)]	Loss: 0.119212

Validation set: Average loss: 3.0120, Accuracy: 1606/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 28 [0/35339 (0%)]	Loss: 0.157929
Train Epoch: 28 [640/35339 (2%)]	Loss: 0.399690
Train Epoch: 28 [1280/35339 (4%)]	Loss: 0.140945
Train Epoch: 28 [1920/35339 (5%)]	Loss: 0.263665
Train Epoch: 28 [2560/35339 (7%)]	Loss: 0.147613
Train Epoch: 28 [3200/35339 (9%)]	Loss: 0.121467
Train Epoch: 28 [3840/35339 (11%)]	Loss: 0.659285
Train Epoch: 28 [4480/35339 (13%)]	Loss: 0.135434
Train Epoch: 28 [5120/35339 (14%)]	Loss: 0.280700
Train Epoch: 28 [5760/35339 (16%)]	Loss: 0.136248
Train Epoch: 28 [6400/35339 (18%)]	Loss: 0.175262
Train Epoch: 28 [7040/35339 (20%)]	Loss: 0.212153
Train Epoch: 28 [7680/35339 (22%)]	Loss: 0.110857
Train Epoch: 28 [8320/35339 (24%)]	Loss: 0.172942
Train Epoch: 28 [8960/35339 (25%)]	Loss: 0.160396
Train Epoch: 28 [9600/35339 (27%)]	Loss: 0.178485
Train Epoch: 28 [10240/35339 (29%)]	Loss: 0.336991
Train Epoch: 28 [10880/35339 (31%)]	Loss: 0.168401
Train Epoch: 28 [11520/35339 (33%)]	Loss: 0.083555
Train Epoch: 28 [12160/35339 (34%)]	Loss: 0.077669
Train Epoch: 28 [12800/35339 (36%)]	Loss: 0.230217
Train Epoch: 28 [13440/35339 (38%)]	Loss: 0.171937
Train Epoch: 28 [14080/35339 (40%)]	Loss: 0.316993
Train Epoch: 28 [14720/35339 (42%)]	Loss: 0.279501
Train Epoch: 28 [15360/35339 (43%)]	Loss: 0.089563
Train Epoch: 28 [16000/35339 (45%)]	Loss: 0.154917
Train Epoch: 28 [16640/35339 (47%)]	Loss: 0.240919
Train Epoch: 28 [17280/35339 (49%)]	Loss: 0.149038
Train Epoch: 28 [17920/35339 (51%)]	Loss: 0.113273
Train Epoch: 28 [18560/35339 (52%)]	Loss: 0.130635
Train Epoch: 28 [19200/35339 (54%)]	Loss: 0.097053
Train Epoch: 28 [19840/35339 (56%)]	Loss: 0.157885
Train Epoch: 28 [20480/35339 (58%)]	Loss: 0.237981
Train Epoch: 28 [21120/35339 (60%)]	Loss: 0.174421
Train Epoch: 28 [21760/35339 (61%)]	Loss: 0.097342
Train Epoch: 28 [22400/35339 (63%)]	Loss: 0.239213
Train Epoch: 28 [23040/35339 (65%)]	Loss: 0.151788
Train Epoch: 28 [23680/35339 (67%)]	Loss: 0.154497
Train Epoch: 28 [24320/35339 (69%)]	Loss: 0.168714
Train Epoch: 28 [24960/35339 (71%)]	Loss: 0.218960
Train Epoch: 28 [25600/35339 (72%)]	Loss: 0.122131
Train Epoch: 28 [26240/35339 (74%)]	Loss: 0.130082
Train Epoch: 28 [26880/35339 (76%)]	Loss: 0.108415
Train Epoch: 28 [27520/35339 (78%)]	Loss: 0.197204
Train Epoch: 28 [28160/35339 (80%)]	Loss: 0.096730
Train Epoch: 28 [28800/35339 (81%)]	Loss: 0.255681
Train Epoch: 28 [29440/35339 (83%)]	Loss: 0.257510
Train Epoch: 28 [30080/35339 (85%)]	Loss: 0.213836
Train Epoch: 28 [30720/35339 (87%)]	Loss: 0.188716
Train Epoch: 28 [31360/35339 (89%)]	Loss: 0.117115
Train Epoch: 28 [32000/35339 (90%)]	Loss: 0.155393
Train Epoch: 28 [32640/35339 (92%)]	Loss: 0.404297
Train Epoch: 28 [33280/35339 (94%)]	Loss: 0.129757
Train Epoch: 28 [33920/35339 (96%)]	Loss: 0.098285
Train Epoch: 28 [34560/35339 (98%)]	Loss: 0.156583
Train Epoch: 28 [35200/35339 (99%)]	Loss: 0.111987

Validation set: Average loss: 3.1387, Accuracy: 1540/3870 (40%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 29 [0/35339 (0%)]	Loss: 0.181139
Train Epoch: 29 [640/35339 (2%)]	Loss: 0.168460
Train Epoch: 29 [1280/35339 (4%)]	Loss: 0.138634
Train Epoch: 29 [1920/35339 (5%)]	Loss: 0.094723
Train Epoch: 29 [2560/35339 (7%)]	Loss: 0.102181
Train Epoch: 29 [3200/35339 (9%)]	Loss: 0.180521
Train Epoch: 29 [3840/35339 (11%)]	Loss: 0.158346
Train Epoch: 29 [4480/35339 (13%)]	Loss: 0.217923
Train Epoch: 29 [5120/35339 (14%)]	Loss: 0.148574
Train Epoch: 29 [5760/35339 (16%)]	Loss: 0.098725
Train Epoch: 29 [6400/35339 (18%)]	Loss: 0.115952
Train Epoch: 29 [7040/35339 (20%)]	Loss: 0.253626
Train Epoch: 29 [7680/35339 (22%)]	Loss: 0.191125
Train Epoch: 29 [8320/35339 (24%)]	Loss: 0.102988
Train Epoch: 29 [8960/35339 (25%)]	Loss: 0.232486
Train Epoch: 29 [9600/35339 (27%)]	Loss: 0.093125
Train Epoch: 29 [10240/35339 (29%)]	Loss: 0.154040
Train Epoch: 29 [10880/35339 (31%)]	Loss: 0.195859
Train Epoch: 29 [11520/35339 (33%)]	Loss: 0.145986
Train Epoch: 29 [12160/35339 (34%)]	Loss: 0.180018
Train Epoch: 29 [12800/35339 (36%)]	Loss: 0.105241
Train Epoch: 29 [13440/35339 (38%)]	Loss: 0.097311
Train Epoch: 29 [14080/35339 (40%)]	Loss: 0.164438
Train Epoch: 29 [14720/35339 (42%)]	Loss: 0.125073
Train Epoch: 29 [15360/35339 (43%)]	Loss: 0.145695
Train Epoch: 29 [16000/35339 (45%)]	Loss: 0.093230
Train Epoch: 29 [16640/35339 (47%)]	Loss: 0.236974
Train Epoch: 29 [17280/35339 (49%)]	Loss: 0.162852
Train Epoch: 29 [17920/35339 (51%)]	Loss: 0.107099
Train Epoch: 29 [18560/35339 (52%)]	Loss: 0.150857
Train Epoch: 29 [19200/35339 (54%)]	Loss: 0.234893
Train Epoch: 29 [19840/35339 (56%)]	Loss: 0.116045
Train Epoch: 29 [20480/35339 (58%)]	Loss: 0.097474
Train Epoch: 29 [21120/35339 (60%)]	Loss: 0.243323
Train Epoch: 29 [21760/35339 (61%)]	Loss: 0.225952
Train Epoch: 29 [22400/35339 (63%)]	Loss: 0.242920
Train Epoch: 29 [23040/35339 (65%)]	Loss: 0.145076
Train Epoch: 29 [23680/35339 (67%)]	Loss: 0.095805
Train Epoch: 29 [24320/35339 (69%)]	Loss: 0.119286
Train Epoch: 29 [24960/35339 (71%)]	Loss: 0.168617
Train Epoch: 29 [25600/35339 (72%)]	Loss: 0.175508
Train Epoch: 29 [26240/35339 (74%)]	Loss: 0.208229
Train Epoch: 29 [26880/35339 (76%)]	Loss: 0.196258
Train Epoch: 29 [27520/35339 (78%)]	Loss: 0.143270
Train Epoch: 29 [28160/35339 (80%)]	Loss: 0.101491
Train Epoch: 29 [28800/35339 (81%)]	Loss: 0.110575
Train Epoch: 29 [29440/35339 (83%)]	Loss: 0.375776
Train Epoch: 29 [30080/35339 (85%)]	Loss: 0.135979
Train Epoch: 29 [30720/35339 (87%)]	Loss: 0.112294
Train Epoch: 29 [31360/35339 (89%)]	Loss: 0.265693
Train Epoch: 29 [32000/35339 (90%)]	Loss: 0.096029
Train Epoch: 29 [32640/35339 (92%)]	Loss: 0.106735
Train Epoch: 29 [33280/35339 (94%)]	Loss: 0.103334
Train Epoch: 29 [33920/35339 (96%)]	Loss: 0.113579
Train Epoch: 29 [34560/35339 (98%)]	Loss: 0.136247
Train Epoch: 29 [35200/35339 (99%)]	Loss: 0.182074

Validation set: Average loss: 3.1046, Accuracy: 1557/3870 (40%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 30 [0/35339 (0%)]	Loss: 0.176910
Train Epoch: 30 [640/35339 (2%)]	Loss: 0.183821
Train Epoch: 30 [1280/35339 (4%)]	Loss: 0.148972
Train Epoch: 30 [1920/35339 (5%)]	Loss: 0.088684
Train Epoch: 30 [2560/35339 (7%)]	Loss: 0.201591
Train Epoch: 30 [3200/35339 (9%)]	Loss: 0.104431
Train Epoch: 30 [3840/35339 (11%)]	Loss: 0.081613
Train Epoch: 30 [4480/35339 (13%)]	Loss: 0.234501
Train Epoch: 30 [5120/35339 (14%)]	Loss: 0.071668
Train Epoch: 30 [5760/35339 (16%)]	Loss: 0.149833
Train Epoch: 30 [6400/35339 (18%)]	Loss: 0.148938
Train Epoch: 30 [7040/35339 (20%)]	Loss: 0.200584
Train Epoch: 30 [7680/35339 (22%)]	Loss: 0.118803
Train Epoch: 30 [8320/35339 (24%)]	Loss: 0.224761
Train Epoch: 30 [8960/35339 (25%)]	Loss: 0.146716
Train Epoch: 30 [9600/35339 (27%)]	Loss: 0.081223
Train Epoch: 30 [10240/35339 (29%)]	Loss: 0.122575
Train Epoch: 30 [10880/35339 (31%)]	Loss: 0.135780
Train Epoch: 30 [11520/35339 (33%)]	Loss: 0.223439
Train Epoch: 30 [12160/35339 (34%)]	Loss: 0.095564
Train Epoch: 30 [12800/35339 (36%)]	Loss: 0.147756
Train Epoch: 30 [13440/35339 (38%)]	Loss: 0.106133
Train Epoch: 30 [14080/35339 (40%)]	Loss: 0.145555
Train Epoch: 30 [14720/35339 (42%)]	Loss: 0.120866
Train Epoch: 30 [15360/35339 (43%)]	Loss: 0.231547
Train Epoch: 30 [16000/35339 (45%)]	Loss: 0.194462
Train Epoch: 30 [16640/35339 (47%)]	Loss: 0.071869
Train Epoch: 30 [17280/35339 (49%)]	Loss: 0.126279
Train Epoch: 30 [17920/35339 (51%)]	Loss: 0.140605
Train Epoch: 30 [18560/35339 (52%)]	Loss: 0.156151
Train Epoch: 30 [19200/35339 (54%)]	Loss: 0.278168
Train Epoch: 30 [19840/35339 (56%)]	Loss: 0.120770
Train Epoch: 30 [20480/35339 (58%)]	Loss: 0.151403
Train Epoch: 30 [21120/35339 (60%)]	Loss: 0.121331
Train Epoch: 30 [21760/35339 (61%)]	Loss: 0.090280
Train Epoch: 30 [22400/35339 (63%)]	Loss: 0.095666
Train Epoch: 30 [23040/35339 (65%)]	Loss: 0.198979
Train Epoch: 30 [23680/35339 (67%)]	Loss: 0.112085
Train Epoch: 30 [24320/35339 (69%)]	Loss: 0.476492
Train Epoch: 30 [24960/35339 (71%)]	Loss: 0.088566
Train Epoch: 30 [25600/35339 (72%)]	Loss: 0.142112
Train Epoch: 30 [26240/35339 (74%)]	Loss: 0.191897
Train Epoch: 30 [26880/35339 (76%)]	Loss: 0.215486
Train Epoch: 30 [27520/35339 (78%)]	Loss: 0.176204
Train Epoch: 30 [28160/35339 (80%)]	Loss: 0.114130
Train Epoch: 30 [28800/35339 (81%)]	Loss: 0.200060
Train Epoch: 30 [29440/35339 (83%)]	Loss: 0.174467
Train Epoch: 30 [30080/35339 (85%)]	Loss: 0.244792
Train Epoch: 30 [30720/35339 (87%)]	Loss: 0.264729
Train Epoch: 30 [31360/35339 (89%)]	Loss: 0.178969
Train Epoch: 30 [32000/35339 (90%)]	Loss: 0.110683
Train Epoch: 30 [32640/35339 (92%)]	Loss: 0.087524
Train Epoch: 30 [33280/35339 (94%)]	Loss: 0.187244
Train Epoch: 30 [33920/35339 (96%)]	Loss: 0.134022
Train Epoch: 30 [34560/35339 (98%)]	Loss: 0.386710
Train Epoch: 30 [35200/35339 (99%)]	Loss: 0.115185

Validation set: Average loss: 3.1081, Accuracy: 1632/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 31 [0/35339 (0%)]	Loss: 0.227800
Train Epoch: 31 [640/35339 (2%)]	Loss: 0.143170
Train Epoch: 31 [1280/35339 (4%)]	Loss: 0.146672
Train Epoch: 31 [1920/35339 (5%)]	Loss: 0.139647
Train Epoch: 31 [2560/35339 (7%)]	Loss: 0.174181
Train Epoch: 31 [3200/35339 (9%)]	Loss: 0.151276
Train Epoch: 31 [3840/35339 (11%)]	Loss: 0.147255
Train Epoch: 31 [4480/35339 (13%)]	Loss: 0.199064
Train Epoch: 31 [5120/35339 (14%)]	Loss: 0.117434
Train Epoch: 31 [5760/35339 (16%)]	Loss: 0.220636
Train Epoch: 31 [6400/35339 (18%)]	Loss: 0.155749
Train Epoch: 31 [7040/35339 (20%)]	Loss: 0.130490
Train Epoch: 31 [7680/35339 (22%)]	Loss: 0.106830
Train Epoch: 31 [8320/35339 (24%)]	Loss: 0.104848
Train Epoch: 31 [8960/35339 (25%)]	Loss: 0.087696
Train Epoch: 31 [9600/35339 (27%)]	Loss: 0.095698
Train Epoch: 31 [10240/35339 (29%)]	Loss: 0.146094
Train Epoch: 31 [10880/35339 (31%)]	Loss: 0.200422
Train Epoch: 31 [11520/35339 (33%)]	Loss: 0.183506
Train Epoch: 31 [12160/35339 (34%)]	Loss: 0.156187
Train Epoch: 31 [12800/35339 (36%)]	Loss: 0.137531
Train Epoch: 31 [13440/35339 (38%)]	Loss: 0.133789
Train Epoch: 31 [14080/35339 (40%)]	Loss: 0.189411
Train Epoch: 31 [14720/35339 (42%)]	Loss: 0.098968
Train Epoch: 31 [15360/35339 (43%)]	Loss: 0.116077
Train Epoch: 31 [16000/35339 (45%)]	Loss: 0.184632
Train Epoch: 31 [16640/35339 (47%)]	Loss: 0.283729
Train Epoch: 31 [17280/35339 (49%)]	Loss: 0.159402
Train Epoch: 31 [17920/35339 (51%)]	Loss: 0.165122
Train Epoch: 31 [18560/35339 (52%)]	Loss: 0.071558
Train Epoch: 31 [19200/35339 (54%)]	Loss: 0.121916
Train Epoch: 31 [19840/35339 (56%)]	Loss: 0.086327
Train Epoch: 31 [20480/35339 (58%)]	Loss: 0.149797
Train Epoch: 31 [21120/35339 (60%)]	Loss: 0.106301
Train Epoch: 31 [21760/35339 (61%)]	Loss: 0.106355
Train Epoch: 31 [22400/35339 (63%)]	Loss: 0.161604
Train Epoch: 31 [23040/35339 (65%)]	Loss: 0.116792
Train Epoch: 31 [23680/35339 (67%)]	Loss: 0.080842
Train Epoch: 31 [24320/35339 (69%)]	Loss: 0.126297
Train Epoch: 31 [24960/35339 (71%)]	Loss: 0.093004
Train Epoch: 31 [25600/35339 (72%)]	Loss: 0.092690
Train Epoch: 31 [26240/35339 (74%)]	Loss: 0.147894
Train Epoch: 31 [26880/35339 (76%)]	Loss: 0.106502
Train Epoch: 31 [27520/35339 (78%)]	Loss: 0.075938
Train Epoch: 31 [28160/35339 (80%)]	Loss: 0.207372
Train Epoch: 31 [28800/35339 (81%)]	Loss: 0.094739
Train Epoch: 31 [29440/35339 (83%)]	Loss: 0.164075
Train Epoch: 31 [30080/35339 (85%)]	Loss: 0.134525
Train Epoch: 31 [30720/35339 (87%)]	Loss: 0.247388
Train Epoch: 31 [31360/35339 (89%)]	Loss: 0.120517
Train Epoch: 31 [32000/35339 (90%)]	Loss: 0.072818
Train Epoch: 31 [32640/35339 (92%)]	Loss: 0.267177
Train Epoch: 31 [33280/35339 (94%)]	Loss: 0.114834
Train Epoch: 31 [33920/35339 (96%)]	Loss: 0.131826
Train Epoch: 31 [34560/35339 (98%)]	Loss: 0.224638
Train Epoch: 31 [35200/35339 (99%)]	Loss: 0.087893

Validation set: Average loss: 3.0390, Accuracy: 1604/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 32 [0/35339 (0%)]	Loss: 0.152251
Train Epoch: 32 [640/35339 (2%)]	Loss: 0.159498
Train Epoch: 32 [1280/35339 (4%)]	Loss: 0.153440
Train Epoch: 32 [1920/35339 (5%)]	Loss: 0.120804
Train Epoch: 32 [2560/35339 (7%)]	Loss: 0.100901
Train Epoch: 32 [3200/35339 (9%)]	Loss: 0.141166
Train Epoch: 32 [3840/35339 (11%)]	Loss: 0.085056
Train Epoch: 32 [4480/35339 (13%)]	Loss: 0.121726
Train Epoch: 32 [5120/35339 (14%)]	Loss: 0.134461
Train Epoch: 32 [5760/35339 (16%)]	Loss: 0.153362
Train Epoch: 32 [6400/35339 (18%)]	Loss: 0.151272
Train Epoch: 32 [7040/35339 (20%)]	Loss: 0.172739
Train Epoch: 32 [7680/35339 (22%)]	Loss: 0.557072
Train Epoch: 32 [8320/35339 (24%)]	Loss: 0.198530
Train Epoch: 32 [8960/35339 (25%)]	Loss: 0.112163
Train Epoch: 32 [9600/35339 (27%)]	Loss: 0.141302
Train Epoch: 32 [10240/35339 (29%)]	Loss: 0.118998
Train Epoch: 32 [10880/35339 (31%)]	Loss: 0.144979
Train Epoch: 32 [11520/35339 (33%)]	Loss: 0.198932
Train Epoch: 32 [12160/35339 (34%)]	Loss: 0.138994
Train Epoch: 32 [12800/35339 (36%)]	Loss: 0.082312
Train Epoch: 32 [13440/35339 (38%)]	Loss: 0.100894
Train Epoch: 32 [14080/35339 (40%)]	Loss: 0.125904
Train Epoch: 32 [14720/35339 (42%)]	Loss: 0.105878
Train Epoch: 32 [15360/35339 (43%)]	Loss: 0.091659
Train Epoch: 32 [16000/35339 (45%)]	Loss: 0.115503
Train Epoch: 32 [16640/35339 (47%)]	Loss: 0.129048
Train Epoch: 32 [17280/35339 (49%)]	Loss: 0.144436
Train Epoch: 32 [17920/35339 (51%)]	Loss: 0.097874
Train Epoch: 32 [18560/35339 (52%)]	Loss: 0.080068
Train Epoch: 32 [19200/35339 (54%)]	Loss: 0.159812
Train Epoch: 32 [19840/35339 (56%)]	Loss: 0.093229
Train Epoch: 32 [20480/35339 (58%)]	Loss: 0.331713
Train Epoch: 32 [21120/35339 (60%)]	Loss: 0.105621
Train Epoch: 32 [21760/35339 (61%)]	Loss: 0.084199
Train Epoch: 32 [22400/35339 (63%)]	Loss: 0.137672
Train Epoch: 32 [23040/35339 (65%)]	Loss: 0.158848
Train Epoch: 32 [23680/35339 (67%)]	Loss: 0.165170
Train Epoch: 32 [24320/35339 (69%)]	Loss: 0.155943
Train Epoch: 32 [24960/35339 (71%)]	Loss: 0.173718
Train Epoch: 32 [25600/35339 (72%)]	Loss: 0.183287
Train Epoch: 32 [26240/35339 (74%)]	Loss: 0.096280
Train Epoch: 32 [26880/35339 (76%)]	Loss: 0.195651
Train Epoch: 32 [27520/35339 (78%)]	Loss: 0.209991
Train Epoch: 32 [28160/35339 (80%)]	Loss: 0.133841
Train Epoch: 32 [28800/35339 (81%)]	Loss: 0.082435
Train Epoch: 32 [29440/35339 (83%)]	Loss: 0.234098
Train Epoch: 32 [30080/35339 (85%)]	Loss: 0.138292
Train Epoch: 32 [30720/35339 (87%)]	Loss: 0.257461
Train Epoch: 32 [31360/35339 (89%)]	Loss: 0.121366
Train Epoch: 32 [32000/35339 (90%)]	Loss: 0.085759
Train Epoch: 32 [32640/35339 (92%)]	Loss: 0.166525
Train Epoch: 32 [33280/35339 (94%)]	Loss: 0.085285
Train Epoch: 32 [33920/35339 (96%)]	Loss: 0.074814
Train Epoch: 32 [34560/35339 (98%)]	Loss: 0.095761
Train Epoch: 32 [35200/35339 (99%)]	Loss: 0.197942

Validation set: Average loss: 3.0667, Accuracy: 1576/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 33 [0/35339 (0%)]	Loss: 0.159257
Train Epoch: 33 [640/35339 (2%)]	Loss: 0.129293
Train Epoch: 33 [1280/35339 (4%)]	Loss: 0.170567
Train Epoch: 33 [1920/35339 (5%)]	Loss: 0.217082
Train Epoch: 33 [2560/35339 (7%)]	Loss: 0.095850
Train Epoch: 33 [3200/35339 (9%)]	Loss: 0.088227
Train Epoch: 33 [3840/35339 (11%)]	Loss: 0.097785
Train Epoch: 33 [4480/35339 (13%)]	Loss: 0.133687
Train Epoch: 33 [5120/35339 (14%)]	Loss: 0.116725
Train Epoch: 33 [5760/35339 (16%)]	Loss: 0.153115
Train Epoch: 33 [6400/35339 (18%)]	Loss: 0.129616
Train Epoch: 33 [7040/35339 (20%)]	Loss: 0.135802
Train Epoch: 33 [7680/35339 (22%)]	Loss: 0.192993
Train Epoch: 33 [8320/35339 (24%)]	Loss: 0.149882
Train Epoch: 33 [8960/35339 (25%)]	Loss: 0.069822
Train Epoch: 33 [9600/35339 (27%)]	Loss: 0.093211
Train Epoch: 33 [10240/35339 (29%)]	Loss: 0.112606
Train Epoch: 33 [10880/35339 (31%)]	Loss: 0.232662
Train Epoch: 33 [11520/35339 (33%)]	Loss: 0.136286
Train Epoch: 33 [12160/35339 (34%)]	Loss: 0.178507
Train Epoch: 33 [12800/35339 (36%)]	Loss: 0.190301
Train Epoch: 33 [13440/35339 (38%)]	Loss: 0.216409
Train Epoch: 33 [14080/35339 (40%)]	Loss: 0.126635
Train Epoch: 33 [14720/35339 (42%)]	Loss: 0.174192
Train Epoch: 33 [15360/35339 (43%)]	Loss: 0.184462
Train Epoch: 33 [16000/35339 (45%)]	Loss: 0.161269
Train Epoch: 33 [16640/35339 (47%)]	Loss: 0.083316
Train Epoch: 33 [17280/35339 (49%)]	Loss: 0.092409
Train Epoch: 33 [17920/35339 (51%)]	Loss: 0.127463
Train Epoch: 33 [18560/35339 (52%)]	Loss: 0.178485
Train Epoch: 33 [19200/35339 (54%)]	Loss: 0.501606
Train Epoch: 33 [19840/35339 (56%)]	Loss: 0.106274
Train Epoch: 33 [20480/35339 (58%)]	Loss: 0.164376
Train Epoch: 33 [21120/35339 (60%)]	Loss: 0.164714
Train Epoch: 33 [21760/35339 (61%)]	Loss: 0.189848
Train Epoch: 33 [22400/35339 (63%)]	Loss: 0.149709
Train Epoch: 33 [23040/35339 (65%)]	Loss: 0.106365
Train Epoch: 33 [23680/35339 (67%)]	Loss: 0.096390
Train Epoch: 33 [24320/35339 (69%)]	Loss: 0.102643
Train Epoch: 33 [24960/35339 (71%)]	Loss: 0.153339
Train Epoch: 33 [25600/35339 (72%)]	Loss: 0.238271
Train Epoch: 33 [26240/35339 (74%)]	Loss: 0.115158
Train Epoch: 33 [26880/35339 (76%)]	Loss: 0.121475
Train Epoch: 33 [27520/35339 (78%)]	Loss: 0.138209
Train Epoch: 33 [28160/35339 (80%)]	Loss: 0.139922
Train Epoch: 33 [28800/35339 (81%)]	Loss: 0.157277
Train Epoch: 33 [29440/35339 (83%)]	Loss: 0.240248
Train Epoch: 33 [30080/35339 (85%)]	Loss: 0.141797
Train Epoch: 33 [30720/35339 (87%)]	Loss: 0.100692
Train Epoch: 33 [31360/35339 (89%)]	Loss: 0.468965
Train Epoch: 33 [32000/35339 (90%)]	Loss: 0.167846
Train Epoch: 33 [32640/35339 (92%)]	Loss: 0.122210
Train Epoch: 33 [33280/35339 (94%)]	Loss: 0.185298
Train Epoch: 33 [33920/35339 (96%)]	Loss: 0.133346
Train Epoch: 33 [34560/35339 (98%)]	Loss: 0.172242
Train Epoch: 33 [35200/35339 (99%)]	Loss: 0.160795

Validation set: Average loss: 3.1122, Accuracy: 1583/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 34 [0/35339 (0%)]	Loss: 0.157136
Train Epoch: 34 [640/35339 (2%)]	Loss: 0.126126
Train Epoch: 34 [1280/35339 (4%)]	Loss: 0.134442
Train Epoch: 34 [1920/35339 (5%)]	Loss: 0.110212
Train Epoch: 34 [2560/35339 (7%)]	Loss: 0.114053
Train Epoch: 34 [3200/35339 (9%)]	Loss: 0.105326
Train Epoch: 34 [3840/35339 (11%)]	Loss: 0.109243
Train Epoch: 34 [4480/35339 (13%)]	Loss: 0.180426
Train Epoch: 34 [5120/35339 (14%)]	Loss: 0.091084
Train Epoch: 34 [5760/35339 (16%)]	Loss: 0.119219
Train Epoch: 34 [6400/35339 (18%)]	Loss: 0.121058
Train Epoch: 34 [7040/35339 (20%)]	Loss: 0.131683
Train Epoch: 34 [7680/35339 (22%)]	Loss: 0.071118
Train Epoch: 34 [8320/35339 (24%)]	Loss: 0.131949
Train Epoch: 34 [8960/35339 (25%)]	Loss: 0.086459
Train Epoch: 34 [9600/35339 (27%)]	Loss: 0.115619
Train Epoch: 34 [10240/35339 (29%)]	Loss: 0.080602
Train Epoch: 34 [10880/35339 (31%)]	Loss: 0.112594
Train Epoch: 34 [11520/35339 (33%)]	Loss: 0.112031
Train Epoch: 34 [12160/35339 (34%)]	Loss: 0.104291
Train Epoch: 34 [12800/35339 (36%)]	Loss: 0.132865
Train Epoch: 34 [13440/35339 (38%)]	Loss: 0.100006
Train Epoch: 34 [14080/35339 (40%)]	Loss: 0.103444
Train Epoch: 34 [14720/35339 (42%)]	Loss: 0.115194
Train Epoch: 34 [15360/35339 (43%)]	Loss: 0.138510
Train Epoch: 34 [16000/35339 (45%)]	Loss: 0.126552
Train Epoch: 34 [16640/35339 (47%)]	Loss: 0.107240
Train Epoch: 34 [17280/35339 (49%)]	Loss: 0.232278
Train Epoch: 34 [17920/35339 (51%)]	Loss: 0.170377
Train Epoch: 34 [18560/35339 (52%)]	Loss: 0.143194
Train Epoch: 34 [19200/35339 (54%)]	Loss: 0.124563
Train Epoch: 34 [19840/35339 (56%)]	Loss: 0.101262
Train Epoch: 34 [20480/35339 (58%)]	Loss: 0.209391
Train Epoch: 34 [21120/35339 (60%)]	Loss: 0.118363
Train Epoch: 34 [21760/35339 (61%)]	Loss: 0.139411
Train Epoch: 34 [22400/35339 (63%)]	Loss: 0.188845
Train Epoch: 34 [23040/35339 (65%)]	Loss: 0.085180
Train Epoch: 34 [23680/35339 (67%)]	Loss: 0.298687
Train Epoch: 34 [24320/35339 (69%)]	Loss: 0.165276
Train Epoch: 34 [24960/35339 (71%)]	Loss: 0.123828
Train Epoch: 34 [25600/35339 (72%)]	Loss: 0.069019
Train Epoch: 34 [26240/35339 (74%)]	Loss: 0.162476
Train Epoch: 34 [26880/35339 (76%)]	Loss: 0.117097
Train Epoch: 34 [27520/35339 (78%)]	Loss: 0.101205
Train Epoch: 34 [28160/35339 (80%)]	Loss: 0.098609
Train Epoch: 34 [28800/35339 (81%)]	Loss: 0.161777
Train Epoch: 34 [29440/35339 (83%)]	Loss: 0.197830
Train Epoch: 34 [30080/35339 (85%)]	Loss: 0.110180
Train Epoch: 34 [30720/35339 (87%)]	Loss: 0.151260
Train Epoch: 34 [31360/35339 (89%)]	Loss: 0.185049
Train Epoch: 34 [32000/35339 (90%)]	Loss: 0.147092
Train Epoch: 34 [32640/35339 (92%)]	Loss: 0.139342
Train Epoch: 34 [33280/35339 (94%)]	Loss: 0.107139
Train Epoch: 34 [33920/35339 (96%)]	Loss: 0.165049
Train Epoch: 34 [34560/35339 (98%)]	Loss: 0.094734
Train Epoch: 34 [35200/35339 (99%)]	Loss: 0.135292

Validation set: Average loss: 3.0609, Accuracy: 1589/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 35 [0/35339 (0%)]	Loss: 0.188770
Train Epoch: 35 [640/35339 (2%)]	Loss: 0.101540
Train Epoch: 35 [1280/35339 (4%)]	Loss: 0.140011
Train Epoch: 35 [1920/35339 (5%)]	Loss: 0.144375
Train Epoch: 35 [2560/35339 (7%)]	Loss: 0.106473
Train Epoch: 35 [3200/35339 (9%)]	Loss: 0.201996
Train Epoch: 35 [3840/35339 (11%)]	Loss: 0.154337
Train Epoch: 35 [4480/35339 (13%)]	Loss: 0.081852
Train Epoch: 35 [5120/35339 (14%)]	Loss: 0.130989
Train Epoch: 35 [5760/35339 (16%)]	Loss: 0.120127
Train Epoch: 35 [6400/35339 (18%)]	Loss: 0.086030
Train Epoch: 35 [7040/35339 (20%)]	Loss: 0.100500
Train Epoch: 35 [7680/35339 (22%)]	Loss: 0.096540
Train Epoch: 35 [8320/35339 (24%)]	Loss: 0.242681
Train Epoch: 35 [8960/35339 (25%)]	Loss: 0.129525
Train Epoch: 35 [9600/35339 (27%)]	Loss: 0.120989
Train Epoch: 35 [10240/35339 (29%)]	Loss: 0.202208
Train Epoch: 35 [10880/35339 (31%)]	Loss: 0.115112
Train Epoch: 35 [11520/35339 (33%)]	Loss: 0.081480
Train Epoch: 35 [12160/35339 (34%)]	Loss: 0.091081
Train Epoch: 35 [12800/35339 (36%)]	Loss: 0.145479
Train Epoch: 35 [13440/35339 (38%)]	Loss: 0.092344
Train Epoch: 35 [14080/35339 (40%)]	Loss: 0.151490
Train Epoch: 35 [14720/35339 (42%)]	Loss: 0.092828
Train Epoch: 35 [15360/35339 (43%)]	Loss: 0.135564
Train Epoch: 35 [16000/35339 (45%)]	Loss: 0.198580
Train Epoch: 35 [16640/35339 (47%)]	Loss: 0.087288
Train Epoch: 35 [17280/35339 (49%)]	Loss: 0.066190
Train Epoch: 35 [17920/35339 (51%)]	Loss: 0.184089
Train Epoch: 35 [18560/35339 (52%)]	Loss: 0.158453
Train Epoch: 35 [19200/35339 (54%)]	Loss: 0.904316
Train Epoch: 35 [19840/35339 (56%)]	Loss: 0.097586
Train Epoch: 35 [20480/35339 (58%)]	Loss: 0.152225
Train Epoch: 35 [21120/35339 (60%)]	Loss: 0.166237
Train Epoch: 35 [21760/35339 (61%)]	Loss: 0.171505
Train Epoch: 35 [22400/35339 (63%)]	Loss: 0.126082
Train Epoch: 35 [23040/35339 (65%)]	Loss: 0.108951
Train Epoch: 35 [23680/35339 (67%)]	Loss: 0.069801
Train Epoch: 35 [24320/35339 (69%)]	Loss: 0.114432
Train Epoch: 35 [24960/35339 (71%)]	Loss: 0.156998
Train Epoch: 35 [25600/35339 (72%)]	Loss: 0.146831
Train Epoch: 35 [26240/35339 (74%)]	Loss: 0.081908
Train Epoch: 35 [26880/35339 (76%)]	Loss: 0.088005
Train Epoch: 35 [27520/35339 (78%)]	Loss: 0.095690
Train Epoch: 35 [28160/35339 (80%)]	Loss: 0.324396
Train Epoch: 35 [28800/35339 (81%)]	Loss: 0.265496
Train Epoch: 35 [29440/35339 (83%)]	Loss: 0.117572
Train Epoch: 35 [30080/35339 (85%)]	Loss: 0.149150
Train Epoch: 35 [30720/35339 (87%)]	Loss: 0.131875
Train Epoch: 35 [31360/35339 (89%)]	Loss: 0.146945
Train Epoch: 35 [32000/35339 (90%)]	Loss: 0.137054
Train Epoch: 35 [32640/35339 (92%)]	Loss: 0.100629
Train Epoch: 35 [33280/35339 (94%)]	Loss: 0.170747
Train Epoch: 35 [33920/35339 (96%)]	Loss: 0.217683
Train Epoch: 35 [34560/35339 (98%)]	Loss: 0.118520
Train Epoch: 35 [35200/35339 (99%)]	Loss: 0.099650

Validation set: Average loss: 2.9797, Accuracy: 1643/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 36 [0/35339 (0%)]	Loss: 0.203997
Train Epoch: 36 [640/35339 (2%)]	Loss: 0.132123
Train Epoch: 36 [1280/35339 (4%)]	Loss: 0.117419
Train Epoch: 36 [1920/35339 (5%)]	Loss: 0.134412
Train Epoch: 36 [2560/35339 (7%)]	Loss: 0.133942
Train Epoch: 36 [3200/35339 (9%)]	Loss: 0.076344
Train Epoch: 36 [3840/35339 (11%)]	Loss: 0.089990
Train Epoch: 36 [4480/35339 (13%)]	Loss: 0.243225
Train Epoch: 36 [5120/35339 (14%)]	Loss: 0.243452
Train Epoch: 36 [5760/35339 (16%)]	Loss: 0.171297
Train Epoch: 36 [6400/35339 (18%)]	Loss: 0.120979
Train Epoch: 36 [7040/35339 (20%)]	Loss: 0.108434
Train Epoch: 36 [7680/35339 (22%)]	Loss: 0.109690
Train Epoch: 36 [8320/35339 (24%)]	Loss: 0.132271
Train Epoch: 36 [8960/35339 (25%)]	Loss: 0.122323
Train Epoch: 36 [9600/35339 (27%)]	Loss: 0.203874
Train Epoch: 36 [10240/35339 (29%)]	Loss: 0.193120
Train Epoch: 36 [10880/35339 (31%)]	Loss: 0.125005
Train Epoch: 36 [11520/35339 (33%)]	Loss: 0.185299
Train Epoch: 36 [12160/35339 (34%)]	Loss: 0.134785
Train Epoch: 36 [12800/35339 (36%)]	Loss: 0.095588
Train Epoch: 36 [13440/35339 (38%)]	Loss: 0.084111
Train Epoch: 36 [14080/35339 (40%)]	Loss: 0.254124
Train Epoch: 36 [14720/35339 (42%)]	Loss: 0.104641
Train Epoch: 36 [15360/35339 (43%)]	Loss: 0.087226
Train Epoch: 36 [16000/35339 (45%)]	Loss: 0.107506
Train Epoch: 36 [16640/35339 (47%)]	Loss: 0.131176
Train Epoch: 36 [17280/35339 (49%)]	Loss: 0.098905
Train Epoch: 36 [17920/35339 (51%)]	Loss: 0.170228
Train Epoch: 36 [18560/35339 (52%)]	Loss: 0.146913
Train Epoch: 36 [19200/35339 (54%)]	Loss: 0.075910
Train Epoch: 36 [19840/35339 (56%)]	Loss: 0.165576
Train Epoch: 36 [20480/35339 (58%)]	Loss: 0.113686
Train Epoch: 36 [21120/35339 (60%)]	Loss: 0.071973
Train Epoch: 36 [21760/35339 (61%)]	Loss: 0.116814
Train Epoch: 36 [22400/35339 (63%)]	Loss: 0.098924
Train Epoch: 36 [23040/35339 (65%)]	Loss: 0.188125
Train Epoch: 36 [23680/35339 (67%)]	Loss: 0.072165
Train Epoch: 36 [24320/35339 (69%)]	Loss: 0.080114
Train Epoch: 36 [24960/35339 (71%)]	Loss: 0.105773
Train Epoch: 36 [25600/35339 (72%)]	Loss: 0.142499
Train Epoch: 36 [26240/35339 (74%)]	Loss: 0.184522
Train Epoch: 36 [26880/35339 (76%)]	Loss: 0.189265
Train Epoch: 36 [27520/35339 (78%)]	Loss: 0.106653
Train Epoch: 36 [28160/35339 (80%)]	Loss: 0.183588
Train Epoch: 36 [28800/35339 (81%)]	Loss: 0.113775
Train Epoch: 36 [29440/35339 (83%)]	Loss: 0.163545
Train Epoch: 36 [30080/35339 (85%)]	Loss: 0.123371
Train Epoch: 36 [30720/35339 (87%)]	Loss: 0.279708
Train Epoch: 36 [31360/35339 (89%)]	Loss: 0.076828
Train Epoch: 36 [32000/35339 (90%)]	Loss: 0.104695
Train Epoch: 36 [32640/35339 (92%)]	Loss: 0.125338
Train Epoch: 36 [33280/35339 (94%)]	Loss: 0.124746
Train Epoch: 36 [33920/35339 (96%)]	Loss: 0.111891
Train Epoch: 36 [34560/35339 (98%)]	Loss: 0.082880
Train Epoch: 36 [35200/35339 (99%)]	Loss: 0.180649

Validation set: Average loss: 3.1323, Accuracy: 1550/3870 (40%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 37 [0/35339 (0%)]	Loss: 0.134437
Train Epoch: 37 [640/35339 (2%)]	Loss: 0.103909
Train Epoch: 37 [1280/35339 (4%)]	Loss: 0.186088
Train Epoch: 37 [1920/35339 (5%)]	Loss: 0.077176
Train Epoch: 37 [2560/35339 (7%)]	Loss: 0.148115
Train Epoch: 37 [3200/35339 (9%)]	Loss: 0.108263
Train Epoch: 37 [3840/35339 (11%)]	Loss: 0.106624
Train Epoch: 37 [4480/35339 (13%)]	Loss: 0.078950
Train Epoch: 37 [5120/35339 (14%)]	Loss: 0.142285
Train Epoch: 37 [5760/35339 (16%)]	Loss: 0.164400
Train Epoch: 37 [6400/35339 (18%)]	Loss: 0.113584
Train Epoch: 37 [7040/35339 (20%)]	Loss: 0.105159
Train Epoch: 37 [7680/35339 (22%)]	Loss: 0.109342
Train Epoch: 37 [8320/35339 (24%)]	Loss: 0.113805
Train Epoch: 37 [8960/35339 (25%)]	Loss: 0.138598
Train Epoch: 37 [9600/35339 (27%)]	Loss: 0.137267
Train Epoch: 37 [10240/35339 (29%)]	Loss: 0.138456
Train Epoch: 37 [10880/35339 (31%)]	Loss: 0.148168
Train Epoch: 37 [11520/35339 (33%)]	Loss: 0.174381
Train Epoch: 37 [12160/35339 (34%)]	Loss: 0.096192
Train Epoch: 37 [12800/35339 (36%)]	Loss: 0.073980
Train Epoch: 37 [13440/35339 (38%)]	Loss: 0.086888
Train Epoch: 37 [14080/35339 (40%)]	Loss: 0.178346
Train Epoch: 37 [14720/35339 (42%)]	Loss: 0.178169
Train Epoch: 37 [15360/35339 (43%)]	Loss: 0.092893
Train Epoch: 37 [16000/35339 (45%)]	Loss: 0.211423
Train Epoch: 37 [16640/35339 (47%)]	Loss: 0.128716
Train Epoch: 37 [17280/35339 (49%)]	Loss: 0.402165
Train Epoch: 37 [17920/35339 (51%)]	Loss: 0.112610
Train Epoch: 37 [18560/35339 (52%)]	Loss: 0.093478
Train Epoch: 37 [19200/35339 (54%)]	Loss: 0.162289
Train Epoch: 37 [19840/35339 (56%)]	Loss: 0.207955
Train Epoch: 37 [20480/35339 (58%)]	Loss: 0.078651
Train Epoch: 37 [21120/35339 (60%)]	Loss: 0.156978
Train Epoch: 37 [21760/35339 (61%)]	Loss: 0.082561
Train Epoch: 37 [22400/35339 (63%)]	Loss: 0.080101
Train Epoch: 37 [23040/35339 (65%)]	Loss: 0.126957
Train Epoch: 37 [23680/35339 (67%)]	Loss: 0.085133
Train Epoch: 37 [24320/35339 (69%)]	Loss: 0.096273
Train Epoch: 37 [24960/35339 (71%)]	Loss: 0.065560
Train Epoch: 37 [25600/35339 (72%)]	Loss: 0.088449
Train Epoch: 37 [26240/35339 (74%)]	Loss: 0.160364
Train Epoch: 37 [26880/35339 (76%)]	Loss: 0.204927
Train Epoch: 37 [27520/35339 (78%)]	Loss: 0.155089
Train Epoch: 37 [28160/35339 (80%)]	Loss: 0.165019
Train Epoch: 37 [28800/35339 (81%)]	Loss: 0.082791
Train Epoch: 37 [29440/35339 (83%)]	Loss: 0.184617
Train Epoch: 37 [30080/35339 (85%)]	Loss: 0.220306
Train Epoch: 37 [30720/35339 (87%)]	Loss: 0.393138
Train Epoch: 37 [31360/35339 (89%)]	Loss: 0.116206
Train Epoch: 37 [32000/35339 (90%)]	Loss: 0.088803
Train Epoch: 37 [32640/35339 (92%)]	Loss: 0.092532
Train Epoch: 37 [33280/35339 (94%)]	Loss: 0.173089
Train Epoch: 37 [33920/35339 (96%)]	Loss: 0.124398
Train Epoch: 37 [34560/35339 (98%)]	Loss: 0.091945
Train Epoch: 37 [35200/35339 (99%)]	Loss: 0.128399

Validation set: Average loss: 3.1504, Accuracy: 1528/3870 (39%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 38 [0/35339 (0%)]	Loss: 0.174730
Train Epoch: 38 [640/35339 (2%)]	Loss: 0.145188
Train Epoch: 38 [1280/35339 (4%)]	Loss: 0.111789
Train Epoch: 38 [1920/35339 (5%)]	Loss: 0.165358
Train Epoch: 38 [2560/35339 (7%)]	Loss: 0.121454
Train Epoch: 38 [3200/35339 (9%)]	Loss: 0.119561
Train Epoch: 38 [3840/35339 (11%)]	Loss: 0.070032
Train Epoch: 38 [4480/35339 (13%)]	Loss: 0.107097
Train Epoch: 38 [5120/35339 (14%)]	Loss: 0.114057
Train Epoch: 38 [5760/35339 (16%)]	Loss: 0.139163
Train Epoch: 38 [6400/35339 (18%)]	Loss: 0.097418
Train Epoch: 38 [7040/35339 (20%)]	Loss: 0.200296
Train Epoch: 38 [7680/35339 (22%)]	Loss: 0.103248
Train Epoch: 38 [8320/35339 (24%)]	Loss: 0.119251
Train Epoch: 38 [8960/35339 (25%)]	Loss: 0.121962
Train Epoch: 38 [9600/35339 (27%)]	Loss: 0.079723
Train Epoch: 38 [10240/35339 (29%)]	Loss: 0.068813
Train Epoch: 38 [10880/35339 (31%)]	Loss: 0.122205
Train Epoch: 38 [11520/35339 (33%)]	Loss: 0.124356
Train Epoch: 38 [12160/35339 (34%)]	Loss: 0.223611
Train Epoch: 38 [12800/35339 (36%)]	Loss: 0.137813
Train Epoch: 38 [13440/35339 (38%)]	Loss: 0.125997
Train Epoch: 38 [14080/35339 (40%)]	Loss: 0.083881
Train Epoch: 38 [14720/35339 (42%)]	Loss: 0.123707
Train Epoch: 38 [15360/35339 (43%)]	Loss: 0.198287
Train Epoch: 38 [16000/35339 (45%)]	Loss: 0.174001
Train Epoch: 38 [16640/35339 (47%)]	Loss: 0.073061
Train Epoch: 38 [17280/35339 (49%)]	Loss: 0.259289
Train Epoch: 38 [17920/35339 (51%)]	Loss: 0.102422
Train Epoch: 38 [18560/35339 (52%)]	Loss: 0.104226
Train Epoch: 38 [19200/35339 (54%)]	Loss: 0.135666
Train Epoch: 38 [19840/35339 (56%)]	Loss: 0.106029
Train Epoch: 38 [20480/35339 (58%)]	Loss: 0.210426
Train Epoch: 38 [21120/35339 (60%)]	Loss: 0.137553
Train Epoch: 38 [21760/35339 (61%)]	Loss: 0.133891
Train Epoch: 38 [22400/35339 (63%)]	Loss: 0.114786
Train Epoch: 38 [23040/35339 (65%)]	Loss: 0.118323
Train Epoch: 38 [23680/35339 (67%)]	Loss: 0.145689
Train Epoch: 38 [24320/35339 (69%)]	Loss: 0.215963
Train Epoch: 38 [24960/35339 (71%)]	Loss: 0.122661
Train Epoch: 38 [25600/35339 (72%)]	Loss: 0.094124
Train Epoch: 38 [26240/35339 (74%)]	Loss: 0.149371
Train Epoch: 38 [26880/35339 (76%)]	Loss: 0.096022
Train Epoch: 38 [27520/35339 (78%)]	Loss: 0.104313
Train Epoch: 38 [28160/35339 (80%)]	Loss: 0.109415
Train Epoch: 38 [28800/35339 (81%)]	Loss: 0.107215
Train Epoch: 38 [29440/35339 (83%)]	Loss: 0.169000
Train Epoch: 38 [30080/35339 (85%)]	Loss: 0.090116
Train Epoch: 38 [30720/35339 (87%)]	Loss: 0.166421
Train Epoch: 38 [31360/35339 (89%)]	Loss: 0.124726
Train Epoch: 38 [32000/35339 (90%)]	Loss: 0.118770
Train Epoch: 38 [32640/35339 (92%)]	Loss: 0.118898
Train Epoch: 38 [33280/35339 (94%)]	Loss: 0.102750
Train Epoch: 38 [33920/35339 (96%)]	Loss: 0.223870
Train Epoch: 38 [34560/35339 (98%)]	Loss: 0.106272
Train Epoch: 38 [35200/35339 (99%)]	Loss: 0.110388

Validation set: Average loss: 3.0740, Accuracy: 1600/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 39 [0/35339 (0%)]	Loss: 0.103570
Train Epoch: 39 [640/35339 (2%)]	Loss: 0.186848
Train Epoch: 39 [1280/35339 (4%)]	Loss: 0.101444
Train Epoch: 39 [1920/35339 (5%)]	Loss: 0.134963
Train Epoch: 39 [2560/35339 (7%)]	Loss: 0.097346
Train Epoch: 39 [3200/35339 (9%)]	Loss: 0.251356
Train Epoch: 39 [3840/35339 (11%)]	Loss: 0.120021
Train Epoch: 39 [4480/35339 (13%)]	Loss: 0.127084
Train Epoch: 39 [5120/35339 (14%)]	Loss: 0.111427
Train Epoch: 39 [5760/35339 (16%)]	Loss: 0.229486
Train Epoch: 39 [6400/35339 (18%)]	Loss: 0.130167
Train Epoch: 39 [7040/35339 (20%)]	Loss: 0.180782
Train Epoch: 39 [7680/35339 (22%)]	Loss: 0.176105
Train Epoch: 39 [8320/35339 (24%)]	Loss: 0.159407
Train Epoch: 39 [8960/35339 (25%)]	Loss: 0.119320
Train Epoch: 39 [9600/35339 (27%)]	Loss: 0.224860
Train Epoch: 39 [10240/35339 (29%)]	Loss: 0.135694
Train Epoch: 39 [10880/35339 (31%)]	Loss: 0.068521
Train Epoch: 39 [11520/35339 (33%)]	Loss: 0.119523
Train Epoch: 39 [12160/35339 (34%)]	Loss: 0.154815
Train Epoch: 39 [12800/35339 (36%)]	Loss: 0.110984
Train Epoch: 39 [13440/35339 (38%)]	Loss: 0.094205
Train Epoch: 39 [14080/35339 (40%)]	Loss: 0.082545
Train Epoch: 39 [14720/35339 (42%)]	Loss: 0.111394
Train Epoch: 39 [15360/35339 (43%)]	Loss: 0.137990
Train Epoch: 39 [16000/35339 (45%)]	Loss: 0.090695
Train Epoch: 39 [16640/35339 (47%)]	Loss: 0.119299
Train Epoch: 39 [17280/35339 (49%)]	Loss: 0.129956
Train Epoch: 39 [17920/35339 (51%)]	Loss: 0.133191
Train Epoch: 39 [18560/35339 (52%)]	Loss: 0.088790
Train Epoch: 39 [19200/35339 (54%)]	Loss: 0.122218
Train Epoch: 39 [19840/35339 (56%)]	Loss: 0.158555
Train Epoch: 39 [20480/35339 (58%)]	Loss: 0.096789
Train Epoch: 39 [21120/35339 (60%)]	Loss: 0.119937
Train Epoch: 39 [21760/35339 (61%)]	Loss: 0.281898
Train Epoch: 39 [22400/35339 (63%)]	Loss: 0.160047
Train Epoch: 39 [23040/35339 (65%)]	Loss: 0.148107
Train Epoch: 39 [23680/35339 (67%)]	Loss: 0.157366
Train Epoch: 39 [24320/35339 (69%)]	Loss: 0.134660
Train Epoch: 39 [24960/35339 (71%)]	Loss: 0.074686
Train Epoch: 39 [25600/35339 (72%)]	Loss: 0.099226
Train Epoch: 39 [26240/35339 (74%)]	Loss: 0.236039
Train Epoch: 39 [26880/35339 (76%)]	Loss: 0.119078
Train Epoch: 39 [27520/35339 (78%)]	Loss: 0.099848
Train Epoch: 39 [28160/35339 (80%)]	Loss: 0.110115
Train Epoch: 39 [28800/35339 (81%)]	Loss: 0.119161
Train Epoch: 39 [29440/35339 (83%)]	Loss: 0.098293
Train Epoch: 39 [30080/35339 (85%)]	Loss: 0.086978
Train Epoch: 39 [30720/35339 (87%)]	Loss: 0.090582
Train Epoch: 39 [31360/35339 (89%)]	Loss: 0.176441
Train Epoch: 39 [32000/35339 (90%)]	Loss: 0.115774
Train Epoch: 39 [32640/35339 (92%)]	Loss: 0.304710
Train Epoch: 39 [33280/35339 (94%)]	Loss: 0.113121
Train Epoch: 39 [33920/35339 (96%)]	Loss: 0.152232
Train Epoch: 39 [34560/35339 (98%)]	Loss: 0.189237
Train Epoch: 39 [35200/35339 (99%)]	Loss: 0.136079

Validation set: Average loss: 3.0400, Accuracy: 1608/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 40 [0/35339 (0%)]	Loss: 0.097959
Train Epoch: 40 [640/35339 (2%)]	Loss: 0.091886
Train Epoch: 40 [1280/35339 (4%)]	Loss: 0.131587
Train Epoch: 40 [1920/35339 (5%)]	Loss: 0.115025
Train Epoch: 40 [2560/35339 (7%)]	Loss: 0.707641
Train Epoch: 40 [3200/35339 (9%)]	Loss: 0.184983
Train Epoch: 40 [3840/35339 (11%)]	Loss: 0.121672
Train Epoch: 40 [4480/35339 (13%)]	Loss: 0.126051
Train Epoch: 40 [5120/35339 (14%)]	Loss: 0.100202
Train Epoch: 40 [5760/35339 (16%)]	Loss: 0.089045
Train Epoch: 40 [6400/35339 (18%)]	Loss: 0.145178
Train Epoch: 40 [7040/35339 (20%)]	Loss: 0.094014
Train Epoch: 40 [7680/35339 (22%)]	Loss: 0.130348
Train Epoch: 40 [8320/35339 (24%)]	Loss: 0.186987
Train Epoch: 40 [8960/35339 (25%)]	Loss: 0.110126
Train Epoch: 40 [9600/35339 (27%)]	Loss: 0.086974
Train Epoch: 40 [10240/35339 (29%)]	Loss: 0.112005
Train Epoch: 40 [10880/35339 (31%)]	Loss: 0.077403
Train Epoch: 40 [11520/35339 (33%)]	Loss: 0.171716
Train Epoch: 40 [12160/35339 (34%)]	Loss: 0.080706
Train Epoch: 40 [12800/35339 (36%)]	Loss: 0.126093
Train Epoch: 40 [13440/35339 (38%)]	Loss: 0.112010
Train Epoch: 40 [14080/35339 (40%)]	Loss: 0.119152
Train Epoch: 40 [14720/35339 (42%)]	Loss: 0.126033
Train Epoch: 40 [15360/35339 (43%)]	Loss: 0.105954
Train Epoch: 40 [16000/35339 (45%)]	Loss: 0.153805
Train Epoch: 40 [16640/35339 (47%)]	Loss: 0.237222
Train Epoch: 40 [17280/35339 (49%)]	Loss: 0.132457
Train Epoch: 40 [17920/35339 (51%)]	Loss: 0.082110
Train Epoch: 40 [18560/35339 (52%)]	Loss: 0.129191
Train Epoch: 40 [19200/35339 (54%)]	Loss: 0.142184
Train Epoch: 40 [19840/35339 (56%)]	Loss: 0.065185
Train Epoch: 40 [20480/35339 (58%)]	Loss: 0.263585
Train Epoch: 40 [21120/35339 (60%)]	Loss: 0.148847
Train Epoch: 40 [21760/35339 (61%)]	Loss: 0.118590
Train Epoch: 40 [22400/35339 (63%)]	Loss: 0.067650
Train Epoch: 40 [23040/35339 (65%)]	Loss: 0.130202
Train Epoch: 40 [23680/35339 (67%)]	Loss: 0.268023
Train Epoch: 40 [24320/35339 (69%)]	Loss: 0.090131
Train Epoch: 40 [24960/35339 (71%)]	Loss: 0.152601
Train Epoch: 40 [25600/35339 (72%)]	Loss: 0.078706
Train Epoch: 40 [26240/35339 (74%)]	Loss: 0.073981
Train Epoch: 40 [26880/35339 (76%)]	Loss: 0.115397
Train Epoch: 40 [27520/35339 (78%)]	Loss: 0.123785
Train Epoch: 40 [28160/35339 (80%)]	Loss: 0.104249
Train Epoch: 40 [28800/35339 (81%)]	Loss: 0.123575
Train Epoch: 40 [29440/35339 (83%)]	Loss: 0.117652
Train Epoch: 40 [30080/35339 (85%)]	Loss: 0.075668
Train Epoch: 40 [30720/35339 (87%)]	Loss: 0.185089
Train Epoch: 40 [31360/35339 (89%)]	Loss: 0.181701
Train Epoch: 40 [32000/35339 (90%)]	Loss: 0.145198
Train Epoch: 40 [32640/35339 (92%)]	Loss: 0.104655
Train Epoch: 40 [33280/35339 (94%)]	Loss: 0.107078
Train Epoch: 40 [33920/35339 (96%)]	Loss: 0.137735
Train Epoch: 40 [34560/35339 (98%)]	Loss: 0.089763
Train Epoch: 40 [35200/35339 (99%)]	Loss: 0.068199

Validation set: Average loss: 3.0310, Accuracy: 1660/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 41 [0/35339 (0%)]	Loss: 0.126630
Train Epoch: 41 [640/35339 (2%)]	Loss: 0.083705
Train Epoch: 41 [1280/35339 (4%)]	Loss: 0.153044
Train Epoch: 41 [1920/35339 (5%)]	Loss: 0.083264
Train Epoch: 41 [2560/35339 (7%)]	Loss: 0.174477
Train Epoch: 41 [3200/35339 (9%)]	Loss: 0.139035
Train Epoch: 41 [3840/35339 (11%)]	Loss: 0.102086
Train Epoch: 41 [4480/35339 (13%)]	Loss: 0.165233
Train Epoch: 41 [5120/35339 (14%)]	Loss: 0.109496
Train Epoch: 41 [5760/35339 (16%)]	Loss: 0.182636
Train Epoch: 41 [6400/35339 (18%)]	Loss: 0.079813
Train Epoch: 41 [7040/35339 (20%)]	Loss: 0.138955
Train Epoch: 41 [7680/35339 (22%)]	Loss: 0.199178
Train Epoch: 41 [8320/35339 (24%)]	Loss: 0.091910
Train Epoch: 41 [8960/35339 (25%)]	Loss: 0.144905
Train Epoch: 41 [9600/35339 (27%)]	Loss: 0.127417
Train Epoch: 41 [10240/35339 (29%)]	Loss: 0.075014
Train Epoch: 41 [10880/35339 (31%)]	Loss: 0.182436
Train Epoch: 41 [11520/35339 (33%)]	Loss: 0.138921
Train Epoch: 41 [12160/35339 (34%)]	Loss: 0.089735
Train Epoch: 41 [12800/35339 (36%)]	Loss: 0.257996
Train Epoch: 41 [13440/35339 (38%)]	Loss: 0.210807
Train Epoch: 41 [14080/35339 (40%)]	Loss: 0.197652
Train Epoch: 41 [14720/35339 (42%)]	Loss: 0.184777
Train Epoch: 41 [15360/35339 (43%)]	Loss: 0.174915
Train Epoch: 41 [16000/35339 (45%)]	Loss: 0.071523
Train Epoch: 41 [16640/35339 (47%)]	Loss: 0.101883
Train Epoch: 41 [17280/35339 (49%)]	Loss: 0.086063
Train Epoch: 41 [17920/35339 (51%)]	Loss: 0.152863
Train Epoch: 41 [18560/35339 (52%)]	Loss: 0.083700
Train Epoch: 41 [19200/35339 (54%)]	Loss: 0.157262
Train Epoch: 41 [19840/35339 (56%)]	Loss: 0.147573
Train Epoch: 41 [20480/35339 (58%)]	Loss: 0.252634
Train Epoch: 41 [21120/35339 (60%)]	Loss: 0.126651
Train Epoch: 41 [21760/35339 (61%)]	Loss: 0.128183
Train Epoch: 41 [22400/35339 (63%)]	Loss: 0.184258
Train Epoch: 41 [23040/35339 (65%)]	Loss: 0.199664
Train Epoch: 41 [23680/35339 (67%)]	Loss: 0.076750
Train Epoch: 41 [24320/35339 (69%)]	Loss: 0.165757
Train Epoch: 41 [24960/35339 (71%)]	Loss: 0.172426
Train Epoch: 41 [25600/35339 (72%)]	Loss: 0.123364
Train Epoch: 41 [26240/35339 (74%)]	Loss: 0.076417
Train Epoch: 41 [26880/35339 (76%)]	Loss: 0.081867
Train Epoch: 41 [27520/35339 (78%)]	Loss: 0.086081
Train Epoch: 41 [28160/35339 (80%)]	Loss: 0.129294
Train Epoch: 41 [28800/35339 (81%)]	Loss: 0.130825
Train Epoch: 41 [29440/35339 (83%)]	Loss: 0.090526
Train Epoch: 41 [30080/35339 (85%)]	Loss: 0.083221
Train Epoch: 41 [30720/35339 (87%)]	Loss: 0.089729
Train Epoch: 41 [31360/35339 (89%)]	Loss: 0.090542
Train Epoch: 41 [32000/35339 (90%)]	Loss: 0.081957
Train Epoch: 41 [32640/35339 (92%)]	Loss: 0.148058
Train Epoch: 41 [33280/35339 (94%)]	Loss: 0.177292
Train Epoch: 41 [33920/35339 (96%)]	Loss: 0.166827
Train Epoch: 41 [34560/35339 (98%)]	Loss: 0.088652
Train Epoch: 41 [35200/35339 (99%)]	Loss: 0.146056

Validation set: Average loss: 3.0714, Accuracy: 1638/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 42 [0/35339 (0%)]	Loss: 0.118737
Train Epoch: 42 [640/35339 (2%)]	Loss: 0.095114
Train Epoch: 42 [1280/35339 (4%)]	Loss: 0.245130
Train Epoch: 42 [1920/35339 (5%)]	Loss: 0.170271
Train Epoch: 42 [2560/35339 (7%)]	Loss: 0.133392
Train Epoch: 42 [3200/35339 (9%)]	Loss: 0.089483
Train Epoch: 42 [3840/35339 (11%)]	Loss: 0.091120
Train Epoch: 42 [4480/35339 (13%)]	Loss: 0.080649
Train Epoch: 42 [5120/35339 (14%)]	Loss: 0.351663
Train Epoch: 42 [5760/35339 (16%)]	Loss: 0.205741
Train Epoch: 42 [6400/35339 (18%)]	Loss: 0.094636
Train Epoch: 42 [7040/35339 (20%)]	Loss: 0.093350
Train Epoch: 42 [7680/35339 (22%)]	Loss: 0.064101
Train Epoch: 42 [8320/35339 (24%)]	Loss: 0.088732
Train Epoch: 42 [8960/35339 (25%)]	Loss: 0.149684
Train Epoch: 42 [9600/35339 (27%)]	Loss: 0.135539
Train Epoch: 42 [10240/35339 (29%)]	Loss: 0.128122
Train Epoch: 42 [10880/35339 (31%)]	Loss: 0.087926
Train Epoch: 42 [11520/35339 (33%)]	Loss: 0.067147
Train Epoch: 42 [12160/35339 (34%)]	Loss: 0.132989
Train Epoch: 42 [12800/35339 (36%)]	Loss: 0.091668
Train Epoch: 42 [13440/35339 (38%)]	Loss: 0.144500
Train Epoch: 42 [14080/35339 (40%)]	Loss: 0.103335
Train Epoch: 42 [14720/35339 (42%)]	Loss: 0.241792
Train Epoch: 42 [15360/35339 (43%)]	Loss: 0.151067
Train Epoch: 42 [16000/35339 (45%)]	Loss: 0.131825
Train Epoch: 42 [16640/35339 (47%)]	Loss: 0.166722
Train Epoch: 42 [17280/35339 (49%)]	Loss: 0.084779
Train Epoch: 42 [17920/35339 (51%)]	Loss: 0.101347
Train Epoch: 42 [18560/35339 (52%)]	Loss: 0.122531
Train Epoch: 42 [19200/35339 (54%)]	Loss: 0.061627
Train Epoch: 42 [19840/35339 (56%)]	Loss: 0.085394
Train Epoch: 42 [20480/35339 (58%)]	Loss: 0.075938
Train Epoch: 42 [21120/35339 (60%)]	Loss: 0.126220
Train Epoch: 42 [21760/35339 (61%)]	Loss: 0.073573
Train Epoch: 42 [22400/35339 (63%)]	Loss: 0.081196
Train Epoch: 42 [23040/35339 (65%)]	Loss: 0.090129
Train Epoch: 42 [23680/35339 (67%)]	Loss: 0.075153
Train Epoch: 42 [24320/35339 (69%)]	Loss: 0.098069
Train Epoch: 42 [24960/35339 (71%)]	Loss: 0.249453
Train Epoch: 42 [25600/35339 (72%)]	Loss: 0.155417
Train Epoch: 42 [26240/35339 (74%)]	Loss: 0.152375
Train Epoch: 42 [26880/35339 (76%)]	Loss: 0.108180
Train Epoch: 42 [27520/35339 (78%)]	Loss: 0.120184
Train Epoch: 42 [28160/35339 (80%)]	Loss: 0.194598
Train Epoch: 42 [28800/35339 (81%)]	Loss: 0.086516
Train Epoch: 42 [29440/35339 (83%)]	Loss: 0.073406
Train Epoch: 42 [30080/35339 (85%)]	Loss: 0.117617
Train Epoch: 42 [30720/35339 (87%)]	Loss: 0.187649
Train Epoch: 42 [31360/35339 (89%)]	Loss: 0.067574
Train Epoch: 42 [32000/35339 (90%)]	Loss: 0.124571
Train Epoch: 42 [32640/35339 (92%)]	Loss: 0.064356
Train Epoch: 42 [33280/35339 (94%)]	Loss: 0.275368
Train Epoch: 42 [33920/35339 (96%)]	Loss: 0.166315
Train Epoch: 42 [34560/35339 (98%)]	Loss: 0.154922
Train Epoch: 42 [35200/35339 (99%)]	Loss: 0.128296

Validation set: Average loss: 2.9422, Accuracy: 1716/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 43 [0/35339 (0%)]	Loss: 0.131778
Train Epoch: 43 [640/35339 (2%)]	Loss: 0.282091
Train Epoch: 43 [1280/35339 (4%)]	Loss: 0.089281
Train Epoch: 43 [1920/35339 (5%)]	Loss: 0.090084
Train Epoch: 43 [2560/35339 (7%)]	Loss: 0.157853
Train Epoch: 43 [3200/35339 (9%)]	Loss: 0.158568
Train Epoch: 43 [3840/35339 (11%)]	Loss: 0.084780
Train Epoch: 43 [4480/35339 (13%)]	Loss: 0.094578
Train Epoch: 43 [5120/35339 (14%)]	Loss: 0.100088
Train Epoch: 43 [5760/35339 (16%)]	Loss: 0.167269
Train Epoch: 43 [6400/35339 (18%)]	Loss: 0.064994
Train Epoch: 43 [7040/35339 (20%)]	Loss: 0.178391
Train Epoch: 43 [7680/35339 (22%)]	Loss: 0.130715
Train Epoch: 43 [8320/35339 (24%)]	Loss: 0.119085
Train Epoch: 43 [8960/35339 (25%)]	Loss: 0.208118
Train Epoch: 43 [9600/35339 (27%)]	Loss: 0.087934
Train Epoch: 43 [10240/35339 (29%)]	Loss: 0.102017
Train Epoch: 43 [10880/35339 (31%)]	Loss: 0.088784
Train Epoch: 43 [11520/35339 (33%)]	Loss: 0.068905
Train Epoch: 43 [12160/35339 (34%)]	Loss: 0.077464
Train Epoch: 43 [12800/35339 (36%)]	Loss: 0.121361
Train Epoch: 43 [13440/35339 (38%)]	Loss: 0.224347
Train Epoch: 43 [14080/35339 (40%)]	Loss: 0.167209
Train Epoch: 43 [14720/35339 (42%)]	Loss: 0.071344
Train Epoch: 43 [15360/35339 (43%)]	Loss: 0.129352
Train Epoch: 43 [16000/35339 (45%)]	Loss: 0.186791
Train Epoch: 43 [16640/35339 (47%)]	Loss: 0.191281
Train Epoch: 43 [17280/35339 (49%)]	Loss: 0.069048
Train Epoch: 43 [17920/35339 (51%)]	Loss: 0.105187
Train Epoch: 43 [18560/35339 (52%)]	Loss: 0.110364
Train Epoch: 43 [19200/35339 (54%)]	Loss: 0.114127
Train Epoch: 43 [19840/35339 (56%)]	Loss: 0.095143
Train Epoch: 43 [20480/35339 (58%)]	Loss: 0.066752
Train Epoch: 43 [21120/35339 (60%)]	Loss: 0.117506
Train Epoch: 43 [21760/35339 (61%)]	Loss: 0.101611
Train Epoch: 43 [22400/35339 (63%)]	Loss: 0.102606
Train Epoch: 43 [23040/35339 (65%)]	Loss: 0.223164
Train Epoch: 43 [23680/35339 (67%)]	Loss: 0.088943
Train Epoch: 43 [24320/35339 (69%)]	Loss: 0.090388
Train Epoch: 43 [24960/35339 (71%)]	Loss: 0.107408
Train Epoch: 43 [25600/35339 (72%)]	Loss: 0.070926
Train Epoch: 43 [26240/35339 (74%)]	Loss: 0.108407
Train Epoch: 43 [26880/35339 (76%)]	Loss: 0.137726
Train Epoch: 43 [27520/35339 (78%)]	Loss: 0.129666
Train Epoch: 43 [28160/35339 (80%)]	Loss: 0.125581
Train Epoch: 43 [28800/35339 (81%)]	Loss: 0.118952
Train Epoch: 43 [29440/35339 (83%)]	Loss: 0.151660
Train Epoch: 43 [30080/35339 (85%)]	Loss: 0.233855
Train Epoch: 43 [30720/35339 (87%)]	Loss: 0.214163
Train Epoch: 43 [31360/35339 (89%)]	Loss: 0.261772
Train Epoch: 43 [32000/35339 (90%)]	Loss: 0.066430
Train Epoch: 43 [32640/35339 (92%)]	Loss: 0.097715
Train Epoch: 43 [33280/35339 (94%)]	Loss: 0.109213
Train Epoch: 43 [33920/35339 (96%)]	Loss: 0.100037
Train Epoch: 43 [34560/35339 (98%)]	Loss: 0.188224
Train Epoch: 43 [35200/35339 (99%)]	Loss: 0.086214

Validation set: Average loss: 3.0879, Accuracy: 1630/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 44 [0/35339 (0%)]	Loss: 0.108805
Train Epoch: 44 [640/35339 (2%)]	Loss: 0.116966
Train Epoch: 44 [1280/35339 (4%)]	Loss: 0.120251
Train Epoch: 44 [1920/35339 (5%)]	Loss: 0.075292
Train Epoch: 44 [2560/35339 (7%)]	Loss: 0.107835
Train Epoch: 44 [3200/35339 (9%)]	Loss: 0.074684
Train Epoch: 44 [3840/35339 (11%)]	Loss: 0.102235
Train Epoch: 44 [4480/35339 (13%)]	Loss: 0.108910
Train Epoch: 44 [5120/35339 (14%)]	Loss: 0.073118
Train Epoch: 44 [5760/35339 (16%)]	Loss: 0.167229
Train Epoch: 44 [6400/35339 (18%)]	Loss: 0.095751
Train Epoch: 44 [7040/35339 (20%)]	Loss: 0.097222
Train Epoch: 44 [7680/35339 (22%)]	Loss: 0.120030
Train Epoch: 44 [8320/35339 (24%)]	Loss: 0.097594
Train Epoch: 44 [8960/35339 (25%)]	Loss: 0.104064
Train Epoch: 44 [9600/35339 (27%)]	Loss: 0.071631
Train Epoch: 44 [10240/35339 (29%)]	Loss: 0.182488
Train Epoch: 44 [10880/35339 (31%)]	Loss: 0.137585
Train Epoch: 44 [11520/35339 (33%)]	Loss: 0.189289
Train Epoch: 44 [12160/35339 (34%)]	Loss: 0.070469
Train Epoch: 44 [12800/35339 (36%)]	Loss: 0.196472
Train Epoch: 44 [13440/35339 (38%)]	Loss: 0.091436
Train Epoch: 44 [14080/35339 (40%)]	Loss: 0.182817
Train Epoch: 44 [14720/35339 (42%)]	Loss: 0.087606
Train Epoch: 44 [15360/35339 (43%)]	Loss: 0.101046
Train Epoch: 44 [16000/35339 (45%)]	Loss: 0.129594
Train Epoch: 44 [16640/35339 (47%)]	Loss: 0.091493
Train Epoch: 44 [17280/35339 (49%)]	Loss: 0.178477
Train Epoch: 44 [17920/35339 (51%)]	Loss: 0.115328
Train Epoch: 44 [18560/35339 (52%)]	Loss: 0.248252
Train Epoch: 44 [19200/35339 (54%)]	Loss: 0.095831
Train Epoch: 44 [19840/35339 (56%)]	Loss: 0.094330
Train Epoch: 44 [20480/35339 (58%)]	Loss: 0.106195
Train Epoch: 44 [21120/35339 (60%)]	Loss: 0.189249
Train Epoch: 44 [21760/35339 (61%)]	Loss: 0.139234
Train Epoch: 44 [22400/35339 (63%)]	Loss: 0.067600
Train Epoch: 44 [23040/35339 (65%)]	Loss: 0.130571
Train Epoch: 44 [23680/35339 (67%)]	Loss: 0.114986
Train Epoch: 44 [24320/35339 (69%)]	Loss: 0.100251
Train Epoch: 44 [24960/35339 (71%)]	Loss: 0.159763
Train Epoch: 44 [25600/35339 (72%)]	Loss: 0.089618
Train Epoch: 44 [26240/35339 (74%)]	Loss: 0.093902
Train Epoch: 44 [26880/35339 (76%)]	Loss: 0.184435
Train Epoch: 44 [27520/35339 (78%)]	Loss: 0.128192
Train Epoch: 44 [28160/35339 (80%)]	Loss: 0.301373
Train Epoch: 44 [28800/35339 (81%)]	Loss: 0.067892
Train Epoch: 44 [29440/35339 (83%)]	Loss: 0.135247
Train Epoch: 44 [30080/35339 (85%)]	Loss: 0.084548
Train Epoch: 44 [30720/35339 (87%)]	Loss: 0.129369
Train Epoch: 44 [31360/35339 (89%)]	Loss: 0.158448
Train Epoch: 44 [32000/35339 (90%)]	Loss: 0.121417
Train Epoch: 44 [32640/35339 (92%)]	Loss: 0.131490
Train Epoch: 44 [33280/35339 (94%)]	Loss: 0.096711
Train Epoch: 44 [33920/35339 (96%)]	Loss: 0.077812
Train Epoch: 44 [34560/35339 (98%)]	Loss: 0.190233
Train Epoch: 44 [35200/35339 (99%)]	Loss: 0.114729

Validation set: Average loss: 2.9914, Accuracy: 1674/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 45 [0/35339 (0%)]	Loss: 0.171101
Train Epoch: 45 [640/35339 (2%)]	Loss: 0.114408
Train Epoch: 45 [1280/35339 (4%)]	Loss: 0.169216
Train Epoch: 45 [1920/35339 (5%)]	Loss: 0.130828
Train Epoch: 45 [2560/35339 (7%)]	Loss: 0.119819
Train Epoch: 45 [3200/35339 (9%)]	Loss: 0.161790
Train Epoch: 45 [3840/35339 (11%)]	Loss: 0.114062
Train Epoch: 45 [4480/35339 (13%)]	Loss: 0.141120
Train Epoch: 45 [5120/35339 (14%)]	Loss: 0.099170
Train Epoch: 45 [5760/35339 (16%)]	Loss: 0.079970
Train Epoch: 45 [6400/35339 (18%)]	Loss: 0.227099
Train Epoch: 45 [7040/35339 (20%)]	Loss: 0.132984
Train Epoch: 45 [7680/35339 (22%)]	Loss: 0.136806
Train Epoch: 45 [8320/35339 (24%)]	Loss: 0.135668
Train Epoch: 45 [8960/35339 (25%)]	Loss: 0.097214
Train Epoch: 45 [9600/35339 (27%)]	Loss: 0.218369
Train Epoch: 45 [10240/35339 (29%)]	Loss: 0.140241
Train Epoch: 45 [10880/35339 (31%)]	Loss: 0.146021
Train Epoch: 45 [11520/35339 (33%)]	Loss: 0.111260
Train Epoch: 45 [12160/35339 (34%)]	Loss: 0.275151
Train Epoch: 45 [12800/35339 (36%)]	Loss: 0.073214
Train Epoch: 45 [13440/35339 (38%)]	Loss: 0.121255
Train Epoch: 45 [14080/35339 (40%)]	Loss: 0.398601
Train Epoch: 45 [14720/35339 (42%)]	Loss: 0.120758
Train Epoch: 45 [15360/35339 (43%)]	Loss: 0.130962
Train Epoch: 45 [16000/35339 (45%)]	Loss: 0.076370
Train Epoch: 45 [16640/35339 (47%)]	Loss: 0.127734
Train Epoch: 45 [17280/35339 (49%)]	Loss: 0.116576
Train Epoch: 45 [17920/35339 (51%)]	Loss: 0.156558
Train Epoch: 45 [18560/35339 (52%)]	Loss: 0.091554
Train Epoch: 45 [19200/35339 (54%)]	Loss: 0.329500
Train Epoch: 45 [19840/35339 (56%)]	Loss: 0.150121
Train Epoch: 45 [20480/35339 (58%)]	Loss: 0.284368
Train Epoch: 45 [21120/35339 (60%)]	Loss: 0.084942
Train Epoch: 45 [21760/35339 (61%)]	Loss: 0.071959
Train Epoch: 45 [22400/35339 (63%)]	Loss: 0.088680
Train Epoch: 45 [23040/35339 (65%)]	Loss: 0.193784
Train Epoch: 45 [23680/35339 (67%)]	Loss: 0.105067
Train Epoch: 45 [24320/35339 (69%)]	Loss: 0.098175
Train Epoch: 45 [24960/35339 (71%)]	Loss: 0.185397
Train Epoch: 45 [25600/35339 (72%)]	Loss: 0.126098
Train Epoch: 45 [26240/35339 (74%)]	Loss: 0.094534
Train Epoch: 45 [26880/35339 (76%)]	Loss: 0.115582
Train Epoch: 45 [27520/35339 (78%)]	Loss: 0.094779
Train Epoch: 45 [28160/35339 (80%)]	Loss: 0.198426
Train Epoch: 45 [28800/35339 (81%)]	Loss: 0.115639
Train Epoch: 45 [29440/35339 (83%)]	Loss: 0.217179
Train Epoch: 45 [30080/35339 (85%)]	Loss: 0.176549
Train Epoch: 45 [30720/35339 (87%)]	Loss: 0.065735
Train Epoch: 45 [31360/35339 (89%)]	Loss: 0.085375
Train Epoch: 45 [32000/35339 (90%)]	Loss: 0.087543
Train Epoch: 45 [32640/35339 (92%)]	Loss: 0.074984
Train Epoch: 45 [33280/35339 (94%)]	Loss: 0.080499
Train Epoch: 45 [33920/35339 (96%)]	Loss: 0.114931
Train Epoch: 45 [34560/35339 (98%)]	Loss: 0.150936
Train Epoch: 45 [35200/35339 (99%)]	Loss: 0.169645

Validation set: Average loss: 2.8360, Accuracy: 1736/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 46 [0/35339 (0%)]	Loss: 0.119279
Train Epoch: 46 [640/35339 (2%)]	Loss: 0.076881
Train Epoch: 46 [1280/35339 (4%)]	Loss: 0.073474
Train Epoch: 46 [1920/35339 (5%)]	Loss: 0.085818
Train Epoch: 46 [2560/35339 (7%)]	Loss: 0.074821
Train Epoch: 46 [3200/35339 (9%)]	Loss: 0.172522
Train Epoch: 46 [3840/35339 (11%)]	Loss: 0.144386
Train Epoch: 46 [4480/35339 (13%)]	Loss: 0.083289
Train Epoch: 46 [5120/35339 (14%)]	Loss: 0.096680
Train Epoch: 46 [5760/35339 (16%)]	Loss: 0.126656
Train Epoch: 46 [6400/35339 (18%)]	Loss: 0.121162
Train Epoch: 46 [7040/35339 (20%)]	Loss: 0.267777
Train Epoch: 46 [7680/35339 (22%)]	Loss: 0.078627
Train Epoch: 46 [8320/35339 (24%)]	Loss: 0.181110
Train Epoch: 46 [8960/35339 (25%)]	Loss: 0.150371
Train Epoch: 46 [9600/35339 (27%)]	Loss: 0.168501
Train Epoch: 46 [10240/35339 (29%)]	Loss: 0.095062
Train Epoch: 46 [10880/35339 (31%)]	Loss: 0.115146
Train Epoch: 46 [11520/35339 (33%)]	Loss: 0.185568
Train Epoch: 46 [12160/35339 (34%)]	Loss: 0.120289
Train Epoch: 46 [12800/35339 (36%)]	Loss: 0.127621
Train Epoch: 46 [13440/35339 (38%)]	Loss: 0.140275
Train Epoch: 46 [14080/35339 (40%)]	Loss: 0.133467
Train Epoch: 46 [14720/35339 (42%)]	Loss: 0.100557
Train Epoch: 46 [15360/35339 (43%)]	Loss: 0.162796
Train Epoch: 46 [16000/35339 (45%)]	Loss: 0.074576
Train Epoch: 46 [16640/35339 (47%)]	Loss: 0.121787
Train Epoch: 46 [17280/35339 (49%)]	Loss: 0.081083
Train Epoch: 46 [17920/35339 (51%)]	Loss: 0.152573
Train Epoch: 46 [18560/35339 (52%)]	Loss: 0.070702
Train Epoch: 46 [19200/35339 (54%)]	Loss: 0.117996
Train Epoch: 46 [19840/35339 (56%)]	Loss: 0.099635
Train Epoch: 46 [20480/35339 (58%)]	Loss: 0.131876
Train Epoch: 46 [21120/35339 (60%)]	Loss: 0.142824
Train Epoch: 46 [21760/35339 (61%)]	Loss: 0.085077
Train Epoch: 46 [22400/35339 (63%)]	Loss: 0.095489
Train Epoch: 46 [23040/35339 (65%)]	Loss: 0.137758
Train Epoch: 46 [23680/35339 (67%)]	Loss: 0.105167
Train Epoch: 46 [24320/35339 (69%)]	Loss: 0.100147
Train Epoch: 46 [24960/35339 (71%)]	Loss: 0.247828
Train Epoch: 46 [25600/35339 (72%)]	Loss: 0.094889
Train Epoch: 46 [26240/35339 (74%)]	Loss: 0.109178
Train Epoch: 46 [26880/35339 (76%)]	Loss: 0.342700
Train Epoch: 46 [27520/35339 (78%)]	Loss: 0.158626
Train Epoch: 46 [28160/35339 (80%)]	Loss: 0.079432
Train Epoch: 46 [28800/35339 (81%)]	Loss: 0.140087
Train Epoch: 46 [29440/35339 (83%)]	Loss: 0.134310
Train Epoch: 46 [30080/35339 (85%)]	Loss: 0.118147
Train Epoch: 46 [30720/35339 (87%)]	Loss: 0.093761
Train Epoch: 46 [31360/35339 (89%)]	Loss: 0.143499
Train Epoch: 46 [32000/35339 (90%)]	Loss: 0.089660
Train Epoch: 46 [32640/35339 (92%)]	Loss: 0.096677
Train Epoch: 46 [33280/35339 (94%)]	Loss: 0.225810
Train Epoch: 46 [33920/35339 (96%)]	Loss: 0.097987
Train Epoch: 46 [34560/35339 (98%)]	Loss: 0.072542
Train Epoch: 46 [35200/35339 (99%)]	Loss: 0.195656

Validation set: Average loss: 2.9534, Accuracy: 1694/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 47 [0/35339 (0%)]	Loss: 0.151634
Train Epoch: 47 [640/35339 (2%)]	Loss: 0.115508
Train Epoch: 47 [1280/35339 (4%)]	Loss: 0.233756
Train Epoch: 47 [1920/35339 (5%)]	Loss: 0.143715
Train Epoch: 47 [2560/35339 (7%)]	Loss: 0.099022
Train Epoch: 47 [3200/35339 (9%)]	Loss: 0.141597
Train Epoch: 47 [3840/35339 (11%)]	Loss: 0.081041
Train Epoch: 47 [4480/35339 (13%)]	Loss: 0.183525
Train Epoch: 47 [5120/35339 (14%)]	Loss: 0.188473
Train Epoch: 47 [5760/35339 (16%)]	Loss: 0.185675
Train Epoch: 47 [6400/35339 (18%)]	Loss: 0.082511
Train Epoch: 47 [7040/35339 (20%)]	Loss: 0.111899
Train Epoch: 47 [7680/35339 (22%)]	Loss: 0.094684
Train Epoch: 47 [8320/35339 (24%)]	Loss: 0.215826
Train Epoch: 47 [8960/35339 (25%)]	Loss: 0.172171
Train Epoch: 47 [9600/35339 (27%)]	Loss: 0.108222
Train Epoch: 47 [10240/35339 (29%)]	Loss: 0.147627
Train Epoch: 47 [10880/35339 (31%)]	Loss: 0.118589
Train Epoch: 47 [11520/35339 (33%)]	Loss: 0.091381
Train Epoch: 47 [12160/35339 (34%)]	Loss: 0.092343
Train Epoch: 47 [12800/35339 (36%)]	Loss: 0.193002
Train Epoch: 47 [13440/35339 (38%)]	Loss: 0.117482
Train Epoch: 47 [14080/35339 (40%)]	Loss: 0.227498
Train Epoch: 47 [14720/35339 (42%)]	Loss: 0.101153
Train Epoch: 47 [15360/35339 (43%)]	Loss: 0.108448
Train Epoch: 47 [16000/35339 (45%)]	Loss: 0.068070
Train Epoch: 47 [16640/35339 (47%)]	Loss: 0.111684
Train Epoch: 47 [17280/35339 (49%)]	Loss: 0.086948
Train Epoch: 47 [17920/35339 (51%)]	Loss: 0.115265
Train Epoch: 47 [18560/35339 (52%)]	Loss: 0.361516
Train Epoch: 47 [19200/35339 (54%)]	Loss: 0.129419
Train Epoch: 47 [19840/35339 (56%)]	Loss: 0.078201
Train Epoch: 47 [20480/35339 (58%)]	Loss: 0.121009
Train Epoch: 47 [21120/35339 (60%)]	Loss: 0.176907
Train Epoch: 47 [21760/35339 (61%)]	Loss: 0.139805
Train Epoch: 47 [22400/35339 (63%)]	Loss: 0.117665
Train Epoch: 47 [23040/35339 (65%)]	Loss: 0.067376
Train Epoch: 47 [23680/35339 (67%)]	Loss: 0.141517
Train Epoch: 47 [24320/35339 (69%)]	Loss: 0.136497
Train Epoch: 47 [24960/35339 (71%)]	Loss: 0.163279
Train Epoch: 47 [25600/35339 (72%)]	Loss: 0.085044
Train Epoch: 47 [26240/35339 (74%)]	Loss: 0.158048
Train Epoch: 47 [26880/35339 (76%)]	Loss: 0.081618
Train Epoch: 47 [27520/35339 (78%)]	Loss: 0.086586
Train Epoch: 47 [28160/35339 (80%)]	Loss: 0.096584
Train Epoch: 47 [28800/35339 (81%)]	Loss: 0.115376
Train Epoch: 47 [29440/35339 (83%)]	Loss: 0.096788
Train Epoch: 47 [30080/35339 (85%)]	Loss: 0.185661
Train Epoch: 47 [30720/35339 (87%)]	Loss: 0.079891
Train Epoch: 47 [31360/35339 (89%)]	Loss: 0.085809
Train Epoch: 47 [32000/35339 (90%)]	Loss: 0.072859
Train Epoch: 47 [32640/35339 (92%)]	Loss: 0.182693
Train Epoch: 47 [33280/35339 (94%)]	Loss: 0.077771
Train Epoch: 47 [33920/35339 (96%)]	Loss: 0.107539
Train Epoch: 47 [34560/35339 (98%)]	Loss: 0.134738
Train Epoch: 47 [35200/35339 (99%)]	Loss: 0.073964

Validation set: Average loss: 3.0374, Accuracy: 1658/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 48 [0/35339 (0%)]	Loss: 0.093817
Train Epoch: 48 [640/35339 (2%)]	Loss: 0.149903
Train Epoch: 48 [1280/35339 (4%)]	Loss: 0.114506
Train Epoch: 48 [1920/35339 (5%)]	Loss: 0.192253
Train Epoch: 48 [2560/35339 (7%)]	Loss: 0.164132
Train Epoch: 48 [3200/35339 (9%)]	Loss: 0.168651
Train Epoch: 48 [3840/35339 (11%)]	Loss: 0.075904
Train Epoch: 48 [4480/35339 (13%)]	Loss: 0.080528
Train Epoch: 48 [5120/35339 (14%)]	Loss: 0.068789
Train Epoch: 48 [5760/35339 (16%)]	Loss: 0.122458
Train Epoch: 48 [6400/35339 (18%)]	Loss: 0.149559
Train Epoch: 48 [7040/35339 (20%)]	Loss: 0.074027
Train Epoch: 48 [7680/35339 (22%)]	Loss: 0.105927
Train Epoch: 48 [8320/35339 (24%)]	Loss: 0.090284
Train Epoch: 48 [8960/35339 (25%)]	Loss: 0.072834
Train Epoch: 48 [9600/35339 (27%)]	Loss: 0.135650
Train Epoch: 48 [10240/35339 (29%)]	Loss: 0.067444
Train Epoch: 48 [10880/35339 (31%)]	Loss: 0.109973
Train Epoch: 48 [11520/35339 (33%)]	Loss: 0.066638
Train Epoch: 48 [12160/35339 (34%)]	Loss: 0.070284
Train Epoch: 48 [12800/35339 (36%)]	Loss: 0.141761
Train Epoch: 48 [13440/35339 (38%)]	Loss: 0.061657
Train Epoch: 48 [14080/35339 (40%)]	Loss: 0.130734
Train Epoch: 48 [14720/35339 (42%)]	Loss: 0.131523
Train Epoch: 48 [15360/35339 (43%)]	Loss: 0.107136
Train Epoch: 48 [16000/35339 (45%)]	Loss: 0.097789
Train Epoch: 48 [16640/35339 (47%)]	Loss: 0.078688
Train Epoch: 48 [17280/35339 (49%)]	Loss: 0.145028
Train Epoch: 48 [17920/35339 (51%)]	Loss: 0.270277
Train Epoch: 48 [18560/35339 (52%)]	Loss: 0.219497
Train Epoch: 48 [19200/35339 (54%)]	Loss: 0.134917
Train Epoch: 48 [19840/35339 (56%)]	Loss: 0.093651
Train Epoch: 48 [20480/35339 (58%)]	Loss: 0.120952
Train Epoch: 48 [21120/35339 (60%)]	Loss: 0.110914
Train Epoch: 48 [21760/35339 (61%)]	Loss: 0.123594
Train Epoch: 48 [22400/35339 (63%)]	Loss: 0.103943
Train Epoch: 48 [23040/35339 (65%)]	Loss: 0.124353
Train Epoch: 48 [23680/35339 (67%)]	Loss: 0.119367
Train Epoch: 48 [24320/35339 (69%)]	Loss: 0.091488
Train Epoch: 48 [24960/35339 (71%)]	Loss: 0.215307
Train Epoch: 48 [25600/35339 (72%)]	Loss: 0.115662
Train Epoch: 48 [26240/35339 (74%)]	Loss: 0.148615
Train Epoch: 48 [26880/35339 (76%)]	Loss: 0.094454
Train Epoch: 48 [27520/35339 (78%)]	Loss: 0.130351
Train Epoch: 48 [28160/35339 (80%)]	Loss: 0.111449
Train Epoch: 48 [28800/35339 (81%)]	Loss: 0.163868
Train Epoch: 48 [29440/35339 (83%)]	Loss: 0.097788
Train Epoch: 48 [30080/35339 (85%)]	Loss: 0.145354
Train Epoch: 48 [30720/35339 (87%)]	Loss: 0.110047
Train Epoch: 48 [31360/35339 (89%)]	Loss: 0.551856
Train Epoch: 48 [32000/35339 (90%)]	Loss: 0.087922
Train Epoch: 48 [32640/35339 (92%)]	Loss: 0.168729
Train Epoch: 48 [33280/35339 (94%)]	Loss: 0.080685
Train Epoch: 48 [33920/35339 (96%)]	Loss: 0.115622
Train Epoch: 48 [34560/35339 (98%)]	Loss: 0.090872
Train Epoch: 48 [35200/35339 (99%)]	Loss: 0.093755

Validation set: Average loss: 3.0770, Accuracy: 1606/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 49 [0/35339 (0%)]	Loss: 0.111205
Train Epoch: 49 [640/35339 (2%)]	Loss: 0.068057
Train Epoch: 49 [1280/35339 (4%)]	Loss: 0.217800
Train Epoch: 49 [1920/35339 (5%)]	Loss: 0.364260
Train Epoch: 49 [2560/35339 (7%)]	Loss: 0.157995
Train Epoch: 49 [3200/35339 (9%)]	Loss: 0.297888
Train Epoch: 49 [3840/35339 (11%)]	Loss: 0.277120
Train Epoch: 49 [4480/35339 (13%)]	Loss: 0.174383
Train Epoch: 49 [5120/35339 (14%)]	Loss: 0.355123
Train Epoch: 49 [5760/35339 (16%)]	Loss: 0.173241
Train Epoch: 49 [6400/35339 (18%)]	Loss: 0.223180
Train Epoch: 49 [7040/35339 (20%)]	Loss: 0.138193
Train Epoch: 49 [7680/35339 (22%)]	Loss: 0.205138
Train Epoch: 49 [8320/35339 (24%)]	Loss: 0.126905
Train Epoch: 49 [8960/35339 (25%)]	Loss: 0.192607
Train Epoch: 49 [9600/35339 (27%)]	Loss: 0.322880
Train Epoch: 49 [10240/35339 (29%)]	Loss: 0.191392
Train Epoch: 49 [10880/35339 (31%)]	Loss: 0.116088
Train Epoch: 49 [11520/35339 (33%)]	Loss: 0.114265
Train Epoch: 49 [12160/35339 (34%)]	Loss: 0.104123
Train Epoch: 49 [12800/35339 (36%)]	Loss: 0.121798
Train Epoch: 49 [13440/35339 (38%)]	Loss: 0.178617
Train Epoch: 49 [14080/35339 (40%)]	Loss: 0.178585
Train Epoch: 49 [14720/35339 (42%)]	Loss: 0.142216
Train Epoch: 49 [15360/35339 (43%)]	Loss: 0.111730
Train Epoch: 49 [16000/35339 (45%)]	Loss: 0.130311
Train Epoch: 49 [16640/35339 (47%)]	Loss: 0.084347
Train Epoch: 49 [17280/35339 (49%)]	Loss: 0.127912
Train Epoch: 49 [17920/35339 (51%)]	Loss: 0.091080
Train Epoch: 49 [18560/35339 (52%)]	Loss: 0.142657
Train Epoch: 49 [19200/35339 (54%)]	Loss: 0.141380
Train Epoch: 49 [19840/35339 (56%)]	Loss: 0.114804
Train Epoch: 49 [20480/35339 (58%)]	Loss: 0.117756
Train Epoch: 49 [21120/35339 (60%)]	Loss: 0.216330
Train Epoch: 49 [21760/35339 (61%)]	Loss: 0.175182
Train Epoch: 49 [22400/35339 (63%)]	Loss: 0.238495
Train Epoch: 49 [23040/35339 (65%)]	Loss: 0.090830
Train Epoch: 49 [23680/35339 (67%)]	Loss: 0.248138
Train Epoch: 49 [24320/35339 (69%)]	Loss: 0.140789
Train Epoch: 49 [24960/35339 (71%)]	Loss: 0.209418
Train Epoch: 49 [25600/35339 (72%)]	Loss: 0.145246
Train Epoch: 49 [26240/35339 (74%)]	Loss: 0.107311
Train Epoch: 49 [26880/35339 (76%)]	Loss: 0.098269
Train Epoch: 49 [27520/35339 (78%)]	Loss: 0.172925
Train Epoch: 49 [28160/35339 (80%)]	Loss: 0.249351
Train Epoch: 49 [28800/35339 (81%)]	Loss: 0.192892
Train Epoch: 49 [29440/35339 (83%)]	Loss: 0.151616
Train Epoch: 49 [30080/35339 (85%)]	Loss: 0.066022
Train Epoch: 49 [30720/35339 (87%)]	Loss: 0.138092
Train Epoch: 49 [31360/35339 (89%)]	Loss: 0.127778
Train Epoch: 49 [32000/35339 (90%)]	Loss: 0.181594
Train Epoch: 49 [32640/35339 (92%)]	Loss: 0.177941
Train Epoch: 49 [33280/35339 (94%)]	Loss: 0.113687
Train Epoch: 49 [33920/35339 (96%)]	Loss: 0.145484
Train Epoch: 49 [34560/35339 (98%)]	Loss: 0.103116
Train Epoch: 49 [35200/35339 (99%)]	Loss: 0.139385

Validation set: Average loss: 3.0971, Accuracy: 1654/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 50 [0/35339 (0%)]	Loss: 0.161117
Train Epoch: 50 [640/35339 (2%)]	Loss: 0.119978
Train Epoch: 50 [1280/35339 (4%)]	Loss: 0.227530
Train Epoch: 50 [1920/35339 (5%)]	Loss: 0.248439
Train Epoch: 50 [2560/35339 (7%)]	Loss: 0.138044
Train Epoch: 50 [3200/35339 (9%)]	Loss: 0.173258
Train Epoch: 50 [3840/35339 (11%)]	Loss: 0.326075
Train Epoch: 50 [4480/35339 (13%)]	Loss: 0.151441
Train Epoch: 50 [5120/35339 (14%)]	Loss: 0.085933
Train Epoch: 50 [5760/35339 (16%)]	Loss: 0.251814
Train Epoch: 50 [6400/35339 (18%)]	Loss: 0.118403
Train Epoch: 50 [7040/35339 (20%)]	Loss: 0.183727
Train Epoch: 50 [7680/35339 (22%)]	Loss: 0.153448
Train Epoch: 50 [8320/35339 (24%)]	Loss: 0.167692
Train Epoch: 50 [8960/35339 (25%)]	Loss: 0.145872
Train Epoch: 50 [9600/35339 (27%)]	Loss: 0.149814
Train Epoch: 50 [10240/35339 (29%)]	Loss: 0.111842
Train Epoch: 50 [10880/35339 (31%)]	Loss: 0.064104
Train Epoch: 50 [11520/35339 (33%)]	Loss: 0.171808
Train Epoch: 50 [12160/35339 (34%)]	Loss: 0.132826
Train Epoch: 50 [12800/35339 (36%)]	Loss: 0.158328
Train Epoch: 50 [13440/35339 (38%)]	Loss: 0.158387
Train Epoch: 50 [14080/35339 (40%)]	Loss: 0.197477
Train Epoch: 50 [14720/35339 (42%)]	Loss: 0.118290
Train Epoch: 50 [15360/35339 (43%)]	Loss: 0.097363
Train Epoch: 50 [16000/35339 (45%)]	Loss: 0.081205
Train Epoch: 50 [16640/35339 (47%)]	Loss: 0.113349
Train Epoch: 50 [17280/35339 (49%)]	Loss: 0.174946
Train Epoch: 50 [17920/35339 (51%)]	Loss: 0.083353
Train Epoch: 50 [18560/35339 (52%)]	Loss: 0.128896
Train Epoch: 50 [19200/35339 (54%)]	Loss: 0.105035
Train Epoch: 50 [19840/35339 (56%)]	Loss: 0.105894
Train Epoch: 50 [20480/35339 (58%)]	Loss: 0.093185
Train Epoch: 50 [21120/35339 (60%)]	Loss: 0.080885
Train Epoch: 50 [21760/35339 (61%)]	Loss: 0.087642
Train Epoch: 50 [22400/35339 (63%)]	Loss: 0.343479
Train Epoch: 50 [23040/35339 (65%)]	Loss: 0.121490
Train Epoch: 50 [23680/35339 (67%)]	Loss: 0.112182
Train Epoch: 50 [24320/35339 (69%)]	Loss: 0.098037
Train Epoch: 50 [24960/35339 (71%)]	Loss: 0.151092
Train Epoch: 50 [25600/35339 (72%)]	Loss: 0.079540
Train Epoch: 50 [26240/35339 (74%)]	Loss: 0.136588
Train Epoch: 50 [26880/35339 (76%)]	Loss: 0.178801
Train Epoch: 50 [27520/35339 (78%)]	Loss: 0.124207
Train Epoch: 50 [28160/35339 (80%)]	Loss: 0.104638
Train Epoch: 50 [28800/35339 (81%)]	Loss: 0.359515
Train Epoch: 50 [29440/35339 (83%)]	Loss: 0.137330
Train Epoch: 50 [30080/35339 (85%)]	Loss: 0.226539
Train Epoch: 50 [30720/35339 (87%)]	Loss: 0.106164
Train Epoch: 50 [31360/35339 (89%)]	Loss: 0.102887
Train Epoch: 50 [32000/35339 (90%)]	Loss: 0.143598
Train Epoch: 50 [32640/35339 (92%)]	Loss: 0.096205
Train Epoch: 50 [33280/35339 (94%)]	Loss: 0.093154
Train Epoch: 50 [33920/35339 (96%)]	Loss: 0.176002
Train Epoch: 50 [34560/35339 (98%)]	Loss: 0.097345
Train Epoch: 50 [35200/35339 (99%)]	Loss: 0.608114

Validation set: Average loss: 2.9325, Accuracy: 1747/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 51 [0/35339 (0%)]	Loss: 0.104845
Train Epoch: 51 [640/35339 (2%)]	Loss: 0.197532
Train Epoch: 51 [1280/35339 (4%)]	Loss: 0.141969
Train Epoch: 51 [1920/35339 (5%)]	Loss: 0.162938
Train Epoch: 51 [2560/35339 (7%)]	Loss: 0.101658
Train Epoch: 51 [3200/35339 (9%)]	Loss: 0.190590
Train Epoch: 51 [3840/35339 (11%)]	Loss: 0.099459
Train Epoch: 51 [4480/35339 (13%)]	Loss: 0.121898
Train Epoch: 51 [5120/35339 (14%)]	Loss: 0.110346
Train Epoch: 51 [5760/35339 (16%)]	Loss: 0.134617
Train Epoch: 51 [6400/35339 (18%)]	Loss: 0.225596
Train Epoch: 51 [7040/35339 (20%)]	Loss: 0.346717
Train Epoch: 51 [7680/35339 (22%)]	Loss: 0.130137
Train Epoch: 51 [8320/35339 (24%)]	Loss: 0.189861
Train Epoch: 51 [8960/35339 (25%)]	Loss: 0.206184
Train Epoch: 51 [9600/35339 (27%)]	Loss: 0.275893
Train Epoch: 51 [10240/35339 (29%)]	Loss: 0.170258
Train Epoch: 51 [10880/35339 (31%)]	Loss: 0.102453
Train Epoch: 51 [11520/35339 (33%)]	Loss: 0.126464
Train Epoch: 51 [12160/35339 (34%)]	Loss: 0.079586
Train Epoch: 51 [12800/35339 (36%)]	Loss: 0.098027
Train Epoch: 51 [13440/35339 (38%)]	Loss: 0.123873
Train Epoch: 51 [14080/35339 (40%)]	Loss: 0.135504
Train Epoch: 51 [14720/35339 (42%)]	Loss: 0.070770
Train Epoch: 51 [15360/35339 (43%)]	Loss: 0.173703
Train Epoch: 51 [16000/35339 (45%)]	Loss: 0.070139
Train Epoch: 51 [16640/35339 (47%)]	Loss: 0.097417
Train Epoch: 51 [17280/35339 (49%)]	Loss: 0.177904
Train Epoch: 51 [17920/35339 (51%)]	Loss: 0.089871
Train Epoch: 51 [18560/35339 (52%)]	Loss: 0.142437
Train Epoch: 51 [19200/35339 (54%)]	Loss: 0.112813
Train Epoch: 51 [19840/35339 (56%)]	Loss: 0.073059
Train Epoch: 51 [20480/35339 (58%)]	Loss: 0.108217
Train Epoch: 51 [21120/35339 (60%)]	Loss: 0.122004
Train Epoch: 51 [21760/35339 (61%)]	Loss: 0.177140
Train Epoch: 51 [22400/35339 (63%)]	Loss: 0.082755
Train Epoch: 51 [23040/35339 (65%)]	Loss: 0.225163
Train Epoch: 51 [23680/35339 (67%)]	Loss: 0.268863
Train Epoch: 51 [24320/35339 (69%)]	Loss: 0.273471
Train Epoch: 51 [24960/35339 (71%)]	Loss: 0.100465
Train Epoch: 51 [25600/35339 (72%)]	Loss: 0.195627
Train Epoch: 51 [26240/35339 (74%)]	Loss: 0.205067
Train Epoch: 51 [26880/35339 (76%)]	Loss: 0.380268
Train Epoch: 51 [27520/35339 (78%)]	Loss: 0.076341
Train Epoch: 51 [28160/35339 (80%)]	Loss: 0.136342
Train Epoch: 51 [28800/35339 (81%)]	Loss: 0.089370
Train Epoch: 51 [29440/35339 (83%)]	Loss: 0.074812
Train Epoch: 51 [30080/35339 (85%)]	Loss: 0.202223
Train Epoch: 51 [30720/35339 (87%)]	Loss: 0.123686
Train Epoch: 51 [31360/35339 (89%)]	Loss: 0.181315
Train Epoch: 51 [32000/35339 (90%)]	Loss: 0.095430
Train Epoch: 51 [32640/35339 (92%)]	Loss: 0.113800
Train Epoch: 51 [33280/35339 (94%)]	Loss: 0.074189
Train Epoch: 51 [33920/35339 (96%)]	Loss: 0.109859
Train Epoch: 51 [34560/35339 (98%)]	Loss: 0.147857
Train Epoch: 51 [35200/35339 (99%)]	Loss: 0.268940

Validation set: Average loss: 3.1678, Accuracy: 1602/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 52 [0/35339 (0%)]	Loss: 0.088097
Train Epoch: 52 [640/35339 (2%)]	Loss: 0.072502
Train Epoch: 52 [1280/35339 (4%)]	Loss: 0.093331
Train Epoch: 52 [1920/35339 (5%)]	Loss: 0.088042
Train Epoch: 52 [2560/35339 (7%)]	Loss: 0.083750
Train Epoch: 52 [3200/35339 (9%)]	Loss: 0.126937
Train Epoch: 52 [3840/35339 (11%)]	Loss: 0.095270
Train Epoch: 52 [4480/35339 (13%)]	Loss: 0.225355
Train Epoch: 52 [5120/35339 (14%)]	Loss: 0.105343
Train Epoch: 52 [5760/35339 (16%)]	Loss: 0.095157
Train Epoch: 52 [6400/35339 (18%)]	Loss: 0.131469
Train Epoch: 52 [7040/35339 (20%)]	Loss: 0.087162
Train Epoch: 52 [7680/35339 (22%)]	Loss: 0.211592
Train Epoch: 52 [8320/35339 (24%)]	Loss: 0.094059
Train Epoch: 52 [8960/35339 (25%)]	Loss: 0.129499
Train Epoch: 52 [9600/35339 (27%)]	Loss: 0.169657
Train Epoch: 52 [10240/35339 (29%)]	Loss: 0.102636
Train Epoch: 52 [10880/35339 (31%)]	Loss: 0.166024
Train Epoch: 52 [11520/35339 (33%)]	Loss: 0.241450
Train Epoch: 52 [12160/35339 (34%)]	Loss: 0.077095
Train Epoch: 52 [12800/35339 (36%)]	Loss: 0.375506
Train Epoch: 52 [13440/35339 (38%)]	Loss: 0.131867
Train Epoch: 52 [14080/35339 (40%)]	Loss: 0.112625
Train Epoch: 52 [14720/35339 (42%)]	Loss: 0.159468
Train Epoch: 52 [15360/35339 (43%)]	Loss: 0.143214
Train Epoch: 52 [16000/35339 (45%)]	Loss: 0.109263
Train Epoch: 52 [16640/35339 (47%)]	Loss: 0.095727
Train Epoch: 52 [17280/35339 (49%)]	Loss: 0.080559
Train Epoch: 52 [17920/35339 (51%)]	Loss: 0.158216
Train Epoch: 52 [18560/35339 (52%)]	Loss: 0.082812
Train Epoch: 52 [19200/35339 (54%)]	Loss: 0.167751
Train Epoch: 52 [19840/35339 (56%)]	Loss: 0.092036
Train Epoch: 52 [20480/35339 (58%)]	Loss: 0.088518
Train Epoch: 52 [21120/35339 (60%)]	Loss: 0.141864
Train Epoch: 52 [21760/35339 (61%)]	Loss: 0.147060
Train Epoch: 52 [22400/35339 (63%)]	Loss: 0.086076
Train Epoch: 52 [23040/35339 (65%)]	Loss: 0.125389
Train Epoch: 52 [23680/35339 (67%)]	Loss: 0.083708
Train Epoch: 52 [24320/35339 (69%)]	Loss: 0.117899
Train Epoch: 52 [24960/35339 (71%)]	Loss: 0.198792
Train Epoch: 52 [25600/35339 (72%)]	Loss: 0.100290
Train Epoch: 52 [26240/35339 (74%)]	Loss: 0.142233
Train Epoch: 52 [26880/35339 (76%)]	Loss: 0.180596
Train Epoch: 52 [27520/35339 (78%)]	Loss: 0.112251
Train Epoch: 52 [28160/35339 (80%)]	Loss: 0.167037
Train Epoch: 52 [28800/35339 (81%)]	Loss: 0.097890
Train Epoch: 52 [29440/35339 (83%)]	Loss: 0.162396
Train Epoch: 52 [30080/35339 (85%)]	Loss: 0.192270
Train Epoch: 52 [30720/35339 (87%)]	Loss: 0.105758
Train Epoch: 52 [31360/35339 (89%)]	Loss: 0.091906
Train Epoch: 52 [32000/35339 (90%)]	Loss: 0.110603
Train Epoch: 52 [32640/35339 (92%)]	Loss: 0.200647
Train Epoch: 52 [33280/35339 (94%)]	Loss: 0.153781
Train Epoch: 52 [33920/35339 (96%)]	Loss: 0.159581
Train Epoch: 52 [34560/35339 (98%)]	Loss: 0.101642
Train Epoch: 52 [35200/35339 (99%)]	Loss: 0.127795

Validation set: Average loss: 2.8657, Accuracy: 1751/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 53 [0/35339 (0%)]	Loss: 0.109652
Train Epoch: 53 [640/35339 (2%)]	Loss: 0.100553
Train Epoch: 53 [1280/35339 (4%)]	Loss: 0.067676
Train Epoch: 53 [1920/35339 (5%)]	Loss: 0.177020
Train Epoch: 53 [2560/35339 (7%)]	Loss: 0.171511
Train Epoch: 53 [3200/35339 (9%)]	Loss: 0.140414
Train Epoch: 53 [3840/35339 (11%)]	Loss: 0.085467
Train Epoch: 53 [4480/35339 (13%)]	Loss: 0.107901
Train Epoch: 53 [5120/35339 (14%)]	Loss: 0.066426
Train Epoch: 53 [5760/35339 (16%)]	Loss: 0.132846
Train Epoch: 53 [6400/35339 (18%)]	Loss: 0.112269
Train Epoch: 53 [7040/35339 (20%)]	Loss: 0.094286
Train Epoch: 53 [7680/35339 (22%)]	Loss: 0.198867
Train Epoch: 53 [8320/35339 (24%)]	Loss: 0.182088
Train Epoch: 53 [8960/35339 (25%)]	Loss: 0.081307
Train Epoch: 53 [9600/35339 (27%)]	Loss: 0.132768
Train Epoch: 53 [10240/35339 (29%)]	Loss: 0.126288
Train Epoch: 53 [10880/35339 (31%)]	Loss: 0.106834
Train Epoch: 53 [11520/35339 (33%)]	Loss: 0.105809
Train Epoch: 53 [12160/35339 (34%)]	Loss: 0.102082
Train Epoch: 53 [12800/35339 (36%)]	Loss: 0.159163
Train Epoch: 53 [13440/35339 (38%)]	Loss: 0.222603
Train Epoch: 53 [14080/35339 (40%)]	Loss: 0.184040
Train Epoch: 53 [14720/35339 (42%)]	Loss: 0.093022
Train Epoch: 53 [15360/35339 (43%)]	Loss: 0.151296
Train Epoch: 53 [16000/35339 (45%)]	Loss: 0.078610
Train Epoch: 53 [16640/35339 (47%)]	Loss: 0.180186
Train Epoch: 53 [17280/35339 (49%)]	Loss: 0.082664
Train Epoch: 53 [17920/35339 (51%)]	Loss: 0.138984
Train Epoch: 53 [18560/35339 (52%)]	Loss: 0.117760
Train Epoch: 53 [19200/35339 (54%)]	Loss: 0.106475
Train Epoch: 53 [19840/35339 (56%)]	Loss: 0.108352
Train Epoch: 53 [20480/35339 (58%)]	Loss: 0.066052
Train Epoch: 53 [21120/35339 (60%)]	Loss: 0.311945
Train Epoch: 53 [21760/35339 (61%)]	Loss: 0.246639
Train Epoch: 53 [22400/35339 (63%)]	Loss: 0.115950
Train Epoch: 53 [23040/35339 (65%)]	Loss: 0.075774
Train Epoch: 53 [23680/35339 (67%)]	Loss: 0.099372
Train Epoch: 53 [24320/35339 (69%)]	Loss: 0.098460
Train Epoch: 53 [24960/35339 (71%)]	Loss: 0.094550
Train Epoch: 53 [25600/35339 (72%)]	Loss: 0.104695
Train Epoch: 53 [26240/35339 (74%)]	Loss: 0.154778
Train Epoch: 53 [26880/35339 (76%)]	Loss: 0.096422
Train Epoch: 53 [27520/35339 (78%)]	Loss: 0.140569
Train Epoch: 53 [28160/35339 (80%)]	Loss: 0.171175
Train Epoch: 53 [28800/35339 (81%)]	Loss: 0.125650
Train Epoch: 53 [29440/35339 (83%)]	Loss: 0.185023
Train Epoch: 53 [30080/35339 (85%)]	Loss: 0.091051
Train Epoch: 53 [30720/35339 (87%)]	Loss: 0.106314
Train Epoch: 53 [31360/35339 (89%)]	Loss: 0.210629
Train Epoch: 53 [32000/35339 (90%)]	Loss: 0.078820
Train Epoch: 53 [32640/35339 (92%)]	Loss: 0.179951
Train Epoch: 53 [33280/35339 (94%)]	Loss: 0.212991
Train Epoch: 53 [33920/35339 (96%)]	Loss: 0.151596
Train Epoch: 53 [34560/35339 (98%)]	Loss: 0.108872
Train Epoch: 53 [35200/35339 (99%)]	Loss: 0.182776

Validation set: Average loss: 3.0106, Accuracy: 1650/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 54 [0/35339 (0%)]	Loss: 0.082583
Train Epoch: 54 [640/35339 (2%)]	Loss: 0.143084
Train Epoch: 54 [1280/35339 (4%)]	Loss: 0.104436
Train Epoch: 54 [1920/35339 (5%)]	Loss: 0.168627
Train Epoch: 54 [2560/35339 (7%)]	Loss: 0.209893
Train Epoch: 54 [3200/35339 (9%)]	Loss: 0.109602
Train Epoch: 54 [3840/35339 (11%)]	Loss: 0.165551
Train Epoch: 54 [4480/35339 (13%)]	Loss: 0.104251
Train Epoch: 54 [5120/35339 (14%)]	Loss: 0.170253
Train Epoch: 54 [5760/35339 (16%)]	Loss: 0.082760
Train Epoch: 54 [6400/35339 (18%)]	Loss: 0.207423
Train Epoch: 54 [7040/35339 (20%)]	Loss: 0.113466
Train Epoch: 54 [7680/35339 (22%)]	Loss: 0.256066
Train Epoch: 54 [8320/35339 (24%)]	Loss: 0.131352
Train Epoch: 54 [8960/35339 (25%)]	Loss: 0.077397
Train Epoch: 54 [9600/35339 (27%)]	Loss: 0.137252
Train Epoch: 54 [10240/35339 (29%)]	Loss: 0.144363
Train Epoch: 54 [10880/35339 (31%)]	Loss: 0.108040
Train Epoch: 54 [11520/35339 (33%)]	Loss: 0.204421
Train Epoch: 54 [12160/35339 (34%)]	Loss: 0.077945
Train Epoch: 54 [12800/35339 (36%)]	Loss: 0.137923
Train Epoch: 54 [13440/35339 (38%)]	Loss: 0.171570
Train Epoch: 54 [14080/35339 (40%)]	Loss: 0.095878
Train Epoch: 54 [14720/35339 (42%)]	Loss: 0.110454
Train Epoch: 54 [15360/35339 (43%)]	Loss: 0.118569
Train Epoch: 54 [16000/35339 (45%)]	Loss: 0.090318
Train Epoch: 54 [16640/35339 (47%)]	Loss: 0.070229
Train Epoch: 54 [17280/35339 (49%)]	Loss: 0.098797
Train Epoch: 54 [17920/35339 (51%)]	Loss: 0.133768
Train Epoch: 54 [18560/35339 (52%)]	Loss: 0.129782
Train Epoch: 54 [19200/35339 (54%)]	Loss: 0.106915
Train Epoch: 54 [19840/35339 (56%)]	Loss: 0.122633
Train Epoch: 54 [20480/35339 (58%)]	Loss: 0.189784
Train Epoch: 54 [21120/35339 (60%)]	Loss: 0.090587
Train Epoch: 54 [21760/35339 (61%)]	Loss: 0.144436
Train Epoch: 54 [22400/35339 (63%)]	Loss: 0.128227
Train Epoch: 54 [23040/35339 (65%)]	Loss: 0.089202
Train Epoch: 54 [23680/35339 (67%)]	Loss: 0.111838
Train Epoch: 54 [24320/35339 (69%)]	Loss: 0.080964
Train Epoch: 54 [24960/35339 (71%)]	Loss: 0.158113
Train Epoch: 54 [25600/35339 (72%)]	Loss: 0.134008
Train Epoch: 54 [26240/35339 (74%)]	Loss: 0.230318
Train Epoch: 54 [26880/35339 (76%)]	Loss: 0.211666
Train Epoch: 54 [27520/35339 (78%)]	Loss: 0.092232
Train Epoch: 54 [28160/35339 (80%)]	Loss: 0.109785
Train Epoch: 54 [28800/35339 (81%)]	Loss: 0.474957
Train Epoch: 54 [29440/35339 (83%)]	Loss: 0.115799
Train Epoch: 54 [30080/35339 (85%)]	Loss: 0.242263
Train Epoch: 54 [30720/35339 (87%)]	Loss: 0.133802
Train Epoch: 54 [31360/35339 (89%)]	Loss: 0.166988
Train Epoch: 54 [32000/35339 (90%)]	Loss: 0.130352
Train Epoch: 54 [32640/35339 (92%)]	Loss: 0.080534
Train Epoch: 54 [33280/35339 (94%)]	Loss: 0.104257
Train Epoch: 54 [33920/35339 (96%)]	Loss: 0.154017
Train Epoch: 54 [34560/35339 (98%)]	Loss: 0.151213
Train Epoch: 54 [35200/35339 (99%)]	Loss: 0.105411

Validation set: Average loss: 3.0337, Accuracy: 1651/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 55 [0/35339 (0%)]	Loss: 0.088606
Train Epoch: 55 [640/35339 (2%)]	Loss: 0.086134
Train Epoch: 55 [1280/35339 (4%)]	Loss: 0.092831
Train Epoch: 55 [1920/35339 (5%)]	Loss: 0.078304
Train Epoch: 55 [2560/35339 (7%)]	Loss: 0.179604
Train Epoch: 55 [3200/35339 (9%)]	Loss: 0.117345
Train Epoch: 55 [3840/35339 (11%)]	Loss: 0.122167
Train Epoch: 55 [4480/35339 (13%)]	Loss: 0.159839
Train Epoch: 55 [5120/35339 (14%)]	Loss: 0.182172
Train Epoch: 55 [5760/35339 (16%)]	Loss: 0.076441
Train Epoch: 55 [6400/35339 (18%)]	Loss: 0.085586
Train Epoch: 55 [7040/35339 (20%)]	Loss: 0.181707
Train Epoch: 55 [7680/35339 (22%)]	Loss: 0.097038
Train Epoch: 55 [8320/35339 (24%)]	Loss: 0.163812
Train Epoch: 55 [8960/35339 (25%)]	Loss: 0.092933
Train Epoch: 55 [9600/35339 (27%)]	Loss: 0.083786
Train Epoch: 55 [10240/35339 (29%)]	Loss: 0.100059
Train Epoch: 55 [10880/35339 (31%)]	Loss: 0.125719
Train Epoch: 55 [11520/35339 (33%)]	Loss: 0.139017
Train Epoch: 55 [12160/35339 (34%)]	Loss: 0.098408
Train Epoch: 55 [12800/35339 (36%)]	Loss: 0.109963
Train Epoch: 55 [13440/35339 (38%)]	Loss: 0.245357
Train Epoch: 55 [14080/35339 (40%)]	Loss: 0.178784
Train Epoch: 55 [14720/35339 (42%)]	Loss: 0.101009
Train Epoch: 55 [15360/35339 (43%)]	Loss: 0.124072
Train Epoch: 55 [16000/35339 (45%)]	Loss: 0.111854
Train Epoch: 55 [16640/35339 (47%)]	Loss: 0.127040
Train Epoch: 55 [17280/35339 (49%)]	Loss: 0.091360
Train Epoch: 55 [17920/35339 (51%)]	Loss: 0.132041
Train Epoch: 55 [18560/35339 (52%)]	Loss: 0.096278
Train Epoch: 55 [19200/35339 (54%)]	Loss: 0.169134
Train Epoch: 55 [19840/35339 (56%)]	Loss: 0.066475
Train Epoch: 55 [20480/35339 (58%)]	Loss: 0.115973
Train Epoch: 55 [21120/35339 (60%)]	Loss: 0.084943
Train Epoch: 55 [21760/35339 (61%)]	Loss: 0.134248
Train Epoch: 55 [22400/35339 (63%)]	Loss: 0.089935
Train Epoch: 55 [23040/35339 (65%)]	Loss: 0.223528
Train Epoch: 55 [23680/35339 (67%)]	Loss: 0.087785
Train Epoch: 55 [24320/35339 (69%)]	Loss: 0.120723
Train Epoch: 55 [24960/35339 (71%)]	Loss: 0.116115
Train Epoch: 55 [25600/35339 (72%)]	Loss: 0.065438
Train Epoch: 55 [26240/35339 (74%)]	Loss: 0.136960
Train Epoch: 55 [26880/35339 (76%)]	Loss: 0.232990
Train Epoch: 55 [27520/35339 (78%)]	Loss: 0.089361
Train Epoch: 55 [28160/35339 (80%)]	Loss: 0.132504
Train Epoch: 55 [28800/35339 (81%)]	Loss: 0.127831
Train Epoch: 55 [29440/35339 (83%)]	Loss: 0.150322
Train Epoch: 55 [30080/35339 (85%)]	Loss: 0.086323
Train Epoch: 55 [30720/35339 (87%)]	Loss: 0.111999
Train Epoch: 55 [31360/35339 (89%)]	Loss: 0.139233
Train Epoch: 55 [32000/35339 (90%)]	Loss: 0.180097
Train Epoch: 55 [32640/35339 (92%)]	Loss: 0.142346
Train Epoch: 55 [33280/35339 (94%)]	Loss: 0.122589
Train Epoch: 55 [33920/35339 (96%)]	Loss: 0.129901
Train Epoch: 55 [34560/35339 (98%)]	Loss: 0.159940
Train Epoch: 55 [35200/35339 (99%)]	Loss: 0.095347

Validation set: Average loss: 3.1697, Accuracy: 1610/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 56 [0/35339 (0%)]	Loss: 0.107554
Train Epoch: 56 [640/35339 (2%)]	Loss: 0.084133
Train Epoch: 56 [1280/35339 (4%)]	Loss: 0.177059
Train Epoch: 56 [1920/35339 (5%)]	Loss: 0.173037
Train Epoch: 56 [2560/35339 (7%)]	Loss: 0.096668
Train Epoch: 56 [3200/35339 (9%)]	Loss: 0.161684
Train Epoch: 56 [3840/35339 (11%)]	Loss: 0.263377
Train Epoch: 56 [4480/35339 (13%)]	Loss: 0.192568
Train Epoch: 56 [5120/35339 (14%)]	Loss: 0.159620
Train Epoch: 56 [5760/35339 (16%)]	Loss: 0.137112
Train Epoch: 56 [6400/35339 (18%)]	Loss: 0.170048
Train Epoch: 56 [7040/35339 (20%)]	Loss: 0.158667
Train Epoch: 56 [7680/35339 (22%)]	Loss: 0.178988
Train Epoch: 56 [8320/35339 (24%)]	Loss: 0.137531
Train Epoch: 56 [8960/35339 (25%)]	Loss: 0.088305
Train Epoch: 56 [9600/35339 (27%)]	Loss: 0.065425
Train Epoch: 56 [10240/35339 (29%)]	Loss: 0.101903
Train Epoch: 56 [10880/35339 (31%)]	Loss: 0.122268
Train Epoch: 56 [11520/35339 (33%)]	Loss: 0.134017
Train Epoch: 56 [12160/35339 (34%)]	Loss: 0.066633
Train Epoch: 56 [12800/35339 (36%)]	Loss: 0.141216
Train Epoch: 56 [13440/35339 (38%)]	Loss: 0.093648
Train Epoch: 56 [14080/35339 (40%)]	Loss: 0.118745
Train Epoch: 56 [14720/35339 (42%)]	Loss: 0.151490
Train Epoch: 56 [15360/35339 (43%)]	Loss: 0.116856
Train Epoch: 56 [16000/35339 (45%)]	Loss: 0.080255
Train Epoch: 56 [16640/35339 (47%)]	Loss: 0.073896
Train Epoch: 56 [17280/35339 (49%)]	Loss: 0.108572
Train Epoch: 56 [17920/35339 (51%)]	Loss: 0.090017
Train Epoch: 56 [18560/35339 (52%)]	Loss: 0.104266
Train Epoch: 56 [19200/35339 (54%)]	Loss: 0.110254
Train Epoch: 56 [19840/35339 (56%)]	Loss: 0.104291
Train Epoch: 56 [20480/35339 (58%)]	Loss: 0.097423
Train Epoch: 56 [21120/35339 (60%)]	Loss: 0.091185
Train Epoch: 56 [21760/35339 (61%)]	Loss: 0.139309
Train Epoch: 56 [22400/35339 (63%)]	Loss: 0.182817
Train Epoch: 56 [23040/35339 (65%)]	Loss: 0.141582
Train Epoch: 56 [23680/35339 (67%)]	Loss: 0.144946
Train Epoch: 56 [24320/35339 (69%)]	Loss: 0.492592
Train Epoch: 56 [24960/35339 (71%)]	Loss: 0.108904
Train Epoch: 56 [25600/35339 (72%)]	Loss: 0.107205
Train Epoch: 56 [26240/35339 (74%)]	Loss: 0.151079
Train Epoch: 56 [26880/35339 (76%)]	Loss: 0.068554
Train Epoch: 56 [27520/35339 (78%)]	Loss: 0.199602
Train Epoch: 56 [28160/35339 (80%)]	Loss: 0.114155
Train Epoch: 56 [28800/35339 (81%)]	Loss: 0.136299
Train Epoch: 56 [29440/35339 (83%)]	Loss: 0.264344
Train Epoch: 56 [30080/35339 (85%)]	Loss: 0.118095
Train Epoch: 56 [30720/35339 (87%)]	Loss: 0.219763
Train Epoch: 56 [31360/35339 (89%)]	Loss: 0.176485
Train Epoch: 56 [32000/35339 (90%)]	Loss: 0.109417
Train Epoch: 56 [32640/35339 (92%)]	Loss: 0.099309
Train Epoch: 56 [33280/35339 (94%)]	Loss: 0.139494
Train Epoch: 56 [33920/35339 (96%)]	Loss: 0.089694
Train Epoch: 56 [34560/35339 (98%)]	Loss: 0.073300
Train Epoch: 56 [35200/35339 (99%)]	Loss: 0.096032

Validation set: Average loss: 2.9680, Accuracy: 1682/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 57 [0/35339 (0%)]	Loss: 0.084498
Train Epoch: 57 [640/35339 (2%)]	Loss: 0.067641
Train Epoch: 57 [1280/35339 (4%)]	Loss: 0.155824
Train Epoch: 57 [1920/35339 (5%)]	Loss: 0.131143
Train Epoch: 57 [2560/35339 (7%)]	Loss: 0.141634
Train Epoch: 57 [3200/35339 (9%)]	Loss: 0.108309
Train Epoch: 57 [3840/35339 (11%)]	Loss: 0.086473
Train Epoch: 57 [4480/35339 (13%)]	Loss: 0.231324
Train Epoch: 57 [5120/35339 (14%)]	Loss: 0.071412
Train Epoch: 57 [5760/35339 (16%)]	Loss: 0.104320
Train Epoch: 57 [6400/35339 (18%)]	Loss: 0.180826
Train Epoch: 57 [7040/35339 (20%)]	Loss: 0.069257
Train Epoch: 57 [7680/35339 (22%)]	Loss: 0.125138
Train Epoch: 57 [8320/35339 (24%)]	Loss: 0.261029
Train Epoch: 57 [8960/35339 (25%)]	Loss: 0.084263
Train Epoch: 57 [9600/35339 (27%)]	Loss: 0.066874
Train Epoch: 57 [10240/35339 (29%)]	Loss: 0.095358
Train Epoch: 57 [10880/35339 (31%)]	Loss: 0.087000
Train Epoch: 57 [11520/35339 (33%)]	Loss: 0.081186
Train Epoch: 57 [12160/35339 (34%)]	Loss: 0.145154
Train Epoch: 57 [12800/35339 (36%)]	Loss: 0.160040
Train Epoch: 57 [13440/35339 (38%)]	Loss: 0.293619
Train Epoch: 57 [14080/35339 (40%)]	Loss: 0.149807
Train Epoch: 57 [14720/35339 (42%)]	Loss: 0.086545
Train Epoch: 57 [15360/35339 (43%)]	Loss: 0.082938
Train Epoch: 57 [16000/35339 (45%)]	Loss: 0.081106
Train Epoch: 57 [16640/35339 (47%)]	Loss: 0.094584
Train Epoch: 57 [17280/35339 (49%)]	Loss: 0.155762
Train Epoch: 57 [17920/35339 (51%)]	Loss: 0.073779
Train Epoch: 57 [18560/35339 (52%)]	Loss: 0.146605
Train Epoch: 57 [19200/35339 (54%)]	Loss: 0.063143
Train Epoch: 57 [19840/35339 (56%)]	Loss: 0.062777
Train Epoch: 57 [20480/35339 (58%)]	Loss: 0.122682
Train Epoch: 57 [21120/35339 (60%)]	Loss: 0.074064
Train Epoch: 57 [21760/35339 (61%)]	Loss: 0.087764
Train Epoch: 57 [22400/35339 (63%)]	Loss: 0.083453
Train Epoch: 57 [23040/35339 (65%)]	Loss: 0.117968
Train Epoch: 57 [23680/35339 (67%)]	Loss: 0.342458
Train Epoch: 57 [24320/35339 (69%)]	Loss: 0.077403
Train Epoch: 57 [24960/35339 (71%)]	Loss: 0.165746
Train Epoch: 57 [25600/35339 (72%)]	Loss: 0.100443
Train Epoch: 57 [26240/35339 (74%)]	Loss: 0.099714
Train Epoch: 57 [26880/35339 (76%)]	Loss: 0.209670
Train Epoch: 57 [27520/35339 (78%)]	Loss: 0.146929
Train Epoch: 57 [28160/35339 (80%)]	Loss: 0.123696
Train Epoch: 57 [28800/35339 (81%)]	Loss: 0.174289
Train Epoch: 57 [29440/35339 (83%)]	Loss: 0.081552
Train Epoch: 57 [30080/35339 (85%)]	Loss: 0.174893
Train Epoch: 57 [30720/35339 (87%)]	Loss: 0.206128
Train Epoch: 57 [31360/35339 (89%)]	Loss: 0.190559
Train Epoch: 57 [32000/35339 (90%)]	Loss: 0.158904
Train Epoch: 57 [32640/35339 (92%)]	Loss: 0.223593
Train Epoch: 57 [33280/35339 (94%)]	Loss: 0.074828
Train Epoch: 57 [33920/35339 (96%)]	Loss: 0.096837
Train Epoch: 57 [34560/35339 (98%)]	Loss: 0.087985
Train Epoch: 57 [35200/35339 (99%)]	Loss: 0.109582

Validation set: Average loss: 2.8390, Accuracy: 1769/3870 (46%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 58 [0/35339 (0%)]	Loss: 0.101159
Train Epoch: 58 [640/35339 (2%)]	Loss: 0.186284
Train Epoch: 58 [1280/35339 (4%)]	Loss: 0.188781
Train Epoch: 58 [1920/35339 (5%)]	Loss: 0.099214
Train Epoch: 58 [2560/35339 (7%)]	Loss: 0.112291
Train Epoch: 58 [3200/35339 (9%)]	Loss: 0.085805
Train Epoch: 58 [3840/35339 (11%)]	Loss: 0.085431
Train Epoch: 58 [4480/35339 (13%)]	Loss: 0.096328
Train Epoch: 58 [5120/35339 (14%)]	Loss: 0.088496
Train Epoch: 58 [5760/35339 (16%)]	Loss: 0.080300
Train Epoch: 58 [6400/35339 (18%)]	Loss: 0.066485
Train Epoch: 58 [7040/35339 (20%)]	Loss: 0.302549
Train Epoch: 58 [7680/35339 (22%)]	Loss: 0.123752
Train Epoch: 58 [8320/35339 (24%)]	Loss: 0.069835
Train Epoch: 58 [8960/35339 (25%)]	Loss: 0.169325
Train Epoch: 58 [9600/35339 (27%)]	Loss: 0.135590
Train Epoch: 58 [10240/35339 (29%)]	Loss: 0.097899
Train Epoch: 58 [10880/35339 (31%)]	Loss: 0.096745
Train Epoch: 58 [11520/35339 (33%)]	Loss: 0.200687
Train Epoch: 58 [12160/35339 (34%)]	Loss: 0.108890
Train Epoch: 58 [12800/35339 (36%)]	Loss: 0.070953
Train Epoch: 58 [13440/35339 (38%)]	Loss: 0.083206
Train Epoch: 58 [14080/35339 (40%)]	Loss: 0.085865
Train Epoch: 58 [14720/35339 (42%)]	Loss: 0.079513
Train Epoch: 58 [15360/35339 (43%)]	Loss: 0.129626
Train Epoch: 58 [16000/35339 (45%)]	Loss: 0.097718
Train Epoch: 58 [16640/35339 (47%)]	Loss: 0.065798
Train Epoch: 58 [17280/35339 (49%)]	Loss: 0.124668
Train Epoch: 58 [17920/35339 (51%)]	Loss: 0.124531
Train Epoch: 58 [18560/35339 (52%)]	Loss: 0.190240
Train Epoch: 58 [19200/35339 (54%)]	Loss: 0.123021
Train Epoch: 58 [19840/35339 (56%)]	Loss: 0.180765
Train Epoch: 58 [20480/35339 (58%)]	Loss: 0.194388
Train Epoch: 58 [21120/35339 (60%)]	Loss: 0.333215
Train Epoch: 58 [21760/35339 (61%)]	Loss: 0.181118
Train Epoch: 58 [22400/35339 (63%)]	Loss: 0.154585
Train Epoch: 58 [23040/35339 (65%)]	Loss: 0.136827
Train Epoch: 58 [23680/35339 (67%)]	Loss: 0.112105
Train Epoch: 58 [24320/35339 (69%)]	Loss: 0.277753
Train Epoch: 58 [24960/35339 (71%)]	Loss: 0.101619
Train Epoch: 58 [25600/35339 (72%)]	Loss: 0.108281
Train Epoch: 58 [26240/35339 (74%)]	Loss: 0.119003
Train Epoch: 58 [26880/35339 (76%)]	Loss: 0.093531
Train Epoch: 58 [27520/35339 (78%)]	Loss: 0.120476
Train Epoch: 58 [28160/35339 (80%)]	Loss: 0.163659
Train Epoch: 58 [28800/35339 (81%)]	Loss: 0.068458
Train Epoch: 58 [29440/35339 (83%)]	Loss: 0.141039
Train Epoch: 58 [30080/35339 (85%)]	Loss: 0.077121
Train Epoch: 58 [30720/35339 (87%)]	Loss: 0.165729
Train Epoch: 58 [31360/35339 (89%)]	Loss: 0.118182
Train Epoch: 58 [32000/35339 (90%)]	Loss: 0.320136
Train Epoch: 58 [32640/35339 (92%)]	Loss: 0.153029
Train Epoch: 58 [33280/35339 (94%)]	Loss: 0.099028
Train Epoch: 58 [33920/35339 (96%)]	Loss: 0.165061
Train Epoch: 58 [34560/35339 (98%)]	Loss: 0.076392
Train Epoch: 58 [35200/35339 (99%)]	Loss: 0.064449

Validation set: Average loss: 3.0259, Accuracy: 1665/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 59 [0/35339 (0%)]	Loss: 0.123132
Train Epoch: 59 [640/35339 (2%)]	Loss: 0.081166
Train Epoch: 59 [1280/35339 (4%)]	Loss: 0.113527
Train Epoch: 59 [1920/35339 (5%)]	Loss: 0.120420
Train Epoch: 59 [2560/35339 (7%)]	Loss: 0.109428
Train Epoch: 59 [3200/35339 (9%)]	Loss: 0.293177
Train Epoch: 59 [3840/35339 (11%)]	Loss: 0.099446
Train Epoch: 59 [4480/35339 (13%)]	Loss: 0.112292
Train Epoch: 59 [5120/35339 (14%)]	Loss: 0.077940
Train Epoch: 59 [5760/35339 (16%)]	Loss: 0.092627
Train Epoch: 59 [6400/35339 (18%)]	Loss: 0.163261
Train Epoch: 59 [7040/35339 (20%)]	Loss: 0.160871
Train Epoch: 59 [7680/35339 (22%)]	Loss: 0.086538
Train Epoch: 59 [8320/35339 (24%)]	Loss: 0.191308
Train Epoch: 59 [8960/35339 (25%)]	Loss: 0.259102
Train Epoch: 59 [9600/35339 (27%)]	Loss: 0.191664
Train Epoch: 59 [10240/35339 (29%)]	Loss: 0.142068
Train Epoch: 59 [10880/35339 (31%)]	Loss: 0.090843
Train Epoch: 59 [11520/35339 (33%)]	Loss: 0.140127
Train Epoch: 59 [12160/35339 (34%)]	Loss: 0.188604
Train Epoch: 59 [12800/35339 (36%)]	Loss: 0.092518
Train Epoch: 59 [13440/35339 (38%)]	Loss: 0.156117
Train Epoch: 59 [14080/35339 (40%)]	Loss: 0.094879
Train Epoch: 59 [14720/35339 (42%)]	Loss: 0.160484
Train Epoch: 59 [15360/35339 (43%)]	Loss: 0.076671
Train Epoch: 59 [16000/35339 (45%)]	Loss: 0.131960
Train Epoch: 59 [16640/35339 (47%)]	Loss: 0.072195
Train Epoch: 59 [17280/35339 (49%)]	Loss: 0.166705
Train Epoch: 59 [17920/35339 (51%)]	Loss: 0.066913
Train Epoch: 59 [18560/35339 (52%)]	Loss: 0.147909
Train Epoch: 59 [19200/35339 (54%)]	Loss: 0.137729
Train Epoch: 59 [19840/35339 (56%)]	Loss: 0.144058
Train Epoch: 59 [20480/35339 (58%)]	Loss: 0.094863
Train Epoch: 59 [21120/35339 (60%)]	Loss: 0.166661
Train Epoch: 59 [21760/35339 (61%)]	Loss: 0.154883
Train Epoch: 59 [22400/35339 (63%)]	Loss: 0.092529
Train Epoch: 59 [23040/35339 (65%)]	Loss: 0.212084
Train Epoch: 59 [23680/35339 (67%)]	Loss: 0.119434
Train Epoch: 59 [24320/35339 (69%)]	Loss: 0.110494
Train Epoch: 59 [24960/35339 (71%)]	Loss: 0.113051
Train Epoch: 59 [25600/35339 (72%)]	Loss: 0.132358
Train Epoch: 59 [26240/35339 (74%)]	Loss: 0.229158
Train Epoch: 59 [26880/35339 (76%)]	Loss: 0.151553
Train Epoch: 59 [27520/35339 (78%)]	Loss: 0.092144
Train Epoch: 59 [28160/35339 (80%)]	Loss: 0.075839
Train Epoch: 59 [28800/35339 (81%)]	Loss: 0.088926
Train Epoch: 59 [29440/35339 (83%)]	Loss: 0.082279
Train Epoch: 59 [30080/35339 (85%)]	Loss: 0.103055
Train Epoch: 59 [30720/35339 (87%)]	Loss: 0.215292
Train Epoch: 59 [31360/35339 (89%)]	Loss: 0.079144
Train Epoch: 59 [32000/35339 (90%)]	Loss: 0.089383
Train Epoch: 59 [32640/35339 (92%)]	Loss: 0.110794
Train Epoch: 59 [33280/35339 (94%)]	Loss: 0.098052
Train Epoch: 59 [33920/35339 (96%)]	Loss: 0.075653
Train Epoch: 59 [34560/35339 (98%)]	Loss: 0.089975
Train Epoch: 59 [35200/35339 (99%)]	Loss: 0.123966

Validation set: Average loss: 3.0302, Accuracy: 1638/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 60 [0/35339 (0%)]	Loss: 0.243464
Train Epoch: 60 [640/35339 (2%)]	Loss: 0.123635
Train Epoch: 60 [1280/35339 (4%)]	Loss: 0.115948
Train Epoch: 60 [1920/35339 (5%)]	Loss: 0.132852
Train Epoch: 60 [2560/35339 (7%)]	Loss: 0.114485
Train Epoch: 60 [3200/35339 (9%)]	Loss: 0.113840
Train Epoch: 60 [3840/35339 (11%)]	Loss: 0.072013
Train Epoch: 60 [4480/35339 (13%)]	Loss: 0.116157
Train Epoch: 60 [5120/35339 (14%)]	Loss: 0.143768
Train Epoch: 60 [5760/35339 (16%)]	Loss: 0.105789
Train Epoch: 60 [6400/35339 (18%)]	Loss: 0.086399
Train Epoch: 60 [7040/35339 (20%)]	Loss: 0.148065
Train Epoch: 60 [7680/35339 (22%)]	Loss: 0.203737
Train Epoch: 60 [8320/35339 (24%)]	Loss: 0.097092
Train Epoch: 60 [8960/35339 (25%)]	Loss: 0.077923
Train Epoch: 60 [9600/35339 (27%)]	Loss: 0.095582
Train Epoch: 60 [10240/35339 (29%)]	Loss: 0.098808
Train Epoch: 60 [10880/35339 (31%)]	Loss: 0.175601
Train Epoch: 60 [11520/35339 (33%)]	Loss: 0.102589
Train Epoch: 60 [12160/35339 (34%)]	Loss: 0.128476
Train Epoch: 60 [12800/35339 (36%)]	Loss: 0.068659
Train Epoch: 60 [13440/35339 (38%)]	Loss: 0.177552
Train Epoch: 60 [14080/35339 (40%)]	Loss: 0.175836
Train Epoch: 60 [14720/35339 (42%)]	Loss: 0.149136
Train Epoch: 60 [15360/35339 (43%)]	Loss: 0.106131
Train Epoch: 60 [16000/35339 (45%)]	Loss: 0.188726
Train Epoch: 60 [16640/35339 (47%)]	Loss: 0.113393
Train Epoch: 60 [17280/35339 (49%)]	Loss: 0.166979
Train Epoch: 60 [17920/35339 (51%)]	Loss: 0.074336
Train Epoch: 60 [18560/35339 (52%)]	Loss: 0.186303
Train Epoch: 60 [19200/35339 (54%)]	Loss: 0.062538
Train Epoch: 60 [19840/35339 (56%)]	Loss: 0.092601
Train Epoch: 60 [20480/35339 (58%)]	Loss: 0.084257
Train Epoch: 60 [21120/35339 (60%)]	Loss: 0.065286
Train Epoch: 60 [21760/35339 (61%)]	Loss: 0.201540
Train Epoch: 60 [22400/35339 (63%)]	Loss: 0.136105
Train Epoch: 60 [23040/35339 (65%)]	Loss: 0.139112
Train Epoch: 60 [23680/35339 (67%)]	Loss: 0.085387
Train Epoch: 60 [24320/35339 (69%)]	Loss: 0.072148
Train Epoch: 60 [24960/35339 (71%)]	Loss: 0.149594
Train Epoch: 60 [25600/35339 (72%)]	Loss: 0.083421
Train Epoch: 60 [26240/35339 (74%)]	Loss: 0.182756
Train Epoch: 60 [26880/35339 (76%)]	Loss: 0.122118
Train Epoch: 60 [27520/35339 (78%)]	Loss: 0.146466
Train Epoch: 60 [28160/35339 (80%)]	Loss: 0.085841
Train Epoch: 60 [28800/35339 (81%)]	Loss: 0.165390
Train Epoch: 60 [29440/35339 (83%)]	Loss: 0.101494
Train Epoch: 60 [30080/35339 (85%)]	Loss: 0.150582
Train Epoch: 60 [30720/35339 (87%)]	Loss: 0.150479
Train Epoch: 60 [31360/35339 (89%)]	Loss: 0.173139
Train Epoch: 60 [32000/35339 (90%)]	Loss: 0.086600
Train Epoch: 60 [32640/35339 (92%)]	Loss: 0.128597
Train Epoch: 60 [33280/35339 (94%)]	Loss: 0.192647
Train Epoch: 60 [33920/35339 (96%)]	Loss: 0.094484
Train Epoch: 60 [34560/35339 (98%)]	Loss: 0.123177
Train Epoch: 60 [35200/35339 (99%)]	Loss: 0.251975

Validation set: Average loss: 3.0281, Accuracy: 1623/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 61 [0/35339 (0%)]	Loss: 0.193702
Train Epoch: 61 [640/35339 (2%)]	Loss: 0.090418
Train Epoch: 61 [1280/35339 (4%)]	Loss: 0.074900
Train Epoch: 61 [1920/35339 (5%)]	Loss: 0.085668
Train Epoch: 61 [2560/35339 (7%)]	Loss: 0.127493
Train Epoch: 61 [3200/35339 (9%)]	Loss: 0.116477
Train Epoch: 61 [3840/35339 (11%)]	Loss: 0.201932
Train Epoch: 61 [4480/35339 (13%)]	Loss: 0.112456
Train Epoch: 61 [5120/35339 (14%)]	Loss: 0.106738
Train Epoch: 61 [5760/35339 (16%)]	Loss: 0.136734
Train Epoch: 61 [6400/35339 (18%)]	Loss: 0.193404
Train Epoch: 61 [7040/35339 (20%)]	Loss: 0.221456
Train Epoch: 61 [7680/35339 (22%)]	Loss: 0.135421
Train Epoch: 61 [8320/35339 (24%)]	Loss: 0.071554
Train Epoch: 61 [8960/35339 (25%)]	Loss: 0.063253
Train Epoch: 61 [9600/35339 (27%)]	Loss: 0.071836
Train Epoch: 61 [10240/35339 (29%)]	Loss: 0.087661
Train Epoch: 61 [10880/35339 (31%)]	Loss: 0.110868
Train Epoch: 61 [11520/35339 (33%)]	Loss: 0.074008
Train Epoch: 61 [12160/35339 (34%)]	Loss: 0.150255
Train Epoch: 61 [12800/35339 (36%)]	Loss: 0.109821
Train Epoch: 61 [13440/35339 (38%)]	Loss: 0.142919
Train Epoch: 61 [14080/35339 (40%)]	Loss: 0.119485
Train Epoch: 61 [14720/35339 (42%)]	Loss: 0.092016
Train Epoch: 61 [15360/35339 (43%)]	Loss: 0.091992
Train Epoch: 61 [16000/35339 (45%)]	Loss: 0.067640
Train Epoch: 61 [16640/35339 (47%)]	Loss: 0.102619
Train Epoch: 61 [17280/35339 (49%)]	Loss: 0.113603
Train Epoch: 61 [17920/35339 (51%)]	Loss: 0.110407
Train Epoch: 61 [18560/35339 (52%)]	Loss: 0.080406
Train Epoch: 61 [19200/35339 (54%)]	Loss: 0.114577
Train Epoch: 61 [19840/35339 (56%)]	Loss: 0.099475
Train Epoch: 61 [20480/35339 (58%)]	Loss: 0.114223
Train Epoch: 61 [21120/35339 (60%)]	Loss: 0.184186
Train Epoch: 61 [21760/35339 (61%)]	Loss: 0.091100
Train Epoch: 61 [22400/35339 (63%)]	Loss: 0.161929
Train Epoch: 61 [23040/35339 (65%)]	Loss: 0.074519
Train Epoch: 61 [23680/35339 (67%)]	Loss: 0.163567
Train Epoch: 61 [24320/35339 (69%)]	Loss: 0.132861
Train Epoch: 61 [24960/35339 (71%)]	Loss: 0.151071
Train Epoch: 61 [25600/35339 (72%)]	Loss: 0.121965
Train Epoch: 61 [26240/35339 (74%)]	Loss: 0.199049
Train Epoch: 61 [26880/35339 (76%)]	Loss: 0.188404
Train Epoch: 61 [27520/35339 (78%)]	Loss: 0.088347
Train Epoch: 61 [28160/35339 (80%)]	Loss: 0.146164
Train Epoch: 61 [28800/35339 (81%)]	Loss: 0.106551
Train Epoch: 61 [29440/35339 (83%)]	Loss: 0.186056
Train Epoch: 61 [30080/35339 (85%)]	Loss: 0.113393
Train Epoch: 61 [30720/35339 (87%)]	Loss: 0.070965
Train Epoch: 61 [31360/35339 (89%)]	Loss: 0.070327
Train Epoch: 61 [32000/35339 (90%)]	Loss: 0.185336
Train Epoch: 61 [32640/35339 (92%)]	Loss: 0.066349
Train Epoch: 61 [33280/35339 (94%)]	Loss: 0.133118
Train Epoch: 61 [33920/35339 (96%)]	Loss: 0.130991
Train Epoch: 61 [34560/35339 (98%)]	Loss: 0.117242
Train Epoch: 61 [35200/35339 (99%)]	Loss: 0.143806

Validation set: Average loss: 3.0336, Accuracy: 1659/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 62 [0/35339 (0%)]	Loss: 0.083555
Train Epoch: 62 [640/35339 (2%)]	Loss: 0.129014
Train Epoch: 62 [1280/35339 (4%)]	Loss: 0.106033
Train Epoch: 62 [1920/35339 (5%)]	Loss: 0.166210
Train Epoch: 62 [2560/35339 (7%)]	Loss: 0.141950
Train Epoch: 62 [3200/35339 (9%)]	Loss: 0.100303
Train Epoch: 62 [3840/35339 (11%)]	Loss: 0.093653
Train Epoch: 62 [4480/35339 (13%)]	Loss: 0.137751
Train Epoch: 62 [5120/35339 (14%)]	Loss: 0.108941
Train Epoch: 62 [5760/35339 (16%)]	Loss: 0.119343
Train Epoch: 62 [6400/35339 (18%)]	Loss: 0.077938
Train Epoch: 62 [7040/35339 (20%)]	Loss: 0.086955
Train Epoch: 62 [7680/35339 (22%)]	Loss: 0.102879
Train Epoch: 62 [8320/35339 (24%)]	Loss: 0.072378
Train Epoch: 62 [8960/35339 (25%)]	Loss: 0.112493
Train Epoch: 62 [9600/35339 (27%)]	Loss: 0.111090
Train Epoch: 62 [10240/35339 (29%)]	Loss: 0.165722
Train Epoch: 62 [10880/35339 (31%)]	Loss: 0.121997
Train Epoch: 62 [11520/35339 (33%)]	Loss: 0.123035
Train Epoch: 62 [12160/35339 (34%)]	Loss: 0.068013
Train Epoch: 62 [12800/35339 (36%)]	Loss: 0.135182
Train Epoch: 62 [13440/35339 (38%)]	Loss: 0.095334
Train Epoch: 62 [14080/35339 (40%)]	Loss: 0.071279
Train Epoch: 62 [14720/35339 (42%)]	Loss: 0.101441
Train Epoch: 62 [15360/35339 (43%)]	Loss: 0.154127
Train Epoch: 62 [16000/35339 (45%)]	Loss: 0.104839
Train Epoch: 62 [16640/35339 (47%)]	Loss: 0.121074
Train Epoch: 62 [17280/35339 (49%)]	Loss: 0.065434
Train Epoch: 62 [17920/35339 (51%)]	Loss: 0.108249
Train Epoch: 62 [18560/35339 (52%)]	Loss: 0.080537
Train Epoch: 62 [19200/35339 (54%)]	Loss: 0.070611
Train Epoch: 62 [19840/35339 (56%)]	Loss: 0.169904
Train Epoch: 62 [20480/35339 (58%)]	Loss: 0.174240
Train Epoch: 62 [21120/35339 (60%)]	Loss: 0.060737
Train Epoch: 62 [21760/35339 (61%)]	Loss: 0.082871
Train Epoch: 62 [22400/35339 (63%)]	Loss: 0.076378
Train Epoch: 62 [23040/35339 (65%)]	Loss: 0.063201
Train Epoch: 62 [23680/35339 (67%)]	Loss: 0.134548
Train Epoch: 62 [24320/35339 (69%)]	Loss: 0.116712
Train Epoch: 62 [24960/35339 (71%)]	Loss: 0.134092
Train Epoch: 62 [25600/35339 (72%)]	Loss: 0.082815
Train Epoch: 62 [26240/35339 (74%)]	Loss: 0.112905
Train Epoch: 62 [26880/35339 (76%)]	Loss: 0.151426
Train Epoch: 62 [27520/35339 (78%)]	Loss: 0.083900
Train Epoch: 62 [28160/35339 (80%)]	Loss: 0.119137
Train Epoch: 62 [28800/35339 (81%)]	Loss: 0.120028
Train Epoch: 62 [29440/35339 (83%)]	Loss: 0.145646
Train Epoch: 62 [30080/35339 (85%)]	Loss: 0.153811
Train Epoch: 62 [30720/35339 (87%)]	Loss: 0.080262
Train Epoch: 62 [31360/35339 (89%)]	Loss: 0.131653
Train Epoch: 62 [32000/35339 (90%)]	Loss: 0.185387
Train Epoch: 62 [32640/35339 (92%)]	Loss: 0.111125
Train Epoch: 62 [33280/35339 (94%)]	Loss: 0.165027
Train Epoch: 62 [33920/35339 (96%)]	Loss: 0.084800
Train Epoch: 62 [34560/35339 (98%)]	Loss: 0.146756
Train Epoch: 62 [35200/35339 (99%)]	Loss: 0.096684

Validation set: Average loss: 3.1659, Accuracy: 1556/3870 (40%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 63 [0/35339 (0%)]	Loss: 0.083873
Train Epoch: 63 [640/35339 (2%)]	Loss: 0.112875
Train Epoch: 63 [1280/35339 (4%)]	Loss: 0.069829
Train Epoch: 63 [1920/35339 (5%)]	Loss: 0.068964
Train Epoch: 63 [2560/35339 (7%)]	Loss: 0.111186
Train Epoch: 63 [3200/35339 (9%)]	Loss: 0.449560
Train Epoch: 63 [3840/35339 (11%)]	Loss: 0.093790
Train Epoch: 63 [4480/35339 (13%)]	Loss: 0.130138
Train Epoch: 63 [5120/35339 (14%)]	Loss: 0.113204
Train Epoch: 63 [5760/35339 (16%)]	Loss: 0.095777
Train Epoch: 63 [6400/35339 (18%)]	Loss: 0.087533
Train Epoch: 63 [7040/35339 (20%)]	Loss: 0.127316
Train Epoch: 63 [7680/35339 (22%)]	Loss: 0.126975
Train Epoch: 63 [8320/35339 (24%)]	Loss: 0.140449
Train Epoch: 63 [8960/35339 (25%)]	Loss: 0.087964
Train Epoch: 63 [9600/35339 (27%)]	Loss: 0.062001
Train Epoch: 63 [10240/35339 (29%)]	Loss: 0.070307
Train Epoch: 63 [10880/35339 (31%)]	Loss: 0.102643
Train Epoch: 63 [11520/35339 (33%)]	Loss: 0.163672
Train Epoch: 63 [12160/35339 (34%)]	Loss: 0.068150
Train Epoch: 63 [12800/35339 (36%)]	Loss: 0.111941
Train Epoch: 63 [13440/35339 (38%)]	Loss: 0.105779
Train Epoch: 63 [14080/35339 (40%)]	Loss: 0.088145
Train Epoch: 63 [14720/35339 (42%)]	Loss: 0.112119
Train Epoch: 63 [15360/35339 (43%)]	Loss: 0.138099
Train Epoch: 63 [16000/35339 (45%)]	Loss: 0.129659
Train Epoch: 63 [16640/35339 (47%)]	Loss: 0.096246
Train Epoch: 63 [17280/35339 (49%)]	Loss: 0.105989
Train Epoch: 63 [17920/35339 (51%)]	Loss: 0.170133
Train Epoch: 63 [18560/35339 (52%)]	Loss: 0.077846
Train Epoch: 63 [19200/35339 (54%)]	Loss: 0.065683
Train Epoch: 63 [19840/35339 (56%)]	Loss: 0.064599
Train Epoch: 63 [20480/35339 (58%)]	Loss: 0.074099
Train Epoch: 63 [21120/35339 (60%)]	Loss: 0.159528
Train Epoch: 63 [21760/35339 (61%)]	Loss: 0.076132
Train Epoch: 63 [22400/35339 (63%)]	Loss: 0.075069
Train Epoch: 63 [23040/35339 (65%)]	Loss: 0.106893
Train Epoch: 63 [23680/35339 (67%)]	Loss: 0.062682
Train Epoch: 63 [24320/35339 (69%)]	Loss: 0.107465
Train Epoch: 63 [24960/35339 (71%)]	Loss: 0.065067
Train Epoch: 63 [25600/35339 (72%)]	Loss: 0.062531
Train Epoch: 63 [26240/35339 (74%)]	Loss: 0.156457
Train Epoch: 63 [26880/35339 (76%)]	Loss: 0.101816
Train Epoch: 63 [27520/35339 (78%)]	Loss: 0.066797
Train Epoch: 63 [28160/35339 (80%)]	Loss: 0.102771
Train Epoch: 63 [28800/35339 (81%)]	Loss: 0.097680
Train Epoch: 63 [29440/35339 (83%)]	Loss: 0.075375
Train Epoch: 63 [30080/35339 (85%)]	Loss: 0.108407
Train Epoch: 63 [30720/35339 (87%)]	Loss: 0.063415
Train Epoch: 63 [31360/35339 (89%)]	Loss: 0.102973
Train Epoch: 63 [32000/35339 (90%)]	Loss: 0.135908
Train Epoch: 63 [32640/35339 (92%)]	Loss: 0.084920
Train Epoch: 63 [33280/35339 (94%)]	Loss: 0.065548
Train Epoch: 63 [33920/35339 (96%)]	Loss: 0.126144
Train Epoch: 63 [34560/35339 (98%)]	Loss: 0.092160
Train Epoch: 63 [35200/35339 (99%)]	Loss: 0.130460

Validation set: Average loss: 3.1584, Accuracy: 1577/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 64 [0/35339 (0%)]	Loss: 0.082303
Train Epoch: 64 [640/35339 (2%)]	Loss: 0.080971
Train Epoch: 64 [1280/35339 (4%)]	Loss: 0.196682
Train Epoch: 64 [1920/35339 (5%)]	Loss: 0.166033
Train Epoch: 64 [2560/35339 (7%)]	Loss: 0.122205
Train Epoch: 64 [3200/35339 (9%)]	Loss: 0.132884
Train Epoch: 64 [3840/35339 (11%)]	Loss: 0.089042
Train Epoch: 64 [4480/35339 (13%)]	Loss: 0.116598
Train Epoch: 64 [5120/35339 (14%)]	Loss: 0.334212
Train Epoch: 64 [5760/35339 (16%)]	Loss: 0.173911
Train Epoch: 64 [6400/35339 (18%)]	Loss: 0.091843
Train Epoch: 64 [7040/35339 (20%)]	Loss: 0.127925
Train Epoch: 64 [7680/35339 (22%)]	Loss: 0.079014
Train Epoch: 64 [8320/35339 (24%)]	Loss: 0.070091
Train Epoch: 64 [8960/35339 (25%)]	Loss: 0.146118
Train Epoch: 64 [9600/35339 (27%)]	Loss: 0.122280
Train Epoch: 64 [10240/35339 (29%)]	Loss: 0.063967
Train Epoch: 64 [10880/35339 (31%)]	Loss: 0.169509
Train Epoch: 64 [11520/35339 (33%)]	Loss: 0.087184
Train Epoch: 64 [12160/35339 (34%)]	Loss: 0.066993
Train Epoch: 64 [12800/35339 (36%)]	Loss: 0.151653
Train Epoch: 64 [13440/35339 (38%)]	Loss: 0.079218
Train Epoch: 64 [14080/35339 (40%)]	Loss: 0.130083
Train Epoch: 64 [14720/35339 (42%)]	Loss: 0.099875
Train Epoch: 64 [15360/35339 (43%)]	Loss: 0.101115
Train Epoch: 64 [16000/35339 (45%)]	Loss: 0.067245
Train Epoch: 64 [16640/35339 (47%)]	Loss: 0.142591
Train Epoch: 64 [17280/35339 (49%)]	Loss: 0.126790
Train Epoch: 64 [17920/35339 (51%)]	Loss: 0.072053
Train Epoch: 64 [18560/35339 (52%)]	Loss: 0.118634
Train Epoch: 64 [19200/35339 (54%)]	Loss: 0.247693
Train Epoch: 64 [19840/35339 (56%)]	Loss: 0.144607
Train Epoch: 64 [20480/35339 (58%)]	Loss: 0.148746
Train Epoch: 64 [21120/35339 (60%)]	Loss: 0.194859
Train Epoch: 64 [21760/35339 (61%)]	Loss: 0.113668
Train Epoch: 64 [22400/35339 (63%)]	Loss: 0.154908
Train Epoch: 64 [23040/35339 (65%)]	Loss: 0.070231
Train Epoch: 64 [23680/35339 (67%)]	Loss: 0.076403
Train Epoch: 64 [24320/35339 (69%)]	Loss: 0.081989
Train Epoch: 64 [24960/35339 (71%)]	Loss: 0.345029
Train Epoch: 64 [25600/35339 (72%)]	Loss: 0.128367
Train Epoch: 64 [26240/35339 (74%)]	Loss: 0.167089
Train Epoch: 64 [26880/35339 (76%)]	Loss: 0.162088
Train Epoch: 64 [27520/35339 (78%)]	Loss: 0.091539
Train Epoch: 64 [28160/35339 (80%)]	Loss: 0.118359
Train Epoch: 64 [28800/35339 (81%)]	Loss: 0.152954
Train Epoch: 64 [29440/35339 (83%)]	Loss: 0.108468
Train Epoch: 64 [30080/35339 (85%)]	Loss: 0.094536
Train Epoch: 64 [30720/35339 (87%)]	Loss: 0.109301
Train Epoch: 64 [31360/35339 (89%)]	Loss: 0.113052
Train Epoch: 64 [32000/35339 (90%)]	Loss: 0.132283
Train Epoch: 64 [32640/35339 (92%)]	Loss: 0.097673
Train Epoch: 64 [33280/35339 (94%)]	Loss: 0.119498
Train Epoch: 64 [33920/35339 (96%)]	Loss: 0.066120
Train Epoch: 64 [34560/35339 (98%)]	Loss: 0.103835
Train Epoch: 64 [35200/35339 (99%)]	Loss: 0.107349

Validation set: Average loss: 3.0259, Accuracy: 1675/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 65 [0/35339 (0%)]	Loss: 0.139601
Train Epoch: 65 [640/35339 (2%)]	Loss: 0.184574
Train Epoch: 65 [1280/35339 (4%)]	Loss: 0.125970
Train Epoch: 65 [1920/35339 (5%)]	Loss: 0.111421
Train Epoch: 65 [2560/35339 (7%)]	Loss: 0.074214
Train Epoch: 65 [3200/35339 (9%)]	Loss: 0.072641
Train Epoch: 65 [3840/35339 (11%)]	Loss: 0.066266
Train Epoch: 65 [4480/35339 (13%)]	Loss: 0.132820
Train Epoch: 65 [5120/35339 (14%)]	Loss: 0.074509
Train Epoch: 65 [5760/35339 (16%)]	Loss: 0.111114
Train Epoch: 65 [6400/35339 (18%)]	Loss: 0.064644
Train Epoch: 65 [7040/35339 (20%)]	Loss: 0.110561
Train Epoch: 65 [7680/35339 (22%)]	Loss: 0.076018
Train Epoch: 65 [8320/35339 (24%)]	Loss: 0.087301
Train Epoch: 65 [8960/35339 (25%)]	Loss: 0.111298
Train Epoch: 65 [9600/35339 (27%)]	Loss: 0.104408
Train Epoch: 65 [10240/35339 (29%)]	Loss: 0.137574
Train Epoch: 65 [10880/35339 (31%)]	Loss: 0.069262
Train Epoch: 65 [11520/35339 (33%)]	Loss: 0.118669
Train Epoch: 65 [12160/35339 (34%)]	Loss: 0.111958
Train Epoch: 65 [12800/35339 (36%)]	Loss: 0.105546
Train Epoch: 65 [13440/35339 (38%)]	Loss: 0.069912
Train Epoch: 65 [14080/35339 (40%)]	Loss: 0.104631
Train Epoch: 65 [14720/35339 (42%)]	Loss: 0.129917
Train Epoch: 65 [15360/35339 (43%)]	Loss: 0.082845
Train Epoch: 65 [16000/35339 (45%)]	Loss: 0.128284
Train Epoch: 65 [16640/35339 (47%)]	Loss: 0.139619
Train Epoch: 65 [17280/35339 (49%)]	Loss: 0.077461
Train Epoch: 65 [17920/35339 (51%)]	Loss: 0.089440
Train Epoch: 65 [18560/35339 (52%)]	Loss: 0.096746
Train Epoch: 65 [19200/35339 (54%)]	Loss: 0.069978
Train Epoch: 65 [19840/35339 (56%)]	Loss: 0.102109
Train Epoch: 65 [20480/35339 (58%)]	Loss: 0.116076
Train Epoch: 65 [21120/35339 (60%)]	Loss: 0.071224
Train Epoch: 65 [21760/35339 (61%)]	Loss: 0.089173
Train Epoch: 65 [22400/35339 (63%)]	Loss: 0.123667
Train Epoch: 65 [23040/35339 (65%)]	Loss: 0.164880
Train Epoch: 65 [23680/35339 (67%)]	Loss: 0.066784
Train Epoch: 65 [24320/35339 (69%)]	Loss: 0.082563
Train Epoch: 65 [24960/35339 (71%)]	Loss: 0.113974
Train Epoch: 65 [25600/35339 (72%)]	Loss: 0.104447
Train Epoch: 65 [26240/35339 (74%)]	Loss: 0.136494
Train Epoch: 65 [26880/35339 (76%)]	Loss: 0.145703
Train Epoch: 65 [27520/35339 (78%)]	Loss: 0.103917
Train Epoch: 65 [28160/35339 (80%)]	Loss: 0.113809
Train Epoch: 65 [28800/35339 (81%)]	Loss: 0.177827
Train Epoch: 65 [29440/35339 (83%)]	Loss: 0.133426
Train Epoch: 65 [30080/35339 (85%)]	Loss: 0.109765
Train Epoch: 65 [30720/35339 (87%)]	Loss: 0.128148
Train Epoch: 65 [31360/35339 (89%)]	Loss: 0.126963
Train Epoch: 65 [32000/35339 (90%)]	Loss: 0.137860
Train Epoch: 65 [32640/35339 (92%)]	Loss: 0.148489
Train Epoch: 65 [33280/35339 (94%)]	Loss: 0.067267
Train Epoch: 65 [33920/35339 (96%)]	Loss: 0.168580
Train Epoch: 65 [34560/35339 (98%)]	Loss: 0.095695
Train Epoch: 65 [35200/35339 (99%)]	Loss: 0.098389

Validation set: Average loss: 3.1372, Accuracy: 1594/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 66 [0/35339 (0%)]	Loss: 0.102987
Train Epoch: 66 [640/35339 (2%)]	Loss: 0.135679
Train Epoch: 66 [1280/35339 (4%)]	Loss: 0.181552
Train Epoch: 66 [1920/35339 (5%)]	Loss: 0.086052
Train Epoch: 66 [2560/35339 (7%)]	Loss: 0.220800
Train Epoch: 66 [3200/35339 (9%)]	Loss: 0.083777
Train Epoch: 66 [3840/35339 (11%)]	Loss: 0.105288
Train Epoch: 66 [4480/35339 (13%)]	Loss: 0.076568
Train Epoch: 66 [5120/35339 (14%)]	Loss: 0.075153
Train Epoch: 66 [5760/35339 (16%)]	Loss: 0.141783
Train Epoch: 66 [6400/35339 (18%)]	Loss: 0.113992
Train Epoch: 66 [7040/35339 (20%)]	Loss: 0.067438
Train Epoch: 66 [7680/35339 (22%)]	Loss: 0.078426
Train Epoch: 66 [8320/35339 (24%)]	Loss: 0.070339
Train Epoch: 66 [8960/35339 (25%)]	Loss: 0.092350
Train Epoch: 66 [9600/35339 (27%)]	Loss: 0.074103
Train Epoch: 66 [10240/35339 (29%)]	Loss: 0.193203
Train Epoch: 66 [10880/35339 (31%)]	Loss: 0.181120
Train Epoch: 66 [11520/35339 (33%)]	Loss: 0.089291
Train Epoch: 66 [12160/35339 (34%)]	Loss: 0.111059
Train Epoch: 66 [12800/35339 (36%)]	Loss: 0.067198
Train Epoch: 66 [13440/35339 (38%)]	Loss: 0.162159
Train Epoch: 66 [14080/35339 (40%)]	Loss: 0.109816
Train Epoch: 66 [14720/35339 (42%)]	Loss: 0.121601
Train Epoch: 66 [15360/35339 (43%)]	Loss: 0.129757
Train Epoch: 66 [16000/35339 (45%)]	Loss: 0.172372
Train Epoch: 66 [16640/35339 (47%)]	Loss: 0.119527
Train Epoch: 66 [17280/35339 (49%)]	Loss: 0.172614
Train Epoch: 66 [17920/35339 (51%)]	Loss: 0.072466
Train Epoch: 66 [18560/35339 (52%)]	Loss: 0.124068
Train Epoch: 66 [19200/35339 (54%)]	Loss: 0.087148
Train Epoch: 66 [19840/35339 (56%)]	Loss: 0.089279
Train Epoch: 66 [20480/35339 (58%)]	Loss: 0.099150
Train Epoch: 66 [21120/35339 (60%)]	Loss: 0.135104
Train Epoch: 66 [21760/35339 (61%)]	Loss: 0.291218
Train Epoch: 66 [22400/35339 (63%)]	Loss: 0.156517
Train Epoch: 66 [23040/35339 (65%)]	Loss: 0.080010
Train Epoch: 66 [23680/35339 (67%)]	Loss: 0.069547
Train Epoch: 66 [24320/35339 (69%)]	Loss: 0.078833
Train Epoch: 66 [24960/35339 (71%)]	Loss: 0.104178
Train Epoch: 66 [25600/35339 (72%)]	Loss: 0.141339
Train Epoch: 66 [26240/35339 (74%)]	Loss: 0.172859
Train Epoch: 66 [26880/35339 (76%)]	Loss: 0.153625
Train Epoch: 66 [27520/35339 (78%)]	Loss: 0.072987
Train Epoch: 66 [28160/35339 (80%)]	Loss: 0.065765
Train Epoch: 66 [28800/35339 (81%)]	Loss: 0.095226
Train Epoch: 66 [29440/35339 (83%)]	Loss: 0.137656
Train Epoch: 66 [30080/35339 (85%)]	Loss: 0.108811
Train Epoch: 66 [30720/35339 (87%)]	Loss: 0.061720
Train Epoch: 66 [31360/35339 (89%)]	Loss: 0.132465
Train Epoch: 66 [32000/35339 (90%)]	Loss: 0.061794
Train Epoch: 66 [32640/35339 (92%)]	Loss: 0.095156
Train Epoch: 66 [33280/35339 (94%)]	Loss: 0.164448
Train Epoch: 66 [33920/35339 (96%)]	Loss: 0.090386
Train Epoch: 66 [34560/35339 (98%)]	Loss: 0.122634
Train Epoch: 66 [35200/35339 (99%)]	Loss: 0.370842

Validation set: Average loss: 2.9332, Accuracy: 1723/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 67 [0/35339 (0%)]	Loss: 0.110215
Train Epoch: 67 [640/35339 (2%)]	Loss: 0.147469
Train Epoch: 67 [1280/35339 (4%)]	Loss: 0.097462
Train Epoch: 67 [1920/35339 (5%)]	Loss: 0.106831
Train Epoch: 67 [2560/35339 (7%)]	Loss: 0.105940
Train Epoch: 67 [3200/35339 (9%)]	Loss: 0.114883
Train Epoch: 67 [3840/35339 (11%)]	Loss: 0.211135
Train Epoch: 67 [4480/35339 (13%)]	Loss: 0.087061
Train Epoch: 67 [5120/35339 (14%)]	Loss: 0.064931
Train Epoch: 67 [5760/35339 (16%)]	Loss: 0.085437
Train Epoch: 67 [6400/35339 (18%)]	Loss: 0.075508
Train Epoch: 67 [7040/35339 (20%)]	Loss: 0.092128
Train Epoch: 67 [7680/35339 (22%)]	Loss: 0.127642
Train Epoch: 67 [8320/35339 (24%)]	Loss: 0.156971
Train Epoch: 67 [8960/35339 (25%)]	Loss: 0.074684
Train Epoch: 67 [9600/35339 (27%)]	Loss: 0.228278
Train Epoch: 67 [10240/35339 (29%)]	Loss: 0.129987
Train Epoch: 67 [10880/35339 (31%)]	Loss: 0.122747
Train Epoch: 67 [11520/35339 (33%)]	Loss: 0.129086
Train Epoch: 67 [12160/35339 (34%)]	Loss: 0.075710
Train Epoch: 67 [12800/35339 (36%)]	Loss: 0.105855
Train Epoch: 67 [13440/35339 (38%)]	Loss: 0.286607
Train Epoch: 67 [14080/35339 (40%)]	Loss: 0.098872
Train Epoch: 67 [14720/35339 (42%)]	Loss: 0.083433
Train Epoch: 67 [15360/35339 (43%)]	Loss: 0.111212
Train Epoch: 67 [16000/35339 (45%)]	Loss: 0.077443
Train Epoch: 67 [16640/35339 (47%)]	Loss: 0.083550
Train Epoch: 67 [17280/35339 (49%)]	Loss: 0.076829
Train Epoch: 67 [17920/35339 (51%)]	Loss: 0.153673
Train Epoch: 67 [18560/35339 (52%)]	Loss: 0.064144
Train Epoch: 67 [19200/35339 (54%)]	Loss: 0.078848
Train Epoch: 67 [19840/35339 (56%)]	Loss: 0.141740
Train Epoch: 67 [20480/35339 (58%)]	Loss: 0.109020
Train Epoch: 67 [21120/35339 (60%)]	Loss: 0.159854
Train Epoch: 67 [21760/35339 (61%)]	Loss: 0.129363
Train Epoch: 67 [22400/35339 (63%)]	Loss: 0.148871
Train Epoch: 67 [23040/35339 (65%)]	Loss: 0.099005
Train Epoch: 67 [23680/35339 (67%)]	Loss: 0.101790
Train Epoch: 67 [24320/35339 (69%)]	Loss: 0.110568
Train Epoch: 67 [24960/35339 (71%)]	Loss: 0.086053
Train Epoch: 67 [25600/35339 (72%)]	Loss: 0.127143
Train Epoch: 67 [26240/35339 (74%)]	Loss: 0.127427
Train Epoch: 67 [26880/35339 (76%)]	Loss: 0.081204
Train Epoch: 67 [27520/35339 (78%)]	Loss: 0.154633
Train Epoch: 67 [28160/35339 (80%)]	Loss: 0.081039
Train Epoch: 67 [28800/35339 (81%)]	Loss: 0.109526
Train Epoch: 67 [29440/35339 (83%)]	Loss: 0.257325
Train Epoch: 67 [30080/35339 (85%)]	Loss: 0.116498
Train Epoch: 67 [30720/35339 (87%)]	Loss: 0.105641
Train Epoch: 67 [31360/35339 (89%)]	Loss: 0.087654
Train Epoch: 67 [32000/35339 (90%)]	Loss: 0.067861
Train Epoch: 67 [32640/35339 (92%)]	Loss: 0.078428
Train Epoch: 67 [33280/35339 (94%)]	Loss: 0.080496
Train Epoch: 67 [33920/35339 (96%)]	Loss: 0.146844
Train Epoch: 67 [34560/35339 (98%)]	Loss: 0.083235
Train Epoch: 67 [35200/35339 (99%)]	Loss: 0.075730

Validation set: Average loss: 3.0895, Accuracy: 1628/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 68 [0/35339 (0%)]	Loss: 0.075335
Train Epoch: 68 [640/35339 (2%)]	Loss: 0.066821
Train Epoch: 68 [1280/35339 (4%)]	Loss: 0.191450
Train Epoch: 68 [1920/35339 (5%)]	Loss: 0.163061
Train Epoch: 68 [2560/35339 (7%)]	Loss: 0.098414
Train Epoch: 68 [3200/35339 (9%)]	Loss: 0.082319
Train Epoch: 68 [3840/35339 (11%)]	Loss: 0.247050
Train Epoch: 68 [4480/35339 (13%)]	Loss: 0.141114
Train Epoch: 68 [5120/35339 (14%)]	Loss: 0.077322
Train Epoch: 68 [5760/35339 (16%)]	Loss: 0.109387
Train Epoch: 68 [6400/35339 (18%)]	Loss: 0.171172
Train Epoch: 68 [7040/35339 (20%)]	Loss: 0.156524
Train Epoch: 68 [7680/35339 (22%)]	Loss: 0.081978
Train Epoch: 68 [8320/35339 (24%)]	Loss: 0.122659
Train Epoch: 68 [8960/35339 (25%)]	Loss: 0.167031
Train Epoch: 68 [9600/35339 (27%)]	Loss: 0.071385
Train Epoch: 68 [10240/35339 (29%)]	Loss: 0.126642
Train Epoch: 68 [10880/35339 (31%)]	Loss: 0.070128
Train Epoch: 68 [11520/35339 (33%)]	Loss: 0.087504
Train Epoch: 68 [12160/35339 (34%)]	Loss: 0.105756
Train Epoch: 68 [12800/35339 (36%)]	Loss: 0.091735
Train Epoch: 68 [13440/35339 (38%)]	Loss: 0.080366
Train Epoch: 68 [14080/35339 (40%)]	Loss: 0.173256
Train Epoch: 68 [14720/35339 (42%)]	Loss: 0.075156
Train Epoch: 68 [15360/35339 (43%)]	Loss: 0.099056
Train Epoch: 68 [16000/35339 (45%)]	Loss: 0.369462
Train Epoch: 68 [16640/35339 (47%)]	Loss: 0.067569
Train Epoch: 68 [17280/35339 (49%)]	Loss: 0.112088
Train Epoch: 68 [17920/35339 (51%)]	Loss: 0.094640
Train Epoch: 68 [18560/35339 (52%)]	Loss: 0.061678
Train Epoch: 68 [19200/35339 (54%)]	Loss: 0.083063
Train Epoch: 68 [19840/35339 (56%)]	Loss: 0.194298
Train Epoch: 68 [20480/35339 (58%)]	Loss: 0.100631
Train Epoch: 68 [21120/35339 (60%)]	Loss: 0.100193
Train Epoch: 68 [21760/35339 (61%)]	Loss: 0.084376
Train Epoch: 68 [22400/35339 (63%)]	Loss: 0.084642
Train Epoch: 68 [23040/35339 (65%)]	Loss: 0.083490
Train Epoch: 68 [23680/35339 (67%)]	Loss: 0.072859
Train Epoch: 68 [24320/35339 (69%)]	Loss: 0.074714
Train Epoch: 68 [24960/35339 (71%)]	Loss: 0.072797
Train Epoch: 68 [25600/35339 (72%)]	Loss: 0.191907
Train Epoch: 68 [26240/35339 (74%)]	Loss: 0.199867
Train Epoch: 68 [26880/35339 (76%)]	Loss: 0.077480
Train Epoch: 68 [27520/35339 (78%)]	Loss: 0.076300
Train Epoch: 68 [28160/35339 (80%)]	Loss: 0.082378
Train Epoch: 68 [28800/35339 (81%)]	Loss: 0.112815
Train Epoch: 68 [29440/35339 (83%)]	Loss: 0.140564
Train Epoch: 68 [30080/35339 (85%)]	Loss: 0.089853
Train Epoch: 68 [30720/35339 (87%)]	Loss: 0.084386
Train Epoch: 68 [31360/35339 (89%)]	Loss: 0.089963
Train Epoch: 68 [32000/35339 (90%)]	Loss: 0.129104
Train Epoch: 68 [32640/35339 (92%)]	Loss: 0.089562
Train Epoch: 68 [33280/35339 (94%)]	Loss: 0.097743
Train Epoch: 68 [33920/35339 (96%)]	Loss: 0.061310
Train Epoch: 68 [34560/35339 (98%)]	Loss: 0.198960
Train Epoch: 68 [35200/35339 (99%)]	Loss: 0.069620

Validation set: Average loss: 2.9689, Accuracy: 1689/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 69 [0/35339 (0%)]	Loss: 0.117203
Train Epoch: 69 [640/35339 (2%)]	Loss: 0.146683
Train Epoch: 69 [1280/35339 (4%)]	Loss: 0.099208
Train Epoch: 69 [1920/35339 (5%)]	Loss: 0.060900
Train Epoch: 69 [2560/35339 (7%)]	Loss: 0.090253
Train Epoch: 69 [3200/35339 (9%)]	Loss: 0.406521
Train Epoch: 69 [3840/35339 (11%)]	Loss: 0.135938
Train Epoch: 69 [4480/35339 (13%)]	Loss: 0.069845
Train Epoch: 69 [5120/35339 (14%)]	Loss: 0.164478
Train Epoch: 69 [5760/35339 (16%)]	Loss: 0.147080
Train Epoch: 69 [6400/35339 (18%)]	Loss: 0.107487
Train Epoch: 69 [7040/35339 (20%)]	Loss: 0.063439
Train Epoch: 69 [7680/35339 (22%)]	Loss: 0.179481
Train Epoch: 69 [8320/35339 (24%)]	Loss: 0.147889
Train Epoch: 69 [8960/35339 (25%)]	Loss: 0.115104
Train Epoch: 69 [9600/35339 (27%)]	Loss: 0.177254
Train Epoch: 69 [10240/35339 (29%)]	Loss: 0.094182
Train Epoch: 69 [10880/35339 (31%)]	Loss: 0.088436
Train Epoch: 69 [11520/35339 (33%)]	Loss: 0.124003
Train Epoch: 69 [12160/35339 (34%)]	Loss: 0.092111
Train Epoch: 69 [12800/35339 (36%)]	Loss: 0.154012
Train Epoch: 69 [13440/35339 (38%)]	Loss: 0.069865
Train Epoch: 69 [14080/35339 (40%)]	Loss: 0.145885
Train Epoch: 69 [14720/35339 (42%)]	Loss: 0.142432
Train Epoch: 69 [15360/35339 (43%)]	Loss: 0.162006
Train Epoch: 69 [16000/35339 (45%)]	Loss: 0.196212
Train Epoch: 69 [16640/35339 (47%)]	Loss: 0.100752
Train Epoch: 69 [17280/35339 (49%)]	Loss: 0.086375
Train Epoch: 69 [17920/35339 (51%)]	Loss: 0.070642
Train Epoch: 69 [18560/35339 (52%)]	Loss: 0.254859
Train Epoch: 69 [19200/35339 (54%)]	Loss: 0.118480
Train Epoch: 69 [19840/35339 (56%)]	Loss: 0.125470
Train Epoch: 69 [20480/35339 (58%)]	Loss: 0.078591
Train Epoch: 69 [21120/35339 (60%)]	Loss: 0.127471
Train Epoch: 69 [21760/35339 (61%)]	Loss: 0.111724
Train Epoch: 69 [22400/35339 (63%)]	Loss: 0.120494
Train Epoch: 69 [23040/35339 (65%)]	Loss: 0.063127
Train Epoch: 69 [23680/35339 (67%)]	Loss: 0.066532
Train Epoch: 69 [24320/35339 (69%)]	Loss: 0.101426
Train Epoch: 69 [24960/35339 (71%)]	Loss: 0.063297
Train Epoch: 69 [25600/35339 (72%)]	Loss: 0.061537
Train Epoch: 69 [26240/35339 (74%)]	Loss: 0.092034
Train Epoch: 69 [26880/35339 (76%)]	Loss: 0.107446
Train Epoch: 69 [27520/35339 (78%)]	Loss: 0.164764
Train Epoch: 69 [28160/35339 (80%)]	Loss: 0.077612
Train Epoch: 69 [28800/35339 (81%)]	Loss: 0.138261
Train Epoch: 69 [29440/35339 (83%)]	Loss: 0.127714
Train Epoch: 69 [30080/35339 (85%)]	Loss: 0.066110
Train Epoch: 69 [30720/35339 (87%)]	Loss: 0.157992
Train Epoch: 69 [31360/35339 (89%)]	Loss: 0.081695
Train Epoch: 69 [32000/35339 (90%)]	Loss: 0.099577
Train Epoch: 69 [32640/35339 (92%)]	Loss: 0.100665
Train Epoch: 69 [33280/35339 (94%)]	Loss: 0.083117
Train Epoch: 69 [33920/35339 (96%)]	Loss: 0.099348
Train Epoch: 69 [34560/35339 (98%)]	Loss: 0.155883
Train Epoch: 69 [35200/35339 (99%)]	Loss: 0.081716

Validation set: Average loss: 3.0307, Accuracy: 1689/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 70 [0/35339 (0%)]	Loss: 0.076877
Train Epoch: 70 [640/35339 (2%)]	Loss: 0.137814
Train Epoch: 70 [1280/35339 (4%)]	Loss: 0.093732
Train Epoch: 70 [1920/35339 (5%)]	Loss: 0.162560
Train Epoch: 70 [2560/35339 (7%)]	Loss: 0.106985
Train Epoch: 70 [3200/35339 (9%)]	Loss: 0.093766
Train Epoch: 70 [3840/35339 (11%)]	Loss: 0.088838
Train Epoch: 70 [4480/35339 (13%)]	Loss: 0.086202
Train Epoch: 70 [5120/35339 (14%)]	Loss: 0.094013
Train Epoch: 70 [5760/35339 (16%)]	Loss: 0.078375
Train Epoch: 70 [6400/35339 (18%)]	Loss: 0.159055
Train Epoch: 70 [7040/35339 (20%)]	Loss: 0.082828
Train Epoch: 70 [7680/35339 (22%)]	Loss: 0.132126
Train Epoch: 70 [8320/35339 (24%)]	Loss: 0.101565
Train Epoch: 70 [8960/35339 (25%)]	Loss: 0.144987
Train Epoch: 70 [9600/35339 (27%)]	Loss: 0.232091
Train Epoch: 70 [10240/35339 (29%)]	Loss: 0.114050
Train Epoch: 70 [10880/35339 (31%)]	Loss: 0.109963
Train Epoch: 70 [11520/35339 (33%)]	Loss: 0.119202
Train Epoch: 70 [12160/35339 (34%)]	Loss: 0.098413
Train Epoch: 70 [12800/35339 (36%)]	Loss: 0.152204
Train Epoch: 70 [13440/35339 (38%)]	Loss: 0.140106
Train Epoch: 70 [14080/35339 (40%)]	Loss: 0.131817
Train Epoch: 70 [14720/35339 (42%)]	Loss: 0.087867
Train Epoch: 70 [15360/35339 (43%)]	Loss: 0.078519
Train Epoch: 70 [16000/35339 (45%)]	Loss: 0.067641
Train Epoch: 70 [16640/35339 (47%)]	Loss: 0.190544
Train Epoch: 70 [17280/35339 (49%)]	Loss: 0.076622
Train Epoch: 70 [17920/35339 (51%)]	Loss: 0.092088
Train Epoch: 70 [18560/35339 (52%)]	Loss: 0.236537
Train Epoch: 70 [19200/35339 (54%)]	Loss: 0.127865
Train Epoch: 70 [19840/35339 (56%)]	Loss: 0.084000
Train Epoch: 70 [20480/35339 (58%)]	Loss: 0.066845
Train Epoch: 70 [21120/35339 (60%)]	Loss: 0.152851
Train Epoch: 70 [21760/35339 (61%)]	Loss: 0.062227
Train Epoch: 70 [22400/35339 (63%)]	Loss: 0.083294
Train Epoch: 70 [23040/35339 (65%)]	Loss: 0.103043
Train Epoch: 70 [23680/35339 (67%)]	Loss: 0.141919
Train Epoch: 70 [24320/35339 (69%)]	Loss: 0.113640
Train Epoch: 70 [24960/35339 (71%)]	Loss: 0.077849
Train Epoch: 70 [25600/35339 (72%)]	Loss: 0.119486
Train Epoch: 70 [26240/35339 (74%)]	Loss: 0.095740
Train Epoch: 70 [26880/35339 (76%)]	Loss: 0.072010
Train Epoch: 70 [27520/35339 (78%)]	Loss: 0.088768
Train Epoch: 70 [28160/35339 (80%)]	Loss: 0.095011
Train Epoch: 70 [28800/35339 (81%)]	Loss: 0.104636
Train Epoch: 70 [29440/35339 (83%)]	Loss: 0.240715
Train Epoch: 70 [30080/35339 (85%)]	Loss: 0.077365
Train Epoch: 70 [30720/35339 (87%)]	Loss: 0.085384
Train Epoch: 70 [31360/35339 (89%)]	Loss: 0.150595
Train Epoch: 70 [32000/35339 (90%)]	Loss: 0.180586
Train Epoch: 70 [32640/35339 (92%)]	Loss: 0.140604
Train Epoch: 70 [33280/35339 (94%)]	Loss: 0.062126
Train Epoch: 70 [33920/35339 (96%)]	Loss: 0.099776
Train Epoch: 70 [34560/35339 (98%)]	Loss: 0.066733
Train Epoch: 70 [35200/35339 (99%)]	Loss: 0.076178

Validation set: Average loss: 2.9406, Accuracy: 1763/3870 (46%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 71 [0/35339 (0%)]	Loss: 0.153167
Train Epoch: 71 [640/35339 (2%)]	Loss: 0.118002
Train Epoch: 71 [1280/35339 (4%)]	Loss: 0.111224
Train Epoch: 71 [1920/35339 (5%)]	Loss: 0.096840
Train Epoch: 71 [2560/35339 (7%)]	Loss: 0.105077
Train Epoch: 71 [3200/35339 (9%)]	Loss: 0.093172
Train Epoch: 71 [3840/35339 (11%)]	Loss: 0.088855
Train Epoch: 71 [4480/35339 (13%)]	Loss: 0.078182
Train Epoch: 71 [5120/35339 (14%)]	Loss: 0.064296
Train Epoch: 71 [5760/35339 (16%)]	Loss: 0.106607
Train Epoch: 71 [6400/35339 (18%)]	Loss: 0.126699
Train Epoch: 71 [7040/35339 (20%)]	Loss: 0.112938
Train Epoch: 71 [7680/35339 (22%)]	Loss: 0.176502
Train Epoch: 71 [8320/35339 (24%)]	Loss: 0.098632
Train Epoch: 71 [8960/35339 (25%)]	Loss: 0.136094
Train Epoch: 71 [9600/35339 (27%)]	Loss: 0.064377
Train Epoch: 71 [10240/35339 (29%)]	Loss: 0.077899
Train Epoch: 71 [10880/35339 (31%)]	Loss: 0.068642
Train Epoch: 71 [11520/35339 (33%)]	Loss: 0.065910
Train Epoch: 71 [12160/35339 (34%)]	Loss: 0.152718
Train Epoch: 71 [12800/35339 (36%)]	Loss: 0.089223
Train Epoch: 71 [13440/35339 (38%)]	Loss: 0.143200
Train Epoch: 71 [14080/35339 (40%)]	Loss: 0.129623
Train Epoch: 71 [14720/35339 (42%)]	Loss: 0.301845
Train Epoch: 71 [15360/35339 (43%)]	Loss: 0.088229
Train Epoch: 71 [16000/35339 (45%)]	Loss: 0.147360
Train Epoch: 71 [16640/35339 (47%)]	Loss: 0.120607
Train Epoch: 71 [17280/35339 (49%)]	Loss: 0.141393
Train Epoch: 71 [17920/35339 (51%)]	Loss: 0.117323
Train Epoch: 71 [18560/35339 (52%)]	Loss: 0.090286
Train Epoch: 71 [19200/35339 (54%)]	Loss: 0.112586
Train Epoch: 71 [19840/35339 (56%)]	Loss: 0.090351
Train Epoch: 71 [20480/35339 (58%)]	Loss: 0.080158
Train Epoch: 71 [21120/35339 (60%)]	Loss: 0.097021
Train Epoch: 71 [21760/35339 (61%)]	Loss: 0.065979
Train Epoch: 71 [22400/35339 (63%)]	Loss: 0.069095
Train Epoch: 71 [23040/35339 (65%)]	Loss: 0.154147
Train Epoch: 71 [23680/35339 (67%)]	Loss: 0.081343
Train Epoch: 71 [24320/35339 (69%)]	Loss: 0.124729
Train Epoch: 71 [24960/35339 (71%)]	Loss: 0.154383
Train Epoch: 71 [25600/35339 (72%)]	Loss: 0.081343
Train Epoch: 71 [26240/35339 (74%)]	Loss: 0.103672
Train Epoch: 71 [26880/35339 (76%)]	Loss: 0.095994
Train Epoch: 71 [27520/35339 (78%)]	Loss: 0.067662
Train Epoch: 71 [28160/35339 (80%)]	Loss: 0.080743
Train Epoch: 71 [28800/35339 (81%)]	Loss: 0.139542
Train Epoch: 71 [29440/35339 (83%)]	Loss: 0.105975
Train Epoch: 71 [30080/35339 (85%)]	Loss: 0.090814
Train Epoch: 71 [30720/35339 (87%)]	Loss: 0.073512
Train Epoch: 71 [31360/35339 (89%)]	Loss: 0.082338
Train Epoch: 71 [32000/35339 (90%)]	Loss: 0.062698
Train Epoch: 71 [32640/35339 (92%)]	Loss: 0.062914
Train Epoch: 71 [33280/35339 (94%)]	Loss: 0.118091
Train Epoch: 71 [33920/35339 (96%)]	Loss: 0.075667
Train Epoch: 71 [34560/35339 (98%)]	Loss: 0.102242
Train Epoch: 71 [35200/35339 (99%)]	Loss: 0.132658

Validation set: Average loss: 3.2543, Accuracy: 1559/3870 (40%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 72 [0/35339 (0%)]	Loss: 0.158373
Train Epoch: 72 [640/35339 (2%)]	Loss: 0.087547
Train Epoch: 72 [1280/35339 (4%)]	Loss: 0.130495
Train Epoch: 72 [1920/35339 (5%)]	Loss: 0.176925
Train Epoch: 72 [2560/35339 (7%)]	Loss: 0.135819
Train Epoch: 72 [3200/35339 (9%)]	Loss: 0.105264
Train Epoch: 72 [3840/35339 (11%)]	Loss: 0.071495
Train Epoch: 72 [4480/35339 (13%)]	Loss: 0.068912
Train Epoch: 72 [5120/35339 (14%)]	Loss: 0.130543
Train Epoch: 72 [5760/35339 (16%)]	Loss: 0.124731
Train Epoch: 72 [6400/35339 (18%)]	Loss: 0.162276
Train Epoch: 72 [7040/35339 (20%)]	Loss: 0.089951
Train Epoch: 72 [7680/35339 (22%)]	Loss: 0.247802
Train Epoch: 72 [8320/35339 (24%)]	Loss: 0.082274
Train Epoch: 72 [8960/35339 (25%)]	Loss: 0.458305
Train Epoch: 72 [9600/35339 (27%)]	Loss: 0.178682
Train Epoch: 72 [10240/35339 (29%)]	Loss: 0.092762
Train Epoch: 72 [10880/35339 (31%)]	Loss: 0.159857
Train Epoch: 72 [11520/35339 (33%)]	Loss: 0.092646
Train Epoch: 72 [12160/35339 (34%)]	Loss: 0.083112
Train Epoch: 72 [12800/35339 (36%)]	Loss: 0.171176
Train Epoch: 72 [13440/35339 (38%)]	Loss: 0.092781
Train Epoch: 72 [14080/35339 (40%)]	Loss: 0.111170
Train Epoch: 72 [14720/35339 (42%)]	Loss: 0.099603
Train Epoch: 72 [15360/35339 (43%)]	Loss: 0.110441
Train Epoch: 72 [16000/35339 (45%)]	Loss: 0.203150
Train Epoch: 72 [16640/35339 (47%)]	Loss: 0.122423
Train Epoch: 72 [17280/35339 (49%)]	Loss: 0.144232
Train Epoch: 72 [17920/35339 (51%)]	Loss: 0.134907
Train Epoch: 72 [18560/35339 (52%)]	Loss: 0.101549
Train Epoch: 72 [19200/35339 (54%)]	Loss: 0.086409
Train Epoch: 72 [19840/35339 (56%)]	Loss: 0.127999
Train Epoch: 72 [20480/35339 (58%)]	Loss: 0.085835
Train Epoch: 72 [21120/35339 (60%)]	Loss: 0.077784
Train Epoch: 72 [21760/35339 (61%)]	Loss: 0.167869
Train Epoch: 72 [22400/35339 (63%)]	Loss: 0.088177
Train Epoch: 72 [23040/35339 (65%)]	Loss: 0.147913
Train Epoch: 72 [23680/35339 (67%)]	Loss: 0.112905
Train Epoch: 72 [24320/35339 (69%)]	Loss: 0.078564
Train Epoch: 72 [24960/35339 (71%)]	Loss: 0.085692
Train Epoch: 72 [25600/35339 (72%)]	Loss: 0.072299
Train Epoch: 72 [26240/35339 (74%)]	Loss: 0.109226
Train Epoch: 72 [26880/35339 (76%)]	Loss: 0.139190
Train Epoch: 72 [27520/35339 (78%)]	Loss: 0.108565
Train Epoch: 72 [28160/35339 (80%)]	Loss: 0.083380
Train Epoch: 72 [28800/35339 (81%)]	Loss: 0.195972
Train Epoch: 72 [29440/35339 (83%)]	Loss: 0.081826
Train Epoch: 72 [30080/35339 (85%)]	Loss: 0.133930
Train Epoch: 72 [30720/35339 (87%)]	Loss: 0.111350
Train Epoch: 72 [31360/35339 (89%)]	Loss: 0.116862
Train Epoch: 72 [32000/35339 (90%)]	Loss: 0.091208
Train Epoch: 72 [32640/35339 (92%)]	Loss: 0.116347
Train Epoch: 72 [33280/35339 (94%)]	Loss: 0.144315
Train Epoch: 72 [33920/35339 (96%)]	Loss: 0.121301
Train Epoch: 72 [34560/35339 (98%)]	Loss: 0.148996
Train Epoch: 72 [35200/35339 (99%)]	Loss: 0.133869

Validation set: Average loss: 3.0899, Accuracy: 1650/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 73 [0/35339 (0%)]	Loss: 0.153889
Train Epoch: 73 [640/35339 (2%)]	Loss: 0.066513
Train Epoch: 73 [1280/35339 (4%)]	Loss: 0.118110
Train Epoch: 73 [1920/35339 (5%)]	Loss: 0.082768
Train Epoch: 73 [2560/35339 (7%)]	Loss: 0.104644
Train Epoch: 73 [3200/35339 (9%)]	Loss: 0.160820
Train Epoch: 73 [3840/35339 (11%)]	Loss: 0.106921
Train Epoch: 73 [4480/35339 (13%)]	Loss: 0.116723
Train Epoch: 73 [5120/35339 (14%)]	Loss: 0.115217
Train Epoch: 73 [5760/35339 (16%)]	Loss: 0.089198
Train Epoch: 73 [6400/35339 (18%)]	Loss: 0.075417
Train Epoch: 73 [7040/35339 (20%)]	Loss: 0.112840
Train Epoch: 73 [7680/35339 (22%)]	Loss: 0.123174
Train Epoch: 73 [8320/35339 (24%)]	Loss: 0.069397
Train Epoch: 73 [8960/35339 (25%)]	Loss: 0.097280
Train Epoch: 73 [9600/35339 (27%)]	Loss: 0.185689
Train Epoch: 73 [10240/35339 (29%)]	Loss: 0.066292
Train Epoch: 73 [10880/35339 (31%)]	Loss: 0.086272
Train Epoch: 73 [11520/35339 (33%)]	Loss: 0.127033
Train Epoch: 73 [12160/35339 (34%)]	Loss: 0.071173
Train Epoch: 73 [12800/35339 (36%)]	Loss: 0.104441
Train Epoch: 73 [13440/35339 (38%)]	Loss: 0.112892
Train Epoch: 73 [14080/35339 (40%)]	Loss: 0.095213
Train Epoch: 73 [14720/35339 (42%)]	Loss: 0.119463
Train Epoch: 73 [15360/35339 (43%)]	Loss: 0.114497
Train Epoch: 73 [16000/35339 (45%)]	Loss: 0.068815
Train Epoch: 73 [16640/35339 (47%)]	Loss: 0.107107
Train Epoch: 73 [17280/35339 (49%)]	Loss: 0.187064
Train Epoch: 73 [17920/35339 (51%)]	Loss: 0.109770
Train Epoch: 73 [18560/35339 (52%)]	Loss: 0.114898
Train Epoch: 73 [19200/35339 (54%)]	Loss: 0.108711
Train Epoch: 73 [19840/35339 (56%)]	Loss: 0.271454
Train Epoch: 73 [20480/35339 (58%)]	Loss: 0.109508
Train Epoch: 73 [21120/35339 (60%)]	Loss: 0.191143
Train Epoch: 73 [21760/35339 (61%)]	Loss: 0.072407
Train Epoch: 73 [22400/35339 (63%)]	Loss: 0.066977
Train Epoch: 73 [23040/35339 (65%)]	Loss: 0.141258
Train Epoch: 73 [23680/35339 (67%)]	Loss: 0.111361
Train Epoch: 73 [24320/35339 (69%)]	Loss: 0.173611
Train Epoch: 73 [24960/35339 (71%)]	Loss: 0.089952
Train Epoch: 73 [25600/35339 (72%)]	Loss: 0.137192
Train Epoch: 73 [26240/35339 (74%)]	Loss: 0.066599
Train Epoch: 73 [26880/35339 (76%)]	Loss: 0.211361
Train Epoch: 73 [27520/35339 (78%)]	Loss: 0.090419
Train Epoch: 73 [28160/35339 (80%)]	Loss: 0.142811
Train Epoch: 73 [28800/35339 (81%)]	Loss: 0.098470
Train Epoch: 73 [29440/35339 (83%)]	Loss: 0.181062
Train Epoch: 73 [30080/35339 (85%)]	Loss: 0.157946
Train Epoch: 73 [30720/35339 (87%)]	Loss: 0.090815
Train Epoch: 73 [31360/35339 (89%)]	Loss: 0.128233
Train Epoch: 73 [32000/35339 (90%)]	Loss: 0.076105
Train Epoch: 73 [32640/35339 (92%)]	Loss: 0.134740
Train Epoch: 73 [33280/35339 (94%)]	Loss: 0.095033
Train Epoch: 73 [33920/35339 (96%)]	Loss: 0.262867
Train Epoch: 73 [34560/35339 (98%)]	Loss: 0.087902
Train Epoch: 73 [35200/35339 (99%)]	Loss: 0.079709

Validation set: Average loss: 2.9766, Accuracy: 1666/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 74 [0/35339 (0%)]	Loss: 0.117687
Train Epoch: 74 [640/35339 (2%)]	Loss: 0.106873
Train Epoch: 74 [1280/35339 (4%)]	Loss: 0.136627
Train Epoch: 74 [1920/35339 (5%)]	Loss: 0.181216
Train Epoch: 74 [2560/35339 (7%)]	Loss: 0.071386
Train Epoch: 74 [3200/35339 (9%)]	Loss: 0.088612
Train Epoch: 74 [3840/35339 (11%)]	Loss: 0.090570
Train Epoch: 74 [4480/35339 (13%)]	Loss: 0.071511
Train Epoch: 74 [5120/35339 (14%)]	Loss: 0.103275
Train Epoch: 74 [5760/35339 (16%)]	Loss: 0.070495
Train Epoch: 74 [6400/35339 (18%)]	Loss: 0.179634
Train Epoch: 74 [7040/35339 (20%)]	Loss: 0.110319
Train Epoch: 74 [7680/35339 (22%)]	Loss: 0.110180
Train Epoch: 74 [8320/35339 (24%)]	Loss: 0.080534
Train Epoch: 74 [8960/35339 (25%)]	Loss: 0.063773
Train Epoch: 74 [9600/35339 (27%)]	Loss: 0.101557
Train Epoch: 74 [10240/35339 (29%)]	Loss: 0.132053
Train Epoch: 74 [10880/35339 (31%)]	Loss: 0.104953
Train Epoch: 74 [11520/35339 (33%)]	Loss: 0.078850
Train Epoch: 74 [12160/35339 (34%)]	Loss: 0.072702
Train Epoch: 74 [12800/35339 (36%)]	Loss: 0.118002
Train Epoch: 74 [13440/35339 (38%)]	Loss: 0.099517
Train Epoch: 74 [14080/35339 (40%)]	Loss: 0.106697
Train Epoch: 74 [14720/35339 (42%)]	Loss: 0.181974
Train Epoch: 74 [15360/35339 (43%)]	Loss: 0.152702
Train Epoch: 74 [16000/35339 (45%)]	Loss: 0.126454
Train Epoch: 74 [16640/35339 (47%)]	Loss: 0.105551
Train Epoch: 74 [17280/35339 (49%)]	Loss: 0.119678
Train Epoch: 74 [17920/35339 (51%)]	Loss: 0.068822
Train Epoch: 74 [18560/35339 (52%)]	Loss: 0.071855
Train Epoch: 74 [19200/35339 (54%)]	Loss: 0.073805
Train Epoch: 74 [19840/35339 (56%)]	Loss: 0.118686
Train Epoch: 74 [20480/35339 (58%)]	Loss: 0.128085
Train Epoch: 74 [21120/35339 (60%)]	Loss: 0.089576
Train Epoch: 74 [21760/35339 (61%)]	Loss: 0.079953
Train Epoch: 74 [22400/35339 (63%)]	Loss: 0.073584
Train Epoch: 74 [23040/35339 (65%)]	Loss: 0.063678
Train Epoch: 74 [23680/35339 (67%)]	Loss: 0.301431
Train Epoch: 74 [24320/35339 (69%)]	Loss: 0.062650
Train Epoch: 74 [24960/35339 (71%)]	Loss: 0.063549
Train Epoch: 74 [25600/35339 (72%)]	Loss: 0.064411
Train Epoch: 74 [26240/35339 (74%)]	Loss: 0.142594
Train Epoch: 74 [26880/35339 (76%)]	Loss: 0.108097
Train Epoch: 74 [27520/35339 (78%)]	Loss: 0.090018
Train Epoch: 74 [28160/35339 (80%)]	Loss: 0.161142
Train Epoch: 74 [28800/35339 (81%)]	Loss: 0.127222
Train Epoch: 74 [29440/35339 (83%)]	Loss: 0.081481
Train Epoch: 74 [30080/35339 (85%)]	Loss: 0.237460
Train Epoch: 74 [30720/35339 (87%)]	Loss: 0.282816
Train Epoch: 74 [31360/35339 (89%)]	Loss: 0.157414
Train Epoch: 74 [32000/35339 (90%)]	Loss: 0.135045
Train Epoch: 74 [32640/35339 (92%)]	Loss: 0.117779
Train Epoch: 74 [33280/35339 (94%)]	Loss: 0.132534
Train Epoch: 74 [33920/35339 (96%)]	Loss: 0.082449
Train Epoch: 74 [34560/35339 (98%)]	Loss: 0.092925
Train Epoch: 74 [35200/35339 (99%)]	Loss: 0.090541

Validation set: Average loss: 3.0547, Accuracy: 1634/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 75 [0/35339 (0%)]	Loss: 0.147439
Train Epoch: 75 [640/35339 (2%)]	Loss: 0.097148
Train Epoch: 75 [1280/35339 (4%)]	Loss: 0.158631
Train Epoch: 75 [1920/35339 (5%)]	Loss: 0.062826
Train Epoch: 75 [2560/35339 (7%)]	Loss: 0.227539
Train Epoch: 75 [3200/35339 (9%)]	Loss: 0.128658
Train Epoch: 75 [3840/35339 (11%)]	Loss: 0.065932
Train Epoch: 75 [4480/35339 (13%)]	Loss: 0.078021
Train Epoch: 75 [5120/35339 (14%)]	Loss: 0.103974
Train Epoch: 75 [5760/35339 (16%)]	Loss: 0.153399
Train Epoch: 75 [6400/35339 (18%)]	Loss: 0.105471
Train Epoch: 75 [7040/35339 (20%)]	Loss: 0.123167
Train Epoch: 75 [7680/35339 (22%)]	Loss: 0.070382
Train Epoch: 75 [8320/35339 (24%)]	Loss: 0.086183
Train Epoch: 75 [8960/35339 (25%)]	Loss: 0.085325
Train Epoch: 75 [9600/35339 (27%)]	Loss: 0.218877
Train Epoch: 75 [10240/35339 (29%)]	Loss: 0.081559
Train Epoch: 75 [10880/35339 (31%)]	Loss: 0.074353
Train Epoch: 75 [11520/35339 (33%)]	Loss: 0.142293
Train Epoch: 75 [12160/35339 (34%)]	Loss: 0.073431
Train Epoch: 75 [12800/35339 (36%)]	Loss: 0.115663
Train Epoch: 75 [13440/35339 (38%)]	Loss: 0.120068
Train Epoch: 75 [14080/35339 (40%)]	Loss: 0.072632
Train Epoch: 75 [14720/35339 (42%)]	Loss: 0.095878
Train Epoch: 75 [15360/35339 (43%)]	Loss: 0.170237
Train Epoch: 75 [16000/35339 (45%)]	Loss: 0.082788
Train Epoch: 75 [16640/35339 (47%)]	Loss: 0.120183
Train Epoch: 75 [17280/35339 (49%)]	Loss: 0.104717
Train Epoch: 75 [17920/35339 (51%)]	Loss: 0.236003
Train Epoch: 75 [18560/35339 (52%)]	Loss: 0.085740
Train Epoch: 75 [19200/35339 (54%)]	Loss: 0.071527
Train Epoch: 75 [19840/35339 (56%)]	Loss: 0.061017
Train Epoch: 75 [20480/35339 (58%)]	Loss: 0.203409
Train Epoch: 75 [21120/35339 (60%)]	Loss: 0.160201
Train Epoch: 75 [21760/35339 (61%)]	Loss: 0.140484
Train Epoch: 75 [22400/35339 (63%)]	Loss: 0.063367
Train Epoch: 75 [23040/35339 (65%)]	Loss: 0.093205
Train Epoch: 75 [23680/35339 (67%)]	Loss: 0.154398
Train Epoch: 75 [24320/35339 (69%)]	Loss: 0.139461
Train Epoch: 75 [24960/35339 (71%)]	Loss: 0.091673
Train Epoch: 75 [25600/35339 (72%)]	Loss: 0.089440
Train Epoch: 75 [26240/35339 (74%)]	Loss: 0.174446
Train Epoch: 75 [26880/35339 (76%)]	Loss: 0.086482
Train Epoch: 75 [27520/35339 (78%)]	Loss: 0.213473
Train Epoch: 75 [28160/35339 (80%)]	Loss: 0.124775
Train Epoch: 75 [28800/35339 (81%)]	Loss: 0.105109
Train Epoch: 75 [29440/35339 (83%)]	Loss: 0.098690
Train Epoch: 75 [30080/35339 (85%)]	Loss: 0.119864
Train Epoch: 75 [30720/35339 (87%)]	Loss: 0.109733
Train Epoch: 75 [31360/35339 (89%)]	Loss: 0.079001
Train Epoch: 75 [32000/35339 (90%)]	Loss: 0.139771
Train Epoch: 75 [32640/35339 (92%)]	Loss: 0.135887
Train Epoch: 75 [33280/35339 (94%)]	Loss: 0.103599
Train Epoch: 75 [33920/35339 (96%)]	Loss: 0.132961
Train Epoch: 75 [34560/35339 (98%)]	Loss: 0.148727
Train Epoch: 75 [35200/35339 (99%)]	Loss: 0.063388

Validation set: Average loss: 3.0311, Accuracy: 1688/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 76 [0/35339 (0%)]	Loss: 0.081224
Train Epoch: 76 [640/35339 (2%)]	Loss: 0.090557
Train Epoch: 76 [1280/35339 (4%)]	Loss: 0.062746
Train Epoch: 76 [1920/35339 (5%)]	Loss: 0.145116
Train Epoch: 76 [2560/35339 (7%)]	Loss: 0.105036
Train Epoch: 76 [3200/35339 (9%)]	Loss: 0.161804
Train Epoch: 76 [3840/35339 (11%)]	Loss: 0.104000
Train Epoch: 76 [4480/35339 (13%)]	Loss: 0.064330
Train Epoch: 76 [5120/35339 (14%)]	Loss: 0.087858
Train Epoch: 76 [5760/35339 (16%)]	Loss: 0.108347
Train Epoch: 76 [6400/35339 (18%)]	Loss: 0.159477
Train Epoch: 76 [7040/35339 (20%)]	Loss: 0.099839
Train Epoch: 76 [7680/35339 (22%)]	Loss: 0.181295
Train Epoch: 76 [8320/35339 (24%)]	Loss: 0.187822
Train Epoch: 76 [8960/35339 (25%)]	Loss: 0.118128
Train Epoch: 76 [9600/35339 (27%)]	Loss: 0.159488
Train Epoch: 76 [10240/35339 (29%)]	Loss: 0.066202
Train Epoch: 76 [10880/35339 (31%)]	Loss: 0.115224
Train Epoch: 76 [11520/35339 (33%)]	Loss: 0.073989
Train Epoch: 76 [12160/35339 (34%)]	Loss: 0.156212
Train Epoch: 76 [12800/35339 (36%)]	Loss: 0.079524
Train Epoch: 76 [13440/35339 (38%)]	Loss: 0.107840
Train Epoch: 76 [14080/35339 (40%)]	Loss: 0.079384
Train Epoch: 76 [14720/35339 (42%)]	Loss: 0.066447
Train Epoch: 76 [15360/35339 (43%)]	Loss: 0.173252
Train Epoch: 76 [16000/35339 (45%)]	Loss: 0.104822
Train Epoch: 76 [16640/35339 (47%)]	Loss: 0.153112
Train Epoch: 76 [17280/35339 (49%)]	Loss: 0.094460
Train Epoch: 76 [17920/35339 (51%)]	Loss: 0.079148
Train Epoch: 76 [18560/35339 (52%)]	Loss: 0.100714
Train Epoch: 76 [19200/35339 (54%)]	Loss: 0.082622
Train Epoch: 76 [19840/35339 (56%)]	Loss: 0.118974
Train Epoch: 76 [20480/35339 (58%)]	Loss: 0.110157
Train Epoch: 76 [21120/35339 (60%)]	Loss: 0.142070
Train Epoch: 76 [21760/35339 (61%)]	Loss: 0.113307
Train Epoch: 76 [22400/35339 (63%)]	Loss: 0.077203
Train Epoch: 76 [23040/35339 (65%)]	Loss: 0.130839
Train Epoch: 76 [23680/35339 (67%)]	Loss: 0.145670
Train Epoch: 76 [24320/35339 (69%)]	Loss: 0.161929
Train Epoch: 76 [24960/35339 (71%)]	Loss: 0.089511
Train Epoch: 76 [25600/35339 (72%)]	Loss: 0.131596
Train Epoch: 76 [26240/35339 (74%)]	Loss: 0.124408
Train Epoch: 76 [26880/35339 (76%)]	Loss: 0.076433
Train Epoch: 76 [27520/35339 (78%)]	Loss: 0.072923
Train Epoch: 76 [28160/35339 (80%)]	Loss: 0.084729
Train Epoch: 76 [28800/35339 (81%)]	Loss: 0.070856
Train Epoch: 76 [29440/35339 (83%)]	Loss: 0.063471
Train Epoch: 76 [30080/35339 (85%)]	Loss: 0.062781
Train Epoch: 76 [30720/35339 (87%)]	Loss: 0.080018
Train Epoch: 76 [31360/35339 (89%)]	Loss: 0.092925
Train Epoch: 76 [32000/35339 (90%)]	Loss: 0.093649
Train Epoch: 76 [32640/35339 (92%)]	Loss: 0.160772
Train Epoch: 76 [33280/35339 (94%)]	Loss: 0.216672
Train Epoch: 76 [33920/35339 (96%)]	Loss: 0.159169
Train Epoch: 76 [34560/35339 (98%)]	Loss: 0.084323
Train Epoch: 76 [35200/35339 (99%)]	Loss: 0.087335

Validation set: Average loss: 3.0160, Accuracy: 1710/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 77 [0/35339 (0%)]	Loss: 0.064663
Train Epoch: 77 [640/35339 (2%)]	Loss: 0.096529
Train Epoch: 77 [1280/35339 (4%)]	Loss: 0.094590
Train Epoch: 77 [1920/35339 (5%)]	Loss: 0.074935
Train Epoch: 77 [2560/35339 (7%)]	Loss: 0.155965
Train Epoch: 77 [3200/35339 (9%)]	Loss: 0.081329
Train Epoch: 77 [3840/35339 (11%)]	Loss: 0.091161
Train Epoch: 77 [4480/35339 (13%)]	Loss: 0.072565
Train Epoch: 77 [5120/35339 (14%)]	Loss: 0.096503
Train Epoch: 77 [5760/35339 (16%)]	Loss: 0.089275
Train Epoch: 77 [6400/35339 (18%)]	Loss: 0.123362
Train Epoch: 77 [7040/35339 (20%)]	Loss: 0.107402
Train Epoch: 77 [7680/35339 (22%)]	Loss: 0.220057
Train Epoch: 77 [8320/35339 (24%)]	Loss: 0.099898
Train Epoch: 77 [8960/35339 (25%)]	Loss: 0.108689
Train Epoch: 77 [9600/35339 (27%)]	Loss: 0.065225
Train Epoch: 77 [10240/35339 (29%)]	Loss: 0.133128
Train Epoch: 77 [10880/35339 (31%)]	Loss: 0.133614
Train Epoch: 77 [11520/35339 (33%)]	Loss: 0.075221
Train Epoch: 77 [12160/35339 (34%)]	Loss: 0.066139
Train Epoch: 77 [12800/35339 (36%)]	Loss: 0.097947
Train Epoch: 77 [13440/35339 (38%)]	Loss: 0.062915
Train Epoch: 77 [14080/35339 (40%)]	Loss: 0.082702
Train Epoch: 77 [14720/35339 (42%)]	Loss: 0.125755
Train Epoch: 77 [15360/35339 (43%)]	Loss: 0.092555
Train Epoch: 77 [16000/35339 (45%)]	Loss: 0.102273
Train Epoch: 77 [16640/35339 (47%)]	Loss: 0.119339
Train Epoch: 77 [17280/35339 (49%)]	Loss: 0.129665
Train Epoch: 77 [17920/35339 (51%)]	Loss: 0.116252
Train Epoch: 77 [18560/35339 (52%)]	Loss: 0.097061
Train Epoch: 77 [19200/35339 (54%)]	Loss: 0.132248
Train Epoch: 77 [19840/35339 (56%)]	Loss: 0.089311
Train Epoch: 77 [20480/35339 (58%)]	Loss: 0.069965
Train Epoch: 77 [21120/35339 (60%)]	Loss: 0.114344
Train Epoch: 77 [21760/35339 (61%)]	Loss: 0.075962
Train Epoch: 77 [22400/35339 (63%)]	Loss: 0.084175
Train Epoch: 77 [23040/35339 (65%)]	Loss: 0.154898
Train Epoch: 77 [23680/35339 (67%)]	Loss: 0.098998
Train Epoch: 77 [24320/35339 (69%)]	Loss: 0.105670
Train Epoch: 77 [24960/35339 (71%)]	Loss: 0.070810
Train Epoch: 77 [25600/35339 (72%)]	Loss: 0.068753
Train Epoch: 77 [26240/35339 (74%)]	Loss: 0.077664
Train Epoch: 77 [26880/35339 (76%)]	Loss: 0.069936
Train Epoch: 77 [27520/35339 (78%)]	Loss: 0.067546
Train Epoch: 77 [28160/35339 (80%)]	Loss: 0.139258
Train Epoch: 77 [28800/35339 (81%)]	Loss: 0.200768
Train Epoch: 77 [29440/35339 (83%)]	Loss: 0.153173
Train Epoch: 77 [30080/35339 (85%)]	Loss: 0.098990
Train Epoch: 77 [30720/35339 (87%)]	Loss: 0.116035
Train Epoch: 77 [31360/35339 (89%)]	Loss: 0.127300
Train Epoch: 77 [32000/35339 (90%)]	Loss: 0.075009
Train Epoch: 77 [32640/35339 (92%)]	Loss: 0.142861
Train Epoch: 77 [33280/35339 (94%)]	Loss: 0.098744
Train Epoch: 77 [33920/35339 (96%)]	Loss: 0.066079
Train Epoch: 77 [34560/35339 (98%)]	Loss: 0.092535
Train Epoch: 77 [35200/35339 (99%)]	Loss: 0.191817

Validation set: Average loss: 3.0753, Accuracy: 1647/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 78 [0/35339 (0%)]	Loss: 0.121840
Train Epoch: 78 [640/35339 (2%)]	Loss: 0.070761
Train Epoch: 78 [1280/35339 (4%)]	Loss: 0.102528
Train Epoch: 78 [1920/35339 (5%)]	Loss: 0.119153
Train Epoch: 78 [2560/35339 (7%)]	Loss: 0.082166
Train Epoch: 78 [3200/35339 (9%)]	Loss: 0.125682
Train Epoch: 78 [3840/35339 (11%)]	Loss: 0.138070
Train Epoch: 78 [4480/35339 (13%)]	Loss: 0.101886
Train Epoch: 78 [5120/35339 (14%)]	Loss: 0.091767
Train Epoch: 78 [5760/35339 (16%)]	Loss: 0.065718
Train Epoch: 78 [6400/35339 (18%)]	Loss: 0.070442
Train Epoch: 78 [7040/35339 (20%)]	Loss: 0.101608
Train Epoch: 78 [7680/35339 (22%)]	Loss: 0.106375
Train Epoch: 78 [8320/35339 (24%)]	Loss: 0.099157
Train Epoch: 78 [8960/35339 (25%)]	Loss: 0.086534
Train Epoch: 78 [9600/35339 (27%)]	Loss: 0.103313
Train Epoch: 78 [10240/35339 (29%)]	Loss: 0.079705
Train Epoch: 78 [10880/35339 (31%)]	Loss: 0.124850
Train Epoch: 78 [11520/35339 (33%)]	Loss: 0.086551
Train Epoch: 78 [12160/35339 (34%)]	Loss: 0.076347
Train Epoch: 78 [12800/35339 (36%)]	Loss: 0.075493
Train Epoch: 78 [13440/35339 (38%)]	Loss: 0.106130
Train Epoch: 78 [14080/35339 (40%)]	Loss: 0.075831
Train Epoch: 78 [14720/35339 (42%)]	Loss: 0.061883
Train Epoch: 78 [15360/35339 (43%)]	Loss: 0.103628
Train Epoch: 78 [16000/35339 (45%)]	Loss: 0.103493
Train Epoch: 78 [16640/35339 (47%)]	Loss: 0.088284
Train Epoch: 78 [17280/35339 (49%)]	Loss: 0.137165
Train Epoch: 78 [17920/35339 (51%)]	Loss: 0.106521
Train Epoch: 78 [18560/35339 (52%)]	Loss: 0.062519
Train Epoch: 78 [19200/35339 (54%)]	Loss: 0.092231
Train Epoch: 78 [19840/35339 (56%)]	Loss: 0.091040
Train Epoch: 78 [20480/35339 (58%)]	Loss: 0.225398
Train Epoch: 78 [21120/35339 (60%)]	Loss: 0.098666
Train Epoch: 78 [21760/35339 (61%)]	Loss: 0.219250
Train Epoch: 78 [22400/35339 (63%)]	Loss: 0.087344
Train Epoch: 78 [23040/35339 (65%)]	Loss: 0.136373
Train Epoch: 78 [23680/35339 (67%)]	Loss: 0.101981
Train Epoch: 78 [24320/35339 (69%)]	Loss: 0.063634
Train Epoch: 78 [24960/35339 (71%)]	Loss: 0.107968
Train Epoch: 78 [25600/35339 (72%)]	Loss: 0.141433
Train Epoch: 78 [26240/35339 (74%)]	Loss: 0.094795
Train Epoch: 78 [26880/35339 (76%)]	Loss: 0.089347
Train Epoch: 78 [27520/35339 (78%)]	Loss: 0.143042
Train Epoch: 78 [28160/35339 (80%)]	Loss: 0.129352
Train Epoch: 78 [28800/35339 (81%)]	Loss: 0.450077
Train Epoch: 78 [29440/35339 (83%)]	Loss: 0.160305
Train Epoch: 78 [30080/35339 (85%)]	Loss: 0.087439
Train Epoch: 78 [30720/35339 (87%)]	Loss: 0.096417
Train Epoch: 78 [31360/35339 (89%)]	Loss: 0.100517
Train Epoch: 78 [32000/35339 (90%)]	Loss: 0.297821
Train Epoch: 78 [32640/35339 (92%)]	Loss: 0.101611
Train Epoch: 78 [33280/35339 (94%)]	Loss: 0.095787
Train Epoch: 78 [33920/35339 (96%)]	Loss: 0.097231
Train Epoch: 78 [34560/35339 (98%)]	Loss: 0.098658
Train Epoch: 78 [35200/35339 (99%)]	Loss: 0.129051

Validation set: Average loss: 3.1559, Accuracy: 1643/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 79 [0/35339 (0%)]	Loss: 0.090310
Train Epoch: 79 [640/35339 (2%)]	Loss: 0.097720
Train Epoch: 79 [1280/35339 (4%)]	Loss: 0.078800
Train Epoch: 79 [1920/35339 (5%)]	Loss: 0.155862
Train Epoch: 79 [2560/35339 (7%)]	Loss: 0.089975
Train Epoch: 79 [3200/35339 (9%)]	Loss: 0.099020
Train Epoch: 79 [3840/35339 (11%)]	Loss: 0.417773
Train Epoch: 79 [4480/35339 (13%)]	Loss: 0.125730
Train Epoch: 79 [5120/35339 (14%)]	Loss: 0.110243
Train Epoch: 79 [5760/35339 (16%)]	Loss: 0.148746
Train Epoch: 79 [6400/35339 (18%)]	Loss: 0.103876
Train Epoch: 79 [7040/35339 (20%)]	Loss: 0.089661
Train Epoch: 79 [7680/35339 (22%)]	Loss: 0.097341
Train Epoch: 79 [8320/35339 (24%)]	Loss: 0.213875
Train Epoch: 79 [8960/35339 (25%)]	Loss: 0.196112
Train Epoch: 79 [9600/35339 (27%)]	Loss: 0.139597
Train Epoch: 79 [10240/35339 (29%)]	Loss: 0.135712
Train Epoch: 79 [10880/35339 (31%)]	Loss: 0.226301
Train Epoch: 79 [11520/35339 (33%)]	Loss: 0.132854
Train Epoch: 79 [12160/35339 (34%)]	Loss: 0.071775
Train Epoch: 79 [12800/35339 (36%)]	Loss: 0.074095
Train Epoch: 79 [13440/35339 (38%)]	Loss: 0.088048
Train Epoch: 79 [14080/35339 (40%)]	Loss: 0.065139
Train Epoch: 79 [14720/35339 (42%)]	Loss: 0.073669
Train Epoch: 79 [15360/35339 (43%)]	Loss: 0.110538
Train Epoch: 79 [16000/35339 (45%)]	Loss: 0.090265
Train Epoch: 79 [16640/35339 (47%)]	Loss: 0.123298
Train Epoch: 79 [17280/35339 (49%)]	Loss: 0.072830
Train Epoch: 79 [17920/35339 (51%)]	Loss: 0.069286
Train Epoch: 79 [18560/35339 (52%)]	Loss: 0.083079
Train Epoch: 79 [19200/35339 (54%)]	Loss: 0.209796
Train Epoch: 79 [19840/35339 (56%)]	Loss: 0.096239
Train Epoch: 79 [20480/35339 (58%)]	Loss: 0.085539
Train Epoch: 79 [21120/35339 (60%)]	Loss: 0.093268
Train Epoch: 79 [21760/35339 (61%)]	Loss: 0.115579
Train Epoch: 79 [22400/35339 (63%)]	Loss: 0.076238
Train Epoch: 79 [23040/35339 (65%)]	Loss: 0.101823
Train Epoch: 79 [23680/35339 (67%)]	Loss: 0.292783
Train Epoch: 79 [24320/35339 (69%)]	Loss: 0.066380
Train Epoch: 79 [24960/35339 (71%)]	Loss: 0.098276
Train Epoch: 79 [25600/35339 (72%)]	Loss: 0.110682
Train Epoch: 79 [26240/35339 (74%)]	Loss: 0.161026
Train Epoch: 79 [26880/35339 (76%)]	Loss: 0.170524
Train Epoch: 79 [27520/35339 (78%)]	Loss: 0.114831
Train Epoch: 79 [28160/35339 (80%)]	Loss: 0.069467
Train Epoch: 79 [28800/35339 (81%)]	Loss: 0.066014
Train Epoch: 79 [29440/35339 (83%)]	Loss: 0.198132
Train Epoch: 79 [30080/35339 (85%)]	Loss: 0.095732
Train Epoch: 79 [30720/35339 (87%)]	Loss: 0.095503
Train Epoch: 79 [31360/35339 (89%)]	Loss: 0.113472
Train Epoch: 79 [32000/35339 (90%)]	Loss: 0.116557
Train Epoch: 79 [32640/35339 (92%)]	Loss: 0.055263
Train Epoch: 79 [33280/35339 (94%)]	Loss: 0.076033
Train Epoch: 79 [33920/35339 (96%)]	Loss: 0.065094
Train Epoch: 79 [34560/35339 (98%)]	Loss: 0.115194
Train Epoch: 79 [35200/35339 (99%)]	Loss: 0.141997

Validation set: Average loss: 3.0256, Accuracy: 1681/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 80 [0/35339 (0%)]	Loss: 0.093197
Train Epoch: 80 [640/35339 (2%)]	Loss: 0.107639
Train Epoch: 80 [1280/35339 (4%)]	Loss: 0.072479
Train Epoch: 80 [1920/35339 (5%)]	Loss: 0.081221
Train Epoch: 80 [2560/35339 (7%)]	Loss: 0.198040
Train Epoch: 80 [3200/35339 (9%)]	Loss: 0.062013
Train Epoch: 80 [3840/35339 (11%)]	Loss: 0.124686
Train Epoch: 80 [4480/35339 (13%)]	Loss: 0.078777
Train Epoch: 80 [5120/35339 (14%)]	Loss: 0.106278
Train Epoch: 80 [5760/35339 (16%)]	Loss: 0.067417
Train Epoch: 80 [6400/35339 (18%)]	Loss: 0.068021
Train Epoch: 80 [7040/35339 (20%)]	Loss: 0.152401
Train Epoch: 80 [7680/35339 (22%)]	Loss: 0.090607
Train Epoch: 80 [8320/35339 (24%)]	Loss: 0.080715
Train Epoch: 80 [8960/35339 (25%)]	Loss: 0.126971
Train Epoch: 80 [9600/35339 (27%)]	Loss: 0.080889
Train Epoch: 80 [10240/35339 (29%)]	Loss: 0.083618
Train Epoch: 80 [10880/35339 (31%)]	Loss: 0.113565
Train Epoch: 80 [11520/35339 (33%)]	Loss: 0.111466
Train Epoch: 80 [12160/35339 (34%)]	Loss: 0.158394
Train Epoch: 80 [12800/35339 (36%)]	Loss: 0.073618
Train Epoch: 80 [13440/35339 (38%)]	Loss: 0.161372
Train Epoch: 80 [14080/35339 (40%)]	Loss: 0.135745
Train Epoch: 80 [14720/35339 (42%)]	Loss: 0.090201
Train Epoch: 80 [15360/35339 (43%)]	Loss: 0.081797
Train Epoch: 80 [16000/35339 (45%)]	Loss: 0.076734
Train Epoch: 80 [16640/35339 (47%)]	Loss: 0.066406
Train Epoch: 80 [17280/35339 (49%)]	Loss: 0.154939
Train Epoch: 80 [17920/35339 (51%)]	Loss: 0.071007
Train Epoch: 80 [18560/35339 (52%)]	Loss: 0.209235
Train Epoch: 80 [19200/35339 (54%)]	Loss: 0.102178
Train Epoch: 80 [19840/35339 (56%)]	Loss: 0.146079
Train Epoch: 80 [20480/35339 (58%)]	Loss: 0.067530
Train Epoch: 80 [21120/35339 (60%)]	Loss: 0.064887
Train Epoch: 80 [21760/35339 (61%)]	Loss: 0.091247
Train Epoch: 80 [22400/35339 (63%)]	Loss: 0.067721
Train Epoch: 80 [23040/35339 (65%)]	Loss: 0.159818
Train Epoch: 80 [23680/35339 (67%)]	Loss: 0.061888
Train Epoch: 80 [24320/35339 (69%)]	Loss: 0.061754
Train Epoch: 80 [24960/35339 (71%)]	Loss: 0.086781
Train Epoch: 80 [25600/35339 (72%)]	Loss: 0.080692
Train Epoch: 80 [26240/35339 (74%)]	Loss: 0.117638
Train Epoch: 80 [26880/35339 (76%)]	Loss: 0.116014
Train Epoch: 80 [27520/35339 (78%)]	Loss: 0.168627
Train Epoch: 80 [28160/35339 (80%)]	Loss: 0.142097
Train Epoch: 80 [28800/35339 (81%)]	Loss: 0.104838
Train Epoch: 80 [29440/35339 (83%)]	Loss: 0.138884
Train Epoch: 80 [30080/35339 (85%)]	Loss: 0.077167
Train Epoch: 80 [30720/35339 (87%)]	Loss: 0.159582
Train Epoch: 80 [31360/35339 (89%)]	Loss: 0.065807
Train Epoch: 80 [32000/35339 (90%)]	Loss: 0.112987
Train Epoch: 80 [32640/35339 (92%)]	Loss: 0.083179
Train Epoch: 80 [33280/35339 (94%)]	Loss: 0.073929
Train Epoch: 80 [33920/35339 (96%)]	Loss: 0.061481
Train Epoch: 80 [34560/35339 (98%)]	Loss: 0.106395
Train Epoch: 80 [35200/35339 (99%)]	Loss: 0.113350

Validation set: Average loss: 3.0469, Accuracy: 1682/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 81 [0/35339 (0%)]	Loss: 0.107260
Train Epoch: 81 [640/35339 (2%)]	Loss: 0.091289
Train Epoch: 81 [1280/35339 (4%)]	Loss: 0.092855
Train Epoch: 81 [1920/35339 (5%)]	Loss: 0.071874
Train Epoch: 81 [2560/35339 (7%)]	Loss: 0.114679
Train Epoch: 81 [3200/35339 (9%)]	Loss: 0.094530
Train Epoch: 81 [3840/35339 (11%)]	Loss: 0.136013
Train Epoch: 81 [4480/35339 (13%)]	Loss: 0.092588
Train Epoch: 81 [5120/35339 (14%)]	Loss: 0.067357
Train Epoch: 81 [5760/35339 (16%)]	Loss: 0.061446
Train Epoch: 81 [6400/35339 (18%)]	Loss: 0.061458
Train Epoch: 81 [7040/35339 (20%)]	Loss: 0.158113
Train Epoch: 81 [7680/35339 (22%)]	Loss: 0.119181
Train Epoch: 81 [8320/35339 (24%)]	Loss: 0.068077
Train Epoch: 81 [8960/35339 (25%)]	Loss: 0.108575
Train Epoch: 81 [9600/35339 (27%)]	Loss: 0.073358
Train Epoch: 81 [10240/35339 (29%)]	Loss: 0.077488
Train Epoch: 81 [10880/35339 (31%)]	Loss: 0.114428
Train Epoch: 81 [11520/35339 (33%)]	Loss: 0.089173
Train Epoch: 81 [12160/35339 (34%)]	Loss: 0.108826
Train Epoch: 81 [12800/35339 (36%)]	Loss: 0.059922
Train Epoch: 81 [13440/35339 (38%)]	Loss: 0.108764
Train Epoch: 81 [14080/35339 (40%)]	Loss: 0.116218
Train Epoch: 81 [14720/35339 (42%)]	Loss: 0.070001
Train Epoch: 81 [15360/35339 (43%)]	Loss: 0.065578
Train Epoch: 81 [16000/35339 (45%)]	Loss: 0.074813
Train Epoch: 81 [16640/35339 (47%)]	Loss: 0.328691
Train Epoch: 81 [17280/35339 (49%)]	Loss: 0.127166
Train Epoch: 81 [17920/35339 (51%)]	Loss: 0.085930
Train Epoch: 81 [18560/35339 (52%)]	Loss: 0.129283
Train Epoch: 81 [19200/35339 (54%)]	Loss: 0.201851
Train Epoch: 81 [19840/35339 (56%)]	Loss: 0.148699
Train Epoch: 81 [20480/35339 (58%)]	Loss: 0.106752
Train Epoch: 81 [21120/35339 (60%)]	Loss: 0.096037
Train Epoch: 81 [21760/35339 (61%)]	Loss: 0.065194
Train Epoch: 81 [22400/35339 (63%)]	Loss: 0.097832
Train Epoch: 81 [23040/35339 (65%)]	Loss: 0.085482
Train Epoch: 81 [23680/35339 (67%)]	Loss: 0.112173
Train Epoch: 81 [24320/35339 (69%)]	Loss: 0.149202
Train Epoch: 81 [24960/35339 (71%)]	Loss: 0.077744
Train Epoch: 81 [25600/35339 (72%)]	Loss: 0.062519
Train Epoch: 81 [26240/35339 (74%)]	Loss: 0.113340
Train Epoch: 81 [26880/35339 (76%)]	Loss: 0.062366
Train Epoch: 81 [27520/35339 (78%)]	Loss: 0.136717
Train Epoch: 81 [28160/35339 (80%)]	Loss: 0.109579
Train Epoch: 81 [28800/35339 (81%)]	Loss: 0.085919
Train Epoch: 81 [29440/35339 (83%)]	Loss: 0.167320
Train Epoch: 81 [30080/35339 (85%)]	Loss: 0.059169
Train Epoch: 81 [30720/35339 (87%)]	Loss: 0.130568
Train Epoch: 81 [31360/35339 (89%)]	Loss: 0.093564
Train Epoch: 81 [32000/35339 (90%)]	Loss: 0.081298
Train Epoch: 81 [32640/35339 (92%)]	Loss: 0.204440
Train Epoch: 81 [33280/35339 (94%)]	Loss: 0.096362
Train Epoch: 81 [33920/35339 (96%)]	Loss: 0.061884
Train Epoch: 81 [34560/35339 (98%)]	Loss: 0.065566
Train Epoch: 81 [35200/35339 (99%)]	Loss: 0.115819

Validation set: Average loss: 3.1294, Accuracy: 1595/3870 (41%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 82 [0/35339 (0%)]	Loss: 0.070626
Train Epoch: 82 [640/35339 (2%)]	Loss: 0.145626
Train Epoch: 82 [1280/35339 (4%)]	Loss: 0.102065
Train Epoch: 82 [1920/35339 (5%)]	Loss: 0.086173
Train Epoch: 82 [2560/35339 (7%)]	Loss: 0.119161
Train Epoch: 82 [3200/35339 (9%)]	Loss: 0.115189
Train Epoch: 82 [3840/35339 (11%)]	Loss: 0.097527
Train Epoch: 82 [4480/35339 (13%)]	Loss: 0.115868
Train Epoch: 82 [5120/35339 (14%)]	Loss: 0.081444
Train Epoch: 82 [5760/35339 (16%)]	Loss: 0.184918
Train Epoch: 82 [6400/35339 (18%)]	Loss: 0.102340
Train Epoch: 82 [7040/35339 (20%)]	Loss: 0.062742
Train Epoch: 82 [7680/35339 (22%)]	Loss: 0.080440
Train Epoch: 82 [8320/35339 (24%)]	Loss: 0.117326
Train Epoch: 82 [8960/35339 (25%)]	Loss: 0.186393
Train Epoch: 82 [9600/35339 (27%)]	Loss: 0.097514
Train Epoch: 82 [10240/35339 (29%)]	Loss: 0.070642
Train Epoch: 82 [10880/35339 (31%)]	Loss: 0.072914
Train Epoch: 82 [11520/35339 (33%)]	Loss: 0.132099
Train Epoch: 82 [12160/35339 (34%)]	Loss: 0.062401
Train Epoch: 82 [12800/35339 (36%)]	Loss: 0.110735
Train Epoch: 82 [13440/35339 (38%)]	Loss: 0.080903
Train Epoch: 82 [14080/35339 (40%)]	Loss: 0.121635
Train Epoch: 82 [14720/35339 (42%)]	Loss: 0.079298
Train Epoch: 82 [15360/35339 (43%)]	Loss: 0.136762
Train Epoch: 82 [16000/35339 (45%)]	Loss: 0.093045
Train Epoch: 82 [16640/35339 (47%)]	Loss: 0.120320
Train Epoch: 82 [17280/35339 (49%)]	Loss: 0.082862
Train Epoch: 82 [17920/35339 (51%)]	Loss: 0.107071
Train Epoch: 82 [18560/35339 (52%)]	Loss: 0.133666
Train Epoch: 82 [19200/35339 (54%)]	Loss: 0.163052
Train Epoch: 82 [19840/35339 (56%)]	Loss: 0.091259
Train Epoch: 82 [20480/35339 (58%)]	Loss: 0.122098
Train Epoch: 82 [21120/35339 (60%)]	Loss: 0.144214
Train Epoch: 82 [21760/35339 (61%)]	Loss: 0.090327
Train Epoch: 82 [22400/35339 (63%)]	Loss: 0.088751
Train Epoch: 82 [23040/35339 (65%)]	Loss: 0.068861
Train Epoch: 82 [23680/35339 (67%)]	Loss: 0.066424
Train Epoch: 82 [24320/35339 (69%)]	Loss: 0.072877
Train Epoch: 82 [24960/35339 (71%)]	Loss: 0.061442
Train Epoch: 82 [25600/35339 (72%)]	Loss: 0.302167
Train Epoch: 82 [26240/35339 (74%)]	Loss: 0.075341
Train Epoch: 82 [26880/35339 (76%)]	Loss: 0.244500
Train Epoch: 82 [27520/35339 (78%)]	Loss: 0.066984
Train Epoch: 82 [28160/35339 (80%)]	Loss: 0.155480
Train Epoch: 82 [28800/35339 (81%)]	Loss: 0.205616
Train Epoch: 82 [29440/35339 (83%)]	Loss: 0.106560
Train Epoch: 82 [30080/35339 (85%)]	Loss: 0.087000
Train Epoch: 82 [30720/35339 (87%)]	Loss: 0.119905
Train Epoch: 82 [31360/35339 (89%)]	Loss: 0.217302
Train Epoch: 82 [32000/35339 (90%)]	Loss: 0.117560
Train Epoch: 82 [32640/35339 (92%)]	Loss: 0.128380
Train Epoch: 82 [33280/35339 (94%)]	Loss: 0.097059
Train Epoch: 82 [33920/35339 (96%)]	Loss: 0.143964
Train Epoch: 82 [34560/35339 (98%)]	Loss: 0.089306
Train Epoch: 82 [35200/35339 (99%)]	Loss: 0.097613

Validation set: Average loss: 3.0488, Accuracy: 1673/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 83 [0/35339 (0%)]	Loss: 0.106328
Train Epoch: 83 [640/35339 (2%)]	Loss: 0.085592
Train Epoch: 83 [1280/35339 (4%)]	Loss: 0.118580
Train Epoch: 83 [1920/35339 (5%)]	Loss: 0.148445
Train Epoch: 83 [2560/35339 (7%)]	Loss: 0.110610
Train Epoch: 83 [3200/35339 (9%)]	Loss: 0.086043
Train Epoch: 83 [3840/35339 (11%)]	Loss: 0.073963
Train Epoch: 83 [4480/35339 (13%)]	Loss: 0.120420
Train Epoch: 83 [5120/35339 (14%)]	Loss: 0.060694
Train Epoch: 83 [5760/35339 (16%)]	Loss: 0.201135
Train Epoch: 83 [6400/35339 (18%)]	Loss: 0.076075
Train Epoch: 83 [7040/35339 (20%)]	Loss: 0.113132
Train Epoch: 83 [7680/35339 (22%)]	Loss: 0.072259
Train Epoch: 83 [8320/35339 (24%)]	Loss: 0.172554
Train Epoch: 83 [8960/35339 (25%)]	Loss: 0.127132
Train Epoch: 83 [9600/35339 (27%)]	Loss: 0.233661
Train Epoch: 83 [10240/35339 (29%)]	Loss: 0.261743
Train Epoch: 83 [10880/35339 (31%)]	Loss: 0.096590
Train Epoch: 83 [11520/35339 (33%)]	Loss: 0.121639
Train Epoch: 83 [12160/35339 (34%)]	Loss: 0.148522
Train Epoch: 83 [12800/35339 (36%)]	Loss: 0.122946
Train Epoch: 83 [13440/35339 (38%)]	Loss: 0.100417
Train Epoch: 83 [14080/35339 (40%)]	Loss: 0.107736
Train Epoch: 83 [14720/35339 (42%)]	Loss: 0.071335
Train Epoch: 83 [15360/35339 (43%)]	Loss: 0.064576
Train Epoch: 83 [16000/35339 (45%)]	Loss: 0.095909
Train Epoch: 83 [16640/35339 (47%)]	Loss: 0.068377
Train Epoch: 83 [17280/35339 (49%)]	Loss: 0.147734
Train Epoch: 83 [17920/35339 (51%)]	Loss: 0.109046
Train Epoch: 83 [18560/35339 (52%)]	Loss: 0.101383
Train Epoch: 83 [19200/35339 (54%)]	Loss: 0.078511
Train Epoch: 83 [19840/35339 (56%)]	Loss: 0.091379
Train Epoch: 83 [20480/35339 (58%)]	Loss: 0.161613
Train Epoch: 83 [21120/35339 (60%)]	Loss: 0.095069
Train Epoch: 83 [21760/35339 (61%)]	Loss: 0.119016
Train Epoch: 83 [22400/35339 (63%)]	Loss: 0.117751
Train Epoch: 83 [23040/35339 (65%)]	Loss: 0.067705
Train Epoch: 83 [23680/35339 (67%)]	Loss: 0.137477
Train Epoch: 83 [24320/35339 (69%)]	Loss: 0.069465
Train Epoch: 83 [24960/35339 (71%)]	Loss: 0.252693
Train Epoch: 83 [25600/35339 (72%)]	Loss: 0.070197
Train Epoch: 83 [26240/35339 (74%)]	Loss: 0.089914
Train Epoch: 83 [26880/35339 (76%)]	Loss: 0.062010
Train Epoch: 83 [27520/35339 (78%)]	Loss: 0.102353
Train Epoch: 83 [28160/35339 (80%)]	Loss: 0.066006
Train Epoch: 83 [28800/35339 (81%)]	Loss: 0.136447
Train Epoch: 83 [29440/35339 (83%)]	Loss: 0.214883
Train Epoch: 83 [30080/35339 (85%)]	Loss: 0.131132
Train Epoch: 83 [30720/35339 (87%)]	Loss: 0.063011
Train Epoch: 83 [31360/35339 (89%)]	Loss: 0.130922
Train Epoch: 83 [32000/35339 (90%)]	Loss: 0.172133
Train Epoch: 83 [32640/35339 (92%)]	Loss: 0.079534
Train Epoch: 83 [33280/35339 (94%)]	Loss: 0.069550
Train Epoch: 83 [33920/35339 (96%)]	Loss: 0.084415
Train Epoch: 83 [34560/35339 (98%)]	Loss: 0.132671
Train Epoch: 83 [35200/35339 (99%)]	Loss: 0.152998

Validation set: Average loss: 2.9701, Accuracy: 1692/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 84 [0/35339 (0%)]	Loss: 0.118769
Train Epoch: 84 [640/35339 (2%)]	Loss: 0.140911
Train Epoch: 84 [1280/35339 (4%)]	Loss: 0.106001
Train Epoch: 84 [1920/35339 (5%)]	Loss: 0.126389
Train Epoch: 84 [2560/35339 (7%)]	Loss: 0.081844
Train Epoch: 84 [3200/35339 (9%)]	Loss: 0.171564
Train Epoch: 84 [3840/35339 (11%)]	Loss: 0.093272
Train Epoch: 84 [4480/35339 (13%)]	Loss: 0.119072
Train Epoch: 84 [5120/35339 (14%)]	Loss: 0.064985
Train Epoch: 84 [5760/35339 (16%)]	Loss: 0.147633
Train Epoch: 84 [6400/35339 (18%)]	Loss: 0.060314
Train Epoch: 84 [7040/35339 (20%)]	Loss: 0.084118
Train Epoch: 84 [7680/35339 (22%)]	Loss: 0.058900
Train Epoch: 84 [8320/35339 (24%)]	Loss: 0.112073
Train Epoch: 84 [8960/35339 (25%)]	Loss: 0.069304
Train Epoch: 84 [9600/35339 (27%)]	Loss: 0.179870
Train Epoch: 84 [10240/35339 (29%)]	Loss: 0.106833
Train Epoch: 84 [10880/35339 (31%)]	Loss: 0.251279
Train Epoch: 84 [11520/35339 (33%)]	Loss: 0.066195
Train Epoch: 84 [12160/35339 (34%)]	Loss: 0.177934
Train Epoch: 84 [12800/35339 (36%)]	Loss: 0.116874
Train Epoch: 84 [13440/35339 (38%)]	Loss: 0.068511
Train Epoch: 84 [14080/35339 (40%)]	Loss: 0.115548
Train Epoch: 84 [14720/35339 (42%)]	Loss: 0.100043
Train Epoch: 84 [15360/35339 (43%)]	Loss: 0.067786
Train Epoch: 84 [16000/35339 (45%)]	Loss: 0.116990
Train Epoch: 84 [16640/35339 (47%)]	Loss: 0.143284
Train Epoch: 84 [17280/35339 (49%)]	Loss: 0.575477
Train Epoch: 84 [17920/35339 (51%)]	Loss: 0.079842
Train Epoch: 84 [18560/35339 (52%)]	Loss: 0.069552
Train Epoch: 84 [19200/35339 (54%)]	Loss: 0.075766
Train Epoch: 84 [19840/35339 (56%)]	Loss: 0.107991
Train Epoch: 84 [20480/35339 (58%)]	Loss: 0.079920
Train Epoch: 84 [21120/35339 (60%)]	Loss: 0.064341
Train Epoch: 84 [21760/35339 (61%)]	Loss: 0.123374
Train Epoch: 84 [22400/35339 (63%)]	Loss: 0.127360
Train Epoch: 84 [23040/35339 (65%)]	Loss: 0.080350
Train Epoch: 84 [23680/35339 (67%)]	Loss: 0.075666
Train Epoch: 84 [24320/35339 (69%)]	Loss: 0.102045
Train Epoch: 84 [24960/35339 (71%)]	Loss: 0.070684
Train Epoch: 84 [25600/35339 (72%)]	Loss: 0.074717
Train Epoch: 84 [26240/35339 (74%)]	Loss: 0.123835
Train Epoch: 84 [26880/35339 (76%)]	Loss: 0.076633
Train Epoch: 84 [27520/35339 (78%)]	Loss: 0.146926
Train Epoch: 84 [28160/35339 (80%)]	Loss: 0.149284
Train Epoch: 84 [28800/35339 (81%)]	Loss: 0.108906
Train Epoch: 84 [29440/35339 (83%)]	Loss: 0.228613
Train Epoch: 84 [30080/35339 (85%)]	Loss: 0.180803
Train Epoch: 84 [30720/35339 (87%)]	Loss: 0.083304
Train Epoch: 84 [31360/35339 (89%)]	Loss: 0.117278
Train Epoch: 84 [32000/35339 (90%)]	Loss: 0.082822
Train Epoch: 84 [32640/35339 (92%)]	Loss: 0.112883
Train Epoch: 84 [33280/35339 (94%)]	Loss: 0.080422
Train Epoch: 84 [33920/35339 (96%)]	Loss: 0.063824
Train Epoch: 84 [34560/35339 (98%)]	Loss: 0.087477
Train Epoch: 84 [35200/35339 (99%)]	Loss: 0.107634

Validation set: Average loss: 3.0129, Accuracy: 1699/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 85 [0/35339 (0%)]	Loss: 0.097213
Train Epoch: 85 [640/35339 (2%)]	Loss: 0.073615
Train Epoch: 85 [1280/35339 (4%)]	Loss: 0.178301
Train Epoch: 85 [1920/35339 (5%)]	Loss: 0.125084
Train Epoch: 85 [2560/35339 (7%)]	Loss: 0.100135
Train Epoch: 85 [3200/35339 (9%)]	Loss: 0.060653
Train Epoch: 85 [3840/35339 (11%)]	Loss: 0.070061
Train Epoch: 85 [4480/35339 (13%)]	Loss: 0.085126
Train Epoch: 85 [5120/35339 (14%)]	Loss: 0.077936
Train Epoch: 85 [5760/35339 (16%)]	Loss: 0.117139
Train Epoch: 85 [6400/35339 (18%)]	Loss: 0.091923
Train Epoch: 85 [7040/35339 (20%)]	Loss: 0.070467
Train Epoch: 85 [7680/35339 (22%)]	Loss: 0.101060
Train Epoch: 85 [8320/35339 (24%)]	Loss: 0.067102
Train Epoch: 85 [8960/35339 (25%)]	Loss: 0.103370
Train Epoch: 85 [9600/35339 (27%)]	Loss: 0.074489
Train Epoch: 85 [10240/35339 (29%)]	Loss: 0.131857
Train Epoch: 85 [10880/35339 (31%)]	Loss: 0.149903
Train Epoch: 85 [11520/35339 (33%)]	Loss: 0.093984
Train Epoch: 85 [12160/35339 (34%)]	Loss: 0.090855
Train Epoch: 85 [12800/35339 (36%)]	Loss: 0.169743
Train Epoch: 85 [13440/35339 (38%)]	Loss: 0.163837
Train Epoch: 85 [14080/35339 (40%)]	Loss: 0.189038
Train Epoch: 85 [14720/35339 (42%)]	Loss: 0.093107
Train Epoch: 85 [15360/35339 (43%)]	Loss: 0.062518
Train Epoch: 85 [16000/35339 (45%)]	Loss: 0.093600
Train Epoch: 85 [16640/35339 (47%)]	Loss: 0.060471
Train Epoch: 85 [17280/35339 (49%)]	Loss: 0.077384
Train Epoch: 85 [17920/35339 (51%)]	Loss: 0.135692
Train Epoch: 85 [18560/35339 (52%)]	Loss: 0.097583
Train Epoch: 85 [19200/35339 (54%)]	Loss: 0.063827
Train Epoch: 85 [19840/35339 (56%)]	Loss: 0.129758
Train Epoch: 85 [20480/35339 (58%)]	Loss: 0.188535
Train Epoch: 85 [21120/35339 (60%)]	Loss: 0.090170
Train Epoch: 85 [21760/35339 (61%)]	Loss: 0.118621
Train Epoch: 85 [22400/35339 (63%)]	Loss: 0.159241
Train Epoch: 85 [23040/35339 (65%)]	Loss: 0.110510
Train Epoch: 85 [23680/35339 (67%)]	Loss: 0.163093
Train Epoch: 85 [24320/35339 (69%)]	Loss: 0.099063
Train Epoch: 85 [24960/35339 (71%)]	Loss: 0.087596
Train Epoch: 85 [25600/35339 (72%)]	Loss: 0.091360
Train Epoch: 85 [26240/35339 (74%)]	Loss: 0.065003
Train Epoch: 85 [26880/35339 (76%)]	Loss: 0.082497
Train Epoch: 85 [27520/35339 (78%)]	Loss: 0.132669
Train Epoch: 85 [28160/35339 (80%)]	Loss: 0.191663
Train Epoch: 85 [28800/35339 (81%)]	Loss: 0.061957
Train Epoch: 85 [29440/35339 (83%)]	Loss: 0.078599
Train Epoch: 85 [30080/35339 (85%)]	Loss: 0.091369
Train Epoch: 85 [30720/35339 (87%)]	Loss: 0.102357
Train Epoch: 85 [31360/35339 (89%)]	Loss: 0.098426
Train Epoch: 85 [32000/35339 (90%)]	Loss: 0.082871
Train Epoch: 85 [32640/35339 (92%)]	Loss: 0.125645
Train Epoch: 85 [33280/35339 (94%)]	Loss: 0.096212
Train Epoch: 85 [33920/35339 (96%)]	Loss: 0.088927
Train Epoch: 85 [34560/35339 (98%)]	Loss: 0.089277
Train Epoch: 85 [35200/35339 (99%)]	Loss: 0.159379

Validation set: Average loss: 2.9426, Accuracy: 1715/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 86 [0/35339 (0%)]	Loss: 0.107884
Train Epoch: 86 [640/35339 (2%)]	Loss: 0.248740
Train Epoch: 86 [1280/35339 (4%)]	Loss: 0.090143
Train Epoch: 86 [1920/35339 (5%)]	Loss: 0.070775
Train Epoch: 86 [2560/35339 (7%)]	Loss: 0.127681
Train Epoch: 86 [3200/35339 (9%)]	Loss: 0.065383
Train Epoch: 86 [3840/35339 (11%)]	Loss: 0.065571
Train Epoch: 86 [4480/35339 (13%)]	Loss: 0.086084
Train Epoch: 86 [5120/35339 (14%)]	Loss: 0.095481
Train Epoch: 86 [5760/35339 (16%)]	Loss: 0.061797
Train Epoch: 86 [6400/35339 (18%)]	Loss: 0.228528
Train Epoch: 86 [7040/35339 (20%)]	Loss: 0.087595
Train Epoch: 86 [7680/35339 (22%)]	Loss: 0.081513
Train Epoch: 86 [8320/35339 (24%)]	Loss: 0.145271
Train Epoch: 86 [8960/35339 (25%)]	Loss: 0.101759
Train Epoch: 86 [9600/35339 (27%)]	Loss: 0.082325
Train Epoch: 86 [10240/35339 (29%)]	Loss: 0.168321
Train Epoch: 86 [10880/35339 (31%)]	Loss: 0.080093
Train Epoch: 86 [11520/35339 (33%)]	Loss: 0.147884
Train Epoch: 86 [12160/35339 (34%)]	Loss: 0.088342
Train Epoch: 86 [12800/35339 (36%)]	Loss: 0.115463
Train Epoch: 86 [13440/35339 (38%)]	Loss: 0.074335
Train Epoch: 86 [14080/35339 (40%)]	Loss: 0.092889
Train Epoch: 86 [14720/35339 (42%)]	Loss: 0.062868
Train Epoch: 86 [15360/35339 (43%)]	Loss: 0.070708
Train Epoch: 86 [16000/35339 (45%)]	Loss: 0.081934
Train Epoch: 86 [16640/35339 (47%)]	Loss: 0.066980
Train Epoch: 86 [17280/35339 (49%)]	Loss: 0.080592
Train Epoch: 86 [17920/35339 (51%)]	Loss: 0.081734
Train Epoch: 86 [18560/35339 (52%)]	Loss: 0.136153
Train Epoch: 86 [19200/35339 (54%)]	Loss: 0.067040
Train Epoch: 86 [19840/35339 (56%)]	Loss: 0.069702
Train Epoch: 86 [20480/35339 (58%)]	Loss: 0.088427
Train Epoch: 86 [21120/35339 (60%)]	Loss: 0.123010
Train Epoch: 86 [21760/35339 (61%)]	Loss: 0.094069
Train Epoch: 86 [22400/35339 (63%)]	Loss: 0.085330
Train Epoch: 86 [23040/35339 (65%)]	Loss: 0.104301
Train Epoch: 86 [23680/35339 (67%)]	Loss: 0.081001
Train Epoch: 86 [24320/35339 (69%)]	Loss: 0.095668
Train Epoch: 86 [24960/35339 (71%)]	Loss: 0.083343
Train Epoch: 86 [25600/35339 (72%)]	Loss: 0.061954
Train Epoch: 86 [26240/35339 (74%)]	Loss: 0.160714
Train Epoch: 86 [26880/35339 (76%)]	Loss: 0.095175
Train Epoch: 86 [27520/35339 (78%)]	Loss: 0.080102
Train Epoch: 86 [28160/35339 (80%)]	Loss: 0.060408
Train Epoch: 86 [28800/35339 (81%)]	Loss: 0.082681
Train Epoch: 86 [29440/35339 (83%)]	Loss: 0.062752
Train Epoch: 86 [30080/35339 (85%)]	Loss: 0.074235
Train Epoch: 86 [30720/35339 (87%)]	Loss: 0.072453
Train Epoch: 86 [31360/35339 (89%)]	Loss: 0.180456
Train Epoch: 86 [32000/35339 (90%)]	Loss: 0.132344
Train Epoch: 86 [32640/35339 (92%)]	Loss: 0.083297
Train Epoch: 86 [33280/35339 (94%)]	Loss: 0.122291
Train Epoch: 86 [33920/35339 (96%)]	Loss: 0.066356
Train Epoch: 86 [34560/35339 (98%)]	Loss: 0.104063
Train Epoch: 86 [35200/35339 (99%)]	Loss: 0.127832

Validation set: Average loss: 2.9804, Accuracy: 1724/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 87 [0/35339 (0%)]	Loss: 0.163853
Train Epoch: 87 [640/35339 (2%)]	Loss: 0.130809
Train Epoch: 87 [1280/35339 (4%)]	Loss: 0.070731
Train Epoch: 87 [1920/35339 (5%)]	Loss: 0.180917
Train Epoch: 87 [2560/35339 (7%)]	Loss: 0.130632
Train Epoch: 87 [3200/35339 (9%)]	Loss: 0.078369
Train Epoch: 87 [3840/35339 (11%)]	Loss: 0.152214
Train Epoch: 87 [4480/35339 (13%)]	Loss: 0.091089
Train Epoch: 87 [5120/35339 (14%)]	Loss: 0.132911
Train Epoch: 87 [5760/35339 (16%)]	Loss: 0.070699
Train Epoch: 87 [6400/35339 (18%)]	Loss: 0.078802
Train Epoch: 87 [7040/35339 (20%)]	Loss: 0.087365
Train Epoch: 87 [7680/35339 (22%)]	Loss: 0.207453
Train Epoch: 87 [8320/35339 (24%)]	Loss: 0.077493
Train Epoch: 87 [8960/35339 (25%)]	Loss: 0.135915
Train Epoch: 87 [9600/35339 (27%)]	Loss: 0.065755
Train Epoch: 87 [10240/35339 (29%)]	Loss: 0.106693
Train Epoch: 87 [10880/35339 (31%)]	Loss: 0.093868
Train Epoch: 87 [11520/35339 (33%)]	Loss: 0.433373
Train Epoch: 87 [12160/35339 (34%)]	Loss: 0.087161
Train Epoch: 87 [12800/35339 (36%)]	Loss: 0.142604
Train Epoch: 87 [13440/35339 (38%)]	Loss: 0.104080
Train Epoch: 87 [14080/35339 (40%)]	Loss: 0.114693
Train Epoch: 87 [14720/35339 (42%)]	Loss: 0.071495
Train Epoch: 87 [15360/35339 (43%)]	Loss: 0.101528
Train Epoch: 87 [16000/35339 (45%)]	Loss: 0.071383
Train Epoch: 87 [16640/35339 (47%)]	Loss: 0.076966
Train Epoch: 87 [17280/35339 (49%)]	Loss: 0.083742
Train Epoch: 87 [17920/35339 (51%)]	Loss: 0.071615
Train Epoch: 87 [18560/35339 (52%)]	Loss: 0.063943
Train Epoch: 87 [19200/35339 (54%)]	Loss: 0.146426
Train Epoch: 87 [19840/35339 (56%)]	Loss: 0.268332
Train Epoch: 87 [20480/35339 (58%)]	Loss: 0.059970
Train Epoch: 87 [21120/35339 (60%)]	Loss: 0.105854
Train Epoch: 87 [21760/35339 (61%)]	Loss: 0.095517
Train Epoch: 87 [22400/35339 (63%)]	Loss: 0.432093
Train Epoch: 87 [23040/35339 (65%)]	Loss: 0.143027
Train Epoch: 87 [23680/35339 (67%)]	Loss: 0.196102
Train Epoch: 87 [24320/35339 (69%)]	Loss: 0.111332
Train Epoch: 87 [24960/35339 (71%)]	Loss: 0.091985
Train Epoch: 87 [25600/35339 (72%)]	Loss: 0.074260
Train Epoch: 87 [26240/35339 (74%)]	Loss: 0.084176
Train Epoch: 87 [26880/35339 (76%)]	Loss: 0.097041
Train Epoch: 87 [27520/35339 (78%)]	Loss: 0.086106
Train Epoch: 87 [28160/35339 (80%)]	Loss: 0.101681
Train Epoch: 87 [28800/35339 (81%)]	Loss: 0.063204
Train Epoch: 87 [29440/35339 (83%)]	Loss: 0.161200
Train Epoch: 87 [30080/35339 (85%)]	Loss: 0.115966
Train Epoch: 87 [30720/35339 (87%)]	Loss: 0.078390
Train Epoch: 87 [31360/35339 (89%)]	Loss: 0.102556
Train Epoch: 87 [32000/35339 (90%)]	Loss: 0.124374
Train Epoch: 87 [32640/35339 (92%)]	Loss: 0.095652
Train Epoch: 87 [33280/35339 (94%)]	Loss: 0.111750
Train Epoch: 87 [33920/35339 (96%)]	Loss: 0.148682
Train Epoch: 87 [34560/35339 (98%)]	Loss: 0.105293
Train Epoch: 87 [35200/35339 (99%)]	Loss: 0.063279

Validation set: Average loss: 2.9608, Accuracy: 1730/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 88 [0/35339 (0%)]	Loss: 0.106447
Train Epoch: 88 [640/35339 (2%)]	Loss: 0.061755
Train Epoch: 88 [1280/35339 (4%)]	Loss: 0.149026
Train Epoch: 88 [1920/35339 (5%)]	Loss: 0.083003
Train Epoch: 88 [2560/35339 (7%)]	Loss: 0.071799
Train Epoch: 88 [3200/35339 (9%)]	Loss: 0.074988
Train Epoch: 88 [3840/35339 (11%)]	Loss: 0.101110
Train Epoch: 88 [4480/35339 (13%)]	Loss: 0.071756
Train Epoch: 88 [5120/35339 (14%)]	Loss: 0.064443
Train Epoch: 88 [5760/35339 (16%)]	Loss: 0.151894
Train Epoch: 88 [6400/35339 (18%)]	Loss: 0.153761
Train Epoch: 88 [7040/35339 (20%)]	Loss: 0.067823
Train Epoch: 88 [7680/35339 (22%)]	Loss: 0.092642
Train Epoch: 88 [8320/35339 (24%)]	Loss: 0.101433
Train Epoch: 88 [8960/35339 (25%)]	Loss: 0.064692
Train Epoch: 88 [9600/35339 (27%)]	Loss: 0.100282
Train Epoch: 88 [10240/35339 (29%)]	Loss: 0.063397
Train Epoch: 88 [10880/35339 (31%)]	Loss: 0.063860
Train Epoch: 88 [11520/35339 (33%)]	Loss: 0.099811
Train Epoch: 88 [12160/35339 (34%)]	Loss: 0.114465
Train Epoch: 88 [12800/35339 (36%)]	Loss: 0.069425
Train Epoch: 88 [13440/35339 (38%)]	Loss: 0.084061
Train Epoch: 88 [14080/35339 (40%)]	Loss: 0.129690
Train Epoch: 88 [14720/35339 (42%)]	Loss: 0.105742
Train Epoch: 88 [15360/35339 (43%)]	Loss: 0.092540
Train Epoch: 88 [16000/35339 (45%)]	Loss: 0.105626
Train Epoch: 88 [16640/35339 (47%)]	Loss: 0.120641
Train Epoch: 88 [17280/35339 (49%)]	Loss: 0.082977
Train Epoch: 88 [17920/35339 (51%)]	Loss: 0.079317
Train Epoch: 88 [18560/35339 (52%)]	Loss: 0.098650
Train Epoch: 88 [19200/35339 (54%)]	Loss: 0.092624
Train Epoch: 88 [19840/35339 (56%)]	Loss: 0.198848
Train Epoch: 88 [20480/35339 (58%)]	Loss: 0.233256
Train Epoch: 88 [21120/35339 (60%)]	Loss: 0.064446
Train Epoch: 88 [21760/35339 (61%)]	Loss: 0.065512
Train Epoch: 88 [22400/35339 (63%)]	Loss: 0.074255
Train Epoch: 88 [23040/35339 (65%)]	Loss: 0.140866
Train Epoch: 88 [23680/35339 (67%)]	Loss: 0.116158
Train Epoch: 88 [24320/35339 (69%)]	Loss: 0.096574
Train Epoch: 88 [24960/35339 (71%)]	Loss: 0.105391
Train Epoch: 88 [25600/35339 (72%)]	Loss: 0.102556
Train Epoch: 88 [26240/35339 (74%)]	Loss: 0.075448
Train Epoch: 88 [26880/35339 (76%)]	Loss: 0.084917
Train Epoch: 88 [27520/35339 (78%)]	Loss: 0.081836
Train Epoch: 88 [28160/35339 (80%)]	Loss: 0.070699
Train Epoch: 88 [28800/35339 (81%)]	Loss: 0.105255
Train Epoch: 88 [29440/35339 (83%)]	Loss: 0.137194
Train Epoch: 88 [30080/35339 (85%)]	Loss: 0.138208
Train Epoch: 88 [30720/35339 (87%)]	Loss: 0.099639
Train Epoch: 88 [31360/35339 (89%)]	Loss: 0.063941
Train Epoch: 88 [32000/35339 (90%)]	Loss: 0.096761
Train Epoch: 88 [32640/35339 (92%)]	Loss: 0.105289
Train Epoch: 88 [33280/35339 (94%)]	Loss: 0.097454
Train Epoch: 88 [33920/35339 (96%)]	Loss: 0.064592
Train Epoch: 88 [34560/35339 (98%)]	Loss: 0.091613
Train Epoch: 88 [35200/35339 (99%)]	Loss: 0.077929

Validation set: Average loss: 2.9628, Accuracy: 1722/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 89 [0/35339 (0%)]	Loss: 0.112792
Train Epoch: 89 [640/35339 (2%)]	Loss: 0.067199
Train Epoch: 89 [1280/35339 (4%)]	Loss: 0.136739
Train Epoch: 89 [1920/35339 (5%)]	Loss: 0.163450
Train Epoch: 89 [2560/35339 (7%)]	Loss: 0.106617
Train Epoch: 89 [3200/35339 (9%)]	Loss: 0.109026
Train Epoch: 89 [3840/35339 (11%)]	Loss: 0.067354
Train Epoch: 89 [4480/35339 (13%)]	Loss: 0.124165
Train Epoch: 89 [5120/35339 (14%)]	Loss: 0.152277
Train Epoch: 89 [5760/35339 (16%)]	Loss: 0.110111
Train Epoch: 89 [6400/35339 (18%)]	Loss: 0.409599
Train Epoch: 89 [7040/35339 (20%)]	Loss: 0.133014
Train Epoch: 89 [7680/35339 (22%)]	Loss: 0.121339
Train Epoch: 89 [8320/35339 (24%)]	Loss: 0.153213
Train Epoch: 89 [8960/35339 (25%)]	Loss: 0.065027
Train Epoch: 89 [9600/35339 (27%)]	Loss: 0.067964
Train Epoch: 89 [10240/35339 (29%)]	Loss: 0.110014
Train Epoch: 89 [10880/35339 (31%)]	Loss: 0.073556
Train Epoch: 89 [11520/35339 (33%)]	Loss: 0.094900
Train Epoch: 89 [12160/35339 (34%)]	Loss: 0.097688
Train Epoch: 89 [12800/35339 (36%)]	Loss: 0.111610
Train Epoch: 89 [13440/35339 (38%)]	Loss: 0.199000
Train Epoch: 89 [14080/35339 (40%)]	Loss: 0.080097
Train Epoch: 89 [14720/35339 (42%)]	Loss: 0.153544
Train Epoch: 89 [15360/35339 (43%)]	Loss: 0.085081
Train Epoch: 89 [16000/35339 (45%)]	Loss: 0.067094
Train Epoch: 89 [16640/35339 (47%)]	Loss: 0.095171
Train Epoch: 89 [17280/35339 (49%)]	Loss: 0.076021
Train Epoch: 89 [17920/35339 (51%)]	Loss: 0.160493
Train Epoch: 89 [18560/35339 (52%)]	Loss: 0.068759
Train Epoch: 89 [19200/35339 (54%)]	Loss: 0.106109
Train Epoch: 89 [19840/35339 (56%)]	Loss: 0.101819
Train Epoch: 89 [20480/35339 (58%)]	Loss: 0.082184
Train Epoch: 89 [21120/35339 (60%)]	Loss: 0.104690
Train Epoch: 89 [21760/35339 (61%)]	Loss: 0.169564
Train Epoch: 89 [22400/35339 (63%)]	Loss: 0.106655
Train Epoch: 89 [23040/35339 (65%)]	Loss: 0.096507
Train Epoch: 89 [23680/35339 (67%)]	Loss: 0.161394
Train Epoch: 89 [24320/35339 (69%)]	Loss: 0.095118
Train Epoch: 89 [24960/35339 (71%)]	Loss: 0.067848
Train Epoch: 89 [25600/35339 (72%)]	Loss: 0.208635
Train Epoch: 89 [26240/35339 (74%)]	Loss: 0.078432
Train Epoch: 89 [26880/35339 (76%)]	Loss: 0.071870
Train Epoch: 89 [27520/35339 (78%)]	Loss: 0.091452
Train Epoch: 89 [28160/35339 (80%)]	Loss: 0.148678
Train Epoch: 89 [28800/35339 (81%)]	Loss: 0.168804
Train Epoch: 89 [29440/35339 (83%)]	Loss: 0.142115
Train Epoch: 89 [30080/35339 (85%)]	Loss: 0.067624
Train Epoch: 89 [30720/35339 (87%)]	Loss: 0.157257
Train Epoch: 89 [31360/35339 (89%)]	Loss: 0.109149
Train Epoch: 89 [32000/35339 (90%)]	Loss: 0.191164
Train Epoch: 89 [32640/35339 (92%)]	Loss: 0.197899
Train Epoch: 89 [33280/35339 (94%)]	Loss: 0.145997
Train Epoch: 89 [33920/35339 (96%)]	Loss: 0.071375
Train Epoch: 89 [34560/35339 (98%)]	Loss: 0.104675
Train Epoch: 89 [35200/35339 (99%)]	Loss: 0.076296

Validation set: Average loss: 3.1061, Accuracy: 1655/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 90 [0/35339 (0%)]	Loss: 0.124454
Train Epoch: 90 [640/35339 (2%)]	Loss: 0.073223
Train Epoch: 90 [1280/35339 (4%)]	Loss: 0.083751
Train Epoch: 90 [1920/35339 (5%)]	Loss: 0.093843
Train Epoch: 90 [2560/35339 (7%)]	Loss: 0.115082
Train Epoch: 90 [3200/35339 (9%)]	Loss: 0.063533
Train Epoch: 90 [3840/35339 (11%)]	Loss: 0.132890
Train Epoch: 90 [4480/35339 (13%)]	Loss: 0.065393
Train Epoch: 90 [5120/35339 (14%)]	Loss: 0.090989
Train Epoch: 90 [5760/35339 (16%)]	Loss: 0.065404
Train Epoch: 90 [6400/35339 (18%)]	Loss: 0.079316
Train Epoch: 90 [7040/35339 (20%)]	Loss: 0.106200
Train Epoch: 90 [7680/35339 (22%)]	Loss: 0.152235
Train Epoch: 90 [8320/35339 (24%)]	Loss: 0.082230
Train Epoch: 90 [8960/35339 (25%)]	Loss: 0.129694
Train Epoch: 90 [9600/35339 (27%)]	Loss: 0.127457
Train Epoch: 90 [10240/35339 (29%)]	Loss: 0.097574
Train Epoch: 90 [10880/35339 (31%)]	Loss: 0.215102
Train Epoch: 90 [11520/35339 (33%)]	Loss: 0.077139
Train Epoch: 90 [12160/35339 (34%)]	Loss: 0.128779
Train Epoch: 90 [12800/35339 (36%)]	Loss: 0.062431
Train Epoch: 90 [13440/35339 (38%)]	Loss: 0.113415
Train Epoch: 90 [14080/35339 (40%)]	Loss: 0.101009
Train Epoch: 90 [14720/35339 (42%)]	Loss: 0.125184
Train Epoch: 90 [15360/35339 (43%)]	Loss: 0.077936
Train Epoch: 90 [16000/35339 (45%)]	Loss: 0.068314
Train Epoch: 90 [16640/35339 (47%)]	Loss: 0.126644
Train Epoch: 90 [17280/35339 (49%)]	Loss: 0.072971
Train Epoch: 90 [17920/35339 (51%)]	Loss: 0.157043
Train Epoch: 90 [18560/35339 (52%)]	Loss: 0.070819
Train Epoch: 90 [19200/35339 (54%)]	Loss: 0.065771
Train Epoch: 90 [19840/35339 (56%)]	Loss: 0.171870
Train Epoch: 90 [20480/35339 (58%)]	Loss: 0.064751
Train Epoch: 90 [21120/35339 (60%)]	Loss: 0.106857
Train Epoch: 90 [21760/35339 (61%)]	Loss: 0.107806
Train Epoch: 90 [22400/35339 (63%)]	Loss: 0.114202
Train Epoch: 90 [23040/35339 (65%)]	Loss: 0.067417
Train Epoch: 90 [23680/35339 (67%)]	Loss: 0.115547
Train Epoch: 90 [24320/35339 (69%)]	Loss: 0.121258
Train Epoch: 90 [24960/35339 (71%)]	Loss: 0.080933
Train Epoch: 90 [25600/35339 (72%)]	Loss: 0.081629
Train Epoch: 90 [26240/35339 (74%)]	Loss: 0.089648
Train Epoch: 90 [26880/35339 (76%)]	Loss: 0.086515
Train Epoch: 90 [27520/35339 (78%)]	Loss: 0.129769
Train Epoch: 90 [28160/35339 (80%)]	Loss: 0.120783
Train Epoch: 90 [28800/35339 (81%)]	Loss: 0.314948
Train Epoch: 90 [29440/35339 (83%)]	Loss: 0.124553
Train Epoch: 90 [30080/35339 (85%)]	Loss: 0.094045
Train Epoch: 90 [30720/35339 (87%)]	Loss: 0.138927
Train Epoch: 90 [31360/35339 (89%)]	Loss: 0.071183
Train Epoch: 90 [32000/35339 (90%)]	Loss: 0.064504
Train Epoch: 90 [32640/35339 (92%)]	Loss: 0.067926
Train Epoch: 90 [33280/35339 (94%)]	Loss: 0.161178
Train Epoch: 90 [33920/35339 (96%)]	Loss: 0.064748
Train Epoch: 90 [34560/35339 (98%)]	Loss: 0.159489
Train Epoch: 90 [35200/35339 (99%)]	Loss: 0.066885

Validation set: Average loss: 3.0102, Accuracy: 1739/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 91 [0/35339 (0%)]	Loss: 0.134279
Train Epoch: 91 [640/35339 (2%)]	Loss: 0.073746
Train Epoch: 91 [1280/35339 (4%)]	Loss: 0.089311
Train Epoch: 91 [1920/35339 (5%)]	Loss: 0.245897
Train Epoch: 91 [2560/35339 (7%)]	Loss: 0.070779
Train Epoch: 91 [3200/35339 (9%)]	Loss: 0.060274
Train Epoch: 91 [3840/35339 (11%)]	Loss: 0.093827
Train Epoch: 91 [4480/35339 (13%)]	Loss: 0.075552
Train Epoch: 91 [5120/35339 (14%)]	Loss: 0.119683
Train Epoch: 91 [5760/35339 (16%)]	Loss: 0.117176
Train Epoch: 91 [6400/35339 (18%)]	Loss: 0.066292
Train Epoch: 91 [7040/35339 (20%)]	Loss: 0.083846
Train Epoch: 91 [7680/35339 (22%)]	Loss: 0.065413
Train Epoch: 91 [8320/35339 (24%)]	Loss: 0.075202
Train Epoch: 91 [8960/35339 (25%)]	Loss: 0.149181
Train Epoch: 91 [9600/35339 (27%)]	Loss: 0.134092
Train Epoch: 91 [10240/35339 (29%)]	Loss: 0.071928
Train Epoch: 91 [10880/35339 (31%)]	Loss: 0.085614
Train Epoch: 91 [11520/35339 (33%)]	Loss: 0.113843
Train Epoch: 91 [12160/35339 (34%)]	Loss: 0.093777
Train Epoch: 91 [12800/35339 (36%)]	Loss: 0.083658
Train Epoch: 91 [13440/35339 (38%)]	Loss: 0.071036
Train Epoch: 91 [14080/35339 (40%)]	Loss: 0.091614
Train Epoch: 91 [14720/35339 (42%)]	Loss: 0.070874
Train Epoch: 91 [15360/35339 (43%)]	Loss: 0.064872
Train Epoch: 91 [16000/35339 (45%)]	Loss: 0.099658
Train Epoch: 91 [16640/35339 (47%)]	Loss: 0.265755
Train Epoch: 91 [17280/35339 (49%)]	Loss: 0.063132
Train Epoch: 91 [17920/35339 (51%)]	Loss: 0.069528
Train Epoch: 91 [18560/35339 (52%)]	Loss: 0.069560
Train Epoch: 91 [19200/35339 (54%)]	Loss: 0.082315
Train Epoch: 91 [19840/35339 (56%)]	Loss: 0.102409
Train Epoch: 91 [20480/35339 (58%)]	Loss: 0.097958
Train Epoch: 91 [21120/35339 (60%)]	Loss: 0.066524
Train Epoch: 91 [21760/35339 (61%)]	Loss: 0.077373
Train Epoch: 91 [22400/35339 (63%)]	Loss: 0.122640
Train Epoch: 91 [23040/35339 (65%)]	Loss: 0.081815
Train Epoch: 91 [23680/35339 (67%)]	Loss: 0.124132
Train Epoch: 91 [24320/35339 (69%)]	Loss: 0.391066
Train Epoch: 91 [24960/35339 (71%)]	Loss: 0.169026
Train Epoch: 91 [25600/35339 (72%)]	Loss: 0.506716
Train Epoch: 91 [26240/35339 (74%)]	Loss: 0.061193
Train Epoch: 91 [26880/35339 (76%)]	Loss: 0.077712
Train Epoch: 91 [27520/35339 (78%)]	Loss: 0.128840
Train Epoch: 91 [28160/35339 (80%)]	Loss: 0.066247
Train Epoch: 91 [28800/35339 (81%)]	Loss: 0.076305
Train Epoch: 91 [29440/35339 (83%)]	Loss: 0.203745
Train Epoch: 91 [30080/35339 (85%)]	Loss: 0.109143
Train Epoch: 91 [30720/35339 (87%)]	Loss: 0.074485
Train Epoch: 91 [31360/35339 (89%)]	Loss: 0.103579
Train Epoch: 91 [32000/35339 (90%)]	Loss: 0.113901
Train Epoch: 91 [32640/35339 (92%)]	Loss: 0.098353
Train Epoch: 91 [33280/35339 (94%)]	Loss: 0.064180
Train Epoch: 91 [33920/35339 (96%)]	Loss: 0.092509
Train Epoch: 91 [34560/35339 (98%)]	Loss: 0.064472
Train Epoch: 91 [35200/35339 (99%)]	Loss: 0.122217

Validation set: Average loss: 2.9393, Accuracy: 1799/3870 (46%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 92 [0/35339 (0%)]	Loss: 0.124979
Train Epoch: 92 [640/35339 (2%)]	Loss: 0.064601
Train Epoch: 92 [1280/35339 (4%)]	Loss: 0.153914
Train Epoch: 92 [1920/35339 (5%)]	Loss: 0.244873
Train Epoch: 92 [2560/35339 (7%)]	Loss: 0.060932
Train Epoch: 92 [3200/35339 (9%)]	Loss: 0.075922
Train Epoch: 92 [3840/35339 (11%)]	Loss: 0.069751
Train Epoch: 92 [4480/35339 (13%)]	Loss: 0.122269
Train Epoch: 92 [5120/35339 (14%)]	Loss: 0.098408
Train Epoch: 92 [5760/35339 (16%)]	Loss: 0.106889
Train Epoch: 92 [6400/35339 (18%)]	Loss: 0.065366
Train Epoch: 92 [7040/35339 (20%)]	Loss: 0.109543
Train Epoch: 92 [7680/35339 (22%)]	Loss: 0.108028
Train Epoch: 92 [8320/35339 (24%)]	Loss: 0.148115
Train Epoch: 92 [8960/35339 (25%)]	Loss: 0.084521
Train Epoch: 92 [9600/35339 (27%)]	Loss: 0.079293
Train Epoch: 92 [10240/35339 (29%)]	Loss: 0.139154
Train Epoch: 92 [10880/35339 (31%)]	Loss: 0.076170
Train Epoch: 92 [11520/35339 (33%)]	Loss: 0.158888
Train Epoch: 92 [12160/35339 (34%)]	Loss: 0.065132
Train Epoch: 92 [12800/35339 (36%)]	Loss: 0.075873
Train Epoch: 92 [13440/35339 (38%)]	Loss: 0.215204
Train Epoch: 92 [14080/35339 (40%)]	Loss: 0.066595
Train Epoch: 92 [14720/35339 (42%)]	Loss: 0.082699
Train Epoch: 92 [15360/35339 (43%)]	Loss: 0.101679
Train Epoch: 92 [16000/35339 (45%)]	Loss: 0.106802
Train Epoch: 92 [16640/35339 (47%)]	Loss: 0.163402
Train Epoch: 92 [17280/35339 (49%)]	Loss: 0.109187
Train Epoch: 92 [17920/35339 (51%)]	Loss: 0.065041
Train Epoch: 92 [18560/35339 (52%)]	Loss: 0.139119
Train Epoch: 92 [19200/35339 (54%)]	Loss: 0.141621
Train Epoch: 92 [19840/35339 (56%)]	Loss: 0.100444
Train Epoch: 92 [20480/35339 (58%)]	Loss: 0.081850
Train Epoch: 92 [21120/35339 (60%)]	Loss: 0.081652
Train Epoch: 92 [21760/35339 (61%)]	Loss: 0.073613
Train Epoch: 92 [22400/35339 (63%)]	Loss: 0.062501
Train Epoch: 92 [23040/35339 (65%)]	Loss: 0.090956
Train Epoch: 92 [23680/35339 (67%)]	Loss: 0.070321
Train Epoch: 92 [24320/35339 (69%)]	Loss: 0.071810
Train Epoch: 92 [24960/35339 (71%)]	Loss: 0.129116
Train Epoch: 92 [25600/35339 (72%)]	Loss: 0.067855
Train Epoch: 92 [26240/35339 (74%)]	Loss: 0.065354
Train Epoch: 92 [26880/35339 (76%)]	Loss: 0.106171
Train Epoch: 92 [27520/35339 (78%)]	Loss: 0.069024
Train Epoch: 92 [28160/35339 (80%)]	Loss: 0.070593
Train Epoch: 92 [28800/35339 (81%)]	Loss: 0.085080
Train Epoch: 92 [29440/35339 (83%)]	Loss: 0.098339
Train Epoch: 92 [30080/35339 (85%)]	Loss: 0.159101
Train Epoch: 92 [30720/35339 (87%)]	Loss: 0.180884
Train Epoch: 92 [31360/35339 (89%)]	Loss: 0.165512
Train Epoch: 92 [32000/35339 (90%)]	Loss: 0.072187
Train Epoch: 92 [32640/35339 (92%)]	Loss: 0.103304
Train Epoch: 92 [33280/35339 (94%)]	Loss: 0.089525
Train Epoch: 92 [33920/35339 (96%)]	Loss: 0.170881
Train Epoch: 92 [34560/35339 (98%)]	Loss: 0.253272
Train Epoch: 92 [35200/35339 (99%)]	Loss: 0.093930

Validation set: Average loss: 2.8392, Accuracy: 1836/3870 (47%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 93 [0/35339 (0%)]	Loss: 0.117794
Train Epoch: 93 [640/35339 (2%)]	Loss: 0.071007
Train Epoch: 93 [1280/35339 (4%)]	Loss: 0.253787
Train Epoch: 93 [1920/35339 (5%)]	Loss: 0.089408
Train Epoch: 93 [2560/35339 (7%)]	Loss: 0.067775
Train Epoch: 93 [3200/35339 (9%)]	Loss: 0.074765
Train Epoch: 93 [3840/35339 (11%)]	Loss: 0.183480
Train Epoch: 93 [4480/35339 (13%)]	Loss: 0.073892
Train Epoch: 93 [5120/35339 (14%)]	Loss: 0.093975
Train Epoch: 93 [5760/35339 (16%)]	Loss: 0.061473
Train Epoch: 93 [6400/35339 (18%)]	Loss: 0.210703
Train Epoch: 93 [7040/35339 (20%)]	Loss: 0.065057
Train Epoch: 93 [7680/35339 (22%)]	Loss: 0.067796
Train Epoch: 93 [8320/35339 (24%)]	Loss: 0.139120
Train Epoch: 93 [8960/35339 (25%)]	Loss: 0.083933
Train Epoch: 93 [9600/35339 (27%)]	Loss: 0.232246
Train Epoch: 93 [10240/35339 (29%)]	Loss: 0.090619
Train Epoch: 93 [10880/35339 (31%)]	Loss: 0.149531
Train Epoch: 93 [11520/35339 (33%)]	Loss: 0.127038
Train Epoch: 93 [12160/35339 (34%)]	Loss: 0.066160
Train Epoch: 93 [12800/35339 (36%)]	Loss: 0.075117
Train Epoch: 93 [13440/35339 (38%)]	Loss: 0.080507
Train Epoch: 93 [14080/35339 (40%)]	Loss: 0.080979
Train Epoch: 93 [14720/35339 (42%)]	Loss: 0.131208
Train Epoch: 93 [15360/35339 (43%)]	Loss: 0.258989
Train Epoch: 93 [16000/35339 (45%)]	Loss: 0.151631
Train Epoch: 93 [16640/35339 (47%)]	Loss: 0.064512
Train Epoch: 93 [17280/35339 (49%)]	Loss: 0.109579
Train Epoch: 93 [17920/35339 (51%)]	Loss: 0.077982
Train Epoch: 93 [18560/35339 (52%)]	Loss: 0.111603
Train Epoch: 93 [19200/35339 (54%)]	Loss: 0.108824
Train Epoch: 93 [19840/35339 (56%)]	Loss: 0.075796
Train Epoch: 93 [20480/35339 (58%)]	Loss: 0.080563
Train Epoch: 93 [21120/35339 (60%)]	Loss: 0.148062
Train Epoch: 93 [21760/35339 (61%)]	Loss: 0.082658
Train Epoch: 93 [22400/35339 (63%)]	Loss: 0.104791
Train Epoch: 93 [23040/35339 (65%)]	Loss: 0.078513
Train Epoch: 93 [23680/35339 (67%)]	Loss: 0.116077
Train Epoch: 93 [24320/35339 (69%)]	Loss: 0.094232
Train Epoch: 93 [24960/35339 (71%)]	Loss: 0.065156
Train Epoch: 93 [25600/35339 (72%)]	Loss: 0.070168
Train Epoch: 93 [26240/35339 (74%)]	Loss: 0.089678
Train Epoch: 93 [26880/35339 (76%)]	Loss: 0.098475
Train Epoch: 93 [27520/35339 (78%)]	Loss: 0.121162
Train Epoch: 93 [28160/35339 (80%)]	Loss: 0.071142
Train Epoch: 93 [28800/35339 (81%)]	Loss: 0.507060
Train Epoch: 93 [29440/35339 (83%)]	Loss: 0.117689
Train Epoch: 93 [30080/35339 (85%)]	Loss: 0.065657
Train Epoch: 93 [30720/35339 (87%)]	Loss: 0.088895
Train Epoch: 93 [31360/35339 (89%)]	Loss: 0.114694
Train Epoch: 93 [32000/35339 (90%)]	Loss: 0.104697
Train Epoch: 93 [32640/35339 (92%)]	Loss: 0.067437
Train Epoch: 93 [33280/35339 (94%)]	Loss: 0.483672
Train Epoch: 93 [33920/35339 (96%)]	Loss: 0.219977
Train Epoch: 93 [34560/35339 (98%)]	Loss: 0.108786
Train Epoch: 93 [35200/35339 (99%)]	Loss: 0.079991

Validation set: Average loss: 2.9821, Accuracy: 1757/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 94 [0/35339 (0%)]	Loss: 0.082771
Train Epoch: 94 [640/35339 (2%)]	Loss: 0.064249
Train Epoch: 94 [1280/35339 (4%)]	Loss: 0.134975
Train Epoch: 94 [1920/35339 (5%)]	Loss: 0.072099
Train Epoch: 94 [2560/35339 (7%)]	Loss: 0.127589
Train Epoch: 94 [3200/35339 (9%)]	Loss: 0.066035
Train Epoch: 94 [3840/35339 (11%)]	Loss: 0.082390
Train Epoch: 94 [4480/35339 (13%)]	Loss: 0.095857
Train Epoch: 94 [5120/35339 (14%)]	Loss: 0.097552
Train Epoch: 94 [5760/35339 (16%)]	Loss: 0.074269
Train Epoch: 94 [6400/35339 (18%)]	Loss: 0.133745
Train Epoch: 94 [7040/35339 (20%)]	Loss: 0.099548
Train Epoch: 94 [7680/35339 (22%)]	Loss: 0.117919
Train Epoch: 94 [8320/35339 (24%)]	Loss: 0.190951
Train Epoch: 94 [8960/35339 (25%)]	Loss: 0.080850
Train Epoch: 94 [9600/35339 (27%)]	Loss: 0.068307
Train Epoch: 94 [10240/35339 (29%)]	Loss: 0.081224
Train Epoch: 94 [10880/35339 (31%)]	Loss: 0.085855
Train Epoch: 94 [11520/35339 (33%)]	Loss: 0.074183
Train Epoch: 94 [12160/35339 (34%)]	Loss: 0.068682
Train Epoch: 94 [12800/35339 (36%)]	Loss: 0.105342
Train Epoch: 94 [13440/35339 (38%)]	Loss: 0.102066
Train Epoch: 94 [14080/35339 (40%)]	Loss: 0.070365
Train Epoch: 94 [14720/35339 (42%)]	Loss: 0.147641
Train Epoch: 94 [15360/35339 (43%)]	Loss: 0.082693
Train Epoch: 94 [16000/35339 (45%)]	Loss: 0.070758
Train Epoch: 94 [16640/35339 (47%)]	Loss: 0.133850
Train Epoch: 94 [17280/35339 (49%)]	Loss: 0.272767
Train Epoch: 94 [17920/35339 (51%)]	Loss: 0.082589
Train Epoch: 94 [18560/35339 (52%)]	Loss: 0.095099
Train Epoch: 94 [19200/35339 (54%)]	Loss: 0.093913
Train Epoch: 94 [19840/35339 (56%)]	Loss: 0.065906
Train Epoch: 94 [20480/35339 (58%)]	Loss: 0.064911
Train Epoch: 94 [21120/35339 (60%)]	Loss: 0.167024
Train Epoch: 94 [21760/35339 (61%)]	Loss: 0.098606
Train Epoch: 94 [22400/35339 (63%)]	Loss: 0.118966
Train Epoch: 94 [23040/35339 (65%)]	Loss: 0.101285
Train Epoch: 94 [23680/35339 (67%)]	Loss: 0.078525
Train Epoch: 94 [24320/35339 (69%)]	Loss: 0.065034
Train Epoch: 94 [24960/35339 (71%)]	Loss: 0.098034
Train Epoch: 94 [25600/35339 (72%)]	Loss: 0.061399
Train Epoch: 94 [26240/35339 (74%)]	Loss: 0.077394
Train Epoch: 94 [26880/35339 (76%)]	Loss: 0.074532
Train Epoch: 94 [27520/35339 (78%)]	Loss: 0.064285
Train Epoch: 94 [28160/35339 (80%)]	Loss: 0.074358
Train Epoch: 94 [28800/35339 (81%)]	Loss: 0.063786
Train Epoch: 94 [29440/35339 (83%)]	Loss: 0.071629
Train Epoch: 94 [30080/35339 (85%)]	Loss: 0.119243
Train Epoch: 94 [30720/35339 (87%)]	Loss: 0.065516
Train Epoch: 94 [31360/35339 (89%)]	Loss: 0.094756
Train Epoch: 94 [32000/35339 (90%)]	Loss: 0.079465
Train Epoch: 94 [32640/35339 (92%)]	Loss: 0.122870
Train Epoch: 94 [33280/35339 (94%)]	Loss: 0.197843
Train Epoch: 94 [33920/35339 (96%)]	Loss: 0.172669
Train Epoch: 94 [34560/35339 (98%)]	Loss: 0.094908
Train Epoch: 94 [35200/35339 (99%)]	Loss: 0.208450

Validation set: Average loss: 2.9680, Accuracy: 1737/3870 (45%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 95 [0/35339 (0%)]	Loss: 0.066507
Train Epoch: 95 [640/35339 (2%)]	Loss: 0.085827
Train Epoch: 95 [1280/35339 (4%)]	Loss: 0.117734
Train Epoch: 95 [1920/35339 (5%)]	Loss: 0.118368
Train Epoch: 95 [2560/35339 (7%)]	Loss: 0.104709
Train Epoch: 95 [3200/35339 (9%)]	Loss: 0.074950
Train Epoch: 95 [3840/35339 (11%)]	Loss: 0.094615
Train Epoch: 95 [4480/35339 (13%)]	Loss: 0.113789
Train Epoch: 95 [5120/35339 (14%)]	Loss: 0.081945
Train Epoch: 95 [5760/35339 (16%)]	Loss: 0.113633
Train Epoch: 95 [6400/35339 (18%)]	Loss: 0.089429
Train Epoch: 95 [7040/35339 (20%)]	Loss: 0.136362
Train Epoch: 95 [7680/35339 (22%)]	Loss: 0.097178
Train Epoch: 95 [8320/35339 (24%)]	Loss: 0.070601
Train Epoch: 95 [8960/35339 (25%)]	Loss: 0.087045
Train Epoch: 95 [9600/35339 (27%)]	Loss: 0.109018
Train Epoch: 95 [10240/35339 (29%)]	Loss: 0.102081
Train Epoch: 95 [10880/35339 (31%)]	Loss: 0.180671
Train Epoch: 95 [11520/35339 (33%)]	Loss: 0.097839
Train Epoch: 95 [12160/35339 (34%)]	Loss: 0.122013
Train Epoch: 95 [12800/35339 (36%)]	Loss: 0.068383
Train Epoch: 95 [13440/35339 (38%)]	Loss: 0.063063
Train Epoch: 95 [14080/35339 (40%)]	Loss: 0.147597
Train Epoch: 95 [14720/35339 (42%)]	Loss: 0.089565
Train Epoch: 95 [15360/35339 (43%)]	Loss: 0.061372
Train Epoch: 95 [16000/35339 (45%)]	Loss: 0.085313
Train Epoch: 95 [16640/35339 (47%)]	Loss: 0.103326
Train Epoch: 95 [17280/35339 (49%)]	Loss: 0.097126
Train Epoch: 95 [17920/35339 (51%)]	Loss: 0.064849
Train Epoch: 95 [18560/35339 (52%)]	Loss: 0.100825
Train Epoch: 95 [19200/35339 (54%)]	Loss: 0.062784
Train Epoch: 95 [19840/35339 (56%)]	Loss: 0.065395
Train Epoch: 95 [20480/35339 (58%)]	Loss: 0.067555
Train Epoch: 95 [21120/35339 (60%)]	Loss: 0.072114
Train Epoch: 95 [21760/35339 (61%)]	Loss: 0.070275
Train Epoch: 95 [22400/35339 (63%)]	Loss: 0.185788
Train Epoch: 95 [23040/35339 (65%)]	Loss: 0.065227
Train Epoch: 95 [23680/35339 (67%)]	Loss: 0.094012
Train Epoch: 95 [24320/35339 (69%)]	Loss: 0.096980
Train Epoch: 95 [24960/35339 (71%)]	Loss: 0.062395
Train Epoch: 95 [25600/35339 (72%)]	Loss: 0.095237
Train Epoch: 95 [26240/35339 (74%)]	Loss: 0.104409
Train Epoch: 95 [26880/35339 (76%)]	Loss: 0.085149
Train Epoch: 95 [27520/35339 (78%)]	Loss: 0.091984
Train Epoch: 95 [28160/35339 (80%)]	Loss: 0.140685
Train Epoch: 95 [28800/35339 (81%)]	Loss: 0.280695
Train Epoch: 95 [29440/35339 (83%)]	Loss: 0.068935
Train Epoch: 95 [30080/35339 (85%)]	Loss: 0.071716
Train Epoch: 95 [30720/35339 (87%)]	Loss: 0.127045
Train Epoch: 95 [31360/35339 (89%)]	Loss: 0.107245
Train Epoch: 95 [32000/35339 (90%)]	Loss: 0.084641
Train Epoch: 95 [32640/35339 (92%)]	Loss: 0.079608
Train Epoch: 95 [33280/35339 (94%)]	Loss: 0.119732
Train Epoch: 95 [33920/35339 (96%)]	Loss: 0.088542
Train Epoch: 95 [34560/35339 (98%)]	Loss: 0.103915
Train Epoch: 95 [35200/35339 (99%)]	Loss: 0.068401

Validation set: Average loss: 3.0363, Accuracy: 1686/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 96 [0/35339 (0%)]	Loss: 0.076424
Train Epoch: 96 [640/35339 (2%)]	Loss: 0.096737
Train Epoch: 96 [1280/35339 (4%)]	Loss: 0.091416
Train Epoch: 96 [1920/35339 (5%)]	Loss: 0.156615
Train Epoch: 96 [2560/35339 (7%)]	Loss: 0.086949
Train Epoch: 96 [3200/35339 (9%)]	Loss: 0.064434
Train Epoch: 96 [3840/35339 (11%)]	Loss: 0.073832
Train Epoch: 96 [4480/35339 (13%)]	Loss: 0.123919
Train Epoch: 96 [5120/35339 (14%)]	Loss: 0.088377
Train Epoch: 96 [5760/35339 (16%)]	Loss: 0.061219
Train Epoch: 96 [6400/35339 (18%)]	Loss: 0.079871
Train Epoch: 96 [7040/35339 (20%)]	Loss: 0.301508
Train Epoch: 96 [7680/35339 (22%)]	Loss: 0.099758
Train Epoch: 96 [8320/35339 (24%)]	Loss: 0.063382
Train Epoch: 96 [8960/35339 (25%)]	Loss: 0.104188
Train Epoch: 96 [9600/35339 (27%)]	Loss: 0.074228
Train Epoch: 96 [10240/35339 (29%)]	Loss: 0.086626
Train Epoch: 96 [10880/35339 (31%)]	Loss: 0.085415
Train Epoch: 96 [11520/35339 (33%)]	Loss: 0.061278
Train Epoch: 96 [12160/35339 (34%)]	Loss: 0.121796
Train Epoch: 96 [12800/35339 (36%)]	Loss: 0.077292
Train Epoch: 96 [13440/35339 (38%)]	Loss: 0.062890
Train Epoch: 96 [14080/35339 (40%)]	Loss: 0.066944
Train Epoch: 96 [14720/35339 (42%)]	Loss: 0.149890
Train Epoch: 96 [15360/35339 (43%)]	Loss: 0.060888
Train Epoch: 96 [16000/35339 (45%)]	Loss: 0.057663
Train Epoch: 96 [16640/35339 (47%)]	Loss: 0.108698
Train Epoch: 96 [17280/35339 (49%)]	Loss: 0.106517
Train Epoch: 96 [17920/35339 (51%)]	Loss: 0.083910
Train Epoch: 96 [18560/35339 (52%)]	Loss: 0.091746
Train Epoch: 96 [19200/35339 (54%)]	Loss: 0.096321
Train Epoch: 96 [19840/35339 (56%)]	Loss: 0.063367
Train Epoch: 96 [20480/35339 (58%)]	Loss: 0.073513
Train Epoch: 96 [21120/35339 (60%)]	Loss: 0.110680
Train Epoch: 96 [21760/35339 (61%)]	Loss: 0.098858
Train Epoch: 96 [22400/35339 (63%)]	Loss: 0.087636
Train Epoch: 96 [23040/35339 (65%)]	Loss: 0.185126
Train Epoch: 96 [23680/35339 (67%)]	Loss: 0.137059
Train Epoch: 96 [24320/35339 (69%)]	Loss: 0.153881
Train Epoch: 96 [24960/35339 (71%)]	Loss: 0.110135
Train Epoch: 96 [25600/35339 (72%)]	Loss: 0.101653
Train Epoch: 96 [26240/35339 (74%)]	Loss: 0.081115
Train Epoch: 96 [26880/35339 (76%)]	Loss: 0.418769
Train Epoch: 96 [27520/35339 (78%)]	Loss: 0.097382
Train Epoch: 96 [28160/35339 (80%)]	Loss: 0.126381
Train Epoch: 96 [28800/35339 (81%)]	Loss: 0.110484
Train Epoch: 96 [29440/35339 (83%)]	Loss: 0.091387
Train Epoch: 96 [30080/35339 (85%)]	Loss: 0.113638
Train Epoch: 96 [30720/35339 (87%)]	Loss: 0.141406
Train Epoch: 96 [31360/35339 (89%)]	Loss: 0.108973
Train Epoch: 96 [32000/35339 (90%)]	Loss: 0.205071
Train Epoch: 96 [32640/35339 (92%)]	Loss: 0.185706
Train Epoch: 96 [33280/35339 (94%)]	Loss: 0.101111
Train Epoch: 96 [33920/35339 (96%)]	Loss: 0.122846
Train Epoch: 96 [34560/35339 (98%)]	Loss: 0.110529
Train Epoch: 96 [35200/35339 (99%)]	Loss: 0.068257

Validation set: Average loss: 3.0375, Accuracy: 1653/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 97 [0/35339 (0%)]	Loss: 0.087924
Train Epoch: 97 [640/35339 (2%)]	Loss: 0.113323
Train Epoch: 97 [1280/35339 (4%)]	Loss: 0.090223
Train Epoch: 97 [1920/35339 (5%)]	Loss: 0.108039
Train Epoch: 97 [2560/35339 (7%)]	Loss: 0.094950
Train Epoch: 97 [3200/35339 (9%)]	Loss: 0.156471
Train Epoch: 97 [3840/35339 (11%)]	Loss: 0.087541
Train Epoch: 97 [4480/35339 (13%)]	Loss: 0.065635
Train Epoch: 97 [5120/35339 (14%)]	Loss: 0.060698
Train Epoch: 97 [5760/35339 (16%)]	Loss: 0.088651
Train Epoch: 97 [6400/35339 (18%)]	Loss: 0.112576
Train Epoch: 97 [7040/35339 (20%)]	Loss: 0.109533
Train Epoch: 97 [7680/35339 (22%)]	Loss: 0.068650
Train Epoch: 97 [8320/35339 (24%)]	Loss: 0.103531
Train Epoch: 97 [8960/35339 (25%)]	Loss: 0.106032
Train Epoch: 97 [9600/35339 (27%)]	Loss: 0.156693
Train Epoch: 97 [10240/35339 (29%)]	Loss: 0.065927
Train Epoch: 97 [10880/35339 (31%)]	Loss: 0.064999
Train Epoch: 97 [11520/35339 (33%)]	Loss: 0.062899
Train Epoch: 97 [12160/35339 (34%)]	Loss: 0.077602
Train Epoch: 97 [12800/35339 (36%)]	Loss: 0.126085
Train Epoch: 97 [13440/35339 (38%)]	Loss: 0.096385
Train Epoch: 97 [14080/35339 (40%)]	Loss: 0.070355
Train Epoch: 97 [14720/35339 (42%)]	Loss: 0.092821
Train Epoch: 97 [15360/35339 (43%)]	Loss: 0.102647
Train Epoch: 97 [16000/35339 (45%)]	Loss: 0.105828
Train Epoch: 97 [16640/35339 (47%)]	Loss: 0.070315
Train Epoch: 97 [17280/35339 (49%)]	Loss: 0.111337
Train Epoch: 97 [17920/35339 (51%)]	Loss: 0.072612
Train Epoch: 97 [18560/35339 (52%)]	Loss: 0.128534
Train Epoch: 97 [19200/35339 (54%)]	Loss: 0.094774
Train Epoch: 97 [19840/35339 (56%)]	Loss: 0.103757
Train Epoch: 97 [20480/35339 (58%)]	Loss: 0.071883
Train Epoch: 97 [21120/35339 (60%)]	Loss: 0.096393
Train Epoch: 97 [21760/35339 (61%)]	Loss: 0.096610
Train Epoch: 97 [22400/35339 (63%)]	Loss: 0.069517
Train Epoch: 97 [23040/35339 (65%)]	Loss: 0.083995
Train Epoch: 97 [23680/35339 (67%)]	Loss: 0.187840
Train Epoch: 97 [24320/35339 (69%)]	Loss: 0.080349
Train Epoch: 97 [24960/35339 (71%)]	Loss: 0.147530
Train Epoch: 97 [25600/35339 (72%)]	Loss: 0.152780
Train Epoch: 97 [26240/35339 (74%)]	Loss: 0.111684
Train Epoch: 97 [26880/35339 (76%)]	Loss: 0.060489
Train Epoch: 97 [27520/35339 (78%)]	Loss: 0.081596
Train Epoch: 97 [28160/35339 (80%)]	Loss: 0.157513
Train Epoch: 97 [28800/35339 (81%)]	Loss: 0.132000
Train Epoch: 97 [29440/35339 (83%)]	Loss: 0.066563
Train Epoch: 97 [30080/35339 (85%)]	Loss: 0.081289
Train Epoch: 97 [30720/35339 (87%)]	Loss: 0.126392
Train Epoch: 97 [31360/35339 (89%)]	Loss: 0.080266
Train Epoch: 97 [32000/35339 (90%)]	Loss: 0.060115
Train Epoch: 97 [32640/35339 (92%)]	Loss: 0.184021
Train Epoch: 97 [33280/35339 (94%)]	Loss: 0.141002
Train Epoch: 97 [33920/35339 (96%)]	Loss: 0.067563
Train Epoch: 97 [34560/35339 (98%)]	Loss: 0.111983
Train Epoch: 97 [35200/35339 (99%)]	Loss: 0.119025

Validation set: Average loss: 3.0664, Accuracy: 1710/3870 (44%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 98 [0/35339 (0%)]	Loss: 0.260878
Train Epoch: 98 [640/35339 (2%)]	Loss: 0.145195
Train Epoch: 98 [1280/35339 (4%)]	Loss: 0.096416
Train Epoch: 98 [1920/35339 (5%)]	Loss: 0.135295
Train Epoch: 98 [2560/35339 (7%)]	Loss: 0.123706
Train Epoch: 98 [3200/35339 (9%)]	Loss: 0.114410
Train Epoch: 98 [3840/35339 (11%)]	Loss: 0.081525
Train Epoch: 98 [4480/35339 (13%)]	Loss: 0.110121
Train Epoch: 98 [5120/35339 (14%)]	Loss: 0.157356
Train Epoch: 98 [5760/35339 (16%)]	Loss: 0.071529
Train Epoch: 98 [6400/35339 (18%)]	Loss: 0.089165
Train Epoch: 98 [7040/35339 (20%)]	Loss: 0.081443
Train Epoch: 98 [7680/35339 (22%)]	Loss: 0.125200
Train Epoch: 98 [8320/35339 (24%)]	Loss: 0.080149
Train Epoch: 98 [8960/35339 (25%)]	Loss: 0.145670
Train Epoch: 98 [9600/35339 (27%)]	Loss: 0.122369
Train Epoch: 98 [10240/35339 (29%)]	Loss: 0.102825
Train Epoch: 98 [10880/35339 (31%)]	Loss: 0.106397
Train Epoch: 98 [11520/35339 (33%)]	Loss: 0.068967
Train Epoch: 98 [12160/35339 (34%)]	Loss: 0.074460
Train Epoch: 98 [12800/35339 (36%)]	Loss: 0.067840
Train Epoch: 98 [13440/35339 (38%)]	Loss: 0.103945
Train Epoch: 98 [14080/35339 (40%)]	Loss: 0.124321
Train Epoch: 98 [14720/35339 (42%)]	Loss: 0.076027
Train Epoch: 98 [15360/35339 (43%)]	Loss: 0.111230
Train Epoch: 98 [16000/35339 (45%)]	Loss: 0.109577
Train Epoch: 98 [16640/35339 (47%)]	Loss: 0.076305
Train Epoch: 98 [17280/35339 (49%)]	Loss: 0.069809
Train Epoch: 98 [17920/35339 (51%)]	Loss: 0.131864
Train Epoch: 98 [18560/35339 (52%)]	Loss: 0.116774
Train Epoch: 98 [19200/35339 (54%)]	Loss: 0.135261
Train Epoch: 98 [19840/35339 (56%)]	Loss: 0.091967
Train Epoch: 98 [20480/35339 (58%)]	Loss: 0.149777
Train Epoch: 98 [21120/35339 (60%)]	Loss: 0.117210
Train Epoch: 98 [21760/35339 (61%)]	Loss: 0.150037
Train Epoch: 98 [22400/35339 (63%)]	Loss: 0.223722
Train Epoch: 98 [23040/35339 (65%)]	Loss: 0.081548
Train Epoch: 98 [23680/35339 (67%)]	Loss: 0.084408
Train Epoch: 98 [24320/35339 (69%)]	Loss: 0.076275
Train Epoch: 98 [24960/35339 (71%)]	Loss: 0.246177
Train Epoch: 98 [25600/35339 (72%)]	Loss: 0.083822
Train Epoch: 98 [26240/35339 (74%)]	Loss: 0.133316
Train Epoch: 98 [26880/35339 (76%)]	Loss: 0.094762
Train Epoch: 98 [27520/35339 (78%)]	Loss: 0.150162
Train Epoch: 98 [28160/35339 (80%)]	Loss: 0.067441
Train Epoch: 98 [28800/35339 (81%)]	Loss: 0.095117
Train Epoch: 98 [29440/35339 (83%)]	Loss: 0.171103
Train Epoch: 98 [30080/35339 (85%)]	Loss: 0.089820
Train Epoch: 98 [30720/35339 (87%)]	Loss: 0.090584
Train Epoch: 98 [31360/35339 (89%)]	Loss: 0.135728
Train Epoch: 98 [32000/35339 (90%)]	Loss: 0.104428
Train Epoch: 98 [32640/35339 (92%)]	Loss: 0.089551
Train Epoch: 98 [33280/35339 (94%)]	Loss: 0.112929
Train Epoch: 98 [33920/35339 (96%)]	Loss: 0.089302
Train Epoch: 98 [34560/35339 (98%)]	Loss: 0.112169
Train Epoch: 98 [35200/35339 (99%)]	Loss: 0.114592

Validation set: Average loss: 3.1214, Accuracy: 1630/3870 (42%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 99 [0/35339 (0%)]	Loss: 0.201525
Train Epoch: 99 [640/35339 (2%)]	Loss: 0.153416
Train Epoch: 99 [1280/35339 (4%)]	Loss: 0.062182
Train Epoch: 99 [1920/35339 (5%)]	Loss: 0.092631
Train Epoch: 99 [2560/35339 (7%)]	Loss: 0.097673
Train Epoch: 99 [3200/35339 (9%)]	Loss: 0.105937
Train Epoch: 99 [3840/35339 (11%)]	Loss: 0.082349
Train Epoch: 99 [4480/35339 (13%)]	Loss: 0.065267
Train Epoch: 99 [5120/35339 (14%)]	Loss: 0.069547
Train Epoch: 99 [5760/35339 (16%)]	Loss: 0.168085
Train Epoch: 99 [6400/35339 (18%)]	Loss: 0.090562
Train Epoch: 99 [7040/35339 (20%)]	Loss: 0.067473
Train Epoch: 99 [7680/35339 (22%)]	Loss: 0.105970
Train Epoch: 99 [8320/35339 (24%)]	Loss: 0.063459
Train Epoch: 99 [8960/35339 (25%)]	Loss: 0.114034
Train Epoch: 99 [9600/35339 (27%)]	Loss: 0.060738
Train Epoch: 99 [10240/35339 (29%)]	Loss: 0.107321
Train Epoch: 99 [10880/35339 (31%)]	Loss: 0.099021
Train Epoch: 99 [11520/35339 (33%)]	Loss: 0.065578
Train Epoch: 99 [12160/35339 (34%)]	Loss: 0.094128
Train Epoch: 99 [12800/35339 (36%)]	Loss: 0.117108
Train Epoch: 99 [13440/35339 (38%)]	Loss: 0.165549
Train Epoch: 99 [14080/35339 (40%)]	Loss: 0.084956
Train Epoch: 99 [14720/35339 (42%)]	Loss: 0.092245
Train Epoch: 99 [15360/35339 (43%)]	Loss: 0.102051
Train Epoch: 99 [16000/35339 (45%)]	Loss: 0.132621
Train Epoch: 99 [16640/35339 (47%)]	Loss: 0.097387
Train Epoch: 99 [17280/35339 (49%)]	Loss: 0.110750
Train Epoch: 99 [17920/35339 (51%)]	Loss: 0.095409
Train Epoch: 99 [18560/35339 (52%)]	Loss: 0.084071
Train Epoch: 99 [19200/35339 (54%)]	Loss: 0.133427
Train Epoch: 99 [19840/35339 (56%)]	Loss: 0.067110
Train Epoch: 99 [20480/35339 (58%)]	Loss: 0.127762
Train Epoch: 99 [21120/35339 (60%)]	Loss: 0.065012
Train Epoch: 99 [21760/35339 (61%)]	Loss: 0.062900
Train Epoch: 99 [22400/35339 (63%)]	Loss: 0.116380
Train Epoch: 99 [23040/35339 (65%)]	Loss: 0.084872
Train Epoch: 99 [23680/35339 (67%)]	Loss: 0.187526
Train Epoch: 99 [24320/35339 (69%)]	Loss: 0.122075
Train Epoch: 99 [24960/35339 (71%)]	Loss: 0.146467
Train Epoch: 99 [25600/35339 (72%)]	Loss: 0.302031
Train Epoch: 99 [26240/35339 (74%)]	Loss: 0.079481
Train Epoch: 99 [26880/35339 (76%)]	Loss: 0.085179
Train Epoch: 99 [27520/35339 (78%)]	Loss: 0.064923
Train Epoch: 99 [28160/35339 (80%)]	Loss: 0.073274
Train Epoch: 99 [28800/35339 (81%)]	Loss: 0.088917
Train Epoch: 99 [29440/35339 (83%)]	Loss: 0.121328
Train Epoch: 99 [30080/35339 (85%)]	Loss: 0.068309
Train Epoch: 99 [30720/35339 (87%)]	Loss: 0.066097
Train Epoch: 99 [31360/35339 (89%)]	Loss: 0.095175
Train Epoch: 99 [32000/35339 (90%)]	Loss: 0.077430
Train Epoch: 99 [32640/35339 (92%)]	Loss: 0.082449
Train Epoch: 99 [33280/35339 (94%)]	Loss: 0.101973
Train Epoch: 99 [33920/35339 (96%)]	Loss: 0.064721
Train Epoch: 99 [34560/35339 (98%)]	Loss: 0.072509
Train Epoch: 99 [35200/35339 (99%)]	Loss: 0.100379

Validation set: Average loss: 3.1676, Accuracy: 1648/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
Train Epoch: 100 [0/35339 (0%)]	Loss: 0.106911
Train Epoch: 100 [640/35339 (2%)]	Loss: 0.110699
Train Epoch: 100 [1280/35339 (4%)]	Loss: 0.100900
Train Epoch: 100 [1920/35339 (5%)]	Loss: 0.244026
Train Epoch: 100 [2560/35339 (7%)]	Loss: 0.132505
Train Epoch: 100 [3200/35339 (9%)]	Loss: 0.077761
Train Epoch: 100 [3840/35339 (11%)]	Loss: 0.072193
Train Epoch: 100 [4480/35339 (13%)]	Loss: 0.066182
Train Epoch: 100 [5120/35339 (14%)]	Loss: 0.097957
Train Epoch: 100 [5760/35339 (16%)]	Loss: 0.080957
Train Epoch: 100 [6400/35339 (18%)]	Loss: 0.063566
Train Epoch: 100 [7040/35339 (20%)]	Loss: 0.077680
Train Epoch: 100 [7680/35339 (22%)]	Loss: 0.099031
Train Epoch: 100 [8320/35339 (24%)]	Loss: 0.080798
Train Epoch: 100 [8960/35339 (25%)]	Loss: 0.135002
Train Epoch: 100 [9600/35339 (27%)]	Loss: 0.119833
Train Epoch: 100 [10240/35339 (29%)]	Loss: 0.106142
Train Epoch: 100 [10880/35339 (31%)]	Loss: 0.072273
Train Epoch: 100 [11520/35339 (33%)]	Loss: 0.066061
Train Epoch: 100 [12160/35339 (34%)]	Loss: 0.064828
Train Epoch: 100 [12800/35339 (36%)]	Loss: 0.098428
Train Epoch: 100 [13440/35339 (38%)]	Loss: 0.137448
Train Epoch: 100 [14080/35339 (40%)]	Loss: 0.088604
Train Epoch: 100 [14720/35339 (42%)]	Loss: 0.103381
Train Epoch: 100 [15360/35339 (43%)]	Loss: 0.070589
Train Epoch: 100 [16000/35339 (45%)]	Loss: 0.076500
Train Epoch: 100 [16640/35339 (47%)]	Loss: 0.092907
Train Epoch: 100 [17280/35339 (49%)]	Loss: 0.068229
Train Epoch: 100 [17920/35339 (51%)]	Loss: 0.074922
Train Epoch: 100 [18560/35339 (52%)]	Loss: 0.159120
Train Epoch: 100 [19200/35339 (54%)]	Loss: 0.112305
Train Epoch: 100 [19840/35339 (56%)]	Loss: 0.103158
Train Epoch: 100 [20480/35339 (58%)]	Loss: 0.077973
Train Epoch: 100 [21120/35339 (60%)]	Loss: 0.064166
Train Epoch: 100 [21760/35339 (61%)]	Loss: 0.090460
Train Epoch: 100 [22400/35339 (63%)]	Loss: 0.076640
Train Epoch: 100 [23040/35339 (65%)]	Loss: 0.063510
Train Epoch: 100 [23680/35339 (67%)]	Loss: 0.062613
Train Epoch: 100 [24320/35339 (69%)]	Loss: 0.191441
Train Epoch: 100 [24960/35339 (71%)]	Loss: 0.116852
Train Epoch: 100 [25600/35339 (72%)]	Loss: 0.081231
Train Epoch: 100 [26240/35339 (74%)]	Loss: 0.122611
Train Epoch: 100 [26880/35339 (76%)]	Loss: 0.124691
Train Epoch: 100 [27520/35339 (78%)]	Loss: 0.086260
Train Epoch: 100 [28160/35339 (80%)]	Loss: 0.092194
Train Epoch: 100 [28800/35339 (81%)]	Loss: 0.089929
Train Epoch: 100 [29440/35339 (83%)]	Loss: 0.060787
Train Epoch: 100 [30080/35339 (85%)]	Loss: 0.085428
Train Epoch: 100 [30720/35339 (87%)]	Loss: 0.074162
Train Epoch: 100 [31360/35339 (89%)]	Loss: 0.110988
Train Epoch: 100 [32000/35339 (90%)]	Loss: 0.101942
Train Epoch: 100 [32640/35339 (92%)]	Loss: 0.063168
Train Epoch: 100 [33280/35339 (94%)]	Loss: 0.066080
Train Epoch: 100 [33920/35339 (96%)]	Loss: 0.112598
Train Epoch: 100 [34560/35339 (98%)]	Loss: 0.059732
Train Epoch: 100 [35200/35339 (99%)]	Loss: 0.113901

Validation set: Average loss: 3.0759, Accuracy: 1683/3870 (43%)


Saved model to model_latest_Adagrad.pth. You can run `python evaluate.py model_latest_Adagrad.pth` to generate the Kaggle formatted csv file
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
  0%|          | 0/12631 [00:00<?, ?it/s]  0%|          | 8/12631 [00:00<02:40, 78.77it/s]  0%|          | 19/12631 [00:00<02:32, 82.91it/s]  0%|          | 30/12631 [00:00<02:23, 87.99it/s]  0%|          | 41/12631 [00:00<02:15, 92.64it/s]  0%|          | 52/12631 [00:00<02:10, 96.65it/s]  0%|          | 63/12631 [00:00<02:07, 98.33it/s]  1%|          | 76/12631 [00:00<01:58, 105.76it/s]  1%|          | 88/12631 [00:00<01:55, 108.80it/s]  1%|          | 99/12631 [00:00<01:59, 105.04it/s]  1%|          | 111/12631 [00:01<01:55, 108.14it/s]  1%|          | 126/12631 [00:01<01:48, 115.29it/s]  1%|1         | 140/12631 [00:01<01:42, 121.32it/s]  1%|1         | 153/12631 [00:01<01:41, 122.76it/s]  1%|1         | 166/12631 [00:01<01:42, 121.89it/s]  1%|1         | 181/12631 [00:01<01:38, 126.63it/s]  2%|1         | 195/12631 [00:01<01:35, 129.94it/s]  2%|1         | 209/12631 [00:01<01:40, 123.28it/s]  2%|1         | 222/12631 [00:01<01:39, 124.91it/s]  2%|1         | 235/12631 [00:02<01:42, 121.36it/s]  2%|1         | 252/12631 [00:02<01:33, 132.01it/s]  2%|2         | 266/12631 [00:02<01:34, 131.43it/s]  2%|2         | 282/12631 [00:02<01:29, 137.95it/s]  2%|2         | 297/12631 [00:02<01:31, 135.51it/s]  2%|2         | 312/12631 [00:02<01:29, 137.89it/s]  3%|2         | 327/12631 [00:02<01:27, 140.61it/s]  3%|2         | 342/12631 [00:02<01:33, 131.26it/s]  3%|2         | 357/12631 [00:02<01:30, 134.96it/s]  3%|2         | 371/12631 [00:03<01:33, 131.48it/s]  3%|3         | 387/12631 [00:03<01:30, 134.86it/s]  3%|3         | 401/12631 [00:03<01:41, 120.62it/s]  3%|3         | 414/12631 [00:03<02:30, 80.93it/s]   3%|3         | 425/12631 [00:03<02:34, 78.85it/s]  3%|3         | 435/12631 [00:03<02:30, 81.30it/s]  4%|3         | 445/12631 [00:03<02:22, 85.39it/s]  4%|3         | 455/12631 [00:04<02:38, 76.61it/s]  4%|3         | 467/12631 [00:04<02:23, 84.78it/s]  4%|3         | 483/12631 [00:04<02:03, 98.21it/s]  4%|3         | 497/12631 [00:04<01:53, 106.74it/s]  4%|4         | 510/12631 [00:04<01:48, 111.35it/s]  4%|4         | 523/12631 [00:04<01:49, 110.67it/s]  4%|4         | 535/12631 [00:04<02:05, 96.29it/s]   4%|4         | 546/12631 [00:04<02:01, 99.69it/s]  4%|4         | 564/12631 [00:04<01:46, 113.41it/s]  5%|4         | 580/12631 [00:05<01:37, 124.01it/s]  5%|4         | 595/12631 [00:05<01:32, 130.07it/s]  5%|4         | 609/12631 [00:05<02:06, 94.66it/s]   5%|4         | 626/12631 [00:05<02:05, 95.50it/s]  5%|5         | 642/12631 [00:05<01:51, 107.79it/s]  5%|5         | 658/12631 [00:05<01:42, 116.71it/s]  5%|5         | 673/12631 [00:05<01:38, 121.60it/s]  5%|5         | 690/12631 [00:06<01:31, 130.93it/s]  6%|5         | 708/12631 [00:06<01:24, 141.22it/s]  6%|5         | 723/12631 [00:06<01:58, 100.42it/s]  6%|5         | 736/12631 [00:06<02:28, 80.17it/s]   6%|5         | 748/12631 [00:06<02:50, 69.65it/s]  6%|5         | 757/12631 [00:06<02:42, 73.25it/s]  6%|6         | 766/12631 [00:07<03:00, 65.75it/s]  6%|6         | 776/12631 [00:07<02:48, 70.56it/s]  6%|6         | 790/12631 [00:07<02:23, 82.71it/s]  6%|6         | 805/12631 [00:07<02:03, 95.47it/s]  6%|6         | 821/12631 [00:07<01:49, 107.97it/s]  7%|6         | 836/12631 [00:07<01:40, 117.74it/s]  7%|6         | 856/12631 [00:07<01:29, 131.38it/s]  7%|6         | 871/12631 [00:07<01:27, 133.71it/s]  7%|7         | 887/12631 [00:07<01:25, 137.01it/s]  7%|7         | 906/12631 [00:08<01:18, 148.47it/s]  7%|7         | 922/12631 [00:08<01:21, 143.90it/s]  7%|7         | 937/12631 [00:08<01:27, 134.41it/s]  8%|7         | 951/12631 [00:08<01:38, 118.10it/s]  8%|7         | 966/12631 [00:08<01:35, 122.62it/s]  8%|7         | 979/12631 [00:08<01:37, 119.67it/s]  8%|7         | 998/12631 [00:08<01:29, 129.90it/s]  8%|8         | 1012/12631 [00:08<01:30, 128.10it/s]  8%|8         | 1026/12631 [00:09<01:35, 121.77it/s]  8%|8         | 1039/12631 [00:09<01:34, 122.53it/s]  8%|8         | 1055/12631 [00:09<01:28, 131.25it/s]  8%|8         | 1069/12631 [00:09<01:26, 133.65it/s]  9%|8         | 1084/12631 [00:09<01:23, 137.78it/s]  9%|8         | 1100/12631 [00:09<01:20, 143.21it/s]  9%|8         | 1117/12631 [00:09<01:17, 149.33it/s]  9%|9         | 1137/12631 [00:09<01:11, 161.15it/s]  9%|9         | 1156/12631 [00:09<01:08, 167.36it/s]  9%|9         | 1176/12631 [00:09<01:05, 174.41it/s]  9%|9         | 1194/12631 [00:10<01:13, 155.66it/s] 10%|9         | 1213/12631 [00:10<01:11, 159.91it/s] 10%|9         | 1231/12631 [00:10<01:09, 162.98it/s] 10%|9         | 1248/12631 [00:10<01:14, 152.65it/s] 10%|#         | 1267/12631 [00:10<01:10, 162.05it/s] 10%|#         | 1285/12631 [00:10<01:07, 167.00it/s] 10%|#         | 1305/12631 [00:10<01:05, 173.65it/s] 10%|#         | 1323/12631 [00:10<01:08, 165.90it/s] 11%|#         | 1341/12631 [00:11<01:07, 166.32it/s] 11%|#         | 1358/12631 [00:11<01:10, 159.69it/s] 11%|#         | 1375/12631 [00:11<01:09, 162.37it/s] 11%|#1        | 1392/12631 [00:11<01:15, 149.44it/s] 11%|#1        | 1408/12631 [00:11<01:18, 142.29it/s] 11%|#1        | 1428/12631 [00:11<01:12, 154.97it/s] 11%|#1        | 1446/12631 [00:11<01:11, 156.79it/s] 12%|#1        | 1464/12631 [00:11<01:09, 159.76it/s] 12%|#1        | 1481/12631 [00:11<01:10, 158.38it/s] 12%|#1        | 1501/12631 [00:12<01:06, 168.19it/s] 12%|#2        | 1519/12631 [00:12<01:07, 165.63it/s] 12%|#2        | 1537/12631 [00:12<01:05, 169.58it/s] 12%|#2        | 1555/12631 [00:12<01:26, 127.38it/s] 12%|#2        | 1570/12631 [00:12<01:39, 110.85it/s] 13%|#2        | 1584/12631 [00:12<01:34, 117.04it/s] 13%|#2        | 1597/12631 [00:12<01:33, 117.44it/s] 13%|#2        | 1614/12631 [00:12<01:25, 128.14it/s] 13%|#2        | 1633/12631 [00:13<01:17, 141.92it/s] 13%|#3        | 1649/12631 [00:13<01:19, 138.61it/s] 13%|#3        | 1664/12631 [00:13<01:36, 113.55it/s] 13%|#3        | 1677/12631 [00:13<01:56, 93.79it/s]  13%|#3        | 1688/12631 [00:13<02:02, 89.32it/s] 13%|#3        | 1699/12631 [00:13<02:06, 86.21it/s] 14%|#3        | 1710/12631 [00:13<01:59, 91.28it/s] 14%|#3        | 1720/12631 [00:14<02:01, 89.94it/s] 14%|#3        | 1735/12631 [00:14<01:47, 101.55it/s] 14%|#3        | 1747/12631 [00:14<02:11, 83.05it/s]  14%|#3        | 1757/12631 [00:14<02:35, 69.74it/s] 14%|#3        | 1766/12631 [00:14<02:47, 64.69it/s] 14%|#4        | 1777/12631 [00:14<02:29, 72.80it/s] 14%|#4        | 1794/12631 [00:14<02:03, 87.83it/s] 14%|#4        | 1811/12631 [00:15<01:46, 101.40it/s] 14%|#4        | 1829/12631 [00:15<01:32, 116.57it/s] 15%|#4        | 1849/12631 [00:15<01:21, 132.84it/s] 15%|#4        | 1866/12631 [00:15<01:16, 141.60it/s] 15%|#4        | 1889/12631 [00:15<01:07, 158.91it/s] 15%|#5        | 1907/12631 [00:15<01:08, 157.10it/s] 15%|#5        | 1925/12631 [00:15<01:10, 151.81it/s] 15%|#5        | 1944/12631 [00:15<01:06, 160.29it/s] 16%|#5        | 1962/12631 [00:15<01:04, 164.31it/s] 16%|#5        | 1983/12631 [00:16<01:01, 173.74it/s] 16%|#5        | 2001/12631 [00:16<01:02, 169.84it/s] 16%|#5        | 2019/12631 [00:16<01:01, 171.56it/s] 16%|#6        | 2038/12631 [00:16<01:00, 175.55it/s] 16%|#6        | 2059/12631 [00:16<00:57, 184.14it/s] 16%|#6        | 2078/12631 [00:16<01:00, 173.57it/s] 17%|#6        | 2096/12631 [00:16<01:02, 169.55it/s] 17%|#6        | 2114/12631 [00:16<01:02, 168.37it/s] 17%|#6        | 2132/12631 [00:16<01:02, 168.25it/s] 17%|#7        | 2149/12631 [00:16<01:02, 167.97it/s] 17%|#7        | 2166/12631 [00:17<01:05, 160.07it/s] 17%|#7        | 2188/12631 [00:17<01:00, 172.46it/s] 17%|#7        | 2206/12631 [00:17<01:20, 129.68it/s] 18%|#7        | 2221/12631 [00:17<01:22, 126.28it/s] 18%|#7        | 2235/12631 [00:17<01:26, 120.52it/s] 18%|#7        | 2252/12631 [00:17<01:18, 131.96it/s] 18%|#7        | 2267/12631 [00:17<01:19, 130.46it/s] 18%|#8        | 2283/12631 [00:17<01:15, 137.82it/s] 18%|#8        | 2302/12631 [00:18<01:09, 149.46it/s] 18%|#8        | 2322/12631 [00:18<01:03, 161.30it/s] 19%|#8        | 2339/12631 [00:18<01:18, 131.47it/s] 19%|#8        | 2357/12631 [00:18<01:12, 142.01it/s] 19%|#8        | 2373/12631 [00:18<01:21, 126.13it/s] 19%|#8        | 2388/12631 [00:18<01:18, 131.23it/s] 19%|#9        | 2403/12631 [00:18<01:18, 130.34it/s] 19%|#9        | 2417/12631 [00:19<01:25, 120.15it/s] 19%|#9        | 2431/12631 [00:19<01:21, 125.18it/s] 19%|#9        | 2445/12631 [00:19<01:19, 128.71it/s] 19%|#9        | 2460/12631 [00:19<01:15, 133.93it/s] 20%|#9        | 2480/12631 [00:19<01:08, 147.97it/s] 20%|#9        | 2497/12631 [00:19<01:06, 152.44it/s] 20%|#9        | 2513/12631 [00:19<01:06, 151.69it/s] 20%|##        | 2529/12631 [00:19<01:10, 144.23it/s] 20%|##        | 2545/12631 [00:19<01:09, 145.56it/s] 20%|##        | 2560/12631 [00:20<01:25, 118.11it/s] 20%|##        | 2575/12631 [00:20<01:20, 125.46it/s] 21%|##        | 2593/12631 [00:20<01:13, 136.78it/s] 21%|##        | 2608/12631 [00:20<01:42, 97.84it/s]  21%|##        | 2623/12631 [00:20<01:32, 108.46it/s] 21%|##        | 2642/12631 [00:20<01:20, 123.76it/s] 21%|##1       | 2657/12631 [00:20<01:19, 126.17it/s] 21%|##1       | 2677/12631 [00:20<01:10, 141.14it/s] 21%|##1       | 2698/12631 [00:21<01:03, 155.83it/s] 22%|##1       | 2716/12631 [00:21<01:04, 154.73it/s] 22%|##1       | 2733/12631 [00:21<01:04, 153.04it/s] 22%|##1       | 2750/12631 [00:21<01:33, 105.60it/s] 22%|##1       | 2765/12631 [00:21<01:25, 115.09it/s] 22%|##2       | 2781/12631 [00:21<01:18, 125.00it/s] 22%|##2       | 2800/12631 [00:21<01:11, 137.05it/s] 22%|##2       | 2816/12631 [00:21<01:08, 142.50it/s] 22%|##2       | 2832/12631 [00:22<01:07, 145.92it/s] 23%|##2       | 2848/12631 [00:22<01:06, 148.11it/s] 23%|##2       | 2864/12631 [00:22<01:34, 103.62it/s] 23%|##2       | 2877/12631 [00:22<01:43, 94.46it/s]  23%|##2       | 2890/12631 [00:22<01:36, 101.36it/s] 23%|##2       | 2902/12631 [00:22<01:59, 81.56it/s]  23%|##3       | 2912/12631 [00:23<02:13, 72.68it/s] 23%|##3       | 2927/12631 [00:23<01:52, 85.88it/s] 23%|##3       | 2938/12631 [00:23<01:46, 91.28it/s] 23%|##3       | 2954/12631 [00:23<01:32, 104.10it/s] 23%|##3       | 2967/12631 [00:23<01:35, 101.45it/s] 24%|##3       | 2981/12631 [00:23<01:30, 107.05it/s] 24%|##3       | 2994/12631 [00:23<01:29, 107.13it/s] 24%|##3       | 3006/12631 [00:23<01:29, 107.13it/s] 24%|##3       | 3018/12631 [00:23<01:27, 110.08it/s] 24%|##4       | 3033/12631 [00:24<01:20, 118.66it/s] 24%|##4       | 3051/12631 [00:24<01:12, 131.79it/s] 24%|##4       | 3066/12631 [00:24<01:10, 135.96it/s] 24%|##4       | 3081/12631 [00:24<01:09, 137.95it/s] 25%|##4       | 3099/12631 [00:24<01:04, 147.16it/s] 25%|##4       | 3115/12631 [00:24<01:04, 146.70it/s] 25%|##4       | 3133/12631 [00:24<01:03, 149.35it/s] 25%|##4       | 3152/12631 [00:24<00:59, 158.16it/s] 25%|##5       | 3170/12631 [00:24<00:58, 162.50it/s] 25%|##5       | 3191/12631 [00:25<00:54, 173.83it/s] 25%|##5       | 3213/12631 [00:25<00:51, 184.18it/s] 26%|##5       | 3232/12631 [00:25<00:51, 180.92it/s] 26%|##5       | 3251/12631 [00:25<00:53, 176.26it/s] 26%|##5       | 3272/12631 [00:25<00:50, 184.19it/s] 26%|##6       | 3291/12631 [00:25<00:52, 179.28it/s] 26%|##6       | 3310/12631 [00:25<00:52, 176.76it/s] 26%|##6       | 3328/12631 [00:25<00:56, 165.96it/s] 26%|##6       | 3345/12631 [00:25<00:58, 158.94it/s] 27%|##6       | 3362/12631 [00:26<00:57, 161.63it/s] 27%|##6       | 3379/12631 [00:26<00:58, 158.42it/s] 27%|##6       | 3399/12631 [00:26<00:54, 168.13it/s] 27%|##7       | 3418/12631 [00:26<00:53, 172.96it/s] 27%|##7       | 3438/12631 [00:26<00:51, 180.03it/s] 27%|##7       | 3457/12631 [00:26<00:54, 166.95it/s] 28%|##7       | 3475/12631 [00:26<00:54, 169.20it/s] 28%|##7       | 3496/12631 [00:26<00:51, 178.36it/s] 28%|##7       | 3515/12631 [00:26<00:50, 179.60it/s] 28%|##7       | 3536/12631 [00:26<00:48, 186.84it/s] 28%|##8       | 3555/12631 [00:27<00:48, 186.60it/s] 28%|##8       | 3576/12631 [00:27<00:47, 191.61it/s] 28%|##8       | 3596/12631 [00:27<00:51, 175.45it/s] 29%|##8       | 3617/12631 [00:27<00:49, 183.41it/s] 29%|##8       | 3636/12631 [00:27<00:50, 179.16it/s] 29%|##8       | 3655/12631 [00:27<00:55, 161.41it/s] 29%|##9       | 3675/12631 [00:27<00:52, 171.17it/s] 29%|##9       | 3693/12631 [00:27<00:52, 169.11it/s] 29%|##9       | 3712/12631 [00:27<00:51, 174.28it/s] 30%|##9       | 3731/12631 [00:28<00:49, 178.00it/s] 30%|##9       | 3750/12631 [00:28<00:49, 178.07it/s] 30%|##9       | 3768/12631 [00:28<00:56, 155.99it/s] 30%|##9       | 3785/12631 [00:28<01:02, 142.24it/s] 30%|###       | 3800/12631 [00:28<01:01, 144.42it/s] 30%|###       | 3816/12631 [00:28<00:59, 148.34it/s] 30%|###       | 3832/12631 [00:28<01:02, 140.00it/s] 30%|###       | 3847/12631 [00:28<01:03, 139.09it/s] 31%|###       | 3862/12631 [00:29<01:03, 137.59it/s] 31%|###       | 3877/12631 [00:29<01:04, 136.62it/s] 31%|###       | 3891/12631 [00:29<01:36, 90.92it/s]  31%|###       | 3904/12631 [00:29<01:27, 99.77it/s] 31%|###1      | 3916/12631 [00:29<01:35, 91.48it/s] 31%|###1      | 3930/12631 [00:29<01:27, 99.69it/s] 31%|###1      | 3945/12631 [00:29<01:18, 110.56it/s] 31%|###1      | 3960/12631 [00:29<01:13, 117.63it/s] 31%|###1      | 3973/12631 [00:30<01:15, 115.19it/s] 32%|###1      | 3992/12631 [00:30<01:06, 130.20it/s] 32%|###1      | 4007/12631 [00:30<01:59, 72.46it/s]  32%|###1      | 4019/12631 [00:30<01:45, 81.79it/s] 32%|###1      | 4031/12631 [00:30<02:04, 69.22it/s] 32%|###1      | 4041/12631 [00:31<02:26, 58.75it/s] 32%|###2      | 4056/12631 [00:31<01:59, 71.84it/s] 32%|###2      | 4066/12631 [00:31<02:00, 71.16it/s] 32%|###2      | 4083/12631 [00:31<01:39, 85.82it/s] 32%|###2      | 4102/12631 [00:31<01:23, 102.28it/s] 33%|###2      | 4120/12631 [00:31<01:13, 115.85it/s] 33%|###2      | 4137/12631 [00:31<01:06, 127.06it/s] 33%|###2      | 4156/12631 [00:31<01:00, 139.64it/s] 33%|###3      | 4175/12631 [00:32<00:56, 150.67it/s] 33%|###3      | 4195/12631 [00:32<00:53, 157.96it/s] 33%|###3      | 4214/12631 [00:32<00:51, 165.00it/s] 34%|###3      | 4233/12631 [00:32<00:48, 171.53it/s] 34%|###3      | 4251/12631 [00:32<00:49, 170.19it/s] 34%|###3      | 4271/12631 [00:32<00:47, 177.48it/s] 34%|###3      | 4290/12631 [00:32<00:47, 176.90it/s] 34%|###4      | 4309/12631 [00:32<00:46, 177.07it/s] 34%|###4      | 4327/12631 [00:32<00:47, 175.82it/s] 34%|###4      | 4345/12631 [00:33<00:47, 173.85it/s] 35%|###4      | 4364/12631 [00:33<00:46, 177.16it/s] 35%|###4      | 4385/12631 [00:33<00:44, 185.83it/s] 35%|###4      | 4404/12631 [00:33<02:04, 66.01it/s]  35%|###4      | 4418/12631 [00:34<01:46, 77.08it/s] 35%|###5      | 4432/12631 [00:34<01:45, 77.69it/s] 35%|###5      | 4444/12631 [00:34<01:41, 80.85it/s] 35%|###5      | 4455/12631 [00:34<01:33, 87.36it/s] 35%|###5      | 4466/12631 [00:34<01:31, 89.20it/s] 35%|###5      | 4477/12631 [00:34<01:42, 79.21it/s] 36%|###5      | 4489/12631 [00:34<01:35, 85.69it/s] 36%|###5      | 4499/12631 [00:34<01:32, 88.07it/s] 36%|###5      | 4512/12631 [00:35<01:24, 95.96it/s] 36%|###5      | 4530/12631 [00:35<01:14, 108.77it/s] 36%|###5      | 4545/12631 [00:35<01:08, 118.24it/s] 36%|###6      | 4565/12631 [00:35<01:00, 133.51it/s] 36%|###6      | 4582/12631 [00:35<00:57, 140.99it/s] 36%|###6      | 4599/12631 [00:35<00:54, 146.90it/s] 37%|###6      | 4615/12631 [00:35<01:13, 109.52it/s] 37%|###6      | 4628/12631 [00:36<01:18, 101.79it/s] 37%|###6      | 4640/12631 [00:36<01:17, 103.38it/s] 37%|###6      | 4654/12631 [00:36<01:11, 111.10it/s] 37%|###6      | 4667/12631 [00:36<01:26, 91.60it/s]  37%|###7      | 4678/12631 [00:36<01:30, 87.79it/s] 37%|###7      | 4688/12631 [00:36<01:36, 82.38it/s] 37%|###7      | 4697/12631 [00:36<01:44, 76.06it/s] 37%|###7      | 4706/12631 [00:36<01:41, 77.82it/s] 37%|###7      | 4717/12631 [00:37<01:33, 84.87it/s] 37%|###7      | 4732/12631 [00:37<01:22, 95.95it/s] 38%|###7      | 4749/12631 [00:37<01:11, 110.35it/s] 38%|###7      | 4762/12631 [00:37<01:21, 97.03it/s]  38%|###7      | 4777/12631 [00:37<01:12, 107.84it/s] 38%|###7      | 4790/12631 [00:37<01:10, 111.68it/s] 38%|###8      | 4807/12631 [00:37<01:03, 123.33it/s] 38%|###8      | 4826/12631 [00:37<00:56, 137.20it/s] 38%|###8      | 4845/12631 [00:37<00:52, 148.53it/s] 39%|###8      | 4865/12631 [00:38<00:48, 159.85it/s] 39%|###8      | 4883/12631 [00:38<00:48, 160.30it/s] 39%|###8      | 4900/12631 [00:38<01:16, 100.72it/s] 39%|###8      | 4914/12631 [00:38<01:13, 105.47it/s] 39%|###9      | 4927/12631 [00:38<01:10, 109.58it/s] 39%|###9      | 4940/12631 [00:38<01:07, 113.62it/s] 39%|###9      | 4953/12631 [00:38<01:06, 115.04it/s] 39%|###9      | 4966/12631 [00:39<01:07, 112.93it/s] 39%|###9      | 4979/12631 [00:39<01:06, 115.54it/s] 40%|###9      | 4993/12631 [00:39<01:03, 121.13it/s] 40%|###9      | 5008/12631 [00:39<00:59, 128.12it/s] 40%|###9      | 5022/12631 [00:39<01:08, 110.76it/s] 40%|###9      | 5035/12631 [00:39<01:05, 115.46it/s] 40%|###9      | 5051/12631 [00:39<01:04, 118.38it/s] 40%|####      | 5067/12631 [00:39<01:00, 124.99it/s] 40%|####      | 5084/12631 [00:39<00:56, 132.91it/s] 40%|####      | 5100/12631 [00:40<00:53, 139.54it/s] 40%|####      | 5115/12631 [00:40<00:54, 138.31it/s] 41%|####      | 5134/12631 [00:40<00:50, 149.21it/s] 41%|####      | 5150/12631 [00:40<00:59, 126.35it/s] 41%|####      | 5165/12631 [00:40<00:56, 131.02it/s] 41%|####1     | 5183/12631 [00:40<00:53, 139.15it/s] 41%|####1     | 5202/12631 [00:40<00:49, 150.00it/s] 41%|####1     | 5218/12631 [00:40<00:51, 142.85it/s] 41%|####1     | 5234/12631 [00:40<00:50, 145.49it/s] 42%|####1     | 5252/12631 [00:41<00:48, 152.08it/s] 42%|####1     | 5268/12631 [00:41<00:47, 154.30it/s] 42%|####1     | 5284/12631 [00:41<00:47, 154.61it/s] 42%|####1     | 5300/12631 [00:41<00:49, 149.53it/s] 42%|####2     | 5318/12631 [00:41<00:47, 154.41it/s] 42%|####2     | 5335/12631 [00:41<00:46, 156.35it/s] 42%|####2     | 5352/12631 [00:41<00:46, 156.02it/s] 42%|####2     | 5368/12631 [00:41<00:47, 151.73it/s] 43%|####2     | 5386/12631 [00:41<00:46, 157.31it/s] 43%|####2     | 5402/12631 [00:42<00:46, 156.29it/s] 43%|####2     | 5420/12631 [00:42<00:45, 157.50it/s] 43%|####3     | 5436/12631 [00:42<00:45, 156.99it/s] 43%|####3     | 5453/12631 [00:42<00:44, 160.54it/s] 43%|####3     | 5472/12631 [00:42<00:42, 166.76it/s] 43%|####3     | 5490/12631 [00:42<00:42, 168.43it/s] 44%|####3     | 5507/12631 [00:42<00:42, 166.63it/s] 44%|####3     | 5527/12631 [00:42<00:40, 174.66it/s] 44%|####3     | 5545/12631 [00:42<00:40, 173.77it/s] 44%|####4     | 5564/12631 [00:42<00:39, 177.98it/s] 44%|####4     | 5583/12631 [00:43<00:39, 176.88it/s] 44%|####4     | 5601/12631 [00:43<00:40, 171.89it/s] 44%|####4     | 5619/12631 [00:43<01:24, 82.61it/s]  45%|####4     | 5634/12631 [00:43<01:13, 94.97it/s] 45%|####4     | 5652/12631 [00:43<01:03, 110.52it/s] 45%|####4     | 5667/12631 [00:44<00:58, 118.35it/s] 45%|####4     | 5682/12631 [00:44<00:57, 121.47it/s] 45%|####5     | 5697/12631 [00:44<00:54, 127.69it/s] 45%|####5     | 5714/12631 [00:44<00:50, 137.98it/s] 45%|####5     | 5730/12631 [00:44<00:48, 141.34it/s] 45%|####5     | 5746/12631 [00:44<00:53, 129.23it/s] 46%|####5     | 5760/12631 [00:44<00:58, 117.95it/s] 46%|####5     | 5773/12631 [00:44<00:57, 119.83it/s] 46%|####5     | 5786/12631 [00:44<00:56, 121.30it/s] 46%|####5     | 5799/12631 [00:45<00:55, 122.62it/s] 46%|####6     | 5814/12631 [00:45<00:52, 129.45it/s] 46%|####6     | 5828/12631 [00:45<00:54, 123.78it/s] 46%|####6     | 5841/12631 [00:45<00:54, 124.39it/s] 46%|####6     | 5854/12631 [00:45<00:59, 114.45it/s] 46%|####6     | 5869/12631 [00:45<00:55, 121.39it/s] 47%|####6     | 5883/12631 [00:45<00:53, 125.61it/s] 47%|####6     | 5896/12631 [00:45<00:59, 113.82it/s] 47%|####6     | 5908/12631 [00:46<01:08, 98.49it/s]  47%|####6     | 5919/12631 [00:46<01:06, 100.39it/s] 47%|####6     | 5931/12631 [00:46<01:04, 104.10it/s] 47%|####7     | 5942/12631 [00:46<01:24, 79.17it/s]  47%|####7     | 5952/12631 [00:46<01:32, 71.95it/s] 47%|####7     | 5962/12631 [00:46<01:26, 77.08it/s] 47%|####7     | 5973/12631 [00:46<01:21, 81.68it/s] 47%|####7     | 5985/12631 [00:46<01:14, 88.80it/s] 47%|####7     | 5998/12631 [00:47<01:07, 97.93it/s] 48%|####7     | 6013/12631 [00:47<01:00, 108.60it/s] 48%|####7     | 6027/12631 [00:47<00:57, 114.04it/s] 48%|####7     | 6040/12631 [00:47<00:57, 114.14it/s] 48%|####7     | 6054/12631 [00:47<00:54, 119.65it/s] 48%|####8     | 6067/12631 [00:47<00:55, 118.53it/s] 48%|####8     | 6080/12631 [00:47<00:59, 110.51it/s] 48%|####8     | 6092/12631 [00:47<01:00, 108.01it/s] 48%|####8     | 6104/12631 [00:47<01:03, 103.22it/s] 48%|####8     | 6115/12631 [00:48<01:03, 103.26it/s] 48%|####8     | 6126/12631 [00:48<01:02, 104.20it/s] 49%|####8     | 6140/12631 [00:48<00:57, 112.24it/s] 49%|####8     | 6157/12631 [00:48<00:53, 120.49it/s] 49%|####8     | 6173/12631 [00:48<00:50, 127.80it/s] 49%|####8     | 6188/12631 [00:48<00:48, 132.27it/s] 49%|####9     | 6202/12631 [00:48<00:48, 131.33it/s] 49%|####9     | 6216/12631 [00:48<00:57, 112.18it/s] 49%|####9     | 6228/12631 [00:48<00:56, 113.25it/s] 49%|####9     | 6242/12631 [00:49<00:53, 120.08it/s] 50%|####9     | 6255/12631 [00:49<00:55, 115.53it/s] 50%|####9     | 6267/12631 [00:49<00:58, 108.06it/s] 50%|####9     | 6283/12631 [00:49<00:53, 119.59it/s] 50%|####9     | 6297/12631 [00:49<00:51, 123.93it/s] 50%|####9     | 6312/12631 [00:49<00:49, 127.66it/s] 50%|#####     | 6326/12631 [00:49<00:50, 124.80it/s] 50%|#####     | 6339/12631 [00:49<00:50, 123.99it/s] 50%|#####     | 6352/12631 [00:49<00:51, 122.84it/s] 50%|#####     | 6365/12631 [00:50<00:52, 120.32it/s] 51%|#####     | 6381/12631 [00:50<00:48, 129.90it/s] 51%|#####     | 6395/12631 [00:50<00:47, 132.38it/s] 51%|#####     | 6411/12631 [00:50<00:44, 138.79it/s] 51%|#####     | 6426/12631 [00:50<00:44, 138.03it/s] 51%|#####     | 6440/12631 [00:50<00:55, 111.39it/s] 51%|#####1    | 6453/12631 [00:50<01:02, 98.21it/s]  51%|#####1    | 6465/12631 [00:50<01:00, 102.06it/s] 51%|#####1    | 6482/12631 [00:51<00:53, 115.67it/s] 51%|#####1    | 6499/12631 [00:51<00:48, 127.56it/s] 52%|#####1    | 6513/12631 [00:51<00:46, 130.49it/s] 52%|#####1    | 6527/12631 [00:51<00:46, 130.70it/s] 52%|#####1    | 6541/12631 [00:51<00:58, 103.51it/s] 52%|#####1    | 6553/12631 [00:51<01:05, 93.12it/s]  52%|#####1    | 6567/12631 [00:51<00:59, 101.62it/s] 52%|#####2    | 6582/12631 [00:51<00:54, 111.60it/s] 52%|#####2    | 6597/12631 [00:52<00:50, 120.34it/s] 52%|#####2    | 6615/12631 [00:52<00:45, 132.86it/s] 52%|#####2    | 6630/12631 [00:52<00:44, 135.15it/s] 53%|#####2    | 6649/12631 [00:52<00:40, 146.40it/s] 53%|#####2    | 6666/12631 [00:52<00:45, 132.37it/s] 53%|#####2    | 6681/12631 [00:52<00:45, 129.78it/s] 53%|#####3    | 6696/12631 [00:52<00:44, 133.74it/s] 53%|#####3    | 6710/12631 [00:52<00:44, 132.97it/s] 53%|#####3    | 6727/12631 [00:52<00:41, 141.08it/s] 53%|#####3    | 6743/12631 [00:53<00:40, 144.85it/s] 54%|#####3    | 6759/12631 [00:53<00:39, 147.98it/s] 54%|#####3    | 6775/12631 [00:53<00:42, 136.69it/s] 54%|#####3    | 6789/12631 [00:53<00:52, 110.32it/s] 54%|#####3    | 6802/12631 [00:53<01:08, 84.76it/s]  54%|#####3    | 6813/12631 [00:53<01:04, 89.87it/s] 54%|#####4    | 6825/12631 [00:53<00:59, 97.19it/s] 54%|#####4    | 6836/12631 [00:54<00:59, 97.86it/s] 54%|#####4    | 6853/12631 [00:54<00:51, 111.77it/s] 54%|#####4    | 6866/12631 [00:54<00:49, 115.48it/s] 54%|#####4    | 6879/12631 [00:54<01:04, 88.86it/s]  55%|#####4    | 6890/12631 [00:54<01:31, 62.45it/s] 55%|#####4    | 6901/12631 [00:54<01:21, 70.64it/s] 55%|#####4    | 6910/12631 [00:55<01:41, 56.12it/s] 55%|#####4    | 6921/12631 [00:55<01:36, 59.46it/s] 55%|#####4    | 6932/12631 [00:55<01:22, 68.77it/s] 55%|#####4    | 6943/12631 [00:55<01:15, 75.53it/s] 55%|#####5    | 6957/12631 [00:55<01:04, 87.36it/s] 55%|#####5    | 6968/12631 [00:55<01:03, 89.62it/s] 55%|#####5    | 6984/12631 [00:55<00:55, 101.17it/s] 55%|#####5    | 6996/12631 [00:56<01:10, 80.29it/s]  55%|#####5    | 7007/12631 [00:56<01:04, 86.91it/s] 56%|#####5    | 7022/12631 [00:56<00:56, 99.16it/s] 56%|#####5    | 7038/12631 [00:56<00:49, 111.90it/s] 56%|#####5    | 7053/12631 [00:56<00:46, 120.70it/s] 56%|#####5    | 7073/12631 [00:56<00:40, 135.92it/s] 56%|#####6    | 7094/12631 [00:56<00:36, 149.97it/s] 56%|#####6    | 7114/12631 [00:56<00:34, 161.93it/s] 56%|#####6    | 7133/12631 [00:56<00:33, 166.59it/s] 57%|#####6    | 7153/12631 [00:56<00:31, 173.47it/s] 57%|#####6    | 7172/12631 [00:57<00:30, 176.46it/s] 57%|#####6    | 7191/12631 [00:57<00:31, 174.89it/s] 57%|#####7    | 7209/12631 [00:57<00:33, 162.74it/s] 57%|#####7    | 7226/12631 [00:57<00:34, 158.33it/s] 57%|#####7    | 7243/12631 [00:57<00:33, 159.35it/s] 57%|#####7    | 7260/12631 [00:57<00:34, 154.68it/s] 58%|#####7    | 7276/12631 [00:57<00:34, 154.08it/s] 58%|#####7    | 7293/12631 [00:57<00:34, 156.77it/s] 58%|#####7    | 7312/12631 [00:57<00:33, 157.70it/s] 58%|#####8    | 7331/12631 [00:58<00:32, 164.57it/s] 58%|#####8    | 7349/12631 [00:58<00:31, 168.19it/s] 58%|#####8    | 7366/12631 [00:58<00:36, 142.78it/s] 58%|#####8    | 7382/12631 [00:58<00:38, 137.19it/s] 59%|#####8    | 7397/12631 [00:58<00:39, 132.72it/s] 59%|#####8    | 7411/12631 [00:58<00:41, 124.39it/s] 59%|#####8    | 7424/12631 [00:58<00:49, 105.52it/s] 59%|#####8    | 7436/12631 [00:59<00:56, 92.55it/s]  59%|#####9    | 7453/12631 [00:59<00:48, 107.00it/s] 59%|#####9    | 7467/12631 [00:59<00:45, 113.92it/s] 59%|#####9    | 7480/12631 [00:59<00:46, 110.50it/s] 59%|#####9    | 7492/12631 [00:59<00:45, 112.22it/s] 59%|#####9    | 7510/12631 [00:59<00:41, 123.31it/s] 60%|#####9    | 7526/12631 [00:59<00:38, 131.51it/s] 60%|#####9    | 7540/12631 [00:59<00:41, 124.02it/s] 60%|#####9    | 7559/12631 [00:59<00:36, 137.72it/s] 60%|#####9    | 7578/12631 [01:00<00:34, 147.72it/s] 60%|######    | 7594/12631 [01:00<00:34, 146.42it/s] 60%|######    | 7610/12631 [01:00<00:35, 141.53it/s] 60%|######    | 7627/12631 [01:00<00:34, 146.31it/s] 61%|######    | 7645/12631 [01:00<00:32, 154.97it/s] 61%|######    | 7661/12631 [01:00<00:33, 149.01it/s] 61%|######    | 7679/12631 [01:00<00:31, 155.04it/s] 61%|######    | 7698/12631 [01:00<00:30, 163.71it/s] 61%|######1   | 7715/12631 [01:00<00:30, 161.62it/s] 61%|######1   | 7733/12631 [01:01<00:29, 165.54it/s] 61%|######1   | 7752/12631 [01:01<00:29, 168.05it/s] 62%|######1   | 7773/12631 [01:01<00:27, 178.33it/s] 62%|######1   | 7792/12631 [01:01<00:41, 115.97it/s] 62%|######1   | 7807/12631 [01:01<00:42, 113.91it/s] 62%|######1   | 7821/12631 [01:01<00:40, 119.44it/s] 62%|######2   | 7838/12631 [01:01<00:37, 127.64it/s] 62%|######2   | 7853/12631 [01:01<00:36, 132.60it/s] 62%|######2   | 7869/12631 [01:02<00:34, 139.53it/s] 62%|######2   | 7884/12631 [01:02<00:33, 139.94it/s] 63%|######2   | 7899/12631 [01:02<00:43, 109.06it/s] 63%|######2   | 7912/12631 [01:02<00:41, 113.24it/s] 63%|######2   | 7929/12631 [01:02<00:37, 124.62it/s] 63%|######2   | 7948/12631 [01:02<00:33, 137.76it/s] 63%|######3   | 7963/12631 [01:02<00:40, 114.96it/s] 63%|######3   | 7980/12631 [01:02<00:36, 126.12it/s] 63%|######3   | 8000/12631 [01:03<00:39, 115.83it/s] 63%|######3   | 8013/12631 [01:03<00:43, 106.45it/s] 64%|######3   | 8026/12631 [01:03<00:41, 111.98it/s] 64%|######3   | 8042/12631 [01:03<00:37, 122.01it/s] 64%|######3   | 8059/12631 [01:03<00:35, 128.06it/s] 64%|######3   | 8075/12631 [01:03<00:33, 135.09it/s] 64%|######4   | 8090/12631 [01:03<00:36, 125.32it/s] 64%|######4   | 8104/12631 [01:04<00:37, 121.34it/s] 64%|######4   | 8117/12631 [01:04<00:39, 114.25it/s] 64%|######4   | 8133/12631 [01:04<00:36, 124.76it/s] 65%|######4   | 8150/12631 [01:04<00:33, 134.34it/s] 65%|######4   | 8165/12631 [01:04<00:34, 130.85it/s] 65%|######4   | 8180/12631 [01:04<00:32, 135.91it/s] 65%|######4   | 8194/12631 [01:04<00:34, 127.18it/s] 65%|######4   | 8208/12631 [01:04<00:37, 118.91it/s] 65%|######5   | 8224/12631 [01:04<00:34, 126.91it/s] 65%|######5   | 8238/12631 [01:05<00:35, 125.32it/s] 65%|######5   | 8257/12631 [01:05<00:31, 139.09it/s] 65%|######5   | 8272/12631 [01:05<00:30, 142.18it/s] 66%|######5   | 8290/12631 [01:05<00:28, 151.53it/s] 66%|######5   | 8310/12631 [01:05<00:26, 162.25it/s] 66%|######5   | 8327/12631 [01:05<00:27, 157.83it/s] 66%|######6   | 8346/12631 [01:05<00:28, 149.51it/s] 66%|######6   | 8362/12631 [01:05<00:29, 145.43it/s] 66%|######6   | 8379/12631 [01:05<00:28, 150.71it/s] 66%|######6   | 8395/12631 [01:06<00:52, 81.22it/s]  67%|######6   | 8407/12631 [01:06<01:18, 54.10it/s] 67%|######6   | 8422/12631 [01:06<01:03, 66.50it/s] 67%|######6   | 8441/12631 [01:06<00:50, 82.26it/s] 67%|######6   | 8460/12631 [01:07<00:42, 98.67it/s] 67%|######7   | 8482/12631 [01:07<00:35, 117.86it/s] 67%|######7   | 8500/12631 [01:07<00:31, 129.31it/s] 67%|######7   | 8517/12631 [01:07<00:31, 132.27it/s] 68%|######7   | 8533/12631 [01:07<00:33, 123.70it/s] 68%|######7   | 8551/12631 [01:07<00:29, 136.27it/s] 68%|######7   | 8567/12631 [01:07<00:28, 141.23it/s] 68%|######7   | 8587/12631 [01:07<00:26, 154.84it/s] 68%|######8   | 8607/12631 [01:07<00:24, 165.23it/s] 68%|######8   | 8626/12631 [01:08<00:23, 166.89it/s] 68%|######8   | 8644/12631 [01:08<00:24, 163.18it/s] 69%|######8   | 8663/12631 [01:08<00:25, 157.58it/s] 69%|######8   | 8680/12631 [01:08<00:35, 111.54it/s] 69%|######8   | 8694/12631 [01:08<00:35, 112.25it/s] 69%|######8   | 8712/12631 [01:08<00:31, 126.09it/s] 69%|######9   | 8727/12631 [01:08<00:30, 128.84it/s] 69%|######9   | 8744/12631 [01:09<00:30, 128.93it/s] 69%|######9   | 8760/12631 [01:09<00:28, 136.59it/s] 69%|######9   | 8777/12631 [01:09<00:26, 142.96it/s] 70%|######9   | 8792/12631 [01:09<00:36, 105.06it/s] 70%|######9   | 8805/12631 [01:09<00:46, 82.07it/s]  70%|######9   | 8816/12631 [01:09<00:43, 87.33it/s] 70%|######9   | 8831/12631 [01:09<00:38, 97.72it/s] 70%|#######   | 8850/12631 [01:10<00:33, 113.82it/s] 70%|#######   | 8870/12631 [01:10<00:29, 129.28it/s] 70%|#######   | 8889/12631 [01:10<00:26, 141.21it/s] 71%|#######   | 8907/12631 [01:10<00:27, 135.14it/s] 71%|#######   | 8922/12631 [01:10<00:31, 118.42it/s] 71%|#######   | 8936/12631 [01:10<00:37, 98.47it/s]  71%|#######   | 8956/12631 [01:10<00:31, 115.33it/s] 71%|#######1  | 8970/12631 [01:11<00:36, 99.20it/s]  71%|#######1  | 8986/12631 [01:11<00:32, 111.76it/s] 71%|#######1  | 9002/12631 [01:11<00:29, 121.59it/s] 71%|#######1  | 9018/12631 [01:11<00:27, 129.81it/s] 72%|#######1  | 9037/12631 [01:11<00:25, 143.31it/s] 72%|#######1  | 9053/12631 [01:11<00:32, 109.09it/s] 72%|#######1  | 9067/12631 [01:11<00:30, 115.38it/s] 72%|#######1  | 9086/12631 [01:11<00:27, 130.59it/s] 72%|#######2  | 9101/12631 [01:12<00:33, 104.26it/s] 72%|#######2  | 9118/12631 [01:12<00:30, 116.97it/s] 72%|#######2  | 9139/12631 [01:12<00:26, 134.25it/s] 73%|#######2  | 9160/12631 [01:12<00:23, 149.84it/s] 73%|#######2  | 9178/12631 [01:12<00:22, 151.06it/s] 73%|#######2  | 9195/12631 [01:12<00:23, 145.77it/s] 73%|#######2  | 9214/12631 [01:12<00:21, 156.44it/s] 73%|#######3  | 9232/12631 [01:12<00:20, 162.04it/s] 73%|#######3  | 9249/12631 [01:12<00:20, 161.12it/s] 73%|#######3  | 9266/12631 [01:13<00:21, 153.13it/s] 73%|#######3  | 9282/12631 [01:13<00:21, 153.20it/s] 74%|#######3  | 9301/12631 [01:13<00:20, 162.64it/s] 74%|#######3  | 9318/12631 [01:13<00:22, 145.96it/s] 74%|#######3  | 9334/12631 [01:13<00:22, 144.89it/s] 74%|#######4  | 9349/12631 [01:13<00:23, 137.49it/s] 74%|#######4  | 9364/12631 [01:13<00:31, 105.26it/s] 74%|#######4  | 9377/12631 [01:13<00:29, 110.83it/s] 74%|#######4  | 9391/12631 [01:14<00:27, 117.47it/s] 74%|#######4  | 9410/12631 [01:14<00:24, 131.55it/s] 75%|#######4  | 9425/12631 [01:14<00:23, 133.90it/s] 75%|#######4  | 9446/12631 [01:14<00:21, 149.25it/s] 75%|#######4  | 9463/12631 [01:14<00:20, 151.98it/s] 75%|#######5  | 9482/12631 [01:14<00:19, 161.03it/s] 75%|#######5  | 9499/12631 [01:14<00:19, 163.35it/s] 75%|#######5  | 9517/12631 [01:14<00:18, 164.60it/s] 75%|#######5  | 9535/12631 [01:14<00:18, 168.04it/s] 76%|#######5  | 9556/12631 [01:15<00:17, 178.24it/s] 76%|#######5  | 9575/12631 [01:15<00:18, 164.90it/s] 76%|#######5  | 9592/12631 [01:15<00:19, 159.70it/s] 76%|#######6  | 9610/12631 [01:15<00:18, 163.40it/s] 76%|#######6  | 9627/12631 [01:15<00:18, 161.93it/s] 76%|#######6  | 9646/12631 [01:15<00:18, 164.87it/s] 77%|#######6  | 9670/12631 [01:15<00:16, 180.99it/s] 77%|#######6  | 9689/12631 [01:15<00:17, 171.84it/s] 77%|#######6  | 9708/12631 [01:15<00:16, 176.65it/s] 77%|#######7  | 9727/12631 [01:16<00:16, 172.51it/s] 77%|#######7  | 9745/12631 [01:16<00:16, 174.53it/s] 77%|#######7  | 9763/12631 [01:16<00:16, 172.30it/s] 77%|#######7  | 9781/12631 [01:16<00:16, 174.32it/s] 78%|#######7  | 9800/12631 [01:16<00:15, 177.39it/s] 78%|#######7  | 9822/12631 [01:16<00:14, 187.28it/s] 78%|#######7  | 9844/12631 [01:16<00:14, 195.66it/s] 78%|#######8  | 9864/12631 [01:16<00:14, 186.91it/s] 78%|#######8  | 9883/12631 [01:16<00:15, 178.87it/s] 78%|#######8  | 9902/12631 [01:16<00:15, 177.56it/s] 79%|#######8  | 9920/12631 [01:17<00:16, 167.21it/s] 79%|#######8  | 9937/12631 [01:17<00:16, 162.53it/s] 79%|#######8  | 9954/12631 [01:17<00:18, 142.41it/s] 79%|#######8  | 9969/12631 [01:17<00:18, 142.53it/s] 79%|#######9  | 9985/12631 [01:17<00:17, 147.32it/s] 79%|#######9  | 10003/12631 [01:17<00:17, 153.78it/s] 79%|#######9  | 10019/12631 [01:17<00:18, 138.37it/s] 79%|#######9  | 10037/12631 [01:17<00:17, 148.16it/s] 80%|#######9  | 10057/12631 [01:18<00:16, 160.55it/s] 80%|#######9  | 10075/12631 [01:18<00:15, 165.15it/s] 80%|#######9  | 10095/12631 [01:18<00:15, 163.38it/s] 80%|########  | 10112/12631 [01:18<00:17, 141.45it/s] 80%|########  | 10127/12631 [01:18<00:18, 138.59it/s] 80%|########  | 10142/12631 [01:18<00:19, 125.84it/s] 80%|########  | 10159/12631 [01:18<00:18, 134.68it/s] 81%|########  | 10174/12631 [01:18<00:19, 124.76it/s] 81%|########  | 10188/12631 [01:19<00:20, 122.11it/s] 81%|########  | 10207/12631 [01:19<00:17, 134.70it/s] 81%|########  | 10222/12631 [01:19<00:17, 134.03it/s] 81%|########1 | 10240/12631 [01:19<00:16, 141.67it/s] 81%|########1 | 10255/12631 [01:19<00:24, 98.64it/s]  81%|########1 | 10273/12631 [01:19<00:20, 113.90it/s] 81%|########1 | 10288/12631 [01:19<00:20, 112.80it/s] 82%|########1 | 10304/12631 [01:19<00:19, 122.41it/s] 82%|########1 | 10326/12631 [01:20<00:16, 137.79it/s] 82%|########1 | 10345/12631 [01:20<00:15, 148.55it/s] 82%|########2 | 10366/12631 [01:20<00:14, 161.20it/s] 82%|########2 | 10385/12631 [01:20<00:13, 168.36it/s] 82%|########2 | 10405/12631 [01:20<00:12, 176.51it/s] 83%|########2 | 10424/12631 [01:20<00:12, 173.50it/s] 83%|########2 | 10442/12631 [01:20<00:12, 173.05it/s] 83%|########2 | 10460/12631 [01:20<00:13, 161.58it/s] 83%|########2 | 10481/12631 [01:20<00:12, 172.16it/s] 83%|########3 | 10504/12631 [01:21<00:11, 186.20it/s] 83%|########3 | 10524/12631 [01:21<00:11, 187.25it/s] 83%|########3 | 10546/12631 [01:21<00:10, 194.13it/s] 84%|########3 | 10568/12631 [01:21<00:10, 200.60it/s] 84%|########3 | 10589/12631 [01:21<00:10, 199.76it/s] 84%|########3 | 10610/12631 [01:21<00:10, 187.81it/s] 84%|########4 | 10630/12631 [01:21<00:10, 186.02it/s] 84%|########4 | 10649/12631 [01:21<00:10, 181.30it/s] 84%|########4 | 10668/12631 [01:21<00:10, 182.85it/s] 85%|########4 | 10688/12631 [01:22<00:10, 187.19it/s] 85%|########4 | 10708/12631 [01:22<00:10, 188.69it/s] 85%|########4 | 10727/12631 [01:22<00:10, 182.33it/s] 85%|########5 | 10746/12631 [01:22<00:10, 183.55it/s] 85%|########5 | 10766/12631 [01:22<00:10, 184.30it/s] 85%|########5 | 10785/12631 [01:22<00:10, 177.97it/s] 86%|########5 | 10803/12631 [01:22<00:10, 178.43it/s] 86%|########5 | 10823/12631 [01:22<00:09, 184.38it/s] 86%|########5 | 10842/12631 [01:22<00:09, 181.67it/s] 86%|########5 | 10862/12631 [01:22<00:09, 185.03it/s] 86%|########6 | 10882/12631 [01:23<00:09, 187.33it/s] 86%|########6 | 10901/12631 [01:23<00:09, 186.55it/s] 86%|########6 | 10920/12631 [01:23<00:16, 104.64it/s] 87%|########6 | 10935/12631 [01:23<00:15, 106.03it/s] 87%|########6 | 10949/12631 [01:23<00:16, 104.32it/s] 87%|########6 | 10962/12631 [01:23<00:15, 108.83it/s] 87%|########6 | 10975/12631 [01:24<00:14, 113.90it/s] 87%|########7 | 10991/12631 [01:24<00:13, 121.70it/s] 87%|########7 | 11006/12631 [01:24<00:17, 93.62it/s]  87%|########7 | 11017/12631 [01:24<00:16, 96.90it/s] 87%|########7 | 11030/12631 [01:24<00:15, 104.16it/s] 87%|########7 | 11043/12631 [01:24<00:14, 107.62it/s] 88%|########7 | 11058/12631 [01:24<00:13, 117.38it/s] 88%|########7 | 11073/12631 [01:24<00:12, 124.25it/s] 88%|########7 | 11087/12631 [01:25<00:12, 127.41it/s] 88%|########7 | 11106/12631 [01:25<00:10, 140.49it/s] 88%|########8 | 11123/12631 [01:25<00:10, 146.67it/s] 88%|########8 | 11139/12631 [01:25<00:15, 96.51it/s]  88%|########8 | 11152/12631 [01:25<00:16, 87.31it/s] 88%|########8 | 11166/12631 [01:25<00:15, 96.80it/s] 89%|########8 | 11183/12631 [01:25<00:13, 110.38it/s] 89%|########8 | 11202/12631 [01:26<00:11, 125.54it/s] 89%|########8 | 11223/12631 [01:26<00:10, 140.80it/s] 89%|########9 | 11242/12631 [01:26<00:09, 150.07it/s] 89%|########9 | 11259/12631 [01:26<00:14, 97.70it/s]  89%|########9 | 11273/12631 [01:26<00:12, 106.11it/s] 89%|########9 | 11291/12631 [01:26<00:11, 120.89it/s] 90%|########9 | 11309/12631 [01:26<00:09, 133.33it/s] 90%|########9 | 11329/12631 [01:26<00:08, 147.22it/s] 90%|########9 | 11346/12631 [01:27<00:10, 124.46it/s] 90%|########9 | 11361/12631 [01:27<00:09, 130.25it/s] 90%|######### | 11378/12631 [01:27<00:09, 138.78it/s] 90%|######### | 11394/12631 [01:27<00:08, 142.46it/s] 90%|######### | 11414/12631 [01:27<00:07, 154.85it/s] 91%|######### | 11434/12631 [01:27<00:07, 164.75it/s] 91%|######### | 11452/12631 [01:27<00:07, 168.05it/s] 91%|######### | 11470/12631 [01:27<00:09, 128.69it/s] 91%|######### | 11486/12631 [01:28<00:08, 132.24it/s] 91%|#########1| 11503/12631 [01:28<00:08, 138.73it/s] 91%|#########1| 11518/12631 [01:28<00:08, 129.39it/s] 91%|#########1| 11532/12631 [01:28<00:09, 120.71it/s] 91%|#########1| 11545/12631 [01:28<00:09, 113.91it/s] 92%|#########1| 11563/12631 [01:28<00:08, 127.73it/s] 92%|#########1| 11578/12631 [01:28<00:07, 132.28it/s] 92%|#########1| 11593/12631 [01:28<00:07, 136.04it/s] 92%|#########1| 11611/12631 [01:29<00:07, 142.55it/s] 92%|#########2| 11629/12631 [01:29<00:06, 151.13it/s] 92%|#########2| 11646/12631 [01:29<00:06, 155.69it/s] 92%|#########2| 11669/12631 [01:29<00:05, 171.03it/s] 93%|#########2| 11687/12631 [01:29<00:06, 150.15it/s] 93%|#########2| 11704/12631 [01:29<00:06, 153.57it/s] 93%|#########2| 11721/12631 [01:29<00:05, 157.19it/s] 93%|#########2| 11738/12631 [01:29<00:05, 149.78it/s] 93%|#########3| 11757/12631 [01:29<00:05, 158.57it/s] 93%|#########3| 11774/12631 [01:30<00:05, 147.75it/s] 93%|#########3| 11790/12631 [01:30<00:05, 140.20it/s] 93%|#########3| 11807/12631 [01:30<00:05, 147.66it/s] 94%|#########3| 11825/12631 [01:30<00:05, 155.05it/s] 94%|#########3| 11845/12631 [01:30<00:04, 165.02it/s] 94%|#########3| 11862/12631 [01:30<00:04, 161.53it/s] 94%|#########4| 11880/12631 [01:30<00:04, 164.00it/s] 94%|#########4| 11897/12631 [01:30<00:04, 157.43it/s] 94%|#########4| 11915/12631 [01:30<00:04, 159.70it/s] 94%|#########4| 11932/12631 [01:31<00:04, 149.88it/s] 95%|#########4| 11952/12631 [01:31<00:04, 158.37it/s] 95%|#########4| 11970/12631 [01:31<00:04, 161.32it/s] 95%|#########4| 11987/12631 [01:31<00:04, 151.92it/s] 95%|#########5| 12006/12631 [01:31<00:03, 159.86it/s] 95%|#########5| 12023/12631 [01:31<00:04, 146.18it/s] 95%|#########5| 12040/12631 [01:31<00:03, 151.49it/s] 95%|#########5| 12061/12631 [01:31<00:03, 162.87it/s] 96%|#########5| 12081/12631 [01:31<00:03, 170.89it/s] 96%|#########5| 12099/12631 [01:32<00:03, 171.76it/s] 96%|#########5| 12120/12631 [01:32<00:02, 181.64it/s] 96%|#########6| 12139/12631 [01:32<00:02, 174.98it/s] 96%|#########6| 12158/12631 [01:32<00:02, 176.80it/s] 96%|#########6| 12176/12631 [01:32<00:03, 131.80it/s] 97%|#########6| 12192/12631 [01:32<00:03, 137.57it/s] 97%|#########6| 12211/12631 [01:32<00:02, 149.24it/s] 97%|#########6| 12233/12631 [01:32<00:02, 164.33it/s] 97%|#########7| 12255/12631 [01:33<00:02, 177.79it/s] 97%|#########7| 12275/12631 [01:33<00:01, 180.18it/s] 97%|#########7| 12294/12631 [01:33<00:01, 182.02it/s] 97%|#########7| 12313/12631 [01:33<00:02, 120.55it/s] 98%|#########7| 12329/12631 [01:33<00:02, 128.81it/s] 98%|#########7| 12346/12631 [01:33<00:02, 137.67it/s] 98%|#########7| 12368/12631 [01:33<00:01, 153.91it/s] 98%|#########8| 12386/12631 [01:33<00:01, 158.79it/s] 98%|#########8| 12407/12631 [01:34<00:01, 170.17it/s] 98%|#########8| 12426/12631 [01:34<00:01, 104.84it/s] 98%|#########8| 12441/12631 [01:34<00:02, 92.59it/s]  99%|#########8| 12455/12631 [01:34<00:01, 102.48it/s] 99%|#########8| 12471/12631 [01:34<00:01, 114.14it/s] 99%|#########8| 12485/12631 [01:34<00:01, 118.64it/s] 99%|#########8| 12504/12631 [01:34<00:00, 133.34it/s] 99%|#########9| 12520/12631 [01:35<00:00, 120.92it/s] 99%|#########9| 12537/12631 [01:35<00:00, 132.38it/s] 99%|#########9| 12552/12631 [01:35<00:00, 109.41it/s] 99%|#########9| 12567/12631 [01:35<00:00, 116.80it/s]100%|#########9| 12580/12631 [01:35<00:00, 99.95it/s] 100%|#########9| 12594/12631 [01:35<00:00, 109.16it/s]100%|#########9| 12610/12631 [01:35<00:00, 117.42it/s]100%|#########9| 12630/12631 [01:36<00:00, 133.37it/s]100%|##########| 12631/12631 [01:36<00:00, 131.53it/s]
Succesfully wrote out_latest_Adagrad.csv, you can upload this file to the kaggle competition at https://www.kaggle.com/c/nyu-cv-fall-2017/
