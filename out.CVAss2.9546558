Lmod has detected the following error: You can only have one PYTORCH  module
loaded at a time.
You already have pytorch/python2.7  loaded.
To correct the situation, please enter the following command:

  module swap pytorch/python2.7  pytorch/0.2.0_1


While processing the following module(s):

Module fullname  Module Filename
---------------  ---------------
pytorch/0.2.0_1  /share/apps/modulefiles/pytorch/0.2.0_1.lua
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
Train Epoch: 1 [0/35339 (0%)]	Loss: 3.867984
Train Epoch: 1 [640/35339 (2%)]	Loss: 3.814288
Train Epoch: 1 [1280/35339 (4%)]	Loss: 3.823790
Train Epoch: 1 [1920/35339 (5%)]	Loss: 3.710029
Train Epoch: 1 [2560/35339 (7%)]	Loss: 3.774116
Train Epoch: 1 [3200/35339 (9%)]	Loss: 3.681269
Train Epoch: 1 [3840/35339 (11%)]	Loss: 3.725893
Train Epoch: 1 [4480/35339 (13%)]	Loss: 3.745886
Train Epoch: 1 [5120/35339 (14%)]	Loss: 3.598979
Train Epoch: 1 [5760/35339 (16%)]	Loss: 3.659860
Train Epoch: 1 [6400/35339 (18%)]	Loss: 3.715675
Train Epoch: 1 [7040/35339 (20%)]	Loss: 3.634847
Train Epoch: 1 [7680/35339 (22%)]	Loss: 3.637345
Train Epoch: 1 [8320/35339 (24%)]	Loss: 3.589828
Train Epoch: 1 [8960/35339 (25%)]	Loss: 3.617696
Train Epoch: 1 [9600/35339 (27%)]	Loss: 3.654517
Train Epoch: 1 [10240/35339 (29%)]	Loss: 3.642383
Train Epoch: 1 [10880/35339 (31%)]	Loss: 3.582598
Train Epoch: 1 [11520/35339 (33%)]	Loss: 3.679852
Train Epoch: 1 [12160/35339 (34%)]	Loss: 3.632619
Train Epoch: 1 [12800/35339 (36%)]	Loss: 3.566193
Train Epoch: 1 [13440/35339 (38%)]	Loss: 3.666558
Train Epoch: 1 [14080/35339 (40%)]	Loss: 3.608467
Train Epoch: 1 [14720/35339 (42%)]	Loss: 3.573112
Train Epoch: 1 [15360/35339 (43%)]	Loss: 3.568060
Train Epoch: 1 [16000/35339 (45%)]	Loss: 3.545476
Train Epoch: 1 [16640/35339 (47%)]	Loss: 3.622594
Train Epoch: 1 [17280/35339 (49%)]	Loss: 3.619729
Train Epoch: 1 [17920/35339 (51%)]	Loss: 3.524600
Train Epoch: 1 [18560/35339 (52%)]	Loss: 3.563002
Train Epoch: 1 [19200/35339 (54%)]	Loss: 3.529855
Train Epoch: 1 [19840/35339 (56%)]	Loss: 3.421491
Train Epoch: 1 [20480/35339 (58%)]	Loss: 3.503196
Train Epoch: 1 [21120/35339 (60%)]	Loss: 3.552312
Train Epoch: 1 [21760/35339 (61%)]	Loss: 3.421456
Train Epoch: 1 [22400/35339 (63%)]	Loss: 3.472836
Train Epoch: 1 [23040/35339 (65%)]	Loss: 3.589219
Train Epoch: 1 [23680/35339 (67%)]	Loss: 3.473973
Train Epoch: 1 [24320/35339 (69%)]	Loss: 3.544795
Train Epoch: 1 [24960/35339 (71%)]	Loss: 3.521956
Train Epoch: 1 [25600/35339 (72%)]	Loss: 3.461886
Train Epoch: 1 [26240/35339 (74%)]	Loss: 3.567376
Train Epoch: 1 [26880/35339 (76%)]	Loss: 3.460039
Train Epoch: 1 [27520/35339 (78%)]	Loss: 3.448686
Train Epoch: 1 [28160/35339 (80%)]	Loss: 3.433758
Train Epoch: 1 [28800/35339 (81%)]	Loss: 3.524644
Train Epoch: 1 [29440/35339 (83%)]	Loss: 3.469910
Train Epoch: 1 [30080/35339 (85%)]	Loss: 3.457617
Train Epoch: 1 [30720/35339 (87%)]	Loss: 3.475044
Train Epoch: 1 [31360/35339 (89%)]	Loss: 3.492715
Train Epoch: 1 [32000/35339 (90%)]	Loss: 3.481915
Train Epoch: 1 [32640/35339 (92%)]	Loss: 3.448151
Train Epoch: 1 [33280/35339 (94%)]	Loss: 3.429343
Train Epoch: 1 [33920/35339 (96%)]	Loss: 3.480290
Train Epoch: 1 [34560/35339 (98%)]	Loss: 3.368871
Train Epoch: 1 [35200/35339 (99%)]	Loss: 3.338446

Validation set: Average loss: 3.7771, Accuracy: 209/3870 (5%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 2 [0/35339 (0%)]	Loss: 3.532117
Train Epoch: 2 [640/35339 (2%)]	Loss: 3.365349
Train Epoch: 2 [1280/35339 (4%)]	Loss: 3.562088
Train Epoch: 2 [1920/35339 (5%)]	Loss: 3.433803
Train Epoch: 2 [2560/35339 (7%)]	Loss: 3.360600
Train Epoch: 2 [3200/35339 (9%)]	Loss: 3.378536
Train Epoch: 2 [3840/35339 (11%)]	Loss: 3.402572
Train Epoch: 2 [4480/35339 (13%)]	Loss: 3.386061
Train Epoch: 2 [5120/35339 (14%)]	Loss: 3.403023
Train Epoch: 2 [5760/35339 (16%)]	Loss: 3.434747
Train Epoch: 2 [6400/35339 (18%)]	Loss: 3.461198
Train Epoch: 2 [7040/35339 (20%)]	Loss: 3.319272
Train Epoch: 2 [7680/35339 (22%)]	Loss: 3.345931
Train Epoch: 2 [8320/35339 (24%)]	Loss: 3.253478
Train Epoch: 2 [8960/35339 (25%)]	Loss: 3.382875
Train Epoch: 2 [9600/35339 (27%)]	Loss: 3.413789
Train Epoch: 2 [10240/35339 (29%)]	Loss: 3.429322
Train Epoch: 2 [10880/35339 (31%)]	Loss: 3.311639
Train Epoch: 2 [11520/35339 (33%)]	Loss: 3.468081
Train Epoch: 2 [12160/35339 (34%)]	Loss: 3.385729
Train Epoch: 2 [12800/35339 (36%)]	Loss: 3.324660
Train Epoch: 2 [13440/35339 (38%)]	Loss: 3.424328
Train Epoch: 2 [14080/35339 (40%)]	Loss: 3.335024
Train Epoch: 2 [14720/35339 (42%)]	Loss: 3.297469
Train Epoch: 2 [15360/35339 (43%)]	Loss: 3.310724
Train Epoch: 2 [16000/35339 (45%)]	Loss: 3.227624
Train Epoch: 2 [16640/35339 (47%)]	Loss: 3.316109
Train Epoch: 2 [17280/35339 (49%)]	Loss: 3.344094
Train Epoch: 2 [17920/35339 (51%)]	Loss: 3.339987
Train Epoch: 2 [18560/35339 (52%)]	Loss: 3.256224
Train Epoch: 2 [19200/35339 (54%)]	Loss: 3.262129
Train Epoch: 2 [19840/35339 (56%)]	Loss: 3.234858
Train Epoch: 2 [20480/35339 (58%)]	Loss: 3.211826
Train Epoch: 2 [21120/35339 (60%)]	Loss: 3.331670
Train Epoch: 2 [21760/35339 (61%)]	Loss: 3.228530
Train Epoch: 2 [22400/35339 (63%)]	Loss: 3.352536
Train Epoch: 2 [23040/35339 (65%)]	Loss: 3.234909
Train Epoch: 2 [23680/35339 (67%)]	Loss: 3.215854
Train Epoch: 2 [24320/35339 (69%)]	Loss: 3.284377
Train Epoch: 2 [24960/35339 (71%)]	Loss: 3.290951
Train Epoch: 2 [25600/35339 (72%)]	Loss: 3.214341
Train Epoch: 2 [26240/35339 (74%)]	Loss: 3.208737
Train Epoch: 2 [26880/35339 (76%)]	Loss: 3.234601
Train Epoch: 2 [27520/35339 (78%)]	Loss: 3.199716
Train Epoch: 2 [28160/35339 (80%)]	Loss: 3.173032
Train Epoch: 2 [28800/35339 (81%)]	Loss: 3.292208
Train Epoch: 2 [29440/35339 (83%)]	Loss: 3.326282
Train Epoch: 2 [30080/35339 (85%)]	Loss: 3.223913
Train Epoch: 2 [30720/35339 (87%)]	Loss: 3.318865
Train Epoch: 2 [31360/35339 (89%)]	Loss: 3.230532
Train Epoch: 2 [32000/35339 (90%)]	Loss: 3.276945
Train Epoch: 2 [32640/35339 (92%)]	Loss: 3.163553
Train Epoch: 2 [33280/35339 (94%)]	Loss: 3.248708
Train Epoch: 2 [33920/35339 (96%)]	Loss: 3.251522
Train Epoch: 2 [34560/35339 (98%)]	Loss: 3.263554
Train Epoch: 2 [35200/35339 (99%)]	Loss: 3.145229

Validation set: Average loss: 3.7782, Accuracy: 288/3870 (7%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 3 [0/35339 (0%)]	Loss: 3.235755
Train Epoch: 3 [640/35339 (2%)]	Loss: 3.202014
Train Epoch: 3 [1280/35339 (4%)]	Loss: 3.095457
Train Epoch: 3 [1920/35339 (5%)]	Loss: 3.210132
Train Epoch: 3 [2560/35339 (7%)]	Loss: 3.112285
Train Epoch: 3 [3200/35339 (9%)]	Loss: 3.148174
Train Epoch: 3 [3840/35339 (11%)]	Loss: 3.174451
Train Epoch: 3 [4480/35339 (13%)]	Loss: 3.132889
Train Epoch: 3 [5120/35339 (14%)]	Loss: 3.113593
Train Epoch: 3 [5760/35339 (16%)]	Loss: 3.191867
Train Epoch: 3 [6400/35339 (18%)]	Loss: 3.171631
Train Epoch: 3 [7040/35339 (20%)]	Loss: 3.130686
Train Epoch: 3 [7680/35339 (22%)]	Loss: 3.205951
Train Epoch: 3 [8320/35339 (24%)]	Loss: 3.143069
Train Epoch: 3 [8960/35339 (25%)]	Loss: 3.183028
Train Epoch: 3 [9600/35339 (27%)]	Loss: 3.139057
Train Epoch: 3 [10240/35339 (29%)]	Loss: 3.134749
Train Epoch: 3 [10880/35339 (31%)]	Loss: 3.137172
Train Epoch: 3 [11520/35339 (33%)]	Loss: 3.125890
Train Epoch: 3 [12160/35339 (34%)]	Loss: 3.150680
Train Epoch: 3 [12800/35339 (36%)]	Loss: 3.171591
Train Epoch: 3 [13440/35339 (38%)]	Loss: 3.109601
Train Epoch: 3 [14080/35339 (40%)]	Loss: 3.055536
Train Epoch: 3 [14720/35339 (42%)]	Loss: 3.001013
Train Epoch: 3 [15360/35339 (43%)]	Loss: 3.125787
Train Epoch: 3 [16000/35339 (45%)]	Loss: 3.208278
Train Epoch: 3 [16640/35339 (47%)]	Loss: 3.159972
Train Epoch: 3 [17280/35339 (49%)]	Loss: 3.136389
Train Epoch: 3 [17920/35339 (51%)]	Loss: 3.080187
Train Epoch: 3 [18560/35339 (52%)]	Loss: 3.182440
Train Epoch: 3 [19200/35339 (54%)]	Loss: 2.949577
Train Epoch: 3 [19840/35339 (56%)]	Loss: 3.171895
Train Epoch: 3 [20480/35339 (58%)]	Loss: 3.164894
Train Epoch: 3 [21120/35339 (60%)]	Loss: 2.947118
Train Epoch: 3 [21760/35339 (61%)]	Loss: 3.153788
Train Epoch: 3 [22400/35339 (63%)]	Loss: 3.152882
Train Epoch: 3 [23040/35339 (65%)]	Loss: 3.021100
Train Epoch: 3 [23680/35339 (67%)]	Loss: 3.095821
Train Epoch: 3 [24320/35339 (69%)]	Loss: 3.155912
Train Epoch: 3 [24960/35339 (71%)]	Loss: 3.135841
Train Epoch: 3 [25600/35339 (72%)]	Loss: 3.060675
Train Epoch: 3 [26240/35339 (74%)]	Loss: 3.060726
Train Epoch: 3 [26880/35339 (76%)]	Loss: 3.046347
Train Epoch: 3 [27520/35339 (78%)]	Loss: 3.033423
Train Epoch: 3 [28160/35339 (80%)]	Loss: 3.035944
Train Epoch: 3 [28800/35339 (81%)]	Loss: 2.992501
Train Epoch: 3 [29440/35339 (83%)]	Loss: 3.079052
Train Epoch: 3 [30080/35339 (85%)]	Loss: 3.078690
Train Epoch: 3 [30720/35339 (87%)]	Loss: 2.972191
Train Epoch: 3 [31360/35339 (89%)]	Loss: 3.017748
Train Epoch: 3 [32000/35339 (90%)]	Loss: 3.053466
Train Epoch: 3 [32640/35339 (92%)]	Loss: 2.985907
Train Epoch: 3 [33280/35339 (94%)]	Loss: 2.960723
Train Epoch: 3 [33920/35339 (96%)]	Loss: 3.097149
Train Epoch: 3 [34560/35339 (98%)]	Loss: 2.948204
Train Epoch: 3 [35200/35339 (99%)]	Loss: 2.992215

Validation set: Average loss: 3.7691, Accuracy: 368/3870 (10%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 4 [0/35339 (0%)]	Loss: 3.066483
Train Epoch: 4 [640/35339 (2%)]	Loss: 2.992519
Train Epoch: 4 [1280/35339 (4%)]	Loss: 2.964217
Train Epoch: 4 [1920/35339 (5%)]	Loss: 2.901537
Train Epoch: 4 [2560/35339 (7%)]	Loss: 3.028130
Train Epoch: 4 [3200/35339 (9%)]	Loss: 2.929638
Train Epoch: 4 [3840/35339 (11%)]	Loss: 2.947550
Train Epoch: 4 [4480/35339 (13%)]	Loss: 2.934296
Train Epoch: 4 [5120/35339 (14%)]	Loss: 2.947046
Train Epoch: 4 [5760/35339 (16%)]	Loss: 2.965862
Train Epoch: 4 [6400/35339 (18%)]	Loss: 3.033597
Train Epoch: 4 [7040/35339 (20%)]	Loss: 2.848878
Train Epoch: 4 [7680/35339 (22%)]	Loss: 2.906007
Train Epoch: 4 [8320/35339 (24%)]	Loss: 3.015805
Train Epoch: 4 [8960/35339 (25%)]	Loss: 3.019493
Train Epoch: 4 [9600/35339 (27%)]	Loss: 2.949939
Train Epoch: 4 [10240/35339 (29%)]	Loss: 2.775486
Train Epoch: 4 [10880/35339 (31%)]	Loss: 2.877961
Train Epoch: 4 [11520/35339 (33%)]	Loss: 3.095504
Train Epoch: 4 [12160/35339 (34%)]	Loss: 2.989709
Train Epoch: 4 [12800/35339 (36%)]	Loss: 2.751892
Train Epoch: 4 [13440/35339 (38%)]	Loss: 3.006241
Train Epoch: 4 [14080/35339 (40%)]	Loss: 2.983481
Train Epoch: 4 [14720/35339 (42%)]	Loss: 2.919821
Train Epoch: 4 [15360/35339 (43%)]	Loss: 2.985790
Train Epoch: 4 [16000/35339 (45%)]	Loss: 2.867818
Train Epoch: 4 [16640/35339 (47%)]	Loss: 2.946512
Train Epoch: 4 [17280/35339 (49%)]	Loss: 2.837610
Train Epoch: 4 [17920/35339 (51%)]	Loss: 2.896019
Train Epoch: 4 [18560/35339 (52%)]	Loss: 2.906327
Train Epoch: 4 [19200/35339 (54%)]	Loss: 2.876272
Train Epoch: 4 [19840/35339 (56%)]	Loss: 3.018635
Train Epoch: 4 [20480/35339 (58%)]	Loss: 2.785173
Train Epoch: 4 [21120/35339 (60%)]	Loss: 2.889648
Train Epoch: 4 [21760/35339 (61%)]	Loss: 2.928612
Train Epoch: 4 [22400/35339 (63%)]	Loss: 2.876470
Train Epoch: 4 [23040/35339 (65%)]	Loss: 2.822570
Train Epoch: 4 [23680/35339 (67%)]	Loss: 2.874261
Train Epoch: 4 [24320/35339 (69%)]	Loss: 2.791361
Train Epoch: 4 [24960/35339 (71%)]	Loss: 2.821334
Train Epoch: 4 [25600/35339 (72%)]	Loss: 2.831897
Train Epoch: 4 [26240/35339 (74%)]	Loss: 2.893774
Train Epoch: 4 [26880/35339 (76%)]	Loss: 2.908556
Train Epoch: 4 [27520/35339 (78%)]	Loss: 2.794522
Train Epoch: 4 [28160/35339 (80%)]	Loss: 2.834468
Train Epoch: 4 [28800/35339 (81%)]	Loss: 2.667614
Train Epoch: 4 [29440/35339 (83%)]	Loss: 2.755682
Train Epoch: 4 [30080/35339 (85%)]	Loss: 2.704863
Train Epoch: 4 [30720/35339 (87%)]	Loss: 2.702700
Train Epoch: 4 [31360/35339 (89%)]	Loss: 2.889642
Train Epoch: 4 [32000/35339 (90%)]	Loss: 2.716002
Train Epoch: 4 [32640/35339 (92%)]	Loss: 2.810130
Train Epoch: 4 [33280/35339 (94%)]	Loss: 2.867361
Train Epoch: 4 [33920/35339 (96%)]	Loss: 2.696848
Train Epoch: 4 [34560/35339 (98%)]	Loss: 2.825342
Train Epoch: 4 [35200/35339 (99%)]	Loss: 2.841977

Validation set: Average loss: 3.7489, Accuracy: 437/3870 (11%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 5 [0/35339 (0%)]	Loss: 2.829491
Train Epoch: 5 [640/35339 (2%)]	Loss: 2.876677
Train Epoch: 5 [1280/35339 (4%)]	Loss: 2.773587
Train Epoch: 5 [1920/35339 (5%)]	Loss: 2.848863
Train Epoch: 5 [2560/35339 (7%)]	Loss: 2.903031
Train Epoch: 5 [3200/35339 (9%)]	Loss: 2.747684
Train Epoch: 5 [3840/35339 (11%)]	Loss: 2.703341
Train Epoch: 5 [4480/35339 (13%)]	Loss: 2.709882
Train Epoch: 5 [5120/35339 (14%)]	Loss: 2.663241
Train Epoch: 5 [5760/35339 (16%)]	Loss: 2.956667
Train Epoch: 5 [6400/35339 (18%)]	Loss: 2.702096
Train Epoch: 5 [7040/35339 (20%)]	Loss: 2.827218
Train Epoch: 5 [7680/35339 (22%)]	Loss: 2.852322
Train Epoch: 5 [8320/35339 (24%)]	Loss: 2.692575
Train Epoch: 5 [8960/35339 (25%)]	Loss: 2.722084
Train Epoch: 5 [9600/35339 (27%)]	Loss: 2.704555
Train Epoch: 5 [10240/35339 (29%)]	Loss: 2.825845
Train Epoch: 5 [10880/35339 (31%)]	Loss: 2.768392
Train Epoch: 5 [11520/35339 (33%)]	Loss: 2.627624
Train Epoch: 5 [12160/35339 (34%)]	Loss: 2.738041
Train Epoch: 5 [12800/35339 (36%)]	Loss: 2.772890
Train Epoch: 5 [13440/35339 (38%)]	Loss: 2.672758
Train Epoch: 5 [14080/35339 (40%)]	Loss: 2.758530
Train Epoch: 5 [14720/35339 (42%)]	Loss: 2.683226
Train Epoch: 5 [15360/35339 (43%)]	Loss: 2.636801
Train Epoch: 5 [16000/35339 (45%)]	Loss: 2.641791
Train Epoch: 5 [16640/35339 (47%)]	Loss: 2.791883
Train Epoch: 5 [17280/35339 (49%)]	Loss: 2.754211
Train Epoch: 5 [17920/35339 (51%)]	Loss: 2.678286
Train Epoch: 5 [18560/35339 (52%)]	Loss: 2.593124
Train Epoch: 5 [19200/35339 (54%)]	Loss: 2.536754
Train Epoch: 5 [19840/35339 (56%)]	Loss: 2.591098
Train Epoch: 5 [20480/35339 (58%)]	Loss: 2.620823
Train Epoch: 5 [21120/35339 (60%)]	Loss: 2.592413
Train Epoch: 5 [21760/35339 (61%)]	Loss: 2.537496
Train Epoch: 5 [22400/35339 (63%)]	Loss: 2.576331
Train Epoch: 5 [23040/35339 (65%)]	Loss: 2.546990
Train Epoch: 5 [23680/35339 (67%)]	Loss: 2.646221
Train Epoch: 5 [24320/35339 (69%)]	Loss: 2.613988
Train Epoch: 5 [24960/35339 (71%)]	Loss: 2.607674
Train Epoch: 5 [25600/35339 (72%)]	Loss: 2.682996
Train Epoch: 5 [26240/35339 (74%)]	Loss: 2.515296
Train Epoch: 5 [26880/35339 (76%)]	Loss: 2.651850
Train Epoch: 5 [27520/35339 (78%)]	Loss: 2.613142
Train Epoch: 5 [28160/35339 (80%)]	Loss: 2.539597
Train Epoch: 5 [28800/35339 (81%)]	Loss: 2.577437
Train Epoch: 5 [29440/35339 (83%)]	Loss: 2.557343
Train Epoch: 5 [30080/35339 (85%)]	Loss: 2.602550
Train Epoch: 5 [30720/35339 (87%)]	Loss: 2.626232
Train Epoch: 5 [31360/35339 (89%)]	Loss: 2.593677
Train Epoch: 5 [32000/35339 (90%)]	Loss: 2.598674
Train Epoch: 5 [32640/35339 (92%)]	Loss: 2.482405
Train Epoch: 5 [33280/35339 (94%)]	Loss: 2.591139
Train Epoch: 5 [33920/35339 (96%)]	Loss: 2.471650
Train Epoch: 5 [34560/35339 (98%)]	Loss: 2.567469
Train Epoch: 5 [35200/35339 (99%)]	Loss: 2.604131

Validation set: Average loss: 3.7422, Accuracy: 490/3870 (13%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 6 [0/35339 (0%)]	Loss: 2.500989
Train Epoch: 6 [640/35339 (2%)]	Loss: 2.618630
Train Epoch: 6 [1280/35339 (4%)]	Loss: 2.471247
Train Epoch: 6 [1920/35339 (5%)]	Loss: 2.510172
Train Epoch: 6 [2560/35339 (7%)]	Loss: 2.707064
Train Epoch: 6 [3200/35339 (9%)]	Loss: 2.472677
Train Epoch: 6 [3840/35339 (11%)]	Loss: 2.479586
Train Epoch: 6 [4480/35339 (13%)]	Loss: 2.603498
Train Epoch: 6 [5120/35339 (14%)]	Loss: 2.503539
Train Epoch: 6 [5760/35339 (16%)]	Loss: 2.627862
Train Epoch: 6 [6400/35339 (18%)]	Loss: 2.453730
Train Epoch: 6 [7040/35339 (20%)]	Loss: 2.370478
Train Epoch: 6 [7680/35339 (22%)]	Loss: 2.740264
Train Epoch: 6 [8320/35339 (24%)]	Loss: 2.576161
Train Epoch: 6 [8960/35339 (25%)]	Loss: 2.468543
Train Epoch: 6 [9600/35339 (27%)]	Loss: 2.612153
Train Epoch: 6 [10240/35339 (29%)]	Loss: 2.578388
Train Epoch: 6 [10880/35339 (31%)]	Loss: 2.592939
Train Epoch: 6 [11520/35339 (33%)]	Loss: 2.593664
Train Epoch: 6 [12160/35339 (34%)]	Loss: 2.532055
Train Epoch: 6 [12800/35339 (36%)]	Loss: 2.549388
Train Epoch: 6 [13440/35339 (38%)]	Loss: 2.532553
Train Epoch: 6 [14080/35339 (40%)]	Loss: 2.526446
Train Epoch: 6 [14720/35339 (42%)]	Loss: 2.483276
Train Epoch: 6 [15360/35339 (43%)]	Loss: 2.554489
Train Epoch: 6 [16000/35339 (45%)]	Loss: 2.589283
Train Epoch: 6 [16640/35339 (47%)]	Loss: 2.525528
Train Epoch: 6 [17280/35339 (49%)]	Loss: 2.517131
Train Epoch: 6 [17920/35339 (51%)]	Loss: 2.333314
Train Epoch: 6 [18560/35339 (52%)]	Loss: 2.431577
Train Epoch: 6 [19200/35339 (54%)]	Loss: 2.558500
Train Epoch: 6 [19840/35339 (56%)]	Loss: 2.466049
Train Epoch: 6 [20480/35339 (58%)]	Loss: 2.491111
Train Epoch: 6 [21120/35339 (60%)]	Loss: 2.486906
Train Epoch: 6 [21760/35339 (61%)]	Loss: 2.386655
Train Epoch: 6 [22400/35339 (63%)]	Loss: 2.383366
Train Epoch: 6 [23040/35339 (65%)]	Loss: 2.487869
Train Epoch: 6 [23680/35339 (67%)]	Loss: 2.452760
Train Epoch: 6 [24320/35339 (69%)]	Loss: 2.435378
Train Epoch: 6 [24960/35339 (71%)]	Loss: 2.521962
Train Epoch: 6 [25600/35339 (72%)]	Loss: 2.332619
Train Epoch: 6 [26240/35339 (74%)]	Loss: 2.490249
Train Epoch: 6 [26880/35339 (76%)]	Loss: 2.405872
Train Epoch: 6 [27520/35339 (78%)]	Loss: 2.461197
Train Epoch: 6 [28160/35339 (80%)]	Loss: 2.531203
Train Epoch: 6 [28800/35339 (81%)]	Loss: 2.522090
Train Epoch: 6 [29440/35339 (83%)]	Loss: 2.589455
Train Epoch: 6 [30080/35339 (85%)]	Loss: 2.488108
Train Epoch: 6 [30720/35339 (87%)]	Loss: 2.418140
Train Epoch: 6 [31360/35339 (89%)]	Loss: 2.393503
Train Epoch: 6 [32000/35339 (90%)]	Loss: 2.400316
Train Epoch: 6 [32640/35339 (92%)]	Loss: 2.308211
Train Epoch: 6 [33280/35339 (94%)]	Loss: 2.340871
Train Epoch: 6 [33920/35339 (96%)]	Loss: 2.388436
Train Epoch: 6 [34560/35339 (98%)]	Loss: 2.354658
Train Epoch: 6 [35200/35339 (99%)]	Loss: 2.314217

Validation set: Average loss: 3.7376, Accuracy: 558/3870 (14%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 7 [0/35339 (0%)]	Loss: 2.386075
Train Epoch: 7 [640/35339 (2%)]	Loss: 2.516993
Train Epoch: 7 [1280/35339 (4%)]	Loss: 2.321290
Train Epoch: 7 [1920/35339 (5%)]	Loss: 2.376243
Train Epoch: 7 [2560/35339 (7%)]	Loss: 2.422688
Train Epoch: 7 [3200/35339 (9%)]	Loss: 2.403906
Train Epoch: 7 [3840/35339 (11%)]	Loss: 2.389645
Train Epoch: 7 [4480/35339 (13%)]	Loss: 2.352396
Train Epoch: 7 [5120/35339 (14%)]	Loss: 2.329371
Train Epoch: 7 [5760/35339 (16%)]	Loss: 2.329235
Train Epoch: 7 [6400/35339 (18%)]	Loss: 2.518794
Train Epoch: 7 [7040/35339 (20%)]	Loss: 2.379658
Train Epoch: 7 [7680/35339 (22%)]	Loss: 2.484408
Train Epoch: 7 [8320/35339 (24%)]	Loss: 2.230461
Train Epoch: 7 [8960/35339 (25%)]	Loss: 2.356359
Train Epoch: 7 [9600/35339 (27%)]	Loss: 2.409115
Train Epoch: 7 [10240/35339 (29%)]	Loss: 2.390524
Train Epoch: 7 [10880/35339 (31%)]	Loss: 2.282214
Train Epoch: 7 [11520/35339 (33%)]	Loss: 2.275415
Train Epoch: 7 [12160/35339 (34%)]	Loss: 2.331735
Train Epoch: 7 [12800/35339 (36%)]	Loss: 2.278539
Train Epoch: 7 [13440/35339 (38%)]	Loss: 2.256454
Train Epoch: 7 [14080/35339 (40%)]	Loss: 2.273181
Train Epoch: 7 [14720/35339 (42%)]	Loss: 2.437989
Train Epoch: 7 [15360/35339 (43%)]	Loss: 2.383134
Train Epoch: 7 [16000/35339 (45%)]	Loss: 2.334563
Train Epoch: 7 [16640/35339 (47%)]	Loss: 2.406595
Train Epoch: 7 [17280/35339 (49%)]	Loss: 2.358553
Train Epoch: 7 [17920/35339 (51%)]	Loss: 2.391665
Train Epoch: 7 [18560/35339 (52%)]	Loss: 2.291648
Train Epoch: 7 [19200/35339 (54%)]	Loss: 2.327872
Train Epoch: 7 [19840/35339 (56%)]	Loss: 2.372558
Train Epoch: 7 [20480/35339 (58%)]	Loss: 2.177487
Train Epoch: 7 [21120/35339 (60%)]	Loss: 2.273373
Train Epoch: 7 [21760/35339 (61%)]	Loss: 2.305603
Train Epoch: 7 [22400/35339 (63%)]	Loss: 2.322567
Train Epoch: 7 [23040/35339 (65%)]	Loss: 2.256799
Train Epoch: 7 [23680/35339 (67%)]	Loss: 2.305518
Train Epoch: 7 [24320/35339 (69%)]	Loss: 2.171501
Train Epoch: 7 [24960/35339 (71%)]	Loss: 2.380775
Train Epoch: 7 [25600/35339 (72%)]	Loss: 2.294462
Train Epoch: 7 [26240/35339 (74%)]	Loss: 2.328635
Train Epoch: 7 [26880/35339 (76%)]	Loss: 2.245699
Train Epoch: 7 [27520/35339 (78%)]	Loss: 2.375695
Train Epoch: 7 [28160/35339 (80%)]	Loss: 2.280663
Train Epoch: 7 [28800/35339 (81%)]	Loss: 2.296450
Train Epoch: 7 [29440/35339 (83%)]	Loss: 2.367340
Train Epoch: 7 [30080/35339 (85%)]	Loss: 2.299532
Train Epoch: 7 [30720/35339 (87%)]	Loss: 2.265824
Train Epoch: 7 [31360/35339 (89%)]	Loss: 2.364740
Train Epoch: 7 [32000/35339 (90%)]	Loss: 2.269560
Train Epoch: 7 [32640/35339 (92%)]	Loss: 2.265046
Train Epoch: 7 [33280/35339 (94%)]	Loss: 2.194944
Train Epoch: 7 [33920/35339 (96%)]	Loss: 2.303502
Train Epoch: 7 [34560/35339 (98%)]	Loss: 2.188387
Train Epoch: 7 [35200/35339 (99%)]	Loss: 2.159637

Validation set: Average loss: 3.7305, Accuracy: 595/3870 (15%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 8 [0/35339 (0%)]	Loss: 2.241683
Train Epoch: 8 [640/35339 (2%)]	Loss: 2.383510
Train Epoch: 8 [1280/35339 (4%)]	Loss: 2.131178
Train Epoch: 8 [1920/35339 (5%)]	Loss: 2.158835
Train Epoch: 8 [2560/35339 (7%)]	Loss: 2.329642
Train Epoch: 8 [3200/35339 (9%)]	Loss: 2.222980
Train Epoch: 8 [3840/35339 (11%)]	Loss: 2.292751
Train Epoch: 8 [4480/35339 (13%)]	Loss: 2.038023
Train Epoch: 8 [5120/35339 (14%)]	Loss: 2.229260
Train Epoch: 8 [5760/35339 (16%)]	Loss: 2.280058
Train Epoch: 8 [6400/35339 (18%)]	Loss: 2.208362
Train Epoch: 8 [7040/35339 (20%)]	Loss: 2.203143
Train Epoch: 8 [7680/35339 (22%)]	Loss: 2.176510
Train Epoch: 8 [8320/35339 (24%)]	Loss: 2.263249
Train Epoch: 8 [8960/35339 (25%)]	Loss: 2.147308
Train Epoch: 8 [9600/35339 (27%)]	Loss: 2.072132
Train Epoch: 8 [10240/35339 (29%)]	Loss: 2.098958
Train Epoch: 8 [10880/35339 (31%)]	Loss: 2.140636
Train Epoch: 8 [11520/35339 (33%)]	Loss: 2.197097
Train Epoch: 8 [12160/35339 (34%)]	Loss: 2.195791
Train Epoch: 8 [12800/35339 (36%)]	Loss: 2.303436
Train Epoch: 8 [13440/35339 (38%)]	Loss: 2.288776
Train Epoch: 8 [14080/35339 (40%)]	Loss: 2.218107
Train Epoch: 8 [14720/35339 (42%)]	Loss: 2.354317
Train Epoch: 8 [15360/35339 (43%)]	Loss: 2.167327
Train Epoch: 8 [16000/35339 (45%)]	Loss: 2.253987
Train Epoch: 8 [16640/35339 (47%)]	Loss: 2.170882
Train Epoch: 8 [17280/35339 (49%)]	Loss: 2.280360
Train Epoch: 8 [17920/35339 (51%)]	Loss: 2.090977
Train Epoch: 8 [18560/35339 (52%)]	Loss: 2.231848
Train Epoch: 8 [19200/35339 (54%)]	Loss: 2.176803
Train Epoch: 8 [19840/35339 (56%)]	Loss: 2.188346
Train Epoch: 8 [20480/35339 (58%)]	Loss: 2.231228
Train Epoch: 8 [21120/35339 (60%)]	Loss: 2.079834
Train Epoch: 8 [21760/35339 (61%)]	Loss: 2.220566
Train Epoch: 8 [22400/35339 (63%)]	Loss: 2.127743
Train Epoch: 8 [23040/35339 (65%)]	Loss: 2.171831
Train Epoch: 8 [23680/35339 (67%)]	Loss: 2.303089
Train Epoch: 8 [24320/35339 (69%)]	Loss: 2.160509
Train Epoch: 8 [24960/35339 (71%)]	Loss: 2.018988
Train Epoch: 8 [25600/35339 (72%)]	Loss: 2.433212
Train Epoch: 8 [26240/35339 (74%)]	Loss: 2.248573
Train Epoch: 8 [26880/35339 (76%)]	Loss: 2.128545
Train Epoch: 8 [27520/35339 (78%)]	Loss: 2.185965
Train Epoch: 8 [28160/35339 (80%)]	Loss: 1.970916
Train Epoch: 8 [28800/35339 (81%)]	Loss: 2.196272
Train Epoch: 8 [29440/35339 (83%)]	Loss: 2.198443
Train Epoch: 8 [30080/35339 (85%)]	Loss: 2.141403
Train Epoch: 8 [30720/35339 (87%)]	Loss: 2.236338
Train Epoch: 8 [31360/35339 (89%)]	Loss: 2.147315
Train Epoch: 8 [32000/35339 (90%)]	Loss: 2.261732
Train Epoch: 8 [32640/35339 (92%)]	Loss: 2.239022
Train Epoch: 8 [33280/35339 (94%)]	Loss: 2.105469
Train Epoch: 8 [33920/35339 (96%)]	Loss: 2.055831
Train Epoch: 8 [34560/35339 (98%)]	Loss: 2.046189
Train Epoch: 8 [35200/35339 (99%)]	Loss: 2.199439

Validation set: Average loss: 3.7208, Accuracy: 652/3870 (17%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 9 [0/35339 (0%)]	Loss: 2.192245
Train Epoch: 9 [640/35339 (2%)]	Loss: 2.072344
Train Epoch: 9 [1280/35339 (4%)]	Loss: 2.327536
Train Epoch: 9 [1920/35339 (5%)]	Loss: 2.101577
Train Epoch: 9 [2560/35339 (7%)]	Loss: 1.925077
Train Epoch: 9 [3200/35339 (9%)]	Loss: 2.054388
Train Epoch: 9 [3840/35339 (11%)]	Loss: 2.252944
Train Epoch: 9 [4480/35339 (13%)]	Loss: 2.224506
Train Epoch: 9 [5120/35339 (14%)]	Loss: 1.932976
Train Epoch: 9 [5760/35339 (16%)]	Loss: 2.224210
Train Epoch: 9 [6400/35339 (18%)]	Loss: 2.185802
Train Epoch: 9 [7040/35339 (20%)]	Loss: 2.177694
Train Epoch: 9 [7680/35339 (22%)]	Loss: 2.037880
Train Epoch: 9 [8320/35339 (24%)]	Loss: 2.138146
Train Epoch: 9 [8960/35339 (25%)]	Loss: 2.171717
Train Epoch: 9 [9600/35339 (27%)]	Loss: 2.197038
Train Epoch: 9 [10240/35339 (29%)]	Loss: 2.079829
Train Epoch: 9 [10880/35339 (31%)]	Loss: 2.059452
Train Epoch: 9 [11520/35339 (33%)]	Loss: 2.077055
Train Epoch: 9 [12160/35339 (34%)]	Loss: 2.129460
Train Epoch: 9 [12800/35339 (36%)]	Loss: 2.089396
Train Epoch: 9 [13440/35339 (38%)]	Loss: 2.250621
Train Epoch: 9 [14080/35339 (40%)]	Loss: 2.205528
Train Epoch: 9 [14720/35339 (42%)]	Loss: 2.108432
Train Epoch: 9 [15360/35339 (43%)]	Loss: 1.958793
Train Epoch: 9 [16000/35339 (45%)]	Loss: 1.960547
Train Epoch: 9 [16640/35339 (47%)]	Loss: 1.956348
Train Epoch: 9 [17280/35339 (49%)]	Loss: 2.138889
Train Epoch: 9 [17920/35339 (51%)]	Loss: 2.030545
Train Epoch: 9 [18560/35339 (52%)]	Loss: 2.073889
Train Epoch: 9 [19200/35339 (54%)]	Loss: 1.919176
Train Epoch: 9 [19840/35339 (56%)]	Loss: 1.873707
Train Epoch: 9 [20480/35339 (58%)]	Loss: 2.087068
Train Epoch: 9 [21120/35339 (60%)]	Loss: 2.003988
Train Epoch: 9 [21760/35339 (61%)]	Loss: 2.016446
Train Epoch: 9 [22400/35339 (63%)]	Loss: 2.060339
Train Epoch: 9 [23040/35339 (65%)]	Loss: 2.065976
Train Epoch: 9 [23680/35339 (67%)]	Loss: 2.052152
Train Epoch: 9 [24320/35339 (69%)]	Loss: 2.160255
Train Epoch: 9 [24960/35339 (71%)]	Loss: 1.887070
Train Epoch: 9 [25600/35339 (72%)]	Loss: 2.058297
Train Epoch: 9 [26240/35339 (74%)]	Loss: 1.878140
Train Epoch: 9 [26880/35339 (76%)]	Loss: 2.023243
Train Epoch: 9 [27520/35339 (78%)]	Loss: 2.020788
Train Epoch: 9 [28160/35339 (80%)]	Loss: 1.998051
Train Epoch: 9 [28800/35339 (81%)]	Loss: 2.014026
Train Epoch: 9 [29440/35339 (83%)]	Loss: 1.923857
Train Epoch: 9 [30080/35339 (85%)]	Loss: 2.088778
Train Epoch: 9 [30720/35339 (87%)]	Loss: 2.085271
Train Epoch: 9 [31360/35339 (89%)]	Loss: 1.889697
Train Epoch: 9 [32000/35339 (90%)]	Loss: 2.108806
Train Epoch: 9 [32640/35339 (92%)]	Loss: 1.995407
Train Epoch: 9 [33280/35339 (94%)]	Loss: 1.943808
Train Epoch: 9 [33920/35339 (96%)]	Loss: 2.060283
Train Epoch: 9 [34560/35339 (98%)]	Loss: 2.085956
Train Epoch: 9 [35200/35339 (99%)]	Loss: 2.003480

Validation set: Average loss: 3.7239, Accuracy: 683/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 10 [0/35339 (0%)]	Loss: 1.982822
Train Epoch: 10 [640/35339 (2%)]	Loss: 1.892018
Train Epoch: 10 [1280/35339 (4%)]	Loss: 1.876064
Train Epoch: 10 [1920/35339 (5%)]	Loss: 1.820361
Train Epoch: 10 [2560/35339 (7%)]	Loss: 2.128408
Train Epoch: 10 [3200/35339 (9%)]	Loss: 1.880827
Train Epoch: 10 [3840/35339 (11%)]	Loss: 1.773400
Train Epoch: 10 [4480/35339 (13%)]	Loss: 1.871712
Train Epoch: 10 [5120/35339 (14%)]	Loss: 1.952563
Train Epoch: 10 [5760/35339 (16%)]	Loss: 2.117443
Train Epoch: 10 [6400/35339 (18%)]	Loss: 1.932861
Train Epoch: 10 [7040/35339 (20%)]	Loss: 2.010385
Train Epoch: 10 [7680/35339 (22%)]	Loss: 2.342394
Train Epoch: 10 [8320/35339 (24%)]	Loss: 2.053178
Train Epoch: 10 [8960/35339 (25%)]	Loss: 2.023030
Train Epoch: 10 [9600/35339 (27%)]	Loss: 1.897266
Train Epoch: 10 [10240/35339 (29%)]	Loss: 1.972284
Train Epoch: 10 [10880/35339 (31%)]	Loss: 1.959344
Train Epoch: 10 [11520/35339 (33%)]	Loss: 2.073402
Train Epoch: 10 [12160/35339 (34%)]	Loss: 1.831119
Train Epoch: 10 [12800/35339 (36%)]	Loss: 1.904797
Train Epoch: 10 [13440/35339 (38%)]	Loss: 1.904280
Train Epoch: 10 [14080/35339 (40%)]	Loss: 1.888250
Train Epoch: 10 [14720/35339 (42%)]	Loss: 2.151533
Train Epoch: 10 [15360/35339 (43%)]	Loss: 2.146995
Train Epoch: 10 [16000/35339 (45%)]	Loss: 1.944390
Train Epoch: 10 [16640/35339 (47%)]	Loss: 2.043229
Train Epoch: 10 [17280/35339 (49%)]	Loss: 1.974272
Train Epoch: 10 [17920/35339 (51%)]	Loss: 2.013737
Train Epoch: 10 [18560/35339 (52%)]	Loss: 1.827366
Train Epoch: 10 [19200/35339 (54%)]	Loss: 1.989965
Train Epoch: 10 [19840/35339 (56%)]	Loss: 1.892350
Train Epoch: 10 [20480/35339 (58%)]	Loss: 2.015547
Train Epoch: 10 [21120/35339 (60%)]	Loss: 2.014430
Train Epoch: 10 [21760/35339 (61%)]	Loss: 1.997905
Train Epoch: 10 [22400/35339 (63%)]	Loss: 2.011917
Train Epoch: 10 [23040/35339 (65%)]	Loss: 1.976217
Train Epoch: 10 [23680/35339 (67%)]	Loss: 1.926018
Train Epoch: 10 [24320/35339 (69%)]	Loss: 1.952405
Train Epoch: 10 [24960/35339 (71%)]	Loss: 1.844684
Train Epoch: 10 [25600/35339 (72%)]	Loss: 2.015129
Train Epoch: 10 [26240/35339 (74%)]	Loss: 1.891618
Train Epoch: 10 [26880/35339 (76%)]	Loss: 1.870417
Train Epoch: 10 [27520/35339 (78%)]	Loss: 1.783171
Train Epoch: 10 [28160/35339 (80%)]	Loss: 1.940107
Train Epoch: 10 [28800/35339 (81%)]	Loss: 1.873358
Train Epoch: 10 [29440/35339 (83%)]	Loss: 1.870633
Train Epoch: 10 [30080/35339 (85%)]	Loss: 2.005479
Train Epoch: 10 [30720/35339 (87%)]	Loss: 1.798781
Train Epoch: 10 [31360/35339 (89%)]	Loss: 2.009417
Train Epoch: 10 [32000/35339 (90%)]	Loss: 1.900465
Train Epoch: 10 [32640/35339 (92%)]	Loss: 1.850778
Train Epoch: 10 [33280/35339 (94%)]	Loss: 1.878716
Train Epoch: 10 [33920/35339 (96%)]	Loss: 1.850544
Train Epoch: 10 [34560/35339 (98%)]	Loss: 1.932925
Train Epoch: 10 [35200/35339 (99%)]	Loss: 1.899861

Validation set: Average loss: 3.7247, Accuracy: 705/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 11 [0/35339 (0%)]	Loss: 2.103801
Train Epoch: 11 [640/35339 (2%)]	Loss: 1.788991
Train Epoch: 11 [1280/35339 (4%)]	Loss: 1.693792
Train Epoch: 11 [1920/35339 (5%)]	Loss: 1.831485
Train Epoch: 11 [2560/35339 (7%)]	Loss: 1.993539
Train Epoch: 11 [3200/35339 (9%)]	Loss: 1.776076
Train Epoch: 11 [3840/35339 (11%)]	Loss: 2.019174
Train Epoch: 11 [4480/35339 (13%)]	Loss: 1.760403
Train Epoch: 11 [5120/35339 (14%)]	Loss: 1.722121
Train Epoch: 11 [5760/35339 (16%)]	Loss: 1.661494
Train Epoch: 11 [6400/35339 (18%)]	Loss: 1.785955
Train Epoch: 11 [7040/35339 (20%)]	Loss: 1.734091
Train Epoch: 11 [7680/35339 (22%)]	Loss: 1.884408
Train Epoch: 11 [8320/35339 (24%)]	Loss: 1.840853
Train Epoch: 11 [8960/35339 (25%)]	Loss: 1.855394
Train Epoch: 11 [9600/35339 (27%)]	Loss: 1.839782
Train Epoch: 11 [10240/35339 (29%)]	Loss: 1.854432
Train Epoch: 11 [10880/35339 (31%)]	Loss: 1.883724
Train Epoch: 11 [11520/35339 (33%)]	Loss: 1.928837
Train Epoch: 11 [12160/35339 (34%)]	Loss: 1.666240
Train Epoch: 11 [12800/35339 (36%)]	Loss: 1.872026
Train Epoch: 11 [13440/35339 (38%)]	Loss: 1.790466
Train Epoch: 11 [14080/35339 (40%)]	Loss: 1.829170
Train Epoch: 11 [14720/35339 (42%)]	Loss: 1.647755
Train Epoch: 11 [15360/35339 (43%)]	Loss: 1.944688
Train Epoch: 11 [16000/35339 (45%)]	Loss: 2.017025
Train Epoch: 11 [16640/35339 (47%)]	Loss: 1.954653
Train Epoch: 11 [17280/35339 (49%)]	Loss: 1.848724
Train Epoch: 11 [17920/35339 (51%)]	Loss: 1.729232
Train Epoch: 11 [18560/35339 (52%)]	Loss: 1.775594
Train Epoch: 11 [19200/35339 (54%)]	Loss: 1.761578
Train Epoch: 11 [19840/35339 (56%)]	Loss: 1.873477
Train Epoch: 11 [20480/35339 (58%)]	Loss: 1.743264
Train Epoch: 11 [21120/35339 (60%)]	Loss: 2.124409
Train Epoch: 11 [21760/35339 (61%)]	Loss: 1.885288
Train Epoch: 11 [22400/35339 (63%)]	Loss: 1.987289
Train Epoch: 11 [23040/35339 (65%)]	Loss: 1.730935
Train Epoch: 11 [23680/35339 (67%)]	Loss: 1.662020
Train Epoch: 11 [24320/35339 (69%)]	Loss: 1.722414
Train Epoch: 11 [24960/35339 (71%)]	Loss: 1.716593
Train Epoch: 11 [25600/35339 (72%)]	Loss: 1.825987
Train Epoch: 11 [26240/35339 (74%)]	Loss: 1.993745
Train Epoch: 11 [26880/35339 (76%)]	Loss: 1.749322
Train Epoch: 11 [27520/35339 (78%)]	Loss: 1.831186
Train Epoch: 11 [28160/35339 (80%)]	Loss: 2.041404
Train Epoch: 11 [28800/35339 (81%)]	Loss: 1.705790
Train Epoch: 11 [29440/35339 (83%)]	Loss: 1.777496
Train Epoch: 11 [30080/35339 (85%)]	Loss: 1.762989
Train Epoch: 11 [30720/35339 (87%)]	Loss: 1.873869
Train Epoch: 11 [31360/35339 (89%)]	Loss: 1.852943
Train Epoch: 11 [32000/35339 (90%)]	Loss: 1.901396
Train Epoch: 11 [32640/35339 (92%)]	Loss: 1.791929
Train Epoch: 11 [33280/35339 (94%)]	Loss: 1.845301
Train Epoch: 11 [33920/35339 (96%)]	Loss: 1.733878
Train Epoch: 11 [34560/35339 (98%)]	Loss: 1.847576
Train Epoch: 11 [35200/35339 (99%)]	Loss: 2.026580

Validation set: Average loss: 3.7179, Accuracy: 717/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 12 [0/35339 (0%)]	Loss: 1.748303
Train Epoch: 12 [640/35339 (2%)]	Loss: 1.943444
Train Epoch: 12 [1280/35339 (4%)]	Loss: 1.718621
Train Epoch: 12 [1920/35339 (5%)]	Loss: 1.769450
Train Epoch: 12 [2560/35339 (7%)]	Loss: 1.909468
Train Epoch: 12 [3200/35339 (9%)]	Loss: 1.817487
Train Epoch: 12 [3840/35339 (11%)]	Loss: 1.667663
Train Epoch: 12 [4480/35339 (13%)]	Loss: 1.742708
Train Epoch: 12 [5120/35339 (14%)]	Loss: 1.878714
Train Epoch: 12 [5760/35339 (16%)]	Loss: 1.811465
Train Epoch: 12 [6400/35339 (18%)]	Loss: 1.732510
Train Epoch: 12 [7040/35339 (20%)]	Loss: 1.787138
Train Epoch: 12 [7680/35339 (22%)]	Loss: 1.812005
Train Epoch: 12 [8320/35339 (24%)]	Loss: 1.653812
Train Epoch: 12 [8960/35339 (25%)]	Loss: 1.873513
Train Epoch: 12 [9600/35339 (27%)]	Loss: 1.800207
Train Epoch: 12 [10240/35339 (29%)]	Loss: 1.754928
Train Epoch: 12 [10880/35339 (31%)]	Loss: 1.761795
Train Epoch: 12 [11520/35339 (33%)]	Loss: 1.748470
Train Epoch: 12 [12160/35339 (34%)]	Loss: 1.740702
Train Epoch: 12 [12800/35339 (36%)]	Loss: 1.777322
Train Epoch: 12 [13440/35339 (38%)]	Loss: 1.800460
Train Epoch: 12 [14080/35339 (40%)]	Loss: 1.604077
Train Epoch: 12 [14720/35339 (42%)]	Loss: 1.721212
Train Epoch: 12 [15360/35339 (43%)]	Loss: 1.728369
Train Epoch: 12 [16000/35339 (45%)]	Loss: 1.724161
Train Epoch: 12 [16640/35339 (47%)]	Loss: 1.710071
Train Epoch: 12 [17280/35339 (49%)]	Loss: 1.792056
Train Epoch: 12 [17920/35339 (51%)]	Loss: 1.804404
Train Epoch: 12 [18560/35339 (52%)]	Loss: 1.650988
Train Epoch: 12 [19200/35339 (54%)]	Loss: 1.861236
Train Epoch: 12 [19840/35339 (56%)]	Loss: 1.695624
Train Epoch: 12 [20480/35339 (58%)]	Loss: 1.775121
Train Epoch: 12 [21120/35339 (60%)]	Loss: 1.729857
Train Epoch: 12 [21760/35339 (61%)]	Loss: 1.680944
Train Epoch: 12 [22400/35339 (63%)]	Loss: 1.594679
Train Epoch: 12 [23040/35339 (65%)]	Loss: 1.856129
Train Epoch: 12 [23680/35339 (67%)]	Loss: 1.661957
Train Epoch: 12 [24320/35339 (69%)]	Loss: 1.846291
Train Epoch: 12 [24960/35339 (71%)]	Loss: 1.875550
Train Epoch: 12 [25600/35339 (72%)]	Loss: 1.769634
Train Epoch: 12 [26240/35339 (74%)]	Loss: 1.768608
Train Epoch: 12 [26880/35339 (76%)]	Loss: 1.680774
Train Epoch: 12 [27520/35339 (78%)]	Loss: 1.754377
Train Epoch: 12 [28160/35339 (80%)]	Loss: 1.701439
Train Epoch: 12 [28800/35339 (81%)]	Loss: 1.782071
Train Epoch: 12 [29440/35339 (83%)]	Loss: 1.668470
Train Epoch: 12 [30080/35339 (85%)]	Loss: 1.630568
Train Epoch: 12 [30720/35339 (87%)]	Loss: 1.732866
Train Epoch: 12 [31360/35339 (89%)]	Loss: 1.829340
Train Epoch: 12 [32000/35339 (90%)]	Loss: 1.594166
Train Epoch: 12 [32640/35339 (92%)]	Loss: 1.685907
Train Epoch: 12 [33280/35339 (94%)]	Loss: 1.777128
Train Epoch: 12 [33920/35339 (96%)]	Loss: 1.617900
Train Epoch: 12 [34560/35339 (98%)]	Loss: 1.600396
Train Epoch: 12 [35200/35339 (99%)]	Loss: 1.638894

Validation set: Average loss: 3.7180, Accuracy: 735/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 13 [0/35339 (0%)]	Loss: 1.797903
Train Epoch: 13 [640/35339 (2%)]	Loss: 1.611126
Train Epoch: 13 [1280/35339 (4%)]	Loss: 1.696762
Train Epoch: 13 [1920/35339 (5%)]	Loss: 1.753299
Train Epoch: 13 [2560/35339 (7%)]	Loss: 1.725390
Train Epoch: 13 [3200/35339 (9%)]	Loss: 1.708498
Train Epoch: 13 [3840/35339 (11%)]	Loss: 1.829848
Train Epoch: 13 [4480/35339 (13%)]	Loss: 1.721022
Train Epoch: 13 [5120/35339 (14%)]	Loss: 1.748163
Train Epoch: 13 [5760/35339 (16%)]	Loss: 1.860406
Train Epoch: 13 [6400/35339 (18%)]	Loss: 1.753083
Train Epoch: 13 [7040/35339 (20%)]	Loss: 1.775816
Train Epoch: 13 [7680/35339 (22%)]	Loss: 1.854501
Train Epoch: 13 [8320/35339 (24%)]	Loss: 1.760102
Train Epoch: 13 [8960/35339 (25%)]	Loss: 1.771399
Train Epoch: 13 [9600/35339 (27%)]	Loss: 1.552710
Train Epoch: 13 [10240/35339 (29%)]	Loss: 1.718358
Train Epoch: 13 [10880/35339 (31%)]	Loss: 1.676964
Train Epoch: 13 [11520/35339 (33%)]	Loss: 1.674361
Train Epoch: 13 [12160/35339 (34%)]	Loss: 1.645258
Train Epoch: 13 [12800/35339 (36%)]	Loss: 1.791089
Train Epoch: 13 [13440/35339 (38%)]	Loss: 1.705050
Train Epoch: 13 [14080/35339 (40%)]	Loss: 1.694605
Train Epoch: 13 [14720/35339 (42%)]	Loss: 1.633504
Train Epoch: 13 [15360/35339 (43%)]	Loss: 1.618507
Train Epoch: 13 [16000/35339 (45%)]	Loss: 1.771902
Train Epoch: 13 [16640/35339 (47%)]	Loss: 1.794800
Train Epoch: 13 [17280/35339 (49%)]	Loss: 1.627216
Train Epoch: 13 [17920/35339 (51%)]	Loss: 1.516255
Train Epoch: 13 [18560/35339 (52%)]	Loss: 1.900836
Train Epoch: 13 [19200/35339 (54%)]	Loss: 1.626229
Train Epoch: 13 [19840/35339 (56%)]	Loss: 1.627518
Train Epoch: 13 [20480/35339 (58%)]	Loss: 1.690144
Train Epoch: 13 [21120/35339 (60%)]	Loss: 1.615399
Train Epoch: 13 [21760/35339 (61%)]	Loss: 1.644475
Train Epoch: 13 [22400/35339 (63%)]	Loss: 1.810727
Train Epoch: 13 [23040/35339 (65%)]	Loss: 1.681270
Train Epoch: 13 [23680/35339 (67%)]	Loss: 1.606508
Train Epoch: 13 [24320/35339 (69%)]	Loss: 1.725912
Train Epoch: 13 [24960/35339 (71%)]	Loss: 1.556778
Train Epoch: 13 [25600/35339 (72%)]	Loss: 1.744697
Train Epoch: 13 [26240/35339 (74%)]	Loss: 1.745640
Train Epoch: 13 [26880/35339 (76%)]	Loss: 1.792754
Train Epoch: 13 [27520/35339 (78%)]	Loss: 1.625764
Train Epoch: 13 [28160/35339 (80%)]	Loss: 1.894867
Train Epoch: 13 [28800/35339 (81%)]	Loss: 1.658522
Train Epoch: 13 [29440/35339 (83%)]	Loss: 1.619075
Train Epoch: 13 [30080/35339 (85%)]	Loss: 1.605686
Train Epoch: 13 [30720/35339 (87%)]	Loss: 1.687280
Train Epoch: 13 [31360/35339 (89%)]	Loss: 1.892039
Train Epoch: 13 [32000/35339 (90%)]	Loss: 1.577471
Train Epoch: 13 [32640/35339 (92%)]	Loss: 1.671130
Train Epoch: 13 [33280/35339 (94%)]	Loss: 1.491412
Train Epoch: 13 [33920/35339 (96%)]	Loss: 1.622194
Train Epoch: 13 [34560/35339 (98%)]	Loss: 1.664348
Train Epoch: 13 [35200/35339 (99%)]	Loss: 1.517177

Validation set: Average loss: 3.7265, Accuracy: 752/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 14 [0/35339 (0%)]	Loss: 1.668526
Train Epoch: 14 [640/35339 (2%)]	Loss: 1.716294
Train Epoch: 14 [1280/35339 (4%)]	Loss: 1.721249
Train Epoch: 14 [1920/35339 (5%)]	Loss: 1.734499
Train Epoch: 14 [2560/35339 (7%)]	Loss: 1.643088
Train Epoch: 14 [3200/35339 (9%)]	Loss: 1.725750
Train Epoch: 14 [3840/35339 (11%)]	Loss: 1.785273
Train Epoch: 14 [4480/35339 (13%)]	Loss: 1.597929
Train Epoch: 14 [5120/35339 (14%)]	Loss: 1.710967
Train Epoch: 14 [5760/35339 (16%)]	Loss: 1.556386
Train Epoch: 14 [6400/35339 (18%)]	Loss: 1.482721
Train Epoch: 14 [7040/35339 (20%)]	Loss: 1.651149
Train Epoch: 14 [7680/35339 (22%)]	Loss: 1.770025
Train Epoch: 14 [8320/35339 (24%)]	Loss: 1.486930
Train Epoch: 14 [8960/35339 (25%)]	Loss: 1.657217
Train Epoch: 14 [9600/35339 (27%)]	Loss: 1.763698
Train Epoch: 14 [10240/35339 (29%)]	Loss: 1.502309
Train Epoch: 14 [10880/35339 (31%)]	Loss: 1.535167
Train Epoch: 14 [11520/35339 (33%)]	Loss: 1.648668
Train Epoch: 14 [12160/35339 (34%)]	Loss: 1.591618
Train Epoch: 14 [12800/35339 (36%)]	Loss: 1.818932
Train Epoch: 14 [13440/35339 (38%)]	Loss: 1.625779
Train Epoch: 14 [14080/35339 (40%)]	Loss: 1.452180
Train Epoch: 14 [14720/35339 (42%)]	Loss: 1.486228
Train Epoch: 14 [15360/35339 (43%)]	Loss: 1.596517
Train Epoch: 14 [16000/35339 (45%)]	Loss: 1.553955
Train Epoch: 14 [16640/35339 (47%)]	Loss: 1.714734
Train Epoch: 14 [17280/35339 (49%)]	Loss: 1.790407
Train Epoch: 14 [17920/35339 (51%)]	Loss: 1.551961
Train Epoch: 14 [18560/35339 (52%)]	Loss: 1.620728
Train Epoch: 14 [19200/35339 (54%)]	Loss: 1.707820
Train Epoch: 14 [19840/35339 (56%)]	Loss: 1.692683
Train Epoch: 14 [20480/35339 (58%)]	Loss: 1.645154
Train Epoch: 14 [21120/35339 (60%)]	Loss: 1.609224
Train Epoch: 14 [21760/35339 (61%)]	Loss: 1.510377
Train Epoch: 14 [22400/35339 (63%)]	Loss: 1.674704
Train Epoch: 14 [23040/35339 (65%)]	Loss: 1.620522
Train Epoch: 14 [23680/35339 (67%)]	Loss: 1.450147
Train Epoch: 14 [24320/35339 (69%)]	Loss: 1.471881
Train Epoch: 14 [24960/35339 (71%)]	Loss: 1.440904
Train Epoch: 14 [25600/35339 (72%)]	Loss: 1.661216
Train Epoch: 14 [26240/35339 (74%)]	Loss: 1.756448
Train Epoch: 14 [26880/35339 (76%)]	Loss: 1.524120
Train Epoch: 14 [27520/35339 (78%)]	Loss: 1.502902
Train Epoch: 14 [28160/35339 (80%)]	Loss: 1.608915
Train Epoch: 14 [28800/35339 (81%)]	Loss: 1.773724
Train Epoch: 14 [29440/35339 (83%)]	Loss: 1.654193
Train Epoch: 14 [30080/35339 (85%)]	Loss: 1.617568
Train Epoch: 14 [30720/35339 (87%)]	Loss: 1.664942
Train Epoch: 14 [31360/35339 (89%)]	Loss: 1.496452
Train Epoch: 14 [32000/35339 (90%)]	Loss: 1.496998
Train Epoch: 14 [32640/35339 (92%)]	Loss: 1.680377
Train Epoch: 14 [33280/35339 (94%)]	Loss: 1.536314
Train Epoch: 14 [33920/35339 (96%)]	Loss: 1.455185
Train Epoch: 14 [34560/35339 (98%)]	Loss: 1.523685
Train Epoch: 14 [35200/35339 (99%)]	Loss: 1.626265

Validation set: Average loss: 3.7219, Accuracy: 760/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 15 [0/35339 (0%)]	Loss: 1.485978
Train Epoch: 15 [640/35339 (2%)]	Loss: 1.445213
Train Epoch: 15 [1280/35339 (4%)]	Loss: 1.610689
Train Epoch: 15 [1920/35339 (5%)]	Loss: 1.612555
Train Epoch: 15 [2560/35339 (7%)]	Loss: 1.663442
Train Epoch: 15 [3200/35339 (9%)]	Loss: 1.619761
Train Epoch: 15 [3840/35339 (11%)]	Loss: 1.619060
Train Epoch: 15 [4480/35339 (13%)]	Loss: 1.568428
Train Epoch: 15 [5120/35339 (14%)]	Loss: 1.522351
Train Epoch: 15 [5760/35339 (16%)]	Loss: 1.550640
Train Epoch: 15 [6400/35339 (18%)]	Loss: 1.608113
Train Epoch: 15 [7040/35339 (20%)]	Loss: 1.529661
Train Epoch: 15 [7680/35339 (22%)]	Loss: 1.674557
Train Epoch: 15 [8320/35339 (24%)]	Loss: 1.426929
Train Epoch: 15 [8960/35339 (25%)]	Loss: 1.546322
Train Epoch: 15 [9600/35339 (27%)]	Loss: 1.563980
Train Epoch: 15 [10240/35339 (29%)]	Loss: 1.663656
Train Epoch: 15 [10880/35339 (31%)]	Loss: 1.607727
Train Epoch: 15 [11520/35339 (33%)]	Loss: 1.556992
Train Epoch: 15 [12160/35339 (34%)]	Loss: 1.494497
Train Epoch: 15 [12800/35339 (36%)]	Loss: 1.477179
Train Epoch: 15 [13440/35339 (38%)]	Loss: 1.490452
Train Epoch: 15 [14080/35339 (40%)]	Loss: 1.478569
Train Epoch: 15 [14720/35339 (42%)]	Loss: 1.650684
Train Epoch: 15 [15360/35339 (43%)]	Loss: 1.513007
Train Epoch: 15 [16000/35339 (45%)]	Loss: 1.496217
Train Epoch: 15 [16640/35339 (47%)]	Loss: 1.452024
Train Epoch: 15 [17280/35339 (49%)]	Loss: 1.538893
Train Epoch: 15 [17920/35339 (51%)]	Loss: 1.251652
Train Epoch: 15 [18560/35339 (52%)]	Loss: 1.443166
Train Epoch: 15 [19200/35339 (54%)]	Loss: 1.581384
Train Epoch: 15 [19840/35339 (56%)]	Loss: 1.394712
Train Epoch: 15 [20480/35339 (58%)]	Loss: 1.494073
Train Epoch: 15 [21120/35339 (60%)]	Loss: 1.508022
Train Epoch: 15 [21760/35339 (61%)]	Loss: 1.585740
Train Epoch: 15 [22400/35339 (63%)]	Loss: 1.561263
Train Epoch: 15 [23040/35339 (65%)]	Loss: 1.496192
Train Epoch: 15 [23680/35339 (67%)]	Loss: 1.583446
Train Epoch: 15 [24320/35339 (69%)]	Loss: 1.855940
Train Epoch: 15 [24960/35339 (71%)]	Loss: 1.506240
Train Epoch: 15 [25600/35339 (72%)]	Loss: 1.507278
Train Epoch: 15 [26240/35339 (74%)]	Loss: 1.590566
Train Epoch: 15 [26880/35339 (76%)]	Loss: 1.516720
Train Epoch: 15 [27520/35339 (78%)]	Loss: 1.546736
Train Epoch: 15 [28160/35339 (80%)]	Loss: 1.510140
Train Epoch: 15 [28800/35339 (81%)]	Loss: 1.478934
Train Epoch: 15 [29440/35339 (83%)]	Loss: 1.431114
Train Epoch: 15 [30080/35339 (85%)]	Loss: 1.505646
Train Epoch: 15 [30720/35339 (87%)]	Loss: 1.333638
Train Epoch: 15 [31360/35339 (89%)]	Loss: 1.344847
Train Epoch: 15 [32000/35339 (90%)]	Loss: 1.464832
Train Epoch: 15 [32640/35339 (92%)]	Loss: 1.352600
Train Epoch: 15 [33280/35339 (94%)]	Loss: 1.556881
Train Epoch: 15 [33920/35339 (96%)]	Loss: 1.488911
Train Epoch: 15 [34560/35339 (98%)]	Loss: 1.484683
Train Epoch: 15 [35200/35339 (99%)]	Loss: 1.561382

Validation set: Average loss: 3.7249, Accuracy: 768/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 16 [0/35339 (0%)]	Loss: 1.592536
Train Epoch: 16 [640/35339 (2%)]	Loss: 1.461885
Train Epoch: 16 [1280/35339 (4%)]	Loss: 1.560196
Train Epoch: 16 [1920/35339 (5%)]	Loss: 1.369923
Train Epoch: 16 [2560/35339 (7%)]	Loss: 1.652867
Train Epoch: 16 [3200/35339 (9%)]	Loss: 1.596069
Train Epoch: 16 [3840/35339 (11%)]	Loss: 1.566823
Train Epoch: 16 [4480/35339 (13%)]	Loss: 1.614139
Train Epoch: 16 [5120/35339 (14%)]	Loss: 1.317885
Train Epoch: 16 [5760/35339 (16%)]	Loss: 1.489979
Train Epoch: 16 [6400/35339 (18%)]	Loss: 1.536933
Train Epoch: 16 [7040/35339 (20%)]	Loss: 1.538371
Train Epoch: 16 [7680/35339 (22%)]	Loss: 1.499233
Train Epoch: 16 [8320/35339 (24%)]	Loss: 1.497370
Train Epoch: 16 [8960/35339 (25%)]	Loss: 1.512162
Train Epoch: 16 [9600/35339 (27%)]	Loss: 1.519771
Train Epoch: 16 [10240/35339 (29%)]	Loss: 1.480061
Train Epoch: 16 [10880/35339 (31%)]	Loss: 1.511388
Train Epoch: 16 [11520/35339 (33%)]	Loss: 1.328007
Train Epoch: 16 [12160/35339 (34%)]	Loss: 1.522692
Train Epoch: 16 [12800/35339 (36%)]	Loss: 1.500671
Train Epoch: 16 [13440/35339 (38%)]	Loss: 1.462955
Train Epoch: 16 [14080/35339 (40%)]	Loss: 1.443008
Train Epoch: 16 [14720/35339 (42%)]	Loss: 1.627251
Train Epoch: 16 [15360/35339 (43%)]	Loss: 1.434738
Train Epoch: 16 [16000/35339 (45%)]	Loss: 1.576984
Train Epoch: 16 [16640/35339 (47%)]	Loss: 1.468914
Train Epoch: 16 [17280/35339 (49%)]	Loss: 1.537269
Train Epoch: 16 [17920/35339 (51%)]	Loss: 1.311847
Train Epoch: 16 [18560/35339 (52%)]	Loss: 1.467506
Train Epoch: 16 [19200/35339 (54%)]	Loss: 1.537889
Train Epoch: 16 [19840/35339 (56%)]	Loss: 1.403544
Train Epoch: 16 [20480/35339 (58%)]	Loss: 1.412115
Train Epoch: 16 [21120/35339 (60%)]	Loss: 1.454934
Train Epoch: 16 [21760/35339 (61%)]	Loss: 1.475422
Train Epoch: 16 [22400/35339 (63%)]	Loss: 1.581960
Train Epoch: 16 [23040/35339 (65%)]	Loss: 1.496488
Train Epoch: 16 [23680/35339 (67%)]	Loss: 1.400021
Train Epoch: 16 [24320/35339 (69%)]	Loss: 1.501571
Train Epoch: 16 [24960/35339 (71%)]	Loss: 1.507850
Train Epoch: 16 [25600/35339 (72%)]	Loss: 1.563063
Train Epoch: 16 [26240/35339 (74%)]	Loss: 1.482759
Train Epoch: 16 [26880/35339 (76%)]	Loss: 1.539706
Train Epoch: 16 [27520/35339 (78%)]	Loss: 1.723931
Train Epoch: 16 [28160/35339 (80%)]	Loss: 1.454416
Train Epoch: 16 [28800/35339 (81%)]	Loss: 1.497711
Train Epoch: 16 [29440/35339 (83%)]	Loss: 1.610088
Train Epoch: 16 [30080/35339 (85%)]	Loss: 1.658635
Train Epoch: 16 [30720/35339 (87%)]	Loss: 1.568551
Train Epoch: 16 [31360/35339 (89%)]	Loss: 1.453299
Train Epoch: 16 [32000/35339 (90%)]	Loss: 1.512189
Train Epoch: 16 [32640/35339 (92%)]	Loss: 1.488809
Train Epoch: 16 [33280/35339 (94%)]	Loss: 1.501343
Train Epoch: 16 [33920/35339 (96%)]	Loss: 1.492483
Train Epoch: 16 [34560/35339 (98%)]	Loss: 1.509177
Train Epoch: 16 [35200/35339 (99%)]	Loss: 1.446655

Validation set: Average loss: 3.7307, Accuracy: 783/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 17 [0/35339 (0%)]	Loss: 1.408178
Train Epoch: 17 [640/35339 (2%)]	Loss: 1.456515
Train Epoch: 17 [1280/35339 (4%)]	Loss: 1.482448
Train Epoch: 17 [1920/35339 (5%)]	Loss: 1.462519
Train Epoch: 17 [2560/35339 (7%)]	Loss: 1.686594
Train Epoch: 17 [3200/35339 (9%)]	Loss: 1.589432
Train Epoch: 17 [3840/35339 (11%)]	Loss: 1.408260
Train Epoch: 17 [4480/35339 (13%)]	Loss: 1.436038
Train Epoch: 17 [5120/35339 (14%)]	Loss: 1.299563
Train Epoch: 17 [5760/35339 (16%)]	Loss: 1.634723
Train Epoch: 17 [6400/35339 (18%)]	Loss: 1.422075
Train Epoch: 17 [7040/35339 (20%)]	Loss: 1.397627
Train Epoch: 17 [7680/35339 (22%)]	Loss: 1.493906
Train Epoch: 17 [8320/35339 (24%)]	Loss: 1.411776
Train Epoch: 17 [8960/35339 (25%)]	Loss: 1.358347
Train Epoch: 17 [9600/35339 (27%)]	Loss: 1.485363
Train Epoch: 17 [10240/35339 (29%)]	Loss: 1.479357
Train Epoch: 17 [10880/35339 (31%)]	Loss: 1.482119
Train Epoch: 17 [11520/35339 (33%)]	Loss: 1.356844
Train Epoch: 17 [12160/35339 (34%)]	Loss: 1.453957
Train Epoch: 17 [12800/35339 (36%)]	Loss: 1.366506
Train Epoch: 17 [13440/35339 (38%)]	Loss: 1.541029
Train Epoch: 17 [14080/35339 (40%)]	Loss: 1.432892
Train Epoch: 17 [14720/35339 (42%)]	Loss: 1.529130
Train Epoch: 17 [15360/35339 (43%)]	Loss: 1.527087
Train Epoch: 17 [16000/35339 (45%)]	Loss: 1.475829
Train Epoch: 17 [16640/35339 (47%)]	Loss: 1.517405
Train Epoch: 17 [17280/35339 (49%)]	Loss: 1.266803
Train Epoch: 17 [17920/35339 (51%)]	Loss: 1.462882
Train Epoch: 17 [18560/35339 (52%)]	Loss: 1.489860
Train Epoch: 17 [19200/35339 (54%)]	Loss: 1.514409
Train Epoch: 17 [19840/35339 (56%)]	Loss: 1.387642
Train Epoch: 17 [20480/35339 (58%)]	Loss: 1.344947
Train Epoch: 17 [21120/35339 (60%)]	Loss: 1.345409
Train Epoch: 17 [21760/35339 (61%)]	Loss: 1.460013
Train Epoch: 17 [22400/35339 (63%)]	Loss: 1.619288
Train Epoch: 17 [23040/35339 (65%)]	Loss: 1.465542
Train Epoch: 17 [23680/35339 (67%)]	Loss: 1.522132
Train Epoch: 17 [24320/35339 (69%)]	Loss: 1.472440
Train Epoch: 17 [24960/35339 (71%)]	Loss: 1.402545
Train Epoch: 17 [25600/35339 (72%)]	Loss: 1.355273
Train Epoch: 17 [26240/35339 (74%)]	Loss: 1.358431
Train Epoch: 17 [26880/35339 (76%)]	Loss: 1.409904
Train Epoch: 17 [27520/35339 (78%)]	Loss: 1.423603
Train Epoch: 17 [28160/35339 (80%)]	Loss: 1.557069
Train Epoch: 17 [28800/35339 (81%)]	Loss: 1.315726
Train Epoch: 17 [29440/35339 (83%)]	Loss: 1.335209
Train Epoch: 17 [30080/35339 (85%)]	Loss: 1.478870
Train Epoch: 17 [30720/35339 (87%)]	Loss: 1.482426
Train Epoch: 17 [31360/35339 (89%)]	Loss: 1.277192
Train Epoch: 17 [32000/35339 (90%)]	Loss: 1.329674
Train Epoch: 17 [32640/35339 (92%)]	Loss: 1.485086
Train Epoch: 17 [33280/35339 (94%)]	Loss: 1.411172
Train Epoch: 17 [33920/35339 (96%)]	Loss: 1.453717
Train Epoch: 17 [34560/35339 (98%)]	Loss: 1.539966
Train Epoch: 17 [35200/35339 (99%)]	Loss: 1.351776

Validation set: Average loss: 3.7307, Accuracy: 790/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 18 [0/35339 (0%)]	Loss: 1.353678
Train Epoch: 18 [640/35339 (2%)]	Loss: 1.601426
Train Epoch: 18 [1280/35339 (4%)]	Loss: 1.253392
Train Epoch: 18 [1920/35339 (5%)]	Loss: 1.565722
Train Epoch: 18 [2560/35339 (7%)]	Loss: 1.440843
Train Epoch: 18 [3200/35339 (9%)]	Loss: 1.480168
Train Epoch: 18 [3840/35339 (11%)]	Loss: 1.322338
Train Epoch: 18 [4480/35339 (13%)]	Loss: 1.459266
Train Epoch: 18 [5120/35339 (14%)]	Loss: 1.497002
Train Epoch: 18 [5760/35339 (16%)]	Loss: 1.276273
Train Epoch: 18 [6400/35339 (18%)]	Loss: 1.472120
Train Epoch: 18 [7040/35339 (20%)]	Loss: 1.349353
Train Epoch: 18 [7680/35339 (22%)]	Loss: 1.249603
Train Epoch: 18 [8320/35339 (24%)]	Loss: 1.427709
Train Epoch: 18 [8960/35339 (25%)]	Loss: 1.256877
Train Epoch: 18 [9600/35339 (27%)]	Loss: 1.552266
Train Epoch: 18 [10240/35339 (29%)]	Loss: 1.667357
Train Epoch: 18 [10880/35339 (31%)]	Loss: 1.516461
Train Epoch: 18 [11520/35339 (33%)]	Loss: 1.256205
Train Epoch: 18 [12160/35339 (34%)]	Loss: 1.482926
Train Epoch: 18 [12800/35339 (36%)]	Loss: 1.269874
Train Epoch: 18 [13440/35339 (38%)]	Loss: 1.341768
Train Epoch: 18 [14080/35339 (40%)]	Loss: 1.332489
Train Epoch: 18 [14720/35339 (42%)]	Loss: 1.493426
Train Epoch: 18 [15360/35339 (43%)]	Loss: 1.244758
Train Epoch: 18 [16000/35339 (45%)]	Loss: 1.451928
Train Epoch: 18 [16640/35339 (47%)]	Loss: 1.482307
Train Epoch: 18 [17280/35339 (49%)]	Loss: 1.278734
Train Epoch: 18 [17920/35339 (51%)]	Loss: 1.295112
Train Epoch: 18 [18560/35339 (52%)]	Loss: 1.442944
Train Epoch: 18 [19200/35339 (54%)]	Loss: 1.414947
Train Epoch: 18 [19840/35339 (56%)]	Loss: 1.289100
Train Epoch: 18 [20480/35339 (58%)]	Loss: 1.643436
Train Epoch: 18 [21120/35339 (60%)]	Loss: 1.416290
Train Epoch: 18 [21760/35339 (61%)]	Loss: 1.471952
Train Epoch: 18 [22400/35339 (63%)]	Loss: 1.364941
Train Epoch: 18 [23040/35339 (65%)]	Loss: 1.562694
Train Epoch: 18 [23680/35339 (67%)]	Loss: 1.444535
Train Epoch: 18 [24320/35339 (69%)]	Loss: 1.268709
Train Epoch: 18 [24960/35339 (71%)]	Loss: 1.413201
Train Epoch: 18 [25600/35339 (72%)]	Loss: 1.352223
Train Epoch: 18 [26240/35339 (74%)]	Loss: 1.653209
Train Epoch: 18 [26880/35339 (76%)]	Loss: 1.356942
Train Epoch: 18 [27520/35339 (78%)]	Loss: 1.235095
Train Epoch: 18 [28160/35339 (80%)]	Loss: 1.251729
Train Epoch: 18 [28800/35339 (81%)]	Loss: 1.384426
Train Epoch: 18 [29440/35339 (83%)]	Loss: 1.361520
Train Epoch: 18 [30080/35339 (85%)]	Loss: 1.326562
Train Epoch: 18 [30720/35339 (87%)]	Loss: 1.417915
Train Epoch: 18 [31360/35339 (89%)]	Loss: 1.411961
Train Epoch: 18 [32000/35339 (90%)]	Loss: 1.331735
Train Epoch: 18 [32640/35339 (92%)]	Loss: 1.357123
Train Epoch: 18 [33280/35339 (94%)]	Loss: 1.338877
Train Epoch: 18 [33920/35339 (96%)]	Loss: 1.360151
Train Epoch: 18 [34560/35339 (98%)]	Loss: 1.373631
Train Epoch: 18 [35200/35339 (99%)]	Loss: 1.327380

Validation set: Average loss: 3.7417, Accuracy: 797/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 19 [0/35339 (0%)]	Loss: 1.589021
Train Epoch: 19 [640/35339 (2%)]	Loss: 1.643225
Train Epoch: 19 [1280/35339 (4%)]	Loss: 1.428518
Train Epoch: 19 [1920/35339 (5%)]	Loss: 1.381831
Train Epoch: 19 [2560/35339 (7%)]	Loss: 1.512038
Train Epoch: 19 [3200/35339 (9%)]	Loss: 1.273085
Train Epoch: 19 [3840/35339 (11%)]	Loss: 1.292135
Train Epoch: 19 [4480/35339 (13%)]	Loss: 1.344709
Train Epoch: 19 [5120/35339 (14%)]	Loss: 1.368358
Train Epoch: 19 [5760/35339 (16%)]	Loss: 1.465293
Train Epoch: 19 [6400/35339 (18%)]	Loss: 1.208405
Train Epoch: 19 [7040/35339 (20%)]	Loss: 1.246151
Train Epoch: 19 [7680/35339 (22%)]	Loss: 1.225880
Train Epoch: 19 [8320/35339 (24%)]	Loss: 1.227611
Train Epoch: 19 [8960/35339 (25%)]	Loss: 1.348579
Train Epoch: 19 [9600/35339 (27%)]	Loss: 1.202192
Train Epoch: 19 [10240/35339 (29%)]	Loss: 1.328074
Train Epoch: 19 [10880/35339 (31%)]	Loss: 1.433874
Train Epoch: 19 [11520/35339 (33%)]	Loss: 1.177059
Train Epoch: 19 [12160/35339 (34%)]	Loss: 1.344826
Train Epoch: 19 [12800/35339 (36%)]	Loss: 1.261814
Train Epoch: 19 [13440/35339 (38%)]	Loss: 1.427655
Train Epoch: 19 [14080/35339 (40%)]	Loss: 1.305050
Train Epoch: 19 [14720/35339 (42%)]	Loss: 1.261497
Train Epoch: 19 [15360/35339 (43%)]	Loss: 1.413496
Train Epoch: 19 [16000/35339 (45%)]	Loss: 1.299540
Train Epoch: 19 [16640/35339 (47%)]	Loss: 1.266361
Train Epoch: 19 [17280/35339 (49%)]	Loss: 1.348841
Train Epoch: 19 [17920/35339 (51%)]	Loss: 1.329453
Train Epoch: 19 [18560/35339 (52%)]	Loss: 1.344134
Train Epoch: 19 [19200/35339 (54%)]	Loss: 1.412372
Train Epoch: 19 [19840/35339 (56%)]	Loss: 1.600051
Train Epoch: 19 [20480/35339 (58%)]	Loss: 1.349663
Train Epoch: 19 [21120/35339 (60%)]	Loss: 1.439299
Train Epoch: 19 [21760/35339 (61%)]	Loss: 1.449082
Train Epoch: 19 [22400/35339 (63%)]	Loss: 1.322227
Train Epoch: 19 [23040/35339 (65%)]	Loss: 1.196353
Train Epoch: 19 [23680/35339 (67%)]	Loss: 1.253686
Train Epoch: 19 [24320/35339 (69%)]	Loss: 1.255646
Train Epoch: 19 [24960/35339 (71%)]	Loss: 1.260436
Train Epoch: 19 [25600/35339 (72%)]	Loss: 1.410540
Train Epoch: 19 [26240/35339 (74%)]	Loss: 1.268532
Train Epoch: 19 [26880/35339 (76%)]	Loss: 1.135209
Train Epoch: 19 [27520/35339 (78%)]	Loss: 1.379037
Train Epoch: 19 [28160/35339 (80%)]	Loss: 1.478589
Train Epoch: 19 [28800/35339 (81%)]	Loss: 1.369364
Train Epoch: 19 [29440/35339 (83%)]	Loss: 1.421407
Train Epoch: 19 [30080/35339 (85%)]	Loss: 1.244963
Train Epoch: 19 [30720/35339 (87%)]	Loss: 1.322734
Train Epoch: 19 [31360/35339 (89%)]	Loss: 1.297281
Train Epoch: 19 [32000/35339 (90%)]	Loss: 1.334059
Train Epoch: 19 [32640/35339 (92%)]	Loss: 1.170030
Train Epoch: 19 [33280/35339 (94%)]	Loss: 1.301738
Train Epoch: 19 [33920/35339 (96%)]	Loss: 1.183715
Train Epoch: 19 [34560/35339 (98%)]	Loss: 1.311815
Train Epoch: 19 [35200/35339 (99%)]	Loss: 1.139362

Validation set: Average loss: 3.7378, Accuracy: 796/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 20 [0/35339 (0%)]	Loss: 1.200907
Train Epoch: 20 [640/35339 (2%)]	Loss: 1.285156
Train Epoch: 20 [1280/35339 (4%)]	Loss: 1.432441
Train Epoch: 20 [1920/35339 (5%)]	Loss: 1.435895
Train Epoch: 20 [2560/35339 (7%)]	Loss: 1.385453
Train Epoch: 20 [3200/35339 (9%)]	Loss: 1.348299
Train Epoch: 20 [3840/35339 (11%)]	Loss: 1.437523
Train Epoch: 20 [4480/35339 (13%)]	Loss: 1.363979
Train Epoch: 20 [5120/35339 (14%)]	Loss: 1.287517
Train Epoch: 20 [5760/35339 (16%)]	Loss: 1.279134
Train Epoch: 20 [6400/35339 (18%)]	Loss: 1.211980
Train Epoch: 20 [7040/35339 (20%)]	Loss: 1.524783
Train Epoch: 20 [7680/35339 (22%)]	Loss: 1.463387
Train Epoch: 20 [8320/35339 (24%)]	Loss: 1.443797
Train Epoch: 20 [8960/35339 (25%)]	Loss: 1.271576
Train Epoch: 20 [9600/35339 (27%)]	Loss: 1.142549
Train Epoch: 20 [10240/35339 (29%)]	Loss: 1.390924
Train Epoch: 20 [10880/35339 (31%)]	Loss: 1.322077
Train Epoch: 20 [11520/35339 (33%)]	Loss: 1.232473
Train Epoch: 20 [12160/35339 (34%)]	Loss: 1.351608
Train Epoch: 20 [12800/35339 (36%)]	Loss: 1.271430
Train Epoch: 20 [13440/35339 (38%)]	Loss: 1.314335
Train Epoch: 20 [14080/35339 (40%)]	Loss: 1.344027
Train Epoch: 20 [14720/35339 (42%)]	Loss: 1.254052
Train Epoch: 20 [15360/35339 (43%)]	Loss: 1.374264
Train Epoch: 20 [16000/35339 (45%)]	Loss: 1.366973
Train Epoch: 20 [16640/35339 (47%)]	Loss: 1.493846
Train Epoch: 20 [17280/35339 (49%)]	Loss: 1.354210
Train Epoch: 20 [17920/35339 (51%)]	Loss: 1.271152
Train Epoch: 20 [18560/35339 (52%)]	Loss: 1.163791
Train Epoch: 20 [19200/35339 (54%)]	Loss: 1.287153
Train Epoch: 20 [19840/35339 (56%)]	Loss: 1.482435
Train Epoch: 20 [20480/35339 (58%)]	Loss: 1.598646
Train Epoch: 20 [21120/35339 (60%)]	Loss: 1.276222
Train Epoch: 20 [21760/35339 (61%)]	Loss: 1.208228
Train Epoch: 20 [22400/35339 (63%)]	Loss: 1.162371
Train Epoch: 20 [23040/35339 (65%)]	Loss: 1.260918
Train Epoch: 20 [23680/35339 (67%)]	Loss: 1.230826
Train Epoch: 20 [24320/35339 (69%)]	Loss: 1.301236
Train Epoch: 20 [24960/35339 (71%)]	Loss: 1.294254
Train Epoch: 20 [25600/35339 (72%)]	Loss: 1.197163
Train Epoch: 20 [26240/35339 (74%)]	Loss: 1.327150
Train Epoch: 20 [26880/35339 (76%)]	Loss: 1.276673
Train Epoch: 20 [27520/35339 (78%)]	Loss: 1.365750
Train Epoch: 20 [28160/35339 (80%)]	Loss: 1.457916
Train Epoch: 20 [28800/35339 (81%)]	Loss: 1.235722
Train Epoch: 20 [29440/35339 (83%)]	Loss: 1.404795
Train Epoch: 20 [30080/35339 (85%)]	Loss: 1.212704
Train Epoch: 20 [30720/35339 (87%)]	Loss: 1.210257
Train Epoch: 20 [31360/35339 (89%)]	Loss: 1.306259
Train Epoch: 20 [32000/35339 (90%)]	Loss: 1.233065
Train Epoch: 20 [32640/35339 (92%)]	Loss: 1.380159
Train Epoch: 20 [33280/35339 (94%)]	Loss: 1.212472
Train Epoch: 20 [33920/35339 (96%)]	Loss: 1.390528
Train Epoch: 20 [34560/35339 (98%)]	Loss: 1.151579
Train Epoch: 20 [35200/35339 (99%)]	Loss: 1.192351

Validation set: Average loss: 3.7435, Accuracy: 792/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 21 [0/35339 (0%)]	Loss: 1.384486
Train Epoch: 21 [640/35339 (2%)]	Loss: 1.215480
Train Epoch: 21 [1280/35339 (4%)]	Loss: 1.277819
Train Epoch: 21 [1920/35339 (5%)]	Loss: 1.324302
Train Epoch: 21 [2560/35339 (7%)]	Loss: 1.767171
Train Epoch: 21 [3200/35339 (9%)]	Loss: 1.368035
Train Epoch: 21 [3840/35339 (11%)]	Loss: 1.331130
Train Epoch: 21 [4480/35339 (13%)]	Loss: 1.527891
Train Epoch: 21 [5120/35339 (14%)]	Loss: 1.320925
Train Epoch: 21 [5760/35339 (16%)]	Loss: 1.212539
Train Epoch: 21 [6400/35339 (18%)]	Loss: 1.229837
Train Epoch: 21 [7040/35339 (20%)]	Loss: 1.302690
Train Epoch: 21 [7680/35339 (22%)]	Loss: 1.347515
Train Epoch: 21 [8320/35339 (24%)]	Loss: 1.084397
Train Epoch: 21 [8960/35339 (25%)]	Loss: 1.186273
Train Epoch: 21 [9600/35339 (27%)]	Loss: 1.169914
Train Epoch: 21 [10240/35339 (29%)]	Loss: 1.185111
Train Epoch: 21 [10880/35339 (31%)]	Loss: 1.296381
Train Epoch: 21 [11520/35339 (33%)]	Loss: 1.170753
Train Epoch: 21 [12160/35339 (34%)]	Loss: 1.281758
Train Epoch: 21 [12800/35339 (36%)]	Loss: 1.236934
Train Epoch: 21 [13440/35339 (38%)]	Loss: 1.233030
Train Epoch: 21 [14080/35339 (40%)]	Loss: 1.449647
Train Epoch: 21 [14720/35339 (42%)]	Loss: 1.293626
Train Epoch: 21 [15360/35339 (43%)]	Loss: 1.131874
Train Epoch: 21 [16000/35339 (45%)]	Loss: 1.102560
Train Epoch: 21 [16640/35339 (47%)]	Loss: 1.256209
Train Epoch: 21 [17280/35339 (49%)]	Loss: 1.323385
Train Epoch: 21 [17920/35339 (51%)]	Loss: 1.183604
Train Epoch: 21 [18560/35339 (52%)]	Loss: 1.331976
Train Epoch: 21 [19200/35339 (54%)]	Loss: 1.354219
Train Epoch: 21 [19840/35339 (56%)]	Loss: 1.269273
Train Epoch: 21 [20480/35339 (58%)]	Loss: 1.332939
Train Epoch: 21 [21120/35339 (60%)]	Loss: 1.215655
Train Epoch: 21 [21760/35339 (61%)]	Loss: 1.210221
Train Epoch: 21 [22400/35339 (63%)]	Loss: 1.194551
Train Epoch: 21 [23040/35339 (65%)]	Loss: 1.246793
Train Epoch: 21 [23680/35339 (67%)]	Loss: 1.280560
Train Epoch: 21 [24320/35339 (69%)]	Loss: 1.367931
Train Epoch: 21 [24960/35339 (71%)]	Loss: 1.210514
Train Epoch: 21 [25600/35339 (72%)]	Loss: 1.040396
Train Epoch: 21 [26240/35339 (74%)]	Loss: 1.355644
Train Epoch: 21 [26880/35339 (76%)]	Loss: 1.274423
Train Epoch: 21 [27520/35339 (78%)]	Loss: 1.235628
Train Epoch: 21 [28160/35339 (80%)]	Loss: 1.307563
Train Epoch: 21 [28800/35339 (81%)]	Loss: 1.170653
Train Epoch: 21 [29440/35339 (83%)]	Loss: 1.234186
Train Epoch: 21 [30080/35339 (85%)]	Loss: 1.095281
Train Epoch: 21 [30720/35339 (87%)]	Loss: 1.377623
Train Epoch: 21 [31360/35339 (89%)]	Loss: 1.233076
Train Epoch: 21 [32000/35339 (90%)]	Loss: 1.324902
Train Epoch: 21 [32640/35339 (92%)]	Loss: 1.392430
Train Epoch: 21 [33280/35339 (94%)]	Loss: 1.281336
Train Epoch: 21 [33920/35339 (96%)]	Loss: 1.028130
Train Epoch: 21 [34560/35339 (98%)]	Loss: 1.137242
Train Epoch: 21 [35200/35339 (99%)]	Loss: 1.455976

Validation set: Average loss: 3.7386, Accuracy: 803/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 22 [0/35339 (0%)]	Loss: 1.198641
Train Epoch: 22 [640/35339 (2%)]	Loss: 1.236716
Train Epoch: 22 [1280/35339 (4%)]	Loss: 1.386412
Train Epoch: 22 [1920/35339 (5%)]	Loss: 1.079270
Train Epoch: 22 [2560/35339 (7%)]	Loss: 1.254597
Train Epoch: 22 [3200/35339 (9%)]	Loss: 1.189875
Train Epoch: 22 [3840/35339 (11%)]	Loss: 1.319544
Train Epoch: 22 [4480/35339 (13%)]	Loss: 1.218682
Train Epoch: 22 [5120/35339 (14%)]	Loss: 1.308300
Train Epoch: 22 [5760/35339 (16%)]	Loss: 1.254714
Train Epoch: 22 [6400/35339 (18%)]	Loss: 1.176206
Train Epoch: 22 [7040/35339 (20%)]	Loss: 1.275547
Train Epoch: 22 [7680/35339 (22%)]	Loss: 1.144791
Train Epoch: 22 [8320/35339 (24%)]	Loss: 1.236259
Train Epoch: 22 [8960/35339 (25%)]	Loss: 1.441768
Train Epoch: 22 [9600/35339 (27%)]	Loss: 1.354678
Train Epoch: 22 [10240/35339 (29%)]	Loss: 1.353471
Train Epoch: 22 [10880/35339 (31%)]	Loss: 1.278061
Train Epoch: 22 [11520/35339 (33%)]	Loss: 1.290387
Train Epoch: 22 [12160/35339 (34%)]	Loss: 1.354190
Train Epoch: 22 [12800/35339 (36%)]	Loss: 1.204546
Train Epoch: 22 [13440/35339 (38%)]	Loss: 1.188605
Train Epoch: 22 [14080/35339 (40%)]	Loss: 1.188835
Train Epoch: 22 [14720/35339 (42%)]	Loss: 1.106266
Train Epoch: 22 [15360/35339 (43%)]	Loss: 1.262068
Train Epoch: 22 [16000/35339 (45%)]	Loss: 1.101972
Train Epoch: 22 [16640/35339 (47%)]	Loss: 1.167812
Train Epoch: 22 [17280/35339 (49%)]	Loss: 1.275765
Train Epoch: 22 [17920/35339 (51%)]	Loss: 1.259770
Train Epoch: 22 [18560/35339 (52%)]	Loss: 1.139272
Train Epoch: 22 [19200/35339 (54%)]	Loss: 1.307816
Train Epoch: 22 [19840/35339 (56%)]	Loss: 1.068138
Train Epoch: 22 [20480/35339 (58%)]	Loss: 1.173312
Train Epoch: 22 [21120/35339 (60%)]	Loss: 1.205243
Train Epoch: 22 [21760/35339 (61%)]	Loss: 1.226317
Train Epoch: 22 [22400/35339 (63%)]	Loss: 1.263486
Train Epoch: 22 [23040/35339 (65%)]	Loss: 1.234346
Train Epoch: 22 [23680/35339 (67%)]	Loss: 1.128381
Train Epoch: 22 [24320/35339 (69%)]	Loss: 1.324145
Train Epoch: 22 [24960/35339 (71%)]	Loss: 1.164396
Train Epoch: 22 [25600/35339 (72%)]	Loss: 1.118182
Train Epoch: 22 [26240/35339 (74%)]	Loss: 1.322257
Train Epoch: 22 [26880/35339 (76%)]	Loss: 1.335272
Train Epoch: 22 [27520/35339 (78%)]	Loss: 1.074047
Train Epoch: 22 [28160/35339 (80%)]	Loss: 1.190945
Train Epoch: 22 [28800/35339 (81%)]	Loss: 1.194367
Train Epoch: 22 [29440/35339 (83%)]	Loss: 1.096047
Train Epoch: 22 [30080/35339 (85%)]	Loss: 1.295958
Train Epoch: 22 [30720/35339 (87%)]	Loss: 1.336845
Train Epoch: 22 [31360/35339 (89%)]	Loss: 1.266086
Train Epoch: 22 [32000/35339 (90%)]	Loss: 1.418942
Train Epoch: 22 [32640/35339 (92%)]	Loss: 1.571055
Train Epoch: 22 [33280/35339 (94%)]	Loss: 1.408937
Train Epoch: 22 [33920/35339 (96%)]	Loss: 1.180899
Train Epoch: 22 [34560/35339 (98%)]	Loss: 1.156397
Train Epoch: 22 [35200/35339 (99%)]	Loss: 1.272643

Validation set: Average loss: 3.7423, Accuracy: 806/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 23 [0/35339 (0%)]	Loss: 1.384485
Train Epoch: 23 [640/35339 (2%)]	Loss: 1.193542
Train Epoch: 23 [1280/35339 (4%)]	Loss: 1.206285
Train Epoch: 23 [1920/35339 (5%)]	Loss: 1.192251
Train Epoch: 23 [2560/35339 (7%)]	Loss: 1.240128
Train Epoch: 23 [3200/35339 (9%)]	Loss: 1.318703
Train Epoch: 23 [3840/35339 (11%)]	Loss: 0.960567
Train Epoch: 23 [4480/35339 (13%)]	Loss: 1.269079
Train Epoch: 23 [5120/35339 (14%)]	Loss: 1.289176
Train Epoch: 23 [5760/35339 (16%)]	Loss: 1.264939
Train Epoch: 23 [6400/35339 (18%)]	Loss: 1.194052
Train Epoch: 23 [7040/35339 (20%)]	Loss: 1.286460
Train Epoch: 23 [7680/35339 (22%)]	Loss: 1.310384
Train Epoch: 23 [8320/35339 (24%)]	Loss: 1.281086
Train Epoch: 23 [8960/35339 (25%)]	Loss: 1.210231
Train Epoch: 23 [9600/35339 (27%)]	Loss: 1.200789
Train Epoch: 23 [10240/35339 (29%)]	Loss: 1.358392
Train Epoch: 23 [10880/35339 (31%)]	Loss: 1.325312
Train Epoch: 23 [11520/35339 (33%)]	Loss: 1.272465
Train Epoch: 23 [12160/35339 (34%)]	Loss: 1.256979
Train Epoch: 23 [12800/35339 (36%)]	Loss: 1.153685
Train Epoch: 23 [13440/35339 (38%)]	Loss: 1.250427
Train Epoch: 23 [14080/35339 (40%)]	Loss: 1.154179
Train Epoch: 23 [14720/35339 (42%)]	Loss: 1.117819
Train Epoch: 23 [15360/35339 (43%)]	Loss: 1.246399
Train Epoch: 23 [16000/35339 (45%)]	Loss: 1.213604
Train Epoch: 23 [16640/35339 (47%)]	Loss: 1.145388
Train Epoch: 23 [17280/35339 (49%)]	Loss: 1.173705
Train Epoch: 23 [17920/35339 (51%)]	Loss: 1.266704
Train Epoch: 23 [18560/35339 (52%)]	Loss: 1.309429
Train Epoch: 23 [19200/35339 (54%)]	Loss: 1.275503
Train Epoch: 23 [19840/35339 (56%)]	Loss: 1.060163
Train Epoch: 23 [20480/35339 (58%)]	Loss: 1.322949
Train Epoch: 23 [21120/35339 (60%)]	Loss: 1.079102
Train Epoch: 23 [21760/35339 (61%)]	Loss: 1.344932
Train Epoch: 23 [22400/35339 (63%)]	Loss: 1.203566
Train Epoch: 23 [23040/35339 (65%)]	Loss: 1.229085
Train Epoch: 23 [23680/35339 (67%)]	Loss: 1.206912
Train Epoch: 23 [24320/35339 (69%)]	Loss: 1.189098
Train Epoch: 23 [24960/35339 (71%)]	Loss: 1.331720
Train Epoch: 23 [25600/35339 (72%)]	Loss: 1.215775
Train Epoch: 23 [26240/35339 (74%)]	Loss: 1.260307
Train Epoch: 23 [26880/35339 (76%)]	Loss: 1.147133
Train Epoch: 23 [27520/35339 (78%)]	Loss: 1.120644
Train Epoch: 23 [28160/35339 (80%)]	Loss: 1.346467
Train Epoch: 23 [28800/35339 (81%)]	Loss: 1.235658
Train Epoch: 23 [29440/35339 (83%)]	Loss: 1.126719
Train Epoch: 23 [30080/35339 (85%)]	Loss: 1.121816
Train Epoch: 23 [30720/35339 (87%)]	Loss: 1.119309
Train Epoch: 23 [31360/35339 (89%)]	Loss: 1.222608
Train Epoch: 23 [32000/35339 (90%)]	Loss: 1.276210
Train Epoch: 23 [32640/35339 (92%)]	Loss: 1.445038
Train Epoch: 23 [33280/35339 (94%)]	Loss: 1.253702
Train Epoch: 23 [33920/35339 (96%)]	Loss: 1.039101
Train Epoch: 23 [34560/35339 (98%)]	Loss: 1.094643
Train Epoch: 23 [35200/35339 (99%)]	Loss: 1.247285

Validation set: Average loss: 3.7432, Accuracy: 819/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 24 [0/35339 (0%)]	Loss: 1.127601
Train Epoch: 24 [640/35339 (2%)]	Loss: 1.097505
Train Epoch: 24 [1280/35339 (4%)]	Loss: 1.178821
Train Epoch: 24 [1920/35339 (5%)]	Loss: 1.247129
Train Epoch: 24 [2560/35339 (7%)]	Loss: 1.266115
Train Epoch: 24 [3200/35339 (9%)]	Loss: 1.102103
Train Epoch: 24 [3840/35339 (11%)]	Loss: 1.097413
Train Epoch: 24 [4480/35339 (13%)]	Loss: 1.159582
Train Epoch: 24 [5120/35339 (14%)]	Loss: 1.269934
Train Epoch: 24 [5760/35339 (16%)]	Loss: 1.165385
Train Epoch: 24 [6400/35339 (18%)]	Loss: 1.248401
Train Epoch: 24 [7040/35339 (20%)]	Loss: 1.213935
Train Epoch: 24 [7680/35339 (22%)]	Loss: 1.259991
Train Epoch: 24 [8320/35339 (24%)]	Loss: 1.075168
Train Epoch: 24 [8960/35339 (25%)]	Loss: 1.195027
Train Epoch: 24 [9600/35339 (27%)]	Loss: 1.126744
Train Epoch: 24 [10240/35339 (29%)]	Loss: 1.074875
Train Epoch: 24 [10880/35339 (31%)]	Loss: 1.128734
Train Epoch: 24 [11520/35339 (33%)]	Loss: 1.079170
Train Epoch: 24 [12160/35339 (34%)]	Loss: 1.030321
Train Epoch: 24 [12800/35339 (36%)]	Loss: 1.133256
Train Epoch: 24 [13440/35339 (38%)]	Loss: 1.315745
Train Epoch: 24 [14080/35339 (40%)]	Loss: 1.233708
Train Epoch: 24 [14720/35339 (42%)]	Loss: 1.157255
Train Epoch: 24 [15360/35339 (43%)]	Loss: 1.249405
Train Epoch: 24 [16000/35339 (45%)]	Loss: 1.078230
Train Epoch: 24 [16640/35339 (47%)]	Loss: 1.198103
Train Epoch: 24 [17280/35339 (49%)]	Loss: 1.071047
Train Epoch: 24 [17920/35339 (51%)]	Loss: 1.066327
Train Epoch: 24 [18560/35339 (52%)]	Loss: 1.197957
Train Epoch: 24 [19200/35339 (54%)]	Loss: 1.151263
Train Epoch: 24 [19840/35339 (56%)]	Loss: 1.098860
Train Epoch: 24 [20480/35339 (58%)]	Loss: 1.235958
Train Epoch: 24 [21120/35339 (60%)]	Loss: 1.259069
Train Epoch: 24 [21760/35339 (61%)]	Loss: 1.064905
Train Epoch: 24 [22400/35339 (63%)]	Loss: 1.266706
Train Epoch: 24 [23040/35339 (65%)]	Loss: 1.205178
Train Epoch: 24 [23680/35339 (67%)]	Loss: 1.111906
Train Epoch: 24 [24320/35339 (69%)]	Loss: 1.235791
Train Epoch: 24 [24960/35339 (71%)]	Loss: 1.206976
Train Epoch: 24 [25600/35339 (72%)]	Loss: 1.178108
Train Epoch: 24 [26240/35339 (74%)]	Loss: 1.083474
Train Epoch: 24 [26880/35339 (76%)]	Loss: 1.256325
Train Epoch: 24 [27520/35339 (78%)]	Loss: 1.230451
Train Epoch: 24 [28160/35339 (80%)]	Loss: 1.192390
Train Epoch: 24 [28800/35339 (81%)]	Loss: 1.250063
Train Epoch: 24 [29440/35339 (83%)]	Loss: 1.220836
Train Epoch: 24 [30080/35339 (85%)]	Loss: 1.242789
Train Epoch: 24 [30720/35339 (87%)]	Loss: 1.097782
Train Epoch: 24 [31360/35339 (89%)]	Loss: 1.123955
Train Epoch: 24 [32000/35339 (90%)]	Loss: 1.254149
Train Epoch: 24 [32640/35339 (92%)]	Loss: 1.156231
Train Epoch: 24 [33280/35339 (94%)]	Loss: 1.288302
Train Epoch: 24 [33920/35339 (96%)]	Loss: 1.259742
Train Epoch: 24 [34560/35339 (98%)]	Loss: 1.200558
Train Epoch: 24 [35200/35339 (99%)]	Loss: 1.179333

Validation set: Average loss: 3.7510, Accuracy: 818/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 25 [0/35339 (0%)]	Loss: 1.083449
Train Epoch: 25 [640/35339 (2%)]	Loss: 1.111516
Train Epoch: 25 [1280/35339 (4%)]	Loss: 1.133181
Train Epoch: 25 [1920/35339 (5%)]	Loss: 1.159123
Train Epoch: 25 [2560/35339 (7%)]	Loss: 1.273050
Train Epoch: 25 [3200/35339 (9%)]	Loss: 0.954828
Train Epoch: 25 [3840/35339 (11%)]	Loss: 1.126527
Train Epoch: 25 [4480/35339 (13%)]	Loss: 1.284704
Train Epoch: 25 [5120/35339 (14%)]	Loss: 1.016786
Train Epoch: 25 [5760/35339 (16%)]	Loss: 1.156693
Train Epoch: 25 [6400/35339 (18%)]	Loss: 0.894930
Train Epoch: 25 [7040/35339 (20%)]	Loss: 0.968248
Train Epoch: 25 [7680/35339 (22%)]	Loss: 1.318399
Train Epoch: 25 [8320/35339 (24%)]	Loss: 1.060282
Train Epoch: 25 [8960/35339 (25%)]	Loss: 1.166309
Train Epoch: 25 [9600/35339 (27%)]	Loss: 1.237775
Train Epoch: 25 [10240/35339 (29%)]	Loss: 1.158005
Train Epoch: 25 [10880/35339 (31%)]	Loss: 1.307534
Train Epoch: 25 [11520/35339 (33%)]	Loss: 1.039815
Train Epoch: 25 [12160/35339 (34%)]	Loss: 1.164912
Train Epoch: 25 [12800/35339 (36%)]	Loss: 1.124192
Train Epoch: 25 [13440/35339 (38%)]	Loss: 1.068227
Train Epoch: 25 [14080/35339 (40%)]	Loss: 1.288493
Train Epoch: 25 [14720/35339 (42%)]	Loss: 1.123403
Train Epoch: 25 [15360/35339 (43%)]	Loss: 1.030970
Train Epoch: 25 [16000/35339 (45%)]	Loss: 1.241349
Train Epoch: 25 [16640/35339 (47%)]	Loss: 1.240441
Train Epoch: 25 [17280/35339 (49%)]	Loss: 1.257933
Train Epoch: 25 [17920/35339 (51%)]	Loss: 1.194438
Train Epoch: 25 [18560/35339 (52%)]	Loss: 1.275668
Train Epoch: 25 [19200/35339 (54%)]	Loss: 1.285401
Train Epoch: 25 [19840/35339 (56%)]	Loss: 1.221337
Train Epoch: 25 [20480/35339 (58%)]	Loss: 1.222614
Train Epoch: 25 [21120/35339 (60%)]	Loss: 1.032811
Train Epoch: 25 [21760/35339 (61%)]	Loss: 1.165272
Train Epoch: 25 [22400/35339 (63%)]	Loss: 1.147077
Train Epoch: 25 [23040/35339 (65%)]	Loss: 1.142589
Train Epoch: 25 [23680/35339 (67%)]	Loss: 1.226657
Train Epoch: 25 [24320/35339 (69%)]	Loss: 1.157532
Train Epoch: 25 [24960/35339 (71%)]	Loss: 0.994429
Train Epoch: 25 [25600/35339 (72%)]	Loss: 1.273507
Train Epoch: 25 [26240/35339 (74%)]	Loss: 1.128837
Train Epoch: 25 [26880/35339 (76%)]	Loss: 1.159552
Train Epoch: 25 [27520/35339 (78%)]	Loss: 1.178679
Train Epoch: 25 [28160/35339 (80%)]	Loss: 1.195764
Train Epoch: 25 [28800/35339 (81%)]	Loss: 1.165056
Train Epoch: 25 [29440/35339 (83%)]	Loss: 1.030274
Train Epoch: 25 [30080/35339 (85%)]	Loss: 1.152933
Train Epoch: 25 [30720/35339 (87%)]	Loss: 1.058185
Train Epoch: 25 [31360/35339 (89%)]	Loss: 1.092537
Train Epoch: 25 [32000/35339 (90%)]	Loss: 1.037009
Train Epoch: 25 [32640/35339 (92%)]	Loss: 1.122362
Train Epoch: 25 [33280/35339 (94%)]	Loss: 1.110685
Train Epoch: 25 [33920/35339 (96%)]	Loss: 1.013843
Train Epoch: 25 [34560/35339 (98%)]	Loss: 1.102344
Train Epoch: 25 [35200/35339 (99%)]	Loss: 1.223906

Validation set: Average loss: 3.7563, Accuracy: 817/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 26 [0/35339 (0%)]	Loss: 1.157763
Train Epoch: 26 [640/35339 (2%)]	Loss: 1.498750
Train Epoch: 26 [1280/35339 (4%)]	Loss: 0.998681
Train Epoch: 26 [1920/35339 (5%)]	Loss: 1.169147
Train Epoch: 26 [2560/35339 (7%)]	Loss: 1.031936
Train Epoch: 26 [3200/35339 (9%)]	Loss: 1.056931
Train Epoch: 26 [3840/35339 (11%)]	Loss: 0.883065
Train Epoch: 26 [4480/35339 (13%)]	Loss: 1.336288
Train Epoch: 26 [5120/35339 (14%)]	Loss: 1.166676
Train Epoch: 26 [5760/35339 (16%)]	Loss: 1.036915
Train Epoch: 26 [6400/35339 (18%)]	Loss: 1.154424
Train Epoch: 26 [7040/35339 (20%)]	Loss: 1.167477
Train Epoch: 26 [7680/35339 (22%)]	Loss: 1.105569
Train Epoch: 26 [8320/35339 (24%)]	Loss: 1.175135
Train Epoch: 26 [8960/35339 (25%)]	Loss: 1.226034
Train Epoch: 26 [9600/35339 (27%)]	Loss: 1.263897
Train Epoch: 26 [10240/35339 (29%)]	Loss: 1.032946
Train Epoch: 26 [10880/35339 (31%)]	Loss: 1.321436
Train Epoch: 26 [11520/35339 (33%)]	Loss: 1.239141
Train Epoch: 26 [12160/35339 (34%)]	Loss: 1.118502
Train Epoch: 26 [12800/35339 (36%)]	Loss: 1.136654
Train Epoch: 26 [13440/35339 (38%)]	Loss: 1.126165
Train Epoch: 26 [14080/35339 (40%)]	Loss: 1.162459
Train Epoch: 26 [14720/35339 (42%)]	Loss: 1.135632
Train Epoch: 26 [15360/35339 (43%)]	Loss: 1.243586
Train Epoch: 26 [16000/35339 (45%)]	Loss: 1.050405
Train Epoch: 26 [16640/35339 (47%)]	Loss: 0.997902
Train Epoch: 26 [17280/35339 (49%)]	Loss: 1.153194
Train Epoch: 26 [17920/35339 (51%)]	Loss: 1.079968
Train Epoch: 26 [18560/35339 (52%)]	Loss: 1.102177
Train Epoch: 26 [19200/35339 (54%)]	Loss: 1.364669
Train Epoch: 26 [19840/35339 (56%)]	Loss: 0.932588
Train Epoch: 26 [20480/35339 (58%)]	Loss: 1.397710
Train Epoch: 26 [21120/35339 (60%)]	Loss: 1.182423
Train Epoch: 26 [21760/35339 (61%)]	Loss: 1.179786
Train Epoch: 26 [22400/35339 (63%)]	Loss: 1.256585
Train Epoch: 26 [23040/35339 (65%)]	Loss: 1.211170
Train Epoch: 26 [23680/35339 (67%)]	Loss: 1.160919
Train Epoch: 26 [24320/35339 (69%)]	Loss: 1.264714
Train Epoch: 26 [24960/35339 (71%)]	Loss: 1.244455
Train Epoch: 26 [25600/35339 (72%)]	Loss: 1.134711
Train Epoch: 26 [26240/35339 (74%)]	Loss: 1.194193
Train Epoch: 26 [26880/35339 (76%)]	Loss: 1.148334
Train Epoch: 26 [27520/35339 (78%)]	Loss: 1.137829
Train Epoch: 26 [28160/35339 (80%)]	Loss: 1.259742
Train Epoch: 26 [28800/35339 (81%)]	Loss: 1.162311
Train Epoch: 26 [29440/35339 (83%)]	Loss: 1.206200
Train Epoch: 26 [30080/35339 (85%)]	Loss: 1.083248
Train Epoch: 26 [30720/35339 (87%)]	Loss: 1.152345
Train Epoch: 26 [31360/35339 (89%)]	Loss: 1.207892
Train Epoch: 26 [32000/35339 (90%)]	Loss: 1.034663
Train Epoch: 26 [32640/35339 (92%)]	Loss: 1.110619
Train Epoch: 26 [33280/35339 (94%)]	Loss: 1.061879
Train Epoch: 26 [33920/35339 (96%)]	Loss: 1.109163
Train Epoch: 26 [34560/35339 (98%)]	Loss: 1.116257
Train Epoch: 26 [35200/35339 (99%)]	Loss: 1.027504

Validation set: Average loss: 3.7558, Accuracy: 825/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 27 [0/35339 (0%)]	Loss: 1.251745
Train Epoch: 27 [640/35339 (2%)]	Loss: 1.033600
Train Epoch: 27 [1280/35339 (4%)]	Loss: 1.081918
Train Epoch: 27 [1920/35339 (5%)]	Loss: 1.093354
Train Epoch: 27 [2560/35339 (7%)]	Loss: 1.037235
Train Epoch: 27 [3200/35339 (9%)]	Loss: 1.125280
Train Epoch: 27 [3840/35339 (11%)]	Loss: 1.167935
Train Epoch: 27 [4480/35339 (13%)]	Loss: 1.175607
Train Epoch: 27 [5120/35339 (14%)]	Loss: 0.980560
Train Epoch: 27 [5760/35339 (16%)]	Loss: 1.168454
Train Epoch: 27 [6400/35339 (18%)]	Loss: 1.143325
Train Epoch: 27 [7040/35339 (20%)]	Loss: 1.104568
Train Epoch: 27 [7680/35339 (22%)]	Loss: 1.011319
Train Epoch: 27 [8320/35339 (24%)]	Loss: 1.107144
Train Epoch: 27 [8960/35339 (25%)]	Loss: 1.150988
Train Epoch: 27 [9600/35339 (27%)]	Loss: 1.105487
Train Epoch: 27 [10240/35339 (29%)]	Loss: 0.969433
Train Epoch: 27 [10880/35339 (31%)]	Loss: 1.180590
Train Epoch: 27 [11520/35339 (33%)]	Loss: 1.123452
Train Epoch: 27 [12160/35339 (34%)]	Loss: 1.095790
Train Epoch: 27 [12800/35339 (36%)]	Loss: 1.262694
Train Epoch: 27 [13440/35339 (38%)]	Loss: 1.234082
Train Epoch: 27 [14080/35339 (40%)]	Loss: 0.970598
Train Epoch: 27 [14720/35339 (42%)]	Loss: 1.013225
Train Epoch: 27 [15360/35339 (43%)]	Loss: 1.069684
Train Epoch: 27 [16000/35339 (45%)]	Loss: 0.980506
Train Epoch: 27 [16640/35339 (47%)]	Loss: 1.210288
Train Epoch: 27 [17280/35339 (49%)]	Loss: 1.256448
Train Epoch: 27 [17920/35339 (51%)]	Loss: 1.214931
Train Epoch: 27 [18560/35339 (52%)]	Loss: 1.056392
Train Epoch: 27 [19200/35339 (54%)]	Loss: 1.163190
Train Epoch: 27 [19840/35339 (56%)]	Loss: 1.032092
Train Epoch: 27 [20480/35339 (58%)]	Loss: 0.960338
Train Epoch: 27 [21120/35339 (60%)]	Loss: 1.112125
Train Epoch: 27 [21760/35339 (61%)]	Loss: 1.113165
Train Epoch: 27 [22400/35339 (63%)]	Loss: 1.254320
Train Epoch: 27 [23040/35339 (65%)]	Loss: 1.127119
Train Epoch: 27 [23680/35339 (67%)]	Loss: 1.171561
Train Epoch: 27 [24320/35339 (69%)]	Loss: 1.099196
Train Epoch: 27 [24960/35339 (71%)]	Loss: 0.953722
Train Epoch: 27 [25600/35339 (72%)]	Loss: 1.102268
Train Epoch: 27 [26240/35339 (74%)]	Loss: 1.233884
Train Epoch: 27 [26880/35339 (76%)]	Loss: 1.217811
Train Epoch: 27 [27520/35339 (78%)]	Loss: 1.375101
Train Epoch: 27 [28160/35339 (80%)]	Loss: 1.006067
Train Epoch: 27 [28800/35339 (81%)]	Loss: 1.011571
Train Epoch: 27 [29440/35339 (83%)]	Loss: 1.141685
Train Epoch: 27 [30080/35339 (85%)]	Loss: 1.043930
Train Epoch: 27 [30720/35339 (87%)]	Loss: 1.186669
Train Epoch: 27 [31360/35339 (89%)]	Loss: 1.177041
Train Epoch: 27 [32000/35339 (90%)]	Loss: 1.084466
Train Epoch: 27 [32640/35339 (92%)]	Loss: 0.923810
Train Epoch: 27 [33280/35339 (94%)]	Loss: 1.261463
Train Epoch: 27 [33920/35339 (96%)]	Loss: 0.995809
Train Epoch: 27 [34560/35339 (98%)]	Loss: 1.006536
Train Epoch: 27 [35200/35339 (99%)]	Loss: 1.258426

Validation set: Average loss: 3.7561, Accuracy: 823/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 28 [0/35339 (0%)]	Loss: 1.159927
Train Epoch: 28 [640/35339 (2%)]	Loss: 1.156202
Train Epoch: 28 [1280/35339 (4%)]	Loss: 1.043636
Train Epoch: 28 [1920/35339 (5%)]	Loss: 1.276962
Train Epoch: 28 [2560/35339 (7%)]	Loss: 0.924127
Train Epoch: 28 [3200/35339 (9%)]	Loss: 1.145850
Train Epoch: 28 [3840/35339 (11%)]	Loss: 1.124354
Train Epoch: 28 [4480/35339 (13%)]	Loss: 1.087828
Train Epoch: 28 [5120/35339 (14%)]	Loss: 1.064356
Train Epoch: 28 [5760/35339 (16%)]	Loss: 1.128896
Train Epoch: 28 [6400/35339 (18%)]	Loss: 1.163306
Train Epoch: 28 [7040/35339 (20%)]	Loss: 1.041652
Train Epoch: 28 [7680/35339 (22%)]	Loss: 1.123053
Train Epoch: 28 [8320/35339 (24%)]	Loss: 1.143920
Train Epoch: 28 [8960/35339 (25%)]	Loss: 1.233354
Train Epoch: 28 [9600/35339 (27%)]	Loss: 1.105988
Train Epoch: 28 [10240/35339 (29%)]	Loss: 1.063241
Train Epoch: 28 [10880/35339 (31%)]	Loss: 1.158907
Train Epoch: 28 [11520/35339 (33%)]	Loss: 0.862845
Train Epoch: 28 [12160/35339 (34%)]	Loss: 1.004675
Train Epoch: 28 [12800/35339 (36%)]	Loss: 0.899585
Train Epoch: 28 [13440/35339 (38%)]	Loss: 0.904272
Train Epoch: 28 [14080/35339 (40%)]	Loss: 1.068881
Train Epoch: 28 [14720/35339 (42%)]	Loss: 1.071473
Train Epoch: 28 [15360/35339 (43%)]	Loss: 0.964073
Train Epoch: 28 [16000/35339 (45%)]	Loss: 1.174895
Train Epoch: 28 [16640/35339 (47%)]	Loss: 1.140561
Train Epoch: 28 [17280/35339 (49%)]	Loss: 0.981313
Train Epoch: 28 [17920/35339 (51%)]	Loss: 0.923742
Train Epoch: 28 [18560/35339 (52%)]	Loss: 0.963546
Train Epoch: 28 [19200/35339 (54%)]	Loss: 1.032192
Train Epoch: 28 [19840/35339 (56%)]	Loss: 1.145479
Train Epoch: 28 [20480/35339 (58%)]	Loss: 1.050987
Train Epoch: 28 [21120/35339 (60%)]	Loss: 0.932117
Train Epoch: 28 [21760/35339 (61%)]	Loss: 1.163501
Train Epoch: 28 [22400/35339 (63%)]	Loss: 0.910069
Train Epoch: 28 [23040/35339 (65%)]	Loss: 1.085890
Train Epoch: 28 [23680/35339 (67%)]	Loss: 1.005693
Train Epoch: 28 [24320/35339 (69%)]	Loss: 1.090417
Train Epoch: 28 [24960/35339 (71%)]	Loss: 1.238449
Train Epoch: 28 [25600/35339 (72%)]	Loss: 1.048719
Train Epoch: 28 [26240/35339 (74%)]	Loss: 1.076414
Train Epoch: 28 [26880/35339 (76%)]	Loss: 1.333109
Train Epoch: 28 [27520/35339 (78%)]	Loss: 1.119135
Train Epoch: 28 [28160/35339 (80%)]	Loss: 1.176592
Train Epoch: 28 [28800/35339 (81%)]	Loss: 1.053826
Train Epoch: 28 [29440/35339 (83%)]	Loss: 1.029315
Train Epoch: 28 [30080/35339 (85%)]	Loss: 0.818458
Train Epoch: 28 [30720/35339 (87%)]	Loss: 1.190979
Train Epoch: 28 [31360/35339 (89%)]	Loss: 1.146457
Train Epoch: 28 [32000/35339 (90%)]	Loss: 1.189273
Train Epoch: 28 [32640/35339 (92%)]	Loss: 0.918225
Train Epoch: 28 [33280/35339 (94%)]	Loss: 1.021848
Train Epoch: 28 [33920/35339 (96%)]	Loss: 1.084624
Train Epoch: 28 [34560/35339 (98%)]	Loss: 0.928600
Train Epoch: 28 [35200/35339 (99%)]	Loss: 0.957968

Validation set: Average loss: 3.7668, Accuracy: 814/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 29 [0/35339 (0%)]	Loss: 1.202430
Train Epoch: 29 [640/35339 (2%)]	Loss: 1.129043
Train Epoch: 29 [1280/35339 (4%)]	Loss: 0.984361
Train Epoch: 29 [1920/35339 (5%)]	Loss: 0.907485
Train Epoch: 29 [2560/35339 (7%)]	Loss: 1.064716
Train Epoch: 29 [3200/35339 (9%)]	Loss: 0.853820
Train Epoch: 29 [3840/35339 (11%)]	Loss: 1.228272
Train Epoch: 29 [4480/35339 (13%)]	Loss: 1.212924
Train Epoch: 29 [5120/35339 (14%)]	Loss: 1.001054
Train Epoch: 29 [5760/35339 (16%)]	Loss: 1.131499
Train Epoch: 29 [6400/35339 (18%)]	Loss: 1.075717
Train Epoch: 29 [7040/35339 (20%)]	Loss: 0.978512
Train Epoch: 29 [7680/35339 (22%)]	Loss: 1.097750
Train Epoch: 29 [8320/35339 (24%)]	Loss: 1.448733
Train Epoch: 29 [8960/35339 (25%)]	Loss: 1.298528
Train Epoch: 29 [9600/35339 (27%)]	Loss: 1.075229
Train Epoch: 29 [10240/35339 (29%)]	Loss: 1.015878
Train Epoch: 29 [10880/35339 (31%)]	Loss: 1.168014
Train Epoch: 29 [11520/35339 (33%)]	Loss: 1.015526
Train Epoch: 29 [12160/35339 (34%)]	Loss: 1.138378
Train Epoch: 29 [12800/35339 (36%)]	Loss: 1.230116
Train Epoch: 29 [13440/35339 (38%)]	Loss: 1.097065
Train Epoch: 29 [14080/35339 (40%)]	Loss: 1.136852
Train Epoch: 29 [14720/35339 (42%)]	Loss: 0.837846
Train Epoch: 29 [15360/35339 (43%)]	Loss: 1.046991
Train Epoch: 29 [16000/35339 (45%)]	Loss: 1.238485
Train Epoch: 29 [16640/35339 (47%)]	Loss: 0.933510
Train Epoch: 29 [17280/35339 (49%)]	Loss: 0.873358
Train Epoch: 29 [17920/35339 (51%)]	Loss: 1.161273
Train Epoch: 29 [18560/35339 (52%)]	Loss: 1.028606
Train Epoch: 29 [19200/35339 (54%)]	Loss: 1.056768
Train Epoch: 29 [19840/35339 (56%)]	Loss: 1.074311
Train Epoch: 29 [20480/35339 (58%)]	Loss: 1.133835
Train Epoch: 29 [21120/35339 (60%)]	Loss: 1.016731
Train Epoch: 29 [21760/35339 (61%)]	Loss: 1.043299
Train Epoch: 29 [22400/35339 (63%)]	Loss: 1.207932
Train Epoch: 29 [23040/35339 (65%)]	Loss: 1.022953
Train Epoch: 29 [23680/35339 (67%)]	Loss: 0.927464
Train Epoch: 29 [24320/35339 (69%)]	Loss: 1.204502
Train Epoch: 29 [24960/35339 (71%)]	Loss: 1.030616
Train Epoch: 29 [25600/35339 (72%)]	Loss: 1.034360
Train Epoch: 29 [26240/35339 (74%)]	Loss: 0.939806
Train Epoch: 29 [26880/35339 (76%)]	Loss: 1.044238
Train Epoch: 29 [27520/35339 (78%)]	Loss: 1.159188
Train Epoch: 29 [28160/35339 (80%)]	Loss: 1.172498
Train Epoch: 29 [28800/35339 (81%)]	Loss: 0.952038
Train Epoch: 29 [29440/35339 (83%)]	Loss: 1.099920
Train Epoch: 29 [30080/35339 (85%)]	Loss: 1.094120
Train Epoch: 29 [30720/35339 (87%)]	Loss: 1.223734
Train Epoch: 29 [31360/35339 (89%)]	Loss: 1.159847
Train Epoch: 29 [32000/35339 (90%)]	Loss: 1.204013
Train Epoch: 29 [32640/35339 (92%)]	Loss: 1.064848
Train Epoch: 29 [33280/35339 (94%)]	Loss: 1.020094
Train Epoch: 29 [33920/35339 (96%)]	Loss: 0.933630
Train Epoch: 29 [34560/35339 (98%)]	Loss: 1.157561
Train Epoch: 29 [35200/35339 (99%)]	Loss: 1.076564

Validation set: Average loss: 3.7550, Accuracy: 810/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 30 [0/35339 (0%)]	Loss: 1.076392
Train Epoch: 30 [640/35339 (2%)]	Loss: 1.000110
Train Epoch: 30 [1280/35339 (4%)]	Loss: 0.973872
Train Epoch: 30 [1920/35339 (5%)]	Loss: 0.965408
Train Epoch: 30 [2560/35339 (7%)]	Loss: 1.110417
Train Epoch: 30 [3200/35339 (9%)]	Loss: 1.047152
Train Epoch: 30 [3840/35339 (11%)]	Loss: 1.044599
Train Epoch: 30 [4480/35339 (13%)]	Loss: 0.928367
Train Epoch: 30 [5120/35339 (14%)]	Loss: 1.075960
Train Epoch: 30 [5760/35339 (16%)]	Loss: 1.161191
Train Epoch: 30 [6400/35339 (18%)]	Loss: 0.838135
Train Epoch: 30 [7040/35339 (20%)]	Loss: 0.988934
Train Epoch: 30 [7680/35339 (22%)]	Loss: 1.071041
Train Epoch: 30 [8320/35339 (24%)]	Loss: 1.229145
Train Epoch: 30 [8960/35339 (25%)]	Loss: 1.002525
Train Epoch: 30 [9600/35339 (27%)]	Loss: 1.005328
Train Epoch: 30 [10240/35339 (29%)]	Loss: 0.966736
Train Epoch: 30 [10880/35339 (31%)]	Loss: 1.150509
Train Epoch: 30 [11520/35339 (33%)]	Loss: 1.141263
Train Epoch: 30 [12160/35339 (34%)]	Loss: 0.999534
Train Epoch: 30 [12800/35339 (36%)]	Loss: 1.280958
Train Epoch: 30 [13440/35339 (38%)]	Loss: 0.979872
Train Epoch: 30 [14080/35339 (40%)]	Loss: 1.043320
Train Epoch: 30 [14720/35339 (42%)]	Loss: 1.141264
Train Epoch: 30 [15360/35339 (43%)]	Loss: 1.059144
Train Epoch: 30 [16000/35339 (45%)]	Loss: 1.055663
Train Epoch: 30 [16640/35339 (47%)]	Loss: 0.922358
Train Epoch: 30 [17280/35339 (49%)]	Loss: 0.924323
Train Epoch: 30 [17920/35339 (51%)]	Loss: 1.064660
Train Epoch: 30 [18560/35339 (52%)]	Loss: 1.061399
Train Epoch: 30 [19200/35339 (54%)]	Loss: 1.036864
Train Epoch: 30 [19840/35339 (56%)]	Loss: 1.192735
Train Epoch: 30 [20480/35339 (58%)]	Loss: 1.149875
Train Epoch: 30 [21120/35339 (60%)]	Loss: 0.985376
Train Epoch: 30 [21760/35339 (61%)]	Loss: 1.148340
Train Epoch: 30 [22400/35339 (63%)]	Loss: 1.050331
Train Epoch: 30 [23040/35339 (65%)]	Loss: 0.877242
Train Epoch: 30 [23680/35339 (67%)]	Loss: 1.016990
Train Epoch: 30 [24320/35339 (69%)]	Loss: 1.033289
Train Epoch: 30 [24960/35339 (71%)]	Loss: 1.114070
Train Epoch: 30 [25600/35339 (72%)]	Loss: 1.168740
Train Epoch: 30 [26240/35339 (74%)]	Loss: 1.085458
Train Epoch: 30 [26880/35339 (76%)]	Loss: 0.927953
Train Epoch: 30 [27520/35339 (78%)]	Loss: 1.050811
Train Epoch: 30 [28160/35339 (80%)]	Loss: 0.916298
Train Epoch: 30 [28800/35339 (81%)]	Loss: 1.029402
Train Epoch: 30 [29440/35339 (83%)]	Loss: 1.099092
Train Epoch: 30 [30080/35339 (85%)]	Loss: 1.060745
Train Epoch: 30 [30720/35339 (87%)]	Loss: 1.145944
Train Epoch: 30 [31360/35339 (89%)]	Loss: 0.992069
Train Epoch: 30 [32000/35339 (90%)]	Loss: 1.066996
Train Epoch: 30 [32640/35339 (92%)]	Loss: 0.996542
Train Epoch: 30 [33280/35339 (94%)]	Loss: 1.084275
Train Epoch: 30 [33920/35339 (96%)]	Loss: 0.977110
Train Epoch: 30 [34560/35339 (98%)]	Loss: 1.011523
Train Epoch: 30 [35200/35339 (99%)]	Loss: 1.165805

Validation set: Average loss: 3.7586, Accuracy: 832/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 31 [0/35339 (0%)]	Loss: 0.960548
Train Epoch: 31 [640/35339 (2%)]	Loss: 1.150898
Train Epoch: 31 [1280/35339 (4%)]	Loss: 1.234997
Train Epoch: 31 [1920/35339 (5%)]	Loss: 1.120823
Train Epoch: 31 [2560/35339 (7%)]	Loss: 0.950304
Train Epoch: 31 [3200/35339 (9%)]	Loss: 1.029571
Train Epoch: 31 [3840/35339 (11%)]	Loss: 0.928250
Train Epoch: 31 [4480/35339 (13%)]	Loss: 0.994646
Train Epoch: 31 [5120/35339 (14%)]	Loss: 1.027122
Train Epoch: 31 [5760/35339 (16%)]	Loss: 0.931504
Train Epoch: 31 [6400/35339 (18%)]	Loss: 1.017141
Train Epoch: 31 [7040/35339 (20%)]	Loss: 1.077634
Train Epoch: 31 [7680/35339 (22%)]	Loss: 0.990210
Train Epoch: 31 [8320/35339 (24%)]	Loss: 1.161643
Train Epoch: 31 [8960/35339 (25%)]	Loss: 1.113104
Train Epoch: 31 [9600/35339 (27%)]	Loss: 1.087949
Train Epoch: 31 [10240/35339 (29%)]	Loss: 1.148040
Train Epoch: 31 [10880/35339 (31%)]	Loss: 1.151711
Train Epoch: 31 [11520/35339 (33%)]	Loss: 0.817852
Train Epoch: 31 [12160/35339 (34%)]	Loss: 0.953624
Train Epoch: 31 [12800/35339 (36%)]	Loss: 1.091610
Train Epoch: 31 [13440/35339 (38%)]	Loss: 1.071602
Train Epoch: 31 [14080/35339 (40%)]	Loss: 0.987921
Train Epoch: 31 [14720/35339 (42%)]	Loss: 0.826494
Train Epoch: 31 [15360/35339 (43%)]	Loss: 1.248989
Train Epoch: 31 [16000/35339 (45%)]	Loss: 0.918761
Train Epoch: 31 [16640/35339 (47%)]	Loss: 1.218925
Train Epoch: 31 [17280/35339 (49%)]	Loss: 1.064522
Train Epoch: 31 [17920/35339 (51%)]	Loss: 0.864600
Train Epoch: 31 [18560/35339 (52%)]	Loss: 0.999812
Train Epoch: 31 [19200/35339 (54%)]	Loss: 1.080110
Train Epoch: 31 [19840/35339 (56%)]	Loss: 0.915041
Train Epoch: 31 [20480/35339 (58%)]	Loss: 1.131204
Train Epoch: 31 [21120/35339 (60%)]	Loss: 0.991562
Train Epoch: 31 [21760/35339 (61%)]	Loss: 1.061917
Train Epoch: 31 [22400/35339 (63%)]	Loss: 1.045982
Train Epoch: 31 [23040/35339 (65%)]	Loss: 1.061259
Train Epoch: 31 [23680/35339 (67%)]	Loss: 0.999256
Train Epoch: 31 [24320/35339 (69%)]	Loss: 0.864163
Train Epoch: 31 [24960/35339 (71%)]	Loss: 1.209674
Train Epoch: 31 [25600/35339 (72%)]	Loss: 1.121334
Train Epoch: 31 [26240/35339 (74%)]	Loss: 1.005300
Train Epoch: 31 [26880/35339 (76%)]	Loss: 0.875811
Train Epoch: 31 [27520/35339 (78%)]	Loss: 1.069285
Train Epoch: 31 [28160/35339 (80%)]	Loss: 0.941140
Train Epoch: 31 [28800/35339 (81%)]	Loss: 1.046452
Train Epoch: 31 [29440/35339 (83%)]	Loss: 0.849905
Train Epoch: 31 [30080/35339 (85%)]	Loss: 0.915856
Train Epoch: 31 [30720/35339 (87%)]	Loss: 0.965713
Train Epoch: 31 [31360/35339 (89%)]	Loss: 0.952574
Train Epoch: 31 [32000/35339 (90%)]	Loss: 1.130030
Train Epoch: 31 [32640/35339 (92%)]	Loss: 1.104072
Train Epoch: 31 [33280/35339 (94%)]	Loss: 1.131211
Train Epoch: 31 [33920/35339 (96%)]	Loss: 0.882588
Train Epoch: 31 [34560/35339 (98%)]	Loss: 0.907844
Train Epoch: 31 [35200/35339 (99%)]	Loss: 1.084536

Validation set: Average loss: 3.7641, Accuracy: 803/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 32 [0/35339 (0%)]	Loss: 1.033965
Train Epoch: 32 [640/35339 (2%)]	Loss: 1.097002
Train Epoch: 32 [1280/35339 (4%)]	Loss: 1.105805
Train Epoch: 32 [1920/35339 (5%)]	Loss: 1.020489
Train Epoch: 32 [2560/35339 (7%)]	Loss: 1.119068
Train Epoch: 32 [3200/35339 (9%)]	Loss: 0.958226
Train Epoch: 32 [3840/35339 (11%)]	Loss: 0.890633
Train Epoch: 32 [4480/35339 (13%)]	Loss: 1.149582
Train Epoch: 32 [5120/35339 (14%)]	Loss: 0.955185
Train Epoch: 32 [5760/35339 (16%)]	Loss: 1.134115
Train Epoch: 32 [6400/35339 (18%)]	Loss: 1.049484
Train Epoch: 32 [7040/35339 (20%)]	Loss: 1.035259
Train Epoch: 32 [7680/35339 (22%)]	Loss: 1.023173
Train Epoch: 32 [8320/35339 (24%)]	Loss: 1.042507
Train Epoch: 32 [8960/35339 (25%)]	Loss: 1.066606
Train Epoch: 32 [9600/35339 (27%)]	Loss: 1.253019
Train Epoch: 32 [10240/35339 (29%)]	Loss: 1.161525
Train Epoch: 32 [10880/35339 (31%)]	Loss: 0.945545
Train Epoch: 32 [11520/35339 (33%)]	Loss: 1.136200
Train Epoch: 32 [12160/35339 (34%)]	Loss: 1.118057
Train Epoch: 32 [12800/35339 (36%)]	Loss: 1.051521
Train Epoch: 32 [13440/35339 (38%)]	Loss: 1.067104
Train Epoch: 32 [14080/35339 (40%)]	Loss: 1.010935
Train Epoch: 32 [14720/35339 (42%)]	Loss: 1.005632
Train Epoch: 32 [15360/35339 (43%)]	Loss: 1.176645
Train Epoch: 32 [16000/35339 (45%)]	Loss: 0.985479
Train Epoch: 32 [16640/35339 (47%)]	Loss: 0.925345
Train Epoch: 32 [17280/35339 (49%)]	Loss: 0.979344
Train Epoch: 32 [17920/35339 (51%)]	Loss: 0.892703
Train Epoch: 32 [18560/35339 (52%)]	Loss: 1.023429
Train Epoch: 32 [19200/35339 (54%)]	Loss: 0.914794
Train Epoch: 32 [19840/35339 (56%)]	Loss: 1.119838
Train Epoch: 32 [20480/35339 (58%)]	Loss: 1.062168
Train Epoch: 32 [21120/35339 (60%)]	Loss: 0.886396
Train Epoch: 32 [21760/35339 (61%)]	Loss: 0.856510
Train Epoch: 32 [22400/35339 (63%)]	Loss: 0.860507
Train Epoch: 32 [23040/35339 (65%)]	Loss: 0.966128
Train Epoch: 32 [23680/35339 (67%)]	Loss: 1.055190
Train Epoch: 32 [24320/35339 (69%)]	Loss: 0.999219
Train Epoch: 32 [24960/35339 (71%)]	Loss: 0.959161
Train Epoch: 32 [25600/35339 (72%)]	Loss: 0.899496
Train Epoch: 32 [26240/35339 (74%)]	Loss: 1.014538
Train Epoch: 32 [26880/35339 (76%)]	Loss: 1.111684
Train Epoch: 32 [27520/35339 (78%)]	Loss: 0.877956
Train Epoch: 32 [28160/35339 (80%)]	Loss: 1.174582
Train Epoch: 32 [28800/35339 (81%)]	Loss: 1.055424
Train Epoch: 32 [29440/35339 (83%)]	Loss: 0.959946
Train Epoch: 32 [30080/35339 (85%)]	Loss: 1.114584
Train Epoch: 32 [30720/35339 (87%)]	Loss: 0.891754
Train Epoch: 32 [31360/35339 (89%)]	Loss: 1.197916
Train Epoch: 32 [32000/35339 (90%)]	Loss: 0.950782
Train Epoch: 32 [32640/35339 (92%)]	Loss: 1.000157
Train Epoch: 32 [33280/35339 (94%)]	Loss: 1.073534
Train Epoch: 32 [33920/35339 (96%)]	Loss: 0.983816
Train Epoch: 32 [34560/35339 (98%)]	Loss: 0.980437
Train Epoch: 32 [35200/35339 (99%)]	Loss: 0.979145

Validation set: Average loss: 3.7600, Accuracy: 810/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 33 [0/35339 (0%)]	Loss: 1.063917
Train Epoch: 33 [640/35339 (2%)]	Loss: 1.037262
Train Epoch: 33 [1280/35339 (4%)]	Loss: 0.924961
Train Epoch: 33 [1920/35339 (5%)]	Loss: 1.069062
Train Epoch: 33 [2560/35339 (7%)]	Loss: 1.075468
Train Epoch: 33 [3200/35339 (9%)]	Loss: 1.051563
Train Epoch: 33 [3840/35339 (11%)]	Loss: 0.791560
Train Epoch: 33 [4480/35339 (13%)]	Loss: 1.035580
Train Epoch: 33 [5120/35339 (14%)]	Loss: 1.170938
Train Epoch: 33 [5760/35339 (16%)]	Loss: 0.871997
Train Epoch: 33 [6400/35339 (18%)]	Loss: 1.195119
Train Epoch: 33 [7040/35339 (20%)]	Loss: 1.029527
Train Epoch: 33 [7680/35339 (22%)]	Loss: 1.065727
Train Epoch: 33 [8320/35339 (24%)]	Loss: 1.094804
Train Epoch: 33 [8960/35339 (25%)]	Loss: 1.068665
Train Epoch: 33 [9600/35339 (27%)]	Loss: 1.104954
Train Epoch: 33 [10240/35339 (29%)]	Loss: 0.975812
Train Epoch: 33 [10880/35339 (31%)]	Loss: 1.030630
Train Epoch: 33 [11520/35339 (33%)]	Loss: 1.075136
Train Epoch: 33 [12160/35339 (34%)]	Loss: 1.018028
Train Epoch: 33 [12800/35339 (36%)]	Loss: 0.830350
Train Epoch: 33 [13440/35339 (38%)]	Loss: 1.079100
Train Epoch: 33 [14080/35339 (40%)]	Loss: 0.899459
Train Epoch: 33 [14720/35339 (42%)]	Loss: 1.179767
Train Epoch: 33 [15360/35339 (43%)]	Loss: 1.199713
Train Epoch: 33 [16000/35339 (45%)]	Loss: 0.845981
Train Epoch: 33 [16640/35339 (47%)]	Loss: 1.101812
Train Epoch: 33 [17280/35339 (49%)]	Loss: 1.114545
Train Epoch: 33 [17920/35339 (51%)]	Loss: 0.998812
Train Epoch: 33 [18560/35339 (52%)]	Loss: 1.117766
Train Epoch: 33 [19200/35339 (54%)]	Loss: 0.965711
Train Epoch: 33 [19840/35339 (56%)]	Loss: 1.094432
Train Epoch: 33 [20480/35339 (58%)]	Loss: 0.974748
Train Epoch: 33 [21120/35339 (60%)]	Loss: 1.190091
Train Epoch: 33 [21760/35339 (61%)]	Loss: 0.981534
Train Epoch: 33 [22400/35339 (63%)]	Loss: 1.165324
Train Epoch: 33 [23040/35339 (65%)]	Loss: 0.864728
Train Epoch: 33 [23680/35339 (67%)]	Loss: 0.951556
Train Epoch: 33 [24320/35339 (69%)]	Loss: 0.994197
Train Epoch: 33 [24960/35339 (71%)]	Loss: 0.913565
Train Epoch: 33 [25600/35339 (72%)]	Loss: 1.000264
Train Epoch: 33 [26240/35339 (74%)]	Loss: 0.827468
Train Epoch: 33 [26880/35339 (76%)]	Loss: 1.029297
Train Epoch: 33 [27520/35339 (78%)]	Loss: 0.958572
Train Epoch: 33 [28160/35339 (80%)]	Loss: 0.901290
Train Epoch: 33 [28800/35339 (81%)]	Loss: 1.085335
Train Epoch: 33 [29440/35339 (83%)]	Loss: 1.129934
Train Epoch: 33 [30080/35339 (85%)]	Loss: 1.043190
Train Epoch: 33 [30720/35339 (87%)]	Loss: 0.995057
Train Epoch: 33 [31360/35339 (89%)]	Loss: 0.838528
Train Epoch: 33 [32000/35339 (90%)]	Loss: 0.859939
Train Epoch: 33 [32640/35339 (92%)]	Loss: 1.132499
Train Epoch: 33 [33280/35339 (94%)]	Loss: 1.070366
Train Epoch: 33 [33920/35339 (96%)]	Loss: 1.066854
Train Epoch: 33 [34560/35339 (98%)]	Loss: 0.756679
Train Epoch: 33 [35200/35339 (99%)]	Loss: 0.954197

Validation set: Average loss: 3.7630, Accuracy: 797/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 34 [0/35339 (0%)]	Loss: 0.826703
Train Epoch: 34 [640/35339 (2%)]	Loss: 1.091011
Train Epoch: 34 [1280/35339 (4%)]	Loss: 1.116097
Train Epoch: 34 [1920/35339 (5%)]	Loss: 1.019389
Train Epoch: 34 [2560/35339 (7%)]	Loss: 0.965707
Train Epoch: 34 [3200/35339 (9%)]	Loss: 0.899049
Train Epoch: 34 [3840/35339 (11%)]	Loss: 0.977360
Train Epoch: 34 [4480/35339 (13%)]	Loss: 0.914529
Train Epoch: 34 [5120/35339 (14%)]	Loss: 0.778883
Train Epoch: 34 [5760/35339 (16%)]	Loss: 1.086501
Train Epoch: 34 [6400/35339 (18%)]	Loss: 1.084229
Train Epoch: 34 [7040/35339 (20%)]	Loss: 1.031982
Train Epoch: 34 [7680/35339 (22%)]	Loss: 0.967912
Train Epoch: 34 [8320/35339 (24%)]	Loss: 0.926130
Train Epoch: 34 [8960/35339 (25%)]	Loss: 1.078155
Train Epoch: 34 [9600/35339 (27%)]	Loss: 1.013266
Train Epoch: 34 [10240/35339 (29%)]	Loss: 0.884318
Train Epoch: 34 [10880/35339 (31%)]	Loss: 0.933227
Train Epoch: 34 [11520/35339 (33%)]	Loss: 1.014103
Train Epoch: 34 [12160/35339 (34%)]	Loss: 1.014177
Train Epoch: 34 [12800/35339 (36%)]	Loss: 0.989571
Train Epoch: 34 [13440/35339 (38%)]	Loss: 1.070752
Train Epoch: 34 [14080/35339 (40%)]	Loss: 0.854399
Train Epoch: 34 [14720/35339 (42%)]	Loss: 1.135166
Train Epoch: 34 [15360/35339 (43%)]	Loss: 1.315780
Train Epoch: 34 [16000/35339 (45%)]	Loss: 1.029357
Train Epoch: 34 [16640/35339 (47%)]	Loss: 0.911595
Train Epoch: 34 [17280/35339 (49%)]	Loss: 1.076143
Train Epoch: 34 [17920/35339 (51%)]	Loss: 0.959161
Train Epoch: 34 [18560/35339 (52%)]	Loss: 1.159755
Train Epoch: 34 [19200/35339 (54%)]	Loss: 1.016367
Train Epoch: 34 [19840/35339 (56%)]	Loss: 0.880366
Train Epoch: 34 [20480/35339 (58%)]	Loss: 1.008956
Train Epoch: 34 [21120/35339 (60%)]	Loss: 1.075263
Train Epoch: 34 [21760/35339 (61%)]	Loss: 1.018588
Train Epoch: 34 [22400/35339 (63%)]	Loss: 0.816314
Train Epoch: 34 [23040/35339 (65%)]	Loss: 0.891547
Train Epoch: 34 [23680/35339 (67%)]	Loss: 0.876111
Train Epoch: 34 [24320/35339 (69%)]	Loss: 0.890365
Train Epoch: 34 [24960/35339 (71%)]	Loss: 0.905922
Train Epoch: 34 [25600/35339 (72%)]	Loss: 1.136302
Train Epoch: 34 [26240/35339 (74%)]	Loss: 1.065031
Train Epoch: 34 [26880/35339 (76%)]	Loss: 1.073022
Train Epoch: 34 [27520/35339 (78%)]	Loss: 0.915379
Train Epoch: 34 [28160/35339 (80%)]	Loss: 0.961865
Train Epoch: 34 [28800/35339 (81%)]	Loss: 0.956055
Train Epoch: 34 [29440/35339 (83%)]	Loss: 0.995971
Train Epoch: 34 [30080/35339 (85%)]	Loss: 0.946359
Train Epoch: 34 [30720/35339 (87%)]	Loss: 0.983836
Train Epoch: 34 [31360/35339 (89%)]	Loss: 0.951161
Train Epoch: 34 [32000/35339 (90%)]	Loss: 0.965546
Train Epoch: 34 [32640/35339 (92%)]	Loss: 0.923107
Train Epoch: 34 [33280/35339 (94%)]	Loss: 0.953447
Train Epoch: 34 [33920/35339 (96%)]	Loss: 0.928603
Train Epoch: 34 [34560/35339 (98%)]	Loss: 0.904042
Train Epoch: 34 [35200/35339 (99%)]	Loss: 0.874353

Validation set: Average loss: 3.7657, Accuracy: 803/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 35 [0/35339 (0%)]	Loss: 0.932148
Train Epoch: 35 [640/35339 (2%)]	Loss: 0.873921
Train Epoch: 35 [1280/35339 (4%)]	Loss: 0.844648
Train Epoch: 35 [1920/35339 (5%)]	Loss: 0.904494
Train Epoch: 35 [2560/35339 (7%)]	Loss: 1.122888
Train Epoch: 35 [3200/35339 (9%)]	Loss: 1.103746
Train Epoch: 35 [3840/35339 (11%)]	Loss: 1.039805
Train Epoch: 35 [4480/35339 (13%)]	Loss: 0.777373
Train Epoch: 35 [5120/35339 (14%)]	Loss: 0.925819
Train Epoch: 35 [5760/35339 (16%)]	Loss: 1.095610
Train Epoch: 35 [6400/35339 (18%)]	Loss: 0.950921
Train Epoch: 35 [7040/35339 (20%)]	Loss: 1.007060
Train Epoch: 35 [7680/35339 (22%)]	Loss: 0.893274
Train Epoch: 35 [8320/35339 (24%)]	Loss: 0.916480
Train Epoch: 35 [8960/35339 (25%)]	Loss: 0.984382
Train Epoch: 35 [9600/35339 (27%)]	Loss: 0.796858
Train Epoch: 35 [10240/35339 (29%)]	Loss: 1.003961
Train Epoch: 35 [10880/35339 (31%)]	Loss: 1.083543
Train Epoch: 35 [11520/35339 (33%)]	Loss: 0.940612
Train Epoch: 35 [12160/35339 (34%)]	Loss: 0.912587
Train Epoch: 35 [12800/35339 (36%)]	Loss: 1.042801
Train Epoch: 35 [13440/35339 (38%)]	Loss: 0.857660
Train Epoch: 35 [14080/35339 (40%)]	Loss: 0.929367
Train Epoch: 35 [14720/35339 (42%)]	Loss: 0.926288
Train Epoch: 35 [15360/35339 (43%)]	Loss: 0.915910
Train Epoch: 35 [16000/35339 (45%)]	Loss: 0.993398
Train Epoch: 35 [16640/35339 (47%)]	Loss: 1.047823
Train Epoch: 35 [17280/35339 (49%)]	Loss: 0.892108
Train Epoch: 35 [17920/35339 (51%)]	Loss: 0.991302
Train Epoch: 35 [18560/35339 (52%)]	Loss: 1.064466
Train Epoch: 35 [19200/35339 (54%)]	Loss: 0.953568
Train Epoch: 35 [19840/35339 (56%)]	Loss: 0.957122
Train Epoch: 35 [20480/35339 (58%)]	Loss: 0.981537
Train Epoch: 35 [21120/35339 (60%)]	Loss: 0.980604
Train Epoch: 35 [21760/35339 (61%)]	Loss: 1.024852
Train Epoch: 35 [22400/35339 (63%)]	Loss: 0.930792
Train Epoch: 35 [23040/35339 (65%)]	Loss: 1.025441
Train Epoch: 35 [23680/35339 (67%)]	Loss: 0.987823
Train Epoch: 35 [24320/35339 (69%)]	Loss: 0.853223
Train Epoch: 35 [24960/35339 (71%)]	Loss: 0.995770
Train Epoch: 35 [25600/35339 (72%)]	Loss: 1.035306
Train Epoch: 35 [26240/35339 (74%)]	Loss: 0.986675
Train Epoch: 35 [26880/35339 (76%)]	Loss: 0.884253
Train Epoch: 35 [27520/35339 (78%)]	Loss: 0.824115
Train Epoch: 35 [28160/35339 (80%)]	Loss: 1.061080
Train Epoch: 35 [28800/35339 (81%)]	Loss: 1.059705
Train Epoch: 35 [29440/35339 (83%)]	Loss: 1.085634
Train Epoch: 35 [30080/35339 (85%)]	Loss: 0.889513
Train Epoch: 35 [30720/35339 (87%)]	Loss: 0.850853
Train Epoch: 35 [31360/35339 (89%)]	Loss: 0.950608
Train Epoch: 35 [32000/35339 (90%)]	Loss: 1.019876
Train Epoch: 35 [32640/35339 (92%)]	Loss: 0.940715
Train Epoch: 35 [33280/35339 (94%)]	Loss: 0.955930
Train Epoch: 35 [33920/35339 (96%)]	Loss: 1.028774
Train Epoch: 35 [34560/35339 (98%)]	Loss: 0.987671
Train Epoch: 35 [35200/35339 (99%)]	Loss: 1.021703

Validation set: Average loss: 3.7652, Accuracy: 797/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 36 [0/35339 (0%)]	Loss: 0.945009
Train Epoch: 36 [640/35339 (2%)]	Loss: 0.805045
Train Epoch: 36 [1280/35339 (4%)]	Loss: 0.789720
Train Epoch: 36 [1920/35339 (5%)]	Loss: 0.919006
Train Epoch: 36 [2560/35339 (7%)]	Loss: 1.092689
Train Epoch: 36 [3200/35339 (9%)]	Loss: 0.963906
Train Epoch: 36 [3840/35339 (11%)]	Loss: 0.868856
Train Epoch: 36 [4480/35339 (13%)]	Loss: 1.057678
Train Epoch: 36 [5120/35339 (14%)]	Loss: 0.996961
Train Epoch: 36 [5760/35339 (16%)]	Loss: 0.961131
Train Epoch: 36 [6400/35339 (18%)]	Loss: 0.996830
Train Epoch: 36 [7040/35339 (20%)]	Loss: 0.994404
Train Epoch: 36 [7680/35339 (22%)]	Loss: 0.865808
Train Epoch: 36 [8320/35339 (24%)]	Loss: 1.083844
Train Epoch: 36 [8960/35339 (25%)]	Loss: 0.972238
Train Epoch: 36 [9600/35339 (27%)]	Loss: 0.800449
Train Epoch: 36 [10240/35339 (29%)]	Loss: 0.863195
Train Epoch: 36 [10880/35339 (31%)]	Loss: 0.917879
Train Epoch: 36 [11520/35339 (33%)]	Loss: 0.903045
Train Epoch: 36 [12160/35339 (34%)]	Loss: 0.996827
Train Epoch: 36 [12800/35339 (36%)]	Loss: 1.035086
Train Epoch: 36 [13440/35339 (38%)]	Loss: 0.779853
Train Epoch: 36 [14080/35339 (40%)]	Loss: 0.894203
Train Epoch: 36 [14720/35339 (42%)]	Loss: 0.827519
Train Epoch: 36 [15360/35339 (43%)]	Loss: 1.029252
Train Epoch: 36 [16000/35339 (45%)]	Loss: 0.862448
Train Epoch: 36 [16640/35339 (47%)]	Loss: 0.744365
Train Epoch: 36 [17280/35339 (49%)]	Loss: 0.893913
Train Epoch: 36 [17920/35339 (51%)]	Loss: 0.975706
Train Epoch: 36 [18560/35339 (52%)]	Loss: 0.932333
Train Epoch: 36 [19200/35339 (54%)]	Loss: 0.926214
Train Epoch: 36 [19840/35339 (56%)]	Loss: 1.102784
Train Epoch: 36 [20480/35339 (58%)]	Loss: 1.131599
Train Epoch: 36 [21120/35339 (60%)]	Loss: 0.855269
Train Epoch: 36 [21760/35339 (61%)]	Loss: 0.786917
Train Epoch: 36 [22400/35339 (63%)]	Loss: 1.021482
Train Epoch: 36 [23040/35339 (65%)]	Loss: 0.896153
Train Epoch: 36 [23680/35339 (67%)]	Loss: 0.819597
Train Epoch: 36 [24320/35339 (69%)]	Loss: 1.039034
Train Epoch: 36 [24960/35339 (71%)]	Loss: 0.972842
Train Epoch: 36 [25600/35339 (72%)]	Loss: 0.906180
Train Epoch: 36 [26240/35339 (74%)]	Loss: 0.838879
Train Epoch: 36 [26880/35339 (76%)]	Loss: 0.722730
Train Epoch: 36 [27520/35339 (78%)]	Loss: 0.986412
Train Epoch: 36 [28160/35339 (80%)]	Loss: 1.131590
Train Epoch: 36 [28800/35339 (81%)]	Loss: 0.852937
Train Epoch: 36 [29440/35339 (83%)]	Loss: 0.928581
Train Epoch: 36 [30080/35339 (85%)]	Loss: 0.806337
Train Epoch: 36 [30720/35339 (87%)]	Loss: 0.889728
Train Epoch: 36 [31360/35339 (89%)]	Loss: 0.765355
Train Epoch: 36 [32000/35339 (90%)]	Loss: 1.037933
Train Epoch: 36 [32640/35339 (92%)]	Loss: 0.874290
Train Epoch: 36 [33280/35339 (94%)]	Loss: 0.857076
Train Epoch: 36 [33920/35339 (96%)]	Loss: 0.884861
Train Epoch: 36 [34560/35339 (98%)]	Loss: 0.894879
Train Epoch: 36 [35200/35339 (99%)]	Loss: 0.852947

Validation set: Average loss: 3.7674, Accuracy: 808/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 37 [0/35339 (0%)]	Loss: 0.934014
Train Epoch: 37 [640/35339 (2%)]	Loss: 1.019557
Train Epoch: 37 [1280/35339 (4%)]	Loss: 1.093598
Train Epoch: 37 [1920/35339 (5%)]	Loss: 0.803111
Train Epoch: 37 [2560/35339 (7%)]	Loss: 0.962695
Train Epoch: 37 [3200/35339 (9%)]	Loss: 0.822624
Train Epoch: 37 [3840/35339 (11%)]	Loss: 0.856855
Train Epoch: 37 [4480/35339 (13%)]	Loss: 1.181743
Train Epoch: 37 [5120/35339 (14%)]	Loss: 0.735908
Train Epoch: 37 [5760/35339 (16%)]	Loss: 0.839389
Train Epoch: 37 [6400/35339 (18%)]	Loss: 0.996255
Train Epoch: 37 [7040/35339 (20%)]	Loss: 1.010726
Train Epoch: 37 [7680/35339 (22%)]	Loss: 1.004746
Train Epoch: 37 [8320/35339 (24%)]	Loss: 1.158240
Train Epoch: 37 [8960/35339 (25%)]	Loss: 0.889643
Train Epoch: 37 [9600/35339 (27%)]	Loss: 0.767801
Train Epoch: 37 [10240/35339 (29%)]	Loss: 0.842386
Train Epoch: 37 [10880/35339 (31%)]	Loss: 0.809378
Train Epoch: 37 [11520/35339 (33%)]	Loss: 0.727975
Train Epoch: 37 [12160/35339 (34%)]	Loss: 0.761016
Train Epoch: 37 [12800/35339 (36%)]	Loss: 0.837917
Train Epoch: 37 [13440/35339 (38%)]	Loss: 0.959100
Train Epoch: 37 [14080/35339 (40%)]	Loss: 0.994840
Train Epoch: 37 [14720/35339 (42%)]	Loss: 1.040510
Train Epoch: 37 [15360/35339 (43%)]	Loss: 0.936675
Train Epoch: 37 [16000/35339 (45%)]	Loss: 0.849171
Train Epoch: 37 [16640/35339 (47%)]	Loss: 0.837130
Train Epoch: 37 [17280/35339 (49%)]	Loss: 1.120527
Train Epoch: 37 [17920/35339 (51%)]	Loss: 0.858201
Train Epoch: 37 [18560/35339 (52%)]	Loss: 1.180337
Train Epoch: 37 [19200/35339 (54%)]	Loss: 0.857379
Train Epoch: 37 [19840/35339 (56%)]	Loss: 1.079445
Train Epoch: 37 [20480/35339 (58%)]	Loss: 1.036965
Train Epoch: 37 [21120/35339 (60%)]	Loss: 1.129400
Train Epoch: 37 [21760/35339 (61%)]	Loss: 0.953693
Train Epoch: 37 [22400/35339 (63%)]	Loss: 1.062775
Train Epoch: 37 [23040/35339 (65%)]	Loss: 0.814862
Train Epoch: 37 [23680/35339 (67%)]	Loss: 0.755672
Train Epoch: 37 [24320/35339 (69%)]	Loss: 0.932823
Train Epoch: 37 [24960/35339 (71%)]	Loss: 0.825393
Train Epoch: 37 [25600/35339 (72%)]	Loss: 0.853271
Train Epoch: 37 [26240/35339 (74%)]	Loss: 1.038898
Train Epoch: 37 [26880/35339 (76%)]	Loss: 0.866316
Train Epoch: 37 [27520/35339 (78%)]	Loss: 1.021747
Train Epoch: 37 [28160/35339 (80%)]	Loss: 0.833247
Train Epoch: 37 [28800/35339 (81%)]	Loss: 0.976614
Train Epoch: 37 [29440/35339 (83%)]	Loss: 0.865411
Train Epoch: 37 [30080/35339 (85%)]	Loss: 0.858397
Train Epoch: 37 [30720/35339 (87%)]	Loss: 0.981701
Train Epoch: 37 [31360/35339 (89%)]	Loss: 0.771863
Train Epoch: 37 [32000/35339 (90%)]	Loss: 1.103632
Train Epoch: 37 [32640/35339 (92%)]	Loss: 0.957402
Train Epoch: 37 [33280/35339 (94%)]	Loss: 0.915346
Train Epoch: 37 [33920/35339 (96%)]	Loss: 1.105837
Train Epoch: 37 [34560/35339 (98%)]	Loss: 0.777505
Train Epoch: 37 [35200/35339 (99%)]	Loss: 0.765647

Validation set: Average loss: 3.7683, Accuracy: 796/3870 (21%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 38 [0/35339 (0%)]	Loss: 0.991609
Train Epoch: 38 [640/35339 (2%)]	Loss: 0.852942
Train Epoch: 38 [1280/35339 (4%)]	Loss: 1.142937
Train Epoch: 38 [1920/35339 (5%)]	Loss: 1.042037
Train Epoch: 38 [2560/35339 (7%)]	Loss: 0.768844
Train Epoch: 38 [3200/35339 (9%)]	Loss: 0.839338
Train Epoch: 38 [3840/35339 (11%)]	Loss: 1.067782
Train Epoch: 38 [4480/35339 (13%)]	Loss: 0.901943
Train Epoch: 38 [5120/35339 (14%)]	Loss: 0.814169
Train Epoch: 38 [5760/35339 (16%)]	Loss: 0.943287
Train Epoch: 38 [6400/35339 (18%)]	Loss: 1.051342
Train Epoch: 38 [7040/35339 (20%)]	Loss: 0.973471
Train Epoch: 38 [7680/35339 (22%)]	Loss: 0.941339
Train Epoch: 38 [8320/35339 (24%)]	Loss: 0.833452
Train Epoch: 38 [8960/35339 (25%)]	Loss: 0.966075
Train Epoch: 38 [9600/35339 (27%)]	Loss: 0.927732
Train Epoch: 38 [10240/35339 (29%)]	Loss: 1.018221
Train Epoch: 38 [10880/35339 (31%)]	Loss: 0.998850
Train Epoch: 38 [11520/35339 (33%)]	Loss: 0.872432
Train Epoch: 38 [12160/35339 (34%)]	Loss: 0.874800
Train Epoch: 38 [12800/35339 (36%)]	Loss: 1.037013
Train Epoch: 38 [13440/35339 (38%)]	Loss: 0.915160
Train Epoch: 38 [14080/35339 (40%)]	Loss: 0.808286
Train Epoch: 38 [14720/35339 (42%)]	Loss: 0.928243
Train Epoch: 38 [15360/35339 (43%)]	Loss: 0.801944
Train Epoch: 38 [16000/35339 (45%)]	Loss: 0.826963
Train Epoch: 38 [16640/35339 (47%)]	Loss: 0.803624
Train Epoch: 38 [17280/35339 (49%)]	Loss: 1.168036
Train Epoch: 38 [17920/35339 (51%)]	Loss: 1.050199
Train Epoch: 38 [18560/35339 (52%)]	Loss: 0.882930
Train Epoch: 38 [19200/35339 (54%)]	Loss: 0.922070
Train Epoch: 38 [19840/35339 (56%)]	Loss: 0.840121
Train Epoch: 38 [20480/35339 (58%)]	Loss: 0.646917
Train Epoch: 38 [21120/35339 (60%)]	Loss: 0.951406
Train Epoch: 38 [21760/35339 (61%)]	Loss: 0.829883
Train Epoch: 38 [22400/35339 (63%)]	Loss: 0.781426
Train Epoch: 38 [23040/35339 (65%)]	Loss: 0.993236
Train Epoch: 38 [23680/35339 (67%)]	Loss: 0.974451
Train Epoch: 38 [24320/35339 (69%)]	Loss: 1.213048
Train Epoch: 38 [24960/35339 (71%)]	Loss: 0.813186
Train Epoch: 38 [25600/35339 (72%)]	Loss: 0.934795
Train Epoch: 38 [26240/35339 (74%)]	Loss: 1.066028
Train Epoch: 38 [26880/35339 (76%)]	Loss: 0.817647
Train Epoch: 38 [27520/35339 (78%)]	Loss: 0.799850
Train Epoch: 38 [28160/35339 (80%)]	Loss: 0.845715
Train Epoch: 38 [28800/35339 (81%)]	Loss: 0.837445
Train Epoch: 38 [29440/35339 (83%)]	Loss: 1.041966
Train Epoch: 38 [30080/35339 (85%)]	Loss: 0.982194
Train Epoch: 38 [30720/35339 (87%)]	Loss: 0.966647
Train Epoch: 38 [31360/35339 (89%)]	Loss: 0.787073
Train Epoch: 38 [32000/35339 (90%)]	Loss: 0.921371
Train Epoch: 38 [32640/35339 (92%)]	Loss: 0.850141
Train Epoch: 38 [33280/35339 (94%)]	Loss: 1.081457
Train Epoch: 38 [33920/35339 (96%)]	Loss: 0.866267
Train Epoch: 38 [34560/35339 (98%)]	Loss: 0.888396
Train Epoch: 38 [35200/35339 (99%)]	Loss: 0.864497

Validation set: Average loss: 3.7730, Accuracy: 782/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 39 [0/35339 (0%)]	Loss: 0.934613
Train Epoch: 39 [640/35339 (2%)]	Loss: 0.938888
Train Epoch: 39 [1280/35339 (4%)]	Loss: 0.684617
Train Epoch: 39 [1920/35339 (5%)]	Loss: 0.819088
Train Epoch: 39 [2560/35339 (7%)]	Loss: 1.060489
Train Epoch: 39 [3200/35339 (9%)]	Loss: 0.903039
Train Epoch: 39 [3840/35339 (11%)]	Loss: 0.908391
Train Epoch: 39 [4480/35339 (13%)]	Loss: 0.832393
Train Epoch: 39 [5120/35339 (14%)]	Loss: 0.879616
Train Epoch: 39 [5760/35339 (16%)]	Loss: 1.068959
Train Epoch: 39 [6400/35339 (18%)]	Loss: 0.742498
Train Epoch: 39 [7040/35339 (20%)]	Loss: 1.003393
Train Epoch: 39 [7680/35339 (22%)]	Loss: 0.909055
Train Epoch: 39 [8320/35339 (24%)]	Loss: 0.811010
Train Epoch: 39 [8960/35339 (25%)]	Loss: 0.955526
Train Epoch: 39 [9600/35339 (27%)]	Loss: 0.903237
Train Epoch: 39 [10240/35339 (29%)]	Loss: 0.910203
Train Epoch: 39 [10880/35339 (31%)]	Loss: 0.889014
Train Epoch: 39 [11520/35339 (33%)]	Loss: 0.950828
Train Epoch: 39 [12160/35339 (34%)]	Loss: 0.705661
Train Epoch: 39 [12800/35339 (36%)]	Loss: 0.967057
Train Epoch: 39 [13440/35339 (38%)]	Loss: 1.005861
Train Epoch: 39 [14080/35339 (40%)]	Loss: 0.836613
Train Epoch: 39 [14720/35339 (42%)]	Loss: 0.876689
Train Epoch: 39 [15360/35339 (43%)]	Loss: 0.850841
Train Epoch: 39 [16000/35339 (45%)]	Loss: 0.688898
Train Epoch: 39 [16640/35339 (47%)]	Loss: 0.827508
Train Epoch: 39 [17280/35339 (49%)]	Loss: 0.712025
Train Epoch: 39 [17920/35339 (51%)]	Loss: 0.910364
Train Epoch: 39 [18560/35339 (52%)]	Loss: 0.967188
Train Epoch: 39 [19200/35339 (54%)]	Loss: 1.161970
Train Epoch: 39 [19840/35339 (56%)]	Loss: 0.997535
Train Epoch: 39 [20480/35339 (58%)]	Loss: 1.045886
Train Epoch: 39 [21120/35339 (60%)]	Loss: 0.981419
Train Epoch: 39 [21760/35339 (61%)]	Loss: 0.743554
Train Epoch: 39 [22400/35339 (63%)]	Loss: 1.010964
Train Epoch: 39 [23040/35339 (65%)]	Loss: 0.813170
Train Epoch: 39 [23680/35339 (67%)]	Loss: 1.021289
Train Epoch: 39 [24320/35339 (69%)]	Loss: 0.750095
Train Epoch: 39 [24960/35339 (71%)]	Loss: 0.826517
Train Epoch: 39 [25600/35339 (72%)]	Loss: 0.871171
Train Epoch: 39 [26240/35339 (74%)]	Loss: 0.949680
Train Epoch: 39 [26880/35339 (76%)]	Loss: 0.997365
Train Epoch: 39 [27520/35339 (78%)]	Loss: 0.807446
Train Epoch: 39 [28160/35339 (80%)]	Loss: 0.952890
Train Epoch: 39 [28800/35339 (81%)]	Loss: 1.011848
Train Epoch: 39 [29440/35339 (83%)]	Loss: 0.771148
Train Epoch: 39 [30080/35339 (85%)]	Loss: 0.890061
Train Epoch: 39 [30720/35339 (87%)]	Loss: 0.953442
Train Epoch: 39 [31360/35339 (89%)]	Loss: 0.778863
Train Epoch: 39 [32000/35339 (90%)]	Loss: 0.918581
Train Epoch: 39 [32640/35339 (92%)]	Loss: 0.858863
Train Epoch: 39 [33280/35339 (94%)]	Loss: 0.763317
Train Epoch: 39 [33920/35339 (96%)]	Loss: 0.920894
Train Epoch: 39 [34560/35339 (98%)]	Loss: 0.914280
Train Epoch: 39 [35200/35339 (99%)]	Loss: 0.750998

Validation set: Average loss: 3.7748, Accuracy: 791/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 40 [0/35339 (0%)]	Loss: 0.951116
Train Epoch: 40 [640/35339 (2%)]	Loss: 1.093222
Train Epoch: 40 [1280/35339 (4%)]	Loss: 1.097678
Train Epoch: 40 [1920/35339 (5%)]	Loss: 0.985322
Train Epoch: 40 [2560/35339 (7%)]	Loss: 0.932662
Train Epoch: 40 [3200/35339 (9%)]	Loss: 0.698983
Train Epoch: 40 [3840/35339 (11%)]	Loss: 0.841787
Train Epoch: 40 [4480/35339 (13%)]	Loss: 0.817594
Train Epoch: 40 [5120/35339 (14%)]	Loss: 0.894014
Train Epoch: 40 [5760/35339 (16%)]	Loss: 1.013232
Train Epoch: 40 [6400/35339 (18%)]	Loss: 0.919890
Train Epoch: 40 [7040/35339 (20%)]	Loss: 0.799988
Train Epoch: 40 [7680/35339 (22%)]	Loss: 0.819508
Train Epoch: 40 [8320/35339 (24%)]	Loss: 0.763513
Train Epoch: 40 [8960/35339 (25%)]	Loss: 0.872011
Train Epoch: 40 [9600/35339 (27%)]	Loss: 0.907821
Train Epoch: 40 [10240/35339 (29%)]	Loss: 0.892197
Train Epoch: 40 [10880/35339 (31%)]	Loss: 0.855652
Train Epoch: 40 [11520/35339 (33%)]	Loss: 0.916483
Train Epoch: 40 [12160/35339 (34%)]	Loss: 0.898809
Train Epoch: 40 [12800/35339 (36%)]	Loss: 0.806948
Train Epoch: 40 [13440/35339 (38%)]	Loss: 0.887128
Train Epoch: 40 [14080/35339 (40%)]	Loss: 0.814264
Train Epoch: 40 [14720/35339 (42%)]	Loss: 0.867970
Train Epoch: 40 [15360/35339 (43%)]	Loss: 1.010303
Train Epoch: 40 [16000/35339 (45%)]	Loss: 0.916343
Train Epoch: 40 [16640/35339 (47%)]	Loss: 0.762864
Train Epoch: 40 [17280/35339 (49%)]	Loss: 0.879858
Train Epoch: 40 [17920/35339 (51%)]	Loss: 0.923976
Train Epoch: 40 [18560/35339 (52%)]	Loss: 0.794289
Train Epoch: 40 [19200/35339 (54%)]	Loss: 0.853016
Train Epoch: 40 [19840/35339 (56%)]	Loss: 0.944805
Train Epoch: 40 [20480/35339 (58%)]	Loss: 0.810691
Train Epoch: 40 [21120/35339 (60%)]	Loss: 0.867309
Train Epoch: 40 [21760/35339 (61%)]	Loss: 0.874130
Train Epoch: 40 [22400/35339 (63%)]	Loss: 0.983514
Train Epoch: 40 [23040/35339 (65%)]	Loss: 0.945687
Train Epoch: 40 [23680/35339 (67%)]	Loss: 0.892785
Train Epoch: 40 [24320/35339 (69%)]	Loss: 0.920961
Train Epoch: 40 [24960/35339 (71%)]	Loss: 0.863099
Train Epoch: 40 [25600/35339 (72%)]	Loss: 0.938266
Train Epoch: 40 [26240/35339 (74%)]	Loss: 1.044805
Train Epoch: 40 [26880/35339 (76%)]	Loss: 0.977041
Train Epoch: 40 [27520/35339 (78%)]	Loss: 0.835354
Train Epoch: 40 [28160/35339 (80%)]	Loss: 0.813058
Train Epoch: 40 [28800/35339 (81%)]	Loss: 0.935858
Train Epoch: 40 [29440/35339 (83%)]	Loss: 0.928797
Train Epoch: 40 [30080/35339 (85%)]	Loss: 0.738633
Train Epoch: 40 [30720/35339 (87%)]	Loss: 0.645604
Train Epoch: 40 [31360/35339 (89%)]	Loss: 0.886146
Train Epoch: 40 [32000/35339 (90%)]	Loss: 0.843106
Train Epoch: 40 [32640/35339 (92%)]	Loss: 0.860981
Train Epoch: 40 [33280/35339 (94%)]	Loss: 0.945760
Train Epoch: 40 [33920/35339 (96%)]	Loss: 1.145535
Train Epoch: 40 [34560/35339 (98%)]	Loss: 0.957011
Train Epoch: 40 [35200/35339 (99%)]	Loss: 0.810344

Validation set: Average loss: 3.7700, Accuracy: 756/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 41 [0/35339 (0%)]	Loss: 0.870169
Train Epoch: 41 [640/35339 (2%)]	Loss: 0.911703
Train Epoch: 41 [1280/35339 (4%)]	Loss: 1.090192
Train Epoch: 41 [1920/35339 (5%)]	Loss: 0.777664
Train Epoch: 41 [2560/35339 (7%)]	Loss: 0.751910
Train Epoch: 41 [3200/35339 (9%)]	Loss: 0.830267
Train Epoch: 41 [3840/35339 (11%)]	Loss: 0.898379
Train Epoch: 41 [4480/35339 (13%)]	Loss: 0.697037
Train Epoch: 41 [5120/35339 (14%)]	Loss: 0.915678
Train Epoch: 41 [5760/35339 (16%)]	Loss: 0.841196
Train Epoch: 41 [6400/35339 (18%)]	Loss: 0.890226
Train Epoch: 41 [7040/35339 (20%)]	Loss: 0.634793
Train Epoch: 41 [7680/35339 (22%)]	Loss: 0.895525
Train Epoch: 41 [8320/35339 (24%)]	Loss: 0.818329
Train Epoch: 41 [8960/35339 (25%)]	Loss: 1.013433
Train Epoch: 41 [9600/35339 (27%)]	Loss: 0.859085
Train Epoch: 41 [10240/35339 (29%)]	Loss: 0.848061
Train Epoch: 41 [10880/35339 (31%)]	Loss: 0.883867
Train Epoch: 41 [11520/35339 (33%)]	Loss: 0.886587
Train Epoch: 41 [12160/35339 (34%)]	Loss: 0.923636
Train Epoch: 41 [12800/35339 (36%)]	Loss: 0.855238
Train Epoch: 41 [13440/35339 (38%)]	Loss: 0.840559
Train Epoch: 41 [14080/35339 (40%)]	Loss: 0.730126
Train Epoch: 41 [14720/35339 (42%)]	Loss: 0.862046
Train Epoch: 41 [15360/35339 (43%)]	Loss: 0.859765
Train Epoch: 41 [16000/35339 (45%)]	Loss: 0.946332
Train Epoch: 41 [16640/35339 (47%)]	Loss: 0.849636
Train Epoch: 41 [17280/35339 (49%)]	Loss: 0.966814
Train Epoch: 41 [17920/35339 (51%)]	Loss: 0.935431
Train Epoch: 41 [18560/35339 (52%)]	Loss: 0.909722
Train Epoch: 41 [19200/35339 (54%)]	Loss: 0.962132
Train Epoch: 41 [19840/35339 (56%)]	Loss: 0.942720
Train Epoch: 41 [20480/35339 (58%)]	Loss: 0.840720
Train Epoch: 41 [21120/35339 (60%)]	Loss: 0.781708
Train Epoch: 41 [21760/35339 (61%)]	Loss: 0.933074
Train Epoch: 41 [22400/35339 (63%)]	Loss: 0.926350
Train Epoch: 41 [23040/35339 (65%)]	Loss: 0.817650
Train Epoch: 41 [23680/35339 (67%)]	Loss: 0.923798
Train Epoch: 41 [24320/35339 (69%)]	Loss: 0.919035
Train Epoch: 41 [24960/35339 (71%)]	Loss: 0.946121
Train Epoch: 41 [25600/35339 (72%)]	Loss: 0.987138
Train Epoch: 41 [26240/35339 (74%)]	Loss: 0.860340
Train Epoch: 41 [26880/35339 (76%)]	Loss: 0.866280
Train Epoch: 41 [27520/35339 (78%)]	Loss: 1.083886
Train Epoch: 41 [28160/35339 (80%)]	Loss: 0.855914
Train Epoch: 41 [28800/35339 (81%)]	Loss: 0.836948
Train Epoch: 41 [29440/35339 (83%)]	Loss: 0.840402
Train Epoch: 41 [30080/35339 (85%)]	Loss: 0.907012
Train Epoch: 41 [30720/35339 (87%)]	Loss: 1.024062
Train Epoch: 41 [31360/35339 (89%)]	Loss: 0.829121
Train Epoch: 41 [32000/35339 (90%)]	Loss: 0.690477
Train Epoch: 41 [32640/35339 (92%)]	Loss: 0.984238
Train Epoch: 41 [33280/35339 (94%)]	Loss: 0.797094
Train Epoch: 41 [33920/35339 (96%)]	Loss: 1.018727
Train Epoch: 41 [34560/35339 (98%)]	Loss: 0.755498
Train Epoch: 41 [35200/35339 (99%)]	Loss: 0.863228

Validation set: Average loss: 3.7747, Accuracy: 778/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 42 [0/35339 (0%)]	Loss: 0.812627
Train Epoch: 42 [640/35339 (2%)]	Loss: 0.788390
Train Epoch: 42 [1280/35339 (4%)]	Loss: 0.997746
Train Epoch: 42 [1920/35339 (5%)]	Loss: 0.850623
Train Epoch: 42 [2560/35339 (7%)]	Loss: 0.796712
Train Epoch: 42 [3200/35339 (9%)]	Loss: 0.757709
Train Epoch: 42 [3840/35339 (11%)]	Loss: 0.674779
Train Epoch: 42 [4480/35339 (13%)]	Loss: 0.797803
Train Epoch: 42 [5120/35339 (14%)]	Loss: 1.101067
Train Epoch: 42 [5760/35339 (16%)]	Loss: 0.859856
Train Epoch: 42 [6400/35339 (18%)]	Loss: 0.821954
Train Epoch: 42 [7040/35339 (20%)]	Loss: 1.010140
Train Epoch: 42 [7680/35339 (22%)]	Loss: 1.052849
Train Epoch: 42 [8320/35339 (24%)]	Loss: 0.803912
Train Epoch: 42 [8960/35339 (25%)]	Loss: 0.764542
Train Epoch: 42 [9600/35339 (27%)]	Loss: 0.853271
Train Epoch: 42 [10240/35339 (29%)]	Loss: 0.797615
Train Epoch: 42 [10880/35339 (31%)]	Loss: 0.872643
Train Epoch: 42 [11520/35339 (33%)]	Loss: 0.913596
Train Epoch: 42 [12160/35339 (34%)]	Loss: 0.805918
Train Epoch: 42 [12800/35339 (36%)]	Loss: 0.800278
Train Epoch: 42 [13440/35339 (38%)]	Loss: 0.799137
Train Epoch: 42 [14080/35339 (40%)]	Loss: 0.862841
Train Epoch: 42 [14720/35339 (42%)]	Loss: 0.945786
Train Epoch: 42 [15360/35339 (43%)]	Loss: 0.963929
Train Epoch: 42 [16000/35339 (45%)]	Loss: 0.797193
Train Epoch: 42 [16640/35339 (47%)]	Loss: 0.704434
Train Epoch: 42 [17280/35339 (49%)]	Loss: 0.894915
Train Epoch: 42 [17920/35339 (51%)]	Loss: 0.830099
Train Epoch: 42 [18560/35339 (52%)]	Loss: 1.001605
Train Epoch: 42 [19200/35339 (54%)]	Loss: 0.807197
Train Epoch: 42 [19840/35339 (56%)]	Loss: 0.951770
Train Epoch: 42 [20480/35339 (58%)]	Loss: 0.763315
Train Epoch: 42 [21120/35339 (60%)]	Loss: 0.908620
Train Epoch: 42 [21760/35339 (61%)]	Loss: 0.849896
Train Epoch: 42 [22400/35339 (63%)]	Loss: 1.108527
Train Epoch: 42 [23040/35339 (65%)]	Loss: 0.852693
Train Epoch: 42 [23680/35339 (67%)]	Loss: 0.744751
Train Epoch: 42 [24320/35339 (69%)]	Loss: 0.883520
Train Epoch: 42 [24960/35339 (71%)]	Loss: 0.766512
Train Epoch: 42 [25600/35339 (72%)]	Loss: 0.832523
Train Epoch: 42 [26240/35339 (74%)]	Loss: 0.863464
Train Epoch: 42 [26880/35339 (76%)]	Loss: 0.854000
Train Epoch: 42 [27520/35339 (78%)]	Loss: 0.780329
Train Epoch: 42 [28160/35339 (80%)]	Loss: 0.950829
Train Epoch: 42 [28800/35339 (81%)]	Loss: 0.991684
Train Epoch: 42 [29440/35339 (83%)]	Loss: 0.781685
Train Epoch: 42 [30080/35339 (85%)]	Loss: 1.009788
Train Epoch: 42 [30720/35339 (87%)]	Loss: 0.862635
Train Epoch: 42 [31360/35339 (89%)]	Loss: 0.710309
Train Epoch: 42 [32000/35339 (90%)]	Loss: 0.809676
Train Epoch: 42 [32640/35339 (92%)]	Loss: 0.771654
Train Epoch: 42 [33280/35339 (94%)]	Loss: 0.960428
Train Epoch: 42 [33920/35339 (96%)]	Loss: 0.729674
Train Epoch: 42 [34560/35339 (98%)]	Loss: 0.973075
Train Epoch: 42 [35200/35339 (99%)]	Loss: 0.994084

Validation set: Average loss: 3.7735, Accuracy: 772/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 43 [0/35339 (0%)]	Loss: 0.853157
Train Epoch: 43 [640/35339 (2%)]	Loss: 0.808704
Train Epoch: 43 [1280/35339 (4%)]	Loss: 1.058293
Train Epoch: 43 [1920/35339 (5%)]	Loss: 0.984388
Train Epoch: 43 [2560/35339 (7%)]	Loss: 0.925359
Train Epoch: 43 [3200/35339 (9%)]	Loss: 0.761904
Train Epoch: 43 [3840/35339 (11%)]	Loss: 0.968765
Train Epoch: 43 [4480/35339 (13%)]	Loss: 0.876744
Train Epoch: 43 [5120/35339 (14%)]	Loss: 1.026564
Train Epoch: 43 [5760/35339 (16%)]	Loss: 0.981382
Train Epoch: 43 [6400/35339 (18%)]	Loss: 0.839256
Train Epoch: 43 [7040/35339 (20%)]	Loss: 0.847849
Train Epoch: 43 [7680/35339 (22%)]	Loss: 0.767662
Train Epoch: 43 [8320/35339 (24%)]	Loss: 0.837338
Train Epoch: 43 [8960/35339 (25%)]	Loss: 0.819685
Train Epoch: 43 [9600/35339 (27%)]	Loss: 0.866166
Train Epoch: 43 [10240/35339 (29%)]	Loss: 0.708135
Train Epoch: 43 [10880/35339 (31%)]	Loss: 0.932520
Train Epoch: 43 [11520/35339 (33%)]	Loss: 0.804739
Train Epoch: 43 [12160/35339 (34%)]	Loss: 0.838499
Train Epoch: 43 [12800/35339 (36%)]	Loss: 0.785737
Train Epoch: 43 [13440/35339 (38%)]	Loss: 0.929214
Train Epoch: 43 [14080/35339 (40%)]	Loss: 0.862142
Train Epoch: 43 [14720/35339 (42%)]	Loss: 0.722229
Train Epoch: 43 [15360/35339 (43%)]	Loss: 0.919038
Train Epoch: 43 [16000/35339 (45%)]	Loss: 0.969796
Train Epoch: 43 [16640/35339 (47%)]	Loss: 0.693405
Train Epoch: 43 [17280/35339 (49%)]	Loss: 0.772313
Train Epoch: 43 [17920/35339 (51%)]	Loss: 0.902682
Train Epoch: 43 [18560/35339 (52%)]	Loss: 1.033393
Train Epoch: 43 [19200/35339 (54%)]	Loss: 0.985736
Train Epoch: 43 [19840/35339 (56%)]	Loss: 1.035879
Train Epoch: 43 [20480/35339 (58%)]	Loss: 0.886820
Train Epoch: 43 [21120/35339 (60%)]	Loss: 0.840042
Train Epoch: 43 [21760/35339 (61%)]	Loss: 0.748171
Train Epoch: 43 [22400/35339 (63%)]	Loss: 0.924211
Train Epoch: 43 [23040/35339 (65%)]	Loss: 0.923365
Train Epoch: 43 [23680/35339 (67%)]	Loss: 0.711898
Train Epoch: 43 [24320/35339 (69%)]	Loss: 0.841755
Train Epoch: 43 [24960/35339 (71%)]	Loss: 0.831806
Train Epoch: 43 [25600/35339 (72%)]	Loss: 0.934794
Train Epoch: 43 [26240/35339 (74%)]	Loss: 0.676291
Train Epoch: 43 [26880/35339 (76%)]	Loss: 0.809707
Train Epoch: 43 [27520/35339 (78%)]	Loss: 0.792223
Train Epoch: 43 [28160/35339 (80%)]	Loss: 0.894295
Train Epoch: 43 [28800/35339 (81%)]	Loss: 0.786798
Train Epoch: 43 [29440/35339 (83%)]	Loss: 0.964772
Train Epoch: 43 [30080/35339 (85%)]	Loss: 0.763224
Train Epoch: 43 [30720/35339 (87%)]	Loss: 0.831488
Train Epoch: 43 [31360/35339 (89%)]	Loss: 0.834243
Train Epoch: 43 [32000/35339 (90%)]	Loss: 0.911944
Train Epoch: 43 [32640/35339 (92%)]	Loss: 1.107010
Train Epoch: 43 [33280/35339 (94%)]	Loss: 0.886615
Train Epoch: 43 [33920/35339 (96%)]	Loss: 0.694035
Train Epoch: 43 [34560/35339 (98%)]	Loss: 0.982109
Train Epoch: 43 [35200/35339 (99%)]	Loss: 0.899915

Validation set: Average loss: 3.7724, Accuracy: 775/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 44 [0/35339 (0%)]	Loss: 0.764021
Train Epoch: 44 [640/35339 (2%)]	Loss: 0.908190
Train Epoch: 44 [1280/35339 (4%)]	Loss: 0.952356
Train Epoch: 44 [1920/35339 (5%)]	Loss: 0.860400
Train Epoch: 44 [2560/35339 (7%)]	Loss: 0.811221
Train Epoch: 44 [3200/35339 (9%)]	Loss: 0.750846
Train Epoch: 44 [3840/35339 (11%)]	Loss: 0.827581
Train Epoch: 44 [4480/35339 (13%)]	Loss: 0.893493
Train Epoch: 44 [5120/35339 (14%)]	Loss: 0.829597
Train Epoch: 44 [5760/35339 (16%)]	Loss: 1.109575
Train Epoch: 44 [6400/35339 (18%)]	Loss: 0.962865
Train Epoch: 44 [7040/35339 (20%)]	Loss: 1.052900
Train Epoch: 44 [7680/35339 (22%)]	Loss: 0.874579
Train Epoch: 44 [8320/35339 (24%)]	Loss: 0.851557
Train Epoch: 44 [8960/35339 (25%)]	Loss: 0.965663
Train Epoch: 44 [9600/35339 (27%)]	Loss: 0.744545
Train Epoch: 44 [10240/35339 (29%)]	Loss: 0.774495
Train Epoch: 44 [10880/35339 (31%)]	Loss: 0.890551
Train Epoch: 44 [11520/35339 (33%)]	Loss: 0.767304
Train Epoch: 44 [12160/35339 (34%)]	Loss: 0.862224
Train Epoch: 44 [12800/35339 (36%)]	Loss: 0.821876
Train Epoch: 44 [13440/35339 (38%)]	Loss: 0.779668
Train Epoch: 44 [14080/35339 (40%)]	Loss: 0.903619
Train Epoch: 44 [14720/35339 (42%)]	Loss: 0.829252
Train Epoch: 44 [15360/35339 (43%)]	Loss: 0.769139
Train Epoch: 44 [16000/35339 (45%)]	Loss: 0.947634
Train Epoch: 44 [16640/35339 (47%)]	Loss: 0.641393
Train Epoch: 44 [17280/35339 (49%)]	Loss: 1.005869
Train Epoch: 44 [17920/35339 (51%)]	Loss: 0.714094
Train Epoch: 44 [18560/35339 (52%)]	Loss: 0.798204
Train Epoch: 44 [19200/35339 (54%)]	Loss: 0.992159
Train Epoch: 44 [19840/35339 (56%)]	Loss: 0.896439
Train Epoch: 44 [20480/35339 (58%)]	Loss: 0.970706
Train Epoch: 44 [21120/35339 (60%)]	Loss: 0.811075
Train Epoch: 44 [21760/35339 (61%)]	Loss: 0.802588
Train Epoch: 44 [22400/35339 (63%)]	Loss: 0.870379
Train Epoch: 44 [23040/35339 (65%)]	Loss: 1.092006
Train Epoch: 44 [23680/35339 (67%)]	Loss: 0.799641
Train Epoch: 44 [24320/35339 (69%)]	Loss: 0.866340
Train Epoch: 44 [24960/35339 (71%)]	Loss: 0.840062
Train Epoch: 44 [25600/35339 (72%)]	Loss: 0.801513
Train Epoch: 44 [26240/35339 (74%)]	Loss: 0.783305
Train Epoch: 44 [26880/35339 (76%)]	Loss: 0.813880
Train Epoch: 44 [27520/35339 (78%)]	Loss: 0.834948
Train Epoch: 44 [28160/35339 (80%)]	Loss: 0.798204
Train Epoch: 44 [28800/35339 (81%)]	Loss: 0.906295
Train Epoch: 44 [29440/35339 (83%)]	Loss: 0.822368
Train Epoch: 44 [30080/35339 (85%)]	Loss: 0.838815
Train Epoch: 44 [30720/35339 (87%)]	Loss: 0.862671
Train Epoch: 44 [31360/35339 (89%)]	Loss: 0.859417
Train Epoch: 44 [32000/35339 (90%)]	Loss: 0.706852
Train Epoch: 44 [32640/35339 (92%)]	Loss: 0.863073
Train Epoch: 44 [33280/35339 (94%)]	Loss: 1.088773
Train Epoch: 44 [33920/35339 (96%)]	Loss: 1.134377
Train Epoch: 44 [34560/35339 (98%)]	Loss: 0.888637
Train Epoch: 44 [35200/35339 (99%)]	Loss: 0.871569

Validation set: Average loss: 3.7793, Accuracy: 761/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 45 [0/35339 (0%)]	Loss: 0.765647
Train Epoch: 45 [640/35339 (2%)]	Loss: 0.791386
Train Epoch: 45 [1280/35339 (4%)]	Loss: 1.055381
Train Epoch: 45 [1920/35339 (5%)]	Loss: 0.774971
Train Epoch: 45 [2560/35339 (7%)]	Loss: 0.936968
Train Epoch: 45 [3200/35339 (9%)]	Loss: 0.752817
Train Epoch: 45 [3840/35339 (11%)]	Loss: 1.045006
Train Epoch: 45 [4480/35339 (13%)]	Loss: 0.831755
Train Epoch: 45 [5120/35339 (14%)]	Loss: 0.914257
Train Epoch: 45 [5760/35339 (16%)]	Loss: 0.779883
Train Epoch: 45 [6400/35339 (18%)]	Loss: 0.884752
Train Epoch: 45 [7040/35339 (20%)]	Loss: 0.953254
Train Epoch: 45 [7680/35339 (22%)]	Loss: 0.804973
Train Epoch: 45 [8320/35339 (24%)]	Loss: 0.831721
Train Epoch: 45 [8960/35339 (25%)]	Loss: 0.856182
Train Epoch: 45 [9600/35339 (27%)]	Loss: 0.784244
Train Epoch: 45 [10240/35339 (29%)]	Loss: 0.856304
Train Epoch: 45 [10880/35339 (31%)]	Loss: 1.086307
Train Epoch: 45 [11520/35339 (33%)]	Loss: 0.960698
Train Epoch: 45 [12160/35339 (34%)]	Loss: 0.782278
Train Epoch: 45 [12800/35339 (36%)]	Loss: 0.943777
Train Epoch: 45 [13440/35339 (38%)]	Loss: 0.867085
Train Epoch: 45 [14080/35339 (40%)]	Loss: 0.822481
Train Epoch: 45 [14720/35339 (42%)]	Loss: 0.815825
Train Epoch: 45 [15360/35339 (43%)]	Loss: 0.759223
Train Epoch: 45 [16000/35339 (45%)]	Loss: 0.831446
Train Epoch: 45 [16640/35339 (47%)]	Loss: 0.902017
Train Epoch: 45 [17280/35339 (49%)]	Loss: 0.962377
Train Epoch: 45 [17920/35339 (51%)]	Loss: 0.848565
Train Epoch: 45 [18560/35339 (52%)]	Loss: 0.836714
Train Epoch: 45 [19200/35339 (54%)]	Loss: 0.885180
Train Epoch: 45 [19840/35339 (56%)]	Loss: 0.799121
Train Epoch: 45 [20480/35339 (58%)]	Loss: 0.776782
Train Epoch: 45 [21120/35339 (60%)]	Loss: 0.825455
Train Epoch: 45 [21760/35339 (61%)]	Loss: 0.752509
Train Epoch: 45 [22400/35339 (63%)]	Loss: 1.085169
Train Epoch: 45 [23040/35339 (65%)]	Loss: 0.742743
Train Epoch: 45 [23680/35339 (67%)]	Loss: 0.914498
Train Epoch: 45 [24320/35339 (69%)]	Loss: 0.680493
Train Epoch: 45 [24960/35339 (71%)]	Loss: 0.822772
Train Epoch: 45 [25600/35339 (72%)]	Loss: 0.920850
Train Epoch: 45 [26240/35339 (74%)]	Loss: 0.685427
Train Epoch: 45 [26880/35339 (76%)]	Loss: 0.758979
Train Epoch: 45 [27520/35339 (78%)]	Loss: 0.729867
Train Epoch: 45 [28160/35339 (80%)]	Loss: 0.775939
Train Epoch: 45 [28800/35339 (81%)]	Loss: 0.798299
Train Epoch: 45 [29440/35339 (83%)]	Loss: 1.018270
Train Epoch: 45 [30080/35339 (85%)]	Loss: 0.858804
Train Epoch: 45 [30720/35339 (87%)]	Loss: 0.631012
Train Epoch: 45 [31360/35339 (89%)]	Loss: 0.697634
Train Epoch: 45 [32000/35339 (90%)]	Loss: 0.877447
Train Epoch: 45 [32640/35339 (92%)]	Loss: 0.620862
Train Epoch: 45 [33280/35339 (94%)]	Loss: 0.921629
Train Epoch: 45 [33920/35339 (96%)]	Loss: 0.795037
Train Epoch: 45 [34560/35339 (98%)]	Loss: 0.950013
Train Epoch: 45 [35200/35339 (99%)]	Loss: 1.084140

Validation set: Average loss: 3.7737, Accuracy: 762/3870 (20%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 46 [0/35339 (0%)]	Loss: 0.886972
Train Epoch: 46 [640/35339 (2%)]	Loss: 0.989097
Train Epoch: 46 [1280/35339 (4%)]	Loss: 0.774183
Train Epoch: 46 [1920/35339 (5%)]	Loss: 0.734323
Train Epoch: 46 [2560/35339 (7%)]	Loss: 0.853511
Train Epoch: 46 [3200/35339 (9%)]	Loss: 0.857722
Train Epoch: 46 [3840/35339 (11%)]	Loss: 0.954991
Train Epoch: 46 [4480/35339 (13%)]	Loss: 0.797264
Train Epoch: 46 [5120/35339 (14%)]	Loss: 0.957647
Train Epoch: 46 [5760/35339 (16%)]	Loss: 0.846522
Train Epoch: 46 [6400/35339 (18%)]	Loss: 0.917867
Train Epoch: 46 [7040/35339 (20%)]	Loss: 0.743157
Train Epoch: 46 [7680/35339 (22%)]	Loss: 0.945069
Train Epoch: 46 [8320/35339 (24%)]	Loss: 0.726710
Train Epoch: 46 [8960/35339 (25%)]	Loss: 0.802404
Train Epoch: 46 [9600/35339 (27%)]	Loss: 0.695936
Train Epoch: 46 [10240/35339 (29%)]	Loss: 0.715157
Train Epoch: 46 [10880/35339 (31%)]	Loss: 0.752420
Train Epoch: 46 [11520/35339 (33%)]	Loss: 0.939372
Train Epoch: 46 [12160/35339 (34%)]	Loss: 0.888969
Train Epoch: 46 [12800/35339 (36%)]	Loss: 0.917858
Train Epoch: 46 [13440/35339 (38%)]	Loss: 0.766856
Train Epoch: 46 [14080/35339 (40%)]	Loss: 0.947435
Train Epoch: 46 [14720/35339 (42%)]	Loss: 0.907898
Train Epoch: 46 [15360/35339 (43%)]	Loss: 0.821459
Train Epoch: 46 [16000/35339 (45%)]	Loss: 0.879376
Train Epoch: 46 [16640/35339 (47%)]	Loss: 0.759292
Train Epoch: 46 [17280/35339 (49%)]	Loss: 0.922414
Train Epoch: 46 [17920/35339 (51%)]	Loss: 0.741397
Train Epoch: 46 [18560/35339 (52%)]	Loss: 0.760440
Train Epoch: 46 [19200/35339 (54%)]	Loss: 0.859244
Train Epoch: 46 [19840/35339 (56%)]	Loss: 0.920875
Train Epoch: 46 [20480/35339 (58%)]	Loss: 1.029536
Train Epoch: 46 [21120/35339 (60%)]	Loss: 1.028702
Train Epoch: 46 [21760/35339 (61%)]	Loss: 0.830621
Train Epoch: 46 [22400/35339 (63%)]	Loss: 0.870071
Train Epoch: 46 [23040/35339 (65%)]	Loss: 0.856063
Train Epoch: 46 [23680/35339 (67%)]	Loss: 0.726808
Train Epoch: 46 [24320/35339 (69%)]	Loss: 0.852294
Train Epoch: 46 [24960/35339 (71%)]	Loss: 0.939052
Train Epoch: 46 [25600/35339 (72%)]	Loss: 0.827417
Train Epoch: 46 [26240/35339 (74%)]	Loss: 0.926758
Train Epoch: 46 [26880/35339 (76%)]	Loss: 0.947756
Train Epoch: 46 [27520/35339 (78%)]	Loss: 0.854603
Train Epoch: 46 [28160/35339 (80%)]	Loss: 0.695787
Train Epoch: 46 [28800/35339 (81%)]	Loss: 0.832708
Train Epoch: 46 [29440/35339 (83%)]	Loss: 0.898189
Train Epoch: 46 [30080/35339 (85%)]	Loss: 1.044132
Train Epoch: 46 [30720/35339 (87%)]	Loss: 0.700773
Train Epoch: 46 [31360/35339 (89%)]	Loss: 0.528153
Train Epoch: 46 [32000/35339 (90%)]	Loss: 0.873255
Train Epoch: 46 [32640/35339 (92%)]	Loss: 0.989574
Train Epoch: 46 [33280/35339 (94%)]	Loss: 1.050243
Train Epoch: 46 [33920/35339 (96%)]	Loss: 0.910484
Train Epoch: 46 [34560/35339 (98%)]	Loss: 0.816088
Train Epoch: 46 [35200/35339 (99%)]	Loss: 0.782986

Validation set: Average loss: 3.7738, Accuracy: 744/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 47 [0/35339 (0%)]	Loss: 0.788425
Train Epoch: 47 [640/35339 (2%)]	Loss: 0.871849
Train Epoch: 47 [1280/35339 (4%)]	Loss: 0.786396
Train Epoch: 47 [1920/35339 (5%)]	Loss: 0.814425
Train Epoch: 47 [2560/35339 (7%)]	Loss: 0.809180
Train Epoch: 47 [3200/35339 (9%)]	Loss: 0.955451
Train Epoch: 47 [3840/35339 (11%)]	Loss: 1.007574
Train Epoch: 47 [4480/35339 (13%)]	Loss: 0.890101
Train Epoch: 47 [5120/35339 (14%)]	Loss: 0.886499
Train Epoch: 47 [5760/35339 (16%)]	Loss: 0.986099
Train Epoch: 47 [6400/35339 (18%)]	Loss: 0.731652
Train Epoch: 47 [7040/35339 (20%)]	Loss: 0.920737
Train Epoch: 47 [7680/35339 (22%)]	Loss: 0.691569
Train Epoch: 47 [8320/35339 (24%)]	Loss: 0.820901
Train Epoch: 47 [8960/35339 (25%)]	Loss: 0.772162
Train Epoch: 47 [9600/35339 (27%)]	Loss: 0.979933
Train Epoch: 47 [10240/35339 (29%)]	Loss: 0.771334
Train Epoch: 47 [10880/35339 (31%)]	Loss: 0.789340
Train Epoch: 47 [11520/35339 (33%)]	Loss: 0.952281
Train Epoch: 47 [12160/35339 (34%)]	Loss: 0.686587
Train Epoch: 47 [12800/35339 (36%)]	Loss: 0.826923
Train Epoch: 47 [13440/35339 (38%)]	Loss: 0.958307
Train Epoch: 47 [14080/35339 (40%)]	Loss: 0.770854
Train Epoch: 47 [14720/35339 (42%)]	Loss: 0.902487
Train Epoch: 47 [15360/35339 (43%)]	Loss: 0.811924
Train Epoch: 47 [16000/35339 (45%)]	Loss: 0.760798
Train Epoch: 47 [16640/35339 (47%)]	Loss: 0.832962
Train Epoch: 47 [17280/35339 (49%)]	Loss: 0.803942
Train Epoch: 47 [17920/35339 (51%)]	Loss: 1.024678
Train Epoch: 47 [18560/35339 (52%)]	Loss: 0.947151
Train Epoch: 47 [19200/35339 (54%)]	Loss: 0.806886
Train Epoch: 47 [19840/35339 (56%)]	Loss: 0.636389
Train Epoch: 47 [20480/35339 (58%)]	Loss: 0.837041
Train Epoch: 47 [21120/35339 (60%)]	Loss: 0.857638
Train Epoch: 47 [21760/35339 (61%)]	Loss: 0.814139
Train Epoch: 47 [22400/35339 (63%)]	Loss: 0.790731
Train Epoch: 47 [23040/35339 (65%)]	Loss: 0.802613
Train Epoch: 47 [23680/35339 (67%)]	Loss: 0.833339
Train Epoch: 47 [24320/35339 (69%)]	Loss: 0.984201
Train Epoch: 47 [24960/35339 (71%)]	Loss: 0.655544
Train Epoch: 47 [25600/35339 (72%)]	Loss: 1.062671
Train Epoch: 47 [26240/35339 (74%)]	Loss: 1.021233
Train Epoch: 47 [26880/35339 (76%)]	Loss: 0.783070
Train Epoch: 47 [27520/35339 (78%)]	Loss: 0.818032
Train Epoch: 47 [28160/35339 (80%)]	Loss: 0.740632
Train Epoch: 47 [28800/35339 (81%)]	Loss: 0.782397
Train Epoch: 47 [29440/35339 (83%)]	Loss: 0.839990
Train Epoch: 47 [30080/35339 (85%)]	Loss: 0.672235
Train Epoch: 47 [30720/35339 (87%)]	Loss: 0.918075
Train Epoch: 47 [31360/35339 (89%)]	Loss: 0.893109
Train Epoch: 47 [32000/35339 (90%)]	Loss: 0.712157
Train Epoch: 47 [32640/35339 (92%)]	Loss: 0.824111
Train Epoch: 47 [33280/35339 (94%)]	Loss: 0.835418
Train Epoch: 47 [33920/35339 (96%)]	Loss: 0.832870
Train Epoch: 47 [34560/35339 (98%)]	Loss: 0.770562
Train Epoch: 47 [35200/35339 (99%)]	Loss: 1.046261

Validation set: Average loss: 3.7792, Accuracy: 730/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 48 [0/35339 (0%)]	Loss: 0.903301
Train Epoch: 48 [640/35339 (2%)]	Loss: 0.850386
Train Epoch: 48 [1280/35339 (4%)]	Loss: 0.719609
Train Epoch: 48 [1920/35339 (5%)]	Loss: 0.765930
Train Epoch: 48 [2560/35339 (7%)]	Loss: 0.719660
Train Epoch: 48 [3200/35339 (9%)]	Loss: 0.944510
Train Epoch: 48 [3840/35339 (11%)]	Loss: 0.805863
Train Epoch: 48 [4480/35339 (13%)]	Loss: 0.844480
Train Epoch: 48 [5120/35339 (14%)]	Loss: 0.790351
Train Epoch: 48 [5760/35339 (16%)]	Loss: 0.821518
Train Epoch: 48 [6400/35339 (18%)]	Loss: 1.008129
Train Epoch: 48 [7040/35339 (20%)]	Loss: 0.805335
Train Epoch: 48 [7680/35339 (22%)]	Loss: 0.914268
Train Epoch: 48 [8320/35339 (24%)]	Loss: 0.769359
Train Epoch: 48 [8960/35339 (25%)]	Loss: 0.984768
Train Epoch: 48 [9600/35339 (27%)]	Loss: 0.907495
Train Epoch: 48 [10240/35339 (29%)]	Loss: 0.818442
Train Epoch: 48 [10880/35339 (31%)]	Loss: 0.941969
Train Epoch: 48 [11520/35339 (33%)]	Loss: 0.779942
Train Epoch: 48 [12160/35339 (34%)]	Loss: 0.721764
Train Epoch: 48 [12800/35339 (36%)]	Loss: 0.884142
Train Epoch: 48 [13440/35339 (38%)]	Loss: 0.866919
Train Epoch: 48 [14080/35339 (40%)]	Loss: 1.027090
Train Epoch: 48 [14720/35339 (42%)]	Loss: 0.878674
Train Epoch: 48 [15360/35339 (43%)]	Loss: 0.855973
Train Epoch: 48 [16000/35339 (45%)]	Loss: 0.986323
Train Epoch: 48 [16640/35339 (47%)]	Loss: 0.850907
Train Epoch: 48 [17280/35339 (49%)]	Loss: 0.980726
Train Epoch: 48 [17920/35339 (51%)]	Loss: 0.869647
Train Epoch: 48 [18560/35339 (52%)]	Loss: 0.655709
Train Epoch: 48 [19200/35339 (54%)]	Loss: 0.731915
Train Epoch: 48 [19840/35339 (56%)]	Loss: 0.812245
Train Epoch: 48 [20480/35339 (58%)]	Loss: 0.860744
Train Epoch: 48 [21120/35339 (60%)]	Loss: 0.851691
Train Epoch: 48 [21760/35339 (61%)]	Loss: 0.759884
Train Epoch: 48 [22400/35339 (63%)]	Loss: 0.833984
Train Epoch: 48 [23040/35339 (65%)]	Loss: 0.842694
Train Epoch: 48 [23680/35339 (67%)]	Loss: 0.650512
Train Epoch: 48 [24320/35339 (69%)]	Loss: 0.663280
Train Epoch: 48 [24960/35339 (71%)]	Loss: 0.872524
Train Epoch: 48 [25600/35339 (72%)]	Loss: 0.765989
Train Epoch: 48 [26240/35339 (74%)]	Loss: 0.877094
Train Epoch: 48 [26880/35339 (76%)]	Loss: 1.043843
Train Epoch: 48 [27520/35339 (78%)]	Loss: 0.899671
Train Epoch: 48 [28160/35339 (80%)]	Loss: 1.034556
Train Epoch: 48 [28800/35339 (81%)]	Loss: 0.983484
Train Epoch: 48 [29440/35339 (83%)]	Loss: 0.804992
Train Epoch: 48 [30080/35339 (85%)]	Loss: 0.834675
Train Epoch: 48 [30720/35339 (87%)]	Loss: 0.774535
Train Epoch: 48 [31360/35339 (89%)]	Loss: 0.735655
Train Epoch: 48 [32000/35339 (90%)]	Loss: 0.744146
Train Epoch: 48 [32640/35339 (92%)]	Loss: 0.989577
Train Epoch: 48 [33280/35339 (94%)]	Loss: 1.103030
Train Epoch: 48 [33920/35339 (96%)]	Loss: 0.701702
Train Epoch: 48 [34560/35339 (98%)]	Loss: 0.848164
Train Epoch: 48 [35200/35339 (99%)]	Loss: 0.917363

Validation set: Average loss: 3.7803, Accuracy: 739/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 49 [0/35339 (0%)]	Loss: 0.630219
Train Epoch: 49 [640/35339 (2%)]	Loss: 0.800088
Train Epoch: 49 [1280/35339 (4%)]	Loss: 0.735566
Train Epoch: 49 [1920/35339 (5%)]	Loss: 0.795959
Train Epoch: 49 [2560/35339 (7%)]	Loss: 0.942951
Train Epoch: 49 [3200/35339 (9%)]	Loss: 0.799401
Train Epoch: 49 [3840/35339 (11%)]	Loss: 0.884345
Train Epoch: 49 [4480/35339 (13%)]	Loss: 0.792835
Train Epoch: 49 [5120/35339 (14%)]	Loss: 0.802883
Train Epoch: 49 [5760/35339 (16%)]	Loss: 0.855724
Train Epoch: 49 [6400/35339 (18%)]	Loss: 0.754461
Train Epoch: 49 [7040/35339 (20%)]	Loss: 0.925974
Train Epoch: 49 [7680/35339 (22%)]	Loss: 0.760544
Train Epoch: 49 [8320/35339 (24%)]	Loss: 0.854407
Train Epoch: 49 [8960/35339 (25%)]	Loss: 1.092406
Train Epoch: 49 [9600/35339 (27%)]	Loss: 0.736607
Train Epoch: 49 [10240/35339 (29%)]	Loss: 0.942780
Train Epoch: 49 [10880/35339 (31%)]	Loss: 0.900372
Train Epoch: 49 [11520/35339 (33%)]	Loss: 0.646649
Train Epoch: 49 [12160/35339 (34%)]	Loss: 0.764190
Train Epoch: 49 [12800/35339 (36%)]	Loss: 0.714957
Train Epoch: 49 [13440/35339 (38%)]	Loss: 0.805015
Train Epoch: 49 [14080/35339 (40%)]	Loss: 0.943666
Train Epoch: 49 [14720/35339 (42%)]	Loss: 0.771106
Train Epoch: 49 [15360/35339 (43%)]	Loss: 0.794963
Train Epoch: 49 [16000/35339 (45%)]	Loss: 0.776167
Train Epoch: 49 [16640/35339 (47%)]	Loss: 0.698309
Train Epoch: 49 [17280/35339 (49%)]	Loss: 0.822292
Train Epoch: 49 [17920/35339 (51%)]	Loss: 0.858967
Train Epoch: 49 [18560/35339 (52%)]	Loss: 0.839132
Train Epoch: 49 [19200/35339 (54%)]	Loss: 0.797758
Train Epoch: 49 [19840/35339 (56%)]	Loss: 0.786540
Train Epoch: 49 [20480/35339 (58%)]	Loss: 0.852334
Train Epoch: 49 [21120/35339 (60%)]	Loss: 0.739306
Train Epoch: 49 [21760/35339 (61%)]	Loss: 0.727976
Train Epoch: 49 [22400/35339 (63%)]	Loss: 0.803661
Train Epoch: 49 [23040/35339 (65%)]	Loss: 0.824207
Train Epoch: 49 [23680/35339 (67%)]	Loss: 0.763391
Train Epoch: 49 [24320/35339 (69%)]	Loss: 0.877718
Train Epoch: 49 [24960/35339 (71%)]	Loss: 0.861788
Train Epoch: 49 [25600/35339 (72%)]	Loss: 0.846327
Train Epoch: 49 [26240/35339 (74%)]	Loss: 0.663303
Train Epoch: 49 [26880/35339 (76%)]	Loss: 0.748608
Train Epoch: 49 [27520/35339 (78%)]	Loss: 0.686318
Train Epoch: 49 [28160/35339 (80%)]	Loss: 0.763525
Train Epoch: 49 [28800/35339 (81%)]	Loss: 0.803729
Train Epoch: 49 [29440/35339 (83%)]	Loss: 0.733578
Train Epoch: 49 [30080/35339 (85%)]	Loss: 0.811393
Train Epoch: 49 [30720/35339 (87%)]	Loss: 0.950648
Train Epoch: 49 [31360/35339 (89%)]	Loss: 0.676724
Train Epoch: 49 [32000/35339 (90%)]	Loss: 0.733063
Train Epoch: 49 [32640/35339 (92%)]	Loss: 0.919840
Train Epoch: 49 [33280/35339 (94%)]	Loss: 0.787279
Train Epoch: 49 [33920/35339 (96%)]	Loss: 0.785078
Train Epoch: 49 [34560/35339 (98%)]	Loss: 0.991277
Train Epoch: 49 [35200/35339 (99%)]	Loss: 0.817991

Validation set: Average loss: 3.7814, Accuracy: 739/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 50 [0/35339 (0%)]	Loss: 0.965908
Train Epoch: 50 [640/35339 (2%)]	Loss: 0.796164
Train Epoch: 50 [1280/35339 (4%)]	Loss: 0.899980
Train Epoch: 50 [1920/35339 (5%)]	Loss: 0.735773
Train Epoch: 50 [2560/35339 (7%)]	Loss: 0.842841
Train Epoch: 50 [3200/35339 (9%)]	Loss: 1.250290
Train Epoch: 50 [3840/35339 (11%)]	Loss: 0.652251
Train Epoch: 50 [4480/35339 (13%)]	Loss: 0.551145
Train Epoch: 50 [5120/35339 (14%)]	Loss: 0.676838
Train Epoch: 50 [5760/35339 (16%)]	Loss: 0.902928
Train Epoch: 50 [6400/35339 (18%)]	Loss: 0.699714
Train Epoch: 50 [7040/35339 (20%)]	Loss: 0.733968
Train Epoch: 50 [7680/35339 (22%)]	Loss: 0.775881
Train Epoch: 50 [8320/35339 (24%)]	Loss: 0.698293
Train Epoch: 50 [8960/35339 (25%)]	Loss: 0.811107
Train Epoch: 50 [9600/35339 (27%)]	Loss: 0.664965
Train Epoch: 50 [10240/35339 (29%)]	Loss: 0.964371
Train Epoch: 50 [10880/35339 (31%)]	Loss: 1.009692
Train Epoch: 50 [11520/35339 (33%)]	Loss: 0.978467
Train Epoch: 50 [12160/35339 (34%)]	Loss: 0.967045
Train Epoch: 50 [12800/35339 (36%)]	Loss: 0.775672
Train Epoch: 50 [13440/35339 (38%)]	Loss: 0.748915
Train Epoch: 50 [14080/35339 (40%)]	Loss: 0.790937
Train Epoch: 50 [14720/35339 (42%)]	Loss: 0.809116
Train Epoch: 50 [15360/35339 (43%)]	Loss: 0.838979
Train Epoch: 50 [16000/35339 (45%)]	Loss: 0.779444
Train Epoch: 50 [16640/35339 (47%)]	Loss: 0.886546
Train Epoch: 50 [17280/35339 (49%)]	Loss: 0.895122
Train Epoch: 50 [17920/35339 (51%)]	Loss: 0.891243
Train Epoch: 50 [18560/35339 (52%)]	Loss: 0.836708
Train Epoch: 50 [19200/35339 (54%)]	Loss: 0.800863
Train Epoch: 50 [19840/35339 (56%)]	Loss: 0.841214
Train Epoch: 50 [20480/35339 (58%)]	Loss: 0.699053
Train Epoch: 50 [21120/35339 (60%)]	Loss: 0.857222
Train Epoch: 50 [21760/35339 (61%)]	Loss: 0.800007
Train Epoch: 50 [22400/35339 (63%)]	Loss: 0.963843
Train Epoch: 50 [23040/35339 (65%)]	Loss: 0.810229
Train Epoch: 50 [23680/35339 (67%)]	Loss: 0.832287
Train Epoch: 50 [24320/35339 (69%)]	Loss: 0.702251
Train Epoch: 50 [24960/35339 (71%)]	Loss: 0.790216
Train Epoch: 50 [25600/35339 (72%)]	Loss: 0.741285
Train Epoch: 50 [26240/35339 (74%)]	Loss: 0.756524
Train Epoch: 50 [26880/35339 (76%)]	Loss: 1.051156
Train Epoch: 50 [27520/35339 (78%)]	Loss: 0.888905
Train Epoch: 50 [28160/35339 (80%)]	Loss: 0.659292
Train Epoch: 50 [28800/35339 (81%)]	Loss: 0.863416
Train Epoch: 50 [29440/35339 (83%)]	Loss: 0.869608
Train Epoch: 50 [30080/35339 (85%)]	Loss: 1.043144
Train Epoch: 50 [30720/35339 (87%)]	Loss: 0.749658
Train Epoch: 50 [31360/35339 (89%)]	Loss: 0.847063
Train Epoch: 50 [32000/35339 (90%)]	Loss: 0.832405
Train Epoch: 50 [32640/35339 (92%)]	Loss: 0.887954
Train Epoch: 50 [33280/35339 (94%)]	Loss: 0.903533
Train Epoch: 50 [33920/35339 (96%)]	Loss: 0.949824
Train Epoch: 50 [34560/35339 (98%)]	Loss: 0.901585
Train Epoch: 50 [35200/35339 (99%)]	Loss: 0.870055

Validation set: Average loss: 3.7881, Accuracy: 736/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 51 [0/35339 (0%)]	Loss: 0.957398
Train Epoch: 51 [640/35339 (2%)]	Loss: 0.995690
Train Epoch: 51 [1280/35339 (4%)]	Loss: 0.783448
Train Epoch: 51 [1920/35339 (5%)]	Loss: 0.735734
Train Epoch: 51 [2560/35339 (7%)]	Loss: 0.925584
Train Epoch: 51 [3200/35339 (9%)]	Loss: 1.119063
Train Epoch: 51 [3840/35339 (11%)]	Loss: 0.759773
Train Epoch: 51 [4480/35339 (13%)]	Loss: 0.939677
Train Epoch: 51 [5120/35339 (14%)]	Loss: 0.770112
Train Epoch: 51 [5760/35339 (16%)]	Loss: 0.670851
Train Epoch: 51 [6400/35339 (18%)]	Loss: 0.701386
Train Epoch: 51 [7040/35339 (20%)]	Loss: 0.642675
Train Epoch: 51 [7680/35339 (22%)]	Loss: 0.877471
Train Epoch: 51 [8320/35339 (24%)]	Loss: 0.713495
Train Epoch: 51 [8960/35339 (25%)]	Loss: 0.767421
Train Epoch: 51 [9600/35339 (27%)]	Loss: 0.740938
Train Epoch: 51 [10240/35339 (29%)]	Loss: 1.000477
Train Epoch: 51 [10880/35339 (31%)]	Loss: 0.810013
Train Epoch: 51 [11520/35339 (33%)]	Loss: 0.871016
Train Epoch: 51 [12160/35339 (34%)]	Loss: 0.752985
Train Epoch: 51 [12800/35339 (36%)]	Loss: 0.861709
Train Epoch: 51 [13440/35339 (38%)]	Loss: 0.710473
Train Epoch: 51 [14080/35339 (40%)]	Loss: 0.726372
Train Epoch: 51 [14720/35339 (42%)]	Loss: 0.715226
Train Epoch: 51 [15360/35339 (43%)]	Loss: 0.856215
Train Epoch: 51 [16000/35339 (45%)]	Loss: 0.847808
Train Epoch: 51 [16640/35339 (47%)]	Loss: 0.845917
Train Epoch: 51 [17280/35339 (49%)]	Loss: 0.806364
Train Epoch: 51 [17920/35339 (51%)]	Loss: 0.845085
Train Epoch: 51 [18560/35339 (52%)]	Loss: 0.810187
Train Epoch: 51 [19200/35339 (54%)]	Loss: 0.780669
Train Epoch: 51 [19840/35339 (56%)]	Loss: 0.746593
Train Epoch: 51 [20480/35339 (58%)]	Loss: 0.754971
Train Epoch: 51 [21120/35339 (60%)]	Loss: 0.692648
Train Epoch: 51 [21760/35339 (61%)]	Loss: 0.776608
Train Epoch: 51 [22400/35339 (63%)]	Loss: 0.776045
Train Epoch: 51 [23040/35339 (65%)]	Loss: 0.976545
Train Epoch: 51 [23680/35339 (67%)]	Loss: 0.833738
Train Epoch: 51 [24320/35339 (69%)]	Loss: 0.608925
Train Epoch: 51 [24960/35339 (71%)]	Loss: 0.780111
Train Epoch: 51 [25600/35339 (72%)]	Loss: 0.796372
Train Epoch: 51 [26240/35339 (74%)]	Loss: 0.718222
Train Epoch: 51 [26880/35339 (76%)]	Loss: 0.640513
Train Epoch: 51 [27520/35339 (78%)]	Loss: 0.563144
Train Epoch: 51 [28160/35339 (80%)]	Loss: 0.818374
Train Epoch: 51 [28800/35339 (81%)]	Loss: 0.791549
Train Epoch: 51 [29440/35339 (83%)]	Loss: 0.780108
Train Epoch: 51 [30080/35339 (85%)]	Loss: 0.698933
Train Epoch: 51 [30720/35339 (87%)]	Loss: 0.670842
Train Epoch: 51 [31360/35339 (89%)]	Loss: 0.755593
Train Epoch: 51 [32000/35339 (90%)]	Loss: 0.822718
Train Epoch: 51 [32640/35339 (92%)]	Loss: 0.903684
Train Epoch: 51 [33280/35339 (94%)]	Loss: 0.797676
Train Epoch: 51 [33920/35339 (96%)]	Loss: 0.629291
Train Epoch: 51 [34560/35339 (98%)]	Loss: 0.888040
Train Epoch: 51 [35200/35339 (99%)]	Loss: 0.904972

Validation set: Average loss: 3.7783, Accuracy: 739/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 52 [0/35339 (0%)]	Loss: 0.829834
Train Epoch: 52 [640/35339 (2%)]	Loss: 0.850603
Train Epoch: 52 [1280/35339 (4%)]	Loss: 0.892023
Train Epoch: 52 [1920/35339 (5%)]	Loss: 0.715755
Train Epoch: 52 [2560/35339 (7%)]	Loss: 0.821506
Train Epoch: 52 [3200/35339 (9%)]	Loss: 0.655736
Train Epoch: 52 [3840/35339 (11%)]	Loss: 0.758323
Train Epoch: 52 [4480/35339 (13%)]	Loss: 0.666278
Train Epoch: 52 [5120/35339 (14%)]	Loss: 0.857670
Train Epoch: 52 [5760/35339 (16%)]	Loss: 0.807624
Train Epoch: 52 [6400/35339 (18%)]	Loss: 0.808476
Train Epoch: 52 [7040/35339 (20%)]	Loss: 0.937774
Train Epoch: 52 [7680/35339 (22%)]	Loss: 0.803953
Train Epoch: 52 [8320/35339 (24%)]	Loss: 0.774632
Train Epoch: 52 [8960/35339 (25%)]	Loss: 0.873997
Train Epoch: 52 [9600/35339 (27%)]	Loss: 0.831834
Train Epoch: 52 [10240/35339 (29%)]	Loss: 0.922370
Train Epoch: 52 [10880/35339 (31%)]	Loss: 0.679926
Train Epoch: 52 [11520/35339 (33%)]	Loss: 0.773402
Train Epoch: 52 [12160/35339 (34%)]	Loss: 0.857083
Train Epoch: 52 [12800/35339 (36%)]	Loss: 1.011073
Train Epoch: 52 [13440/35339 (38%)]	Loss: 0.695288
Train Epoch: 52 [14080/35339 (40%)]	Loss: 0.758865
Train Epoch: 52 [14720/35339 (42%)]	Loss: 0.824870
Train Epoch: 52 [15360/35339 (43%)]	Loss: 0.785039
Train Epoch: 52 [16000/35339 (45%)]	Loss: 0.867269
Train Epoch: 52 [16640/35339 (47%)]	Loss: 0.781709
Train Epoch: 52 [17280/35339 (49%)]	Loss: 0.740887
Train Epoch: 52 [17920/35339 (51%)]	Loss: 0.875742
Train Epoch: 52 [18560/35339 (52%)]	Loss: 0.836524
Train Epoch: 52 [19200/35339 (54%)]	Loss: 0.692869
Train Epoch: 52 [19840/35339 (56%)]	Loss: 0.950764
Train Epoch: 52 [20480/35339 (58%)]	Loss: 0.798413
Train Epoch: 52 [21120/35339 (60%)]	Loss: 0.793149
Train Epoch: 52 [21760/35339 (61%)]	Loss: 0.620786
Train Epoch: 52 [22400/35339 (63%)]	Loss: 0.735876
Train Epoch: 52 [23040/35339 (65%)]	Loss: 0.962678
Train Epoch: 52 [23680/35339 (67%)]	Loss: 0.785483
Train Epoch: 52 [24320/35339 (69%)]	Loss: 0.835094
Train Epoch: 52 [24960/35339 (71%)]	Loss: 0.823801
Train Epoch: 52 [25600/35339 (72%)]	Loss: 0.844862
Train Epoch: 52 [26240/35339 (74%)]	Loss: 0.917948
Train Epoch: 52 [26880/35339 (76%)]	Loss: 0.517967
Train Epoch: 52 [27520/35339 (78%)]	Loss: 0.785648
Train Epoch: 52 [28160/35339 (80%)]	Loss: 1.005762
Train Epoch: 52 [28800/35339 (81%)]	Loss: 0.959921
Train Epoch: 52 [29440/35339 (83%)]	Loss: 0.794232
Train Epoch: 52 [30080/35339 (85%)]	Loss: 0.617729
Train Epoch: 52 [30720/35339 (87%)]	Loss: 0.867765
Train Epoch: 52 [31360/35339 (89%)]	Loss: 0.822885
Train Epoch: 52 [32000/35339 (90%)]	Loss: 0.734800
Train Epoch: 52 [32640/35339 (92%)]	Loss: 0.736113
Train Epoch: 52 [33280/35339 (94%)]	Loss: 0.914932
Train Epoch: 52 [33920/35339 (96%)]	Loss: 0.752835
Train Epoch: 52 [34560/35339 (98%)]	Loss: 0.726737
Train Epoch: 52 [35200/35339 (99%)]	Loss: 0.756844

Validation set: Average loss: 3.7743, Accuracy: 733/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 53 [0/35339 (0%)]	Loss: 0.849903
Train Epoch: 53 [640/35339 (2%)]	Loss: 0.803591
Train Epoch: 53 [1280/35339 (4%)]	Loss: 0.782330
Train Epoch: 53 [1920/35339 (5%)]	Loss: 0.824705
Train Epoch: 53 [2560/35339 (7%)]	Loss: 0.747083
Train Epoch: 53 [3200/35339 (9%)]	Loss: 0.802678
Train Epoch: 53 [3840/35339 (11%)]	Loss: 0.793370
Train Epoch: 53 [4480/35339 (13%)]	Loss: 0.814430
Train Epoch: 53 [5120/35339 (14%)]	Loss: 0.764825
Train Epoch: 53 [5760/35339 (16%)]	Loss: 0.749837
Train Epoch: 53 [6400/35339 (18%)]	Loss: 0.740572
Train Epoch: 53 [7040/35339 (20%)]	Loss: 0.693989
Train Epoch: 53 [7680/35339 (22%)]	Loss: 0.719011
Train Epoch: 53 [8320/35339 (24%)]	Loss: 0.719944
Train Epoch: 53 [8960/35339 (25%)]	Loss: 0.794034
Train Epoch: 53 [9600/35339 (27%)]	Loss: 0.827971
Train Epoch: 53 [10240/35339 (29%)]	Loss: 0.886862
Train Epoch: 53 [10880/35339 (31%)]	Loss: 0.834231
Train Epoch: 53 [11520/35339 (33%)]	Loss: 0.710144
Train Epoch: 53 [12160/35339 (34%)]	Loss: 0.718986
Train Epoch: 53 [12800/35339 (36%)]	Loss: 0.723645
Train Epoch: 53 [13440/35339 (38%)]	Loss: 0.832775
Train Epoch: 53 [14080/35339 (40%)]	Loss: 0.989257
Train Epoch: 53 [14720/35339 (42%)]	Loss: 0.659867
Train Epoch: 53 [15360/35339 (43%)]	Loss: 0.754672
Train Epoch: 53 [16000/35339 (45%)]	Loss: 0.720935
Train Epoch: 53 [16640/35339 (47%)]	Loss: 0.651209
Train Epoch: 53 [17280/35339 (49%)]	Loss: 0.738360
Train Epoch: 53 [17920/35339 (51%)]	Loss: 0.684841
Train Epoch: 53 [18560/35339 (52%)]	Loss: 0.727004
Train Epoch: 53 [19200/35339 (54%)]	Loss: 0.858703
Train Epoch: 53 [19840/35339 (56%)]	Loss: 0.830271
Train Epoch: 53 [20480/35339 (58%)]	Loss: 0.891711
Train Epoch: 53 [21120/35339 (60%)]	Loss: 0.933547
Train Epoch: 53 [21760/35339 (61%)]	Loss: 0.741587
Train Epoch: 53 [22400/35339 (63%)]	Loss: 0.705601
Train Epoch: 53 [23040/35339 (65%)]	Loss: 0.795913
Train Epoch: 53 [23680/35339 (67%)]	Loss: 0.736494
Train Epoch: 53 [24320/35339 (69%)]	Loss: 0.785014
Train Epoch: 53 [24960/35339 (71%)]	Loss: 0.805947
Train Epoch: 53 [25600/35339 (72%)]	Loss: 0.972609
Train Epoch: 53 [26240/35339 (74%)]	Loss: 0.633634
Train Epoch: 53 [26880/35339 (76%)]	Loss: 0.931038
Train Epoch: 53 [27520/35339 (78%)]	Loss: 0.794626
Train Epoch: 53 [28160/35339 (80%)]	Loss: 0.718573
Train Epoch: 53 [28800/35339 (81%)]	Loss: 0.745970
Train Epoch: 53 [29440/35339 (83%)]	Loss: 0.766260
Train Epoch: 53 [30080/35339 (85%)]	Loss: 0.963271
Train Epoch: 53 [30720/35339 (87%)]	Loss: 0.640081
Train Epoch: 53 [31360/35339 (89%)]	Loss: 0.639565
Train Epoch: 53 [32000/35339 (90%)]	Loss: 0.784988
Train Epoch: 53 [32640/35339 (92%)]	Loss: 0.822585
Train Epoch: 53 [33280/35339 (94%)]	Loss: 0.629163
Train Epoch: 53 [33920/35339 (96%)]	Loss: 0.797944
Train Epoch: 53 [34560/35339 (98%)]	Loss: 0.791718
Train Epoch: 53 [35200/35339 (99%)]	Loss: 0.720265

Validation set: Average loss: 3.7737, Accuracy: 716/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 54 [0/35339 (0%)]	Loss: 0.849409
Train Epoch: 54 [640/35339 (2%)]	Loss: 0.727954
Train Epoch: 54 [1280/35339 (4%)]	Loss: 0.839549
Train Epoch: 54 [1920/35339 (5%)]	Loss: 0.915645
Train Epoch: 54 [2560/35339 (7%)]	Loss: 0.787114
Train Epoch: 54 [3200/35339 (9%)]	Loss: 0.761272
Train Epoch: 54 [3840/35339 (11%)]	Loss: 0.856941
Train Epoch: 54 [4480/35339 (13%)]	Loss: 0.785028
Train Epoch: 54 [5120/35339 (14%)]	Loss: 0.662260
Train Epoch: 54 [5760/35339 (16%)]	Loss: 0.694011
Train Epoch: 54 [6400/35339 (18%)]	Loss: 0.736383
Train Epoch: 54 [7040/35339 (20%)]	Loss: 0.761003
Train Epoch: 54 [7680/35339 (22%)]	Loss: 0.809750
Train Epoch: 54 [8320/35339 (24%)]	Loss: 0.571750
Train Epoch: 54 [8960/35339 (25%)]	Loss: 0.766024
Train Epoch: 54 [9600/35339 (27%)]	Loss: 0.855393
Train Epoch: 54 [10240/35339 (29%)]	Loss: 0.839121
Train Epoch: 54 [10880/35339 (31%)]	Loss: 0.923116
Train Epoch: 54 [11520/35339 (33%)]	Loss: 0.829083
Train Epoch: 54 [12160/35339 (34%)]	Loss: 0.752944
Train Epoch: 54 [12800/35339 (36%)]	Loss: 0.727336
Train Epoch: 54 [13440/35339 (38%)]	Loss: 0.779422
Train Epoch: 54 [14080/35339 (40%)]	Loss: 0.849385
Train Epoch: 54 [14720/35339 (42%)]	Loss: 0.850366
Train Epoch: 54 [15360/35339 (43%)]	Loss: 0.799252
Train Epoch: 54 [16000/35339 (45%)]	Loss: 0.634714
Train Epoch: 54 [16640/35339 (47%)]	Loss: 0.842031
Train Epoch: 54 [17280/35339 (49%)]	Loss: 0.605472
Train Epoch: 54 [17920/35339 (51%)]	Loss: 0.763455
Train Epoch: 54 [18560/35339 (52%)]	Loss: 0.820003
Train Epoch: 54 [19200/35339 (54%)]	Loss: 0.646358
Train Epoch: 54 [19840/35339 (56%)]	Loss: 0.769543
Train Epoch: 54 [20480/35339 (58%)]	Loss: 0.755451
Train Epoch: 54 [21120/35339 (60%)]	Loss: 0.955703
Train Epoch: 54 [21760/35339 (61%)]	Loss: 0.842476
Train Epoch: 54 [22400/35339 (63%)]	Loss: 1.064951
Train Epoch: 54 [23040/35339 (65%)]	Loss: 0.878985
Train Epoch: 54 [23680/35339 (67%)]	Loss: 0.882891
Train Epoch: 54 [24320/35339 (69%)]	Loss: 0.544650
Train Epoch: 54 [24960/35339 (71%)]	Loss: 0.771573
Train Epoch: 54 [25600/35339 (72%)]	Loss: 0.822148
Train Epoch: 54 [26240/35339 (74%)]	Loss: 0.671172
Train Epoch: 54 [26880/35339 (76%)]	Loss: 0.772536
Train Epoch: 54 [27520/35339 (78%)]	Loss: 0.882783
Train Epoch: 54 [28160/35339 (80%)]	Loss: 0.795732
Train Epoch: 54 [28800/35339 (81%)]	Loss: 0.690303
Train Epoch: 54 [29440/35339 (83%)]	Loss: 0.721849
Train Epoch: 54 [30080/35339 (85%)]	Loss: 0.698794
Train Epoch: 54 [30720/35339 (87%)]	Loss: 0.763259
Train Epoch: 54 [31360/35339 (89%)]	Loss: 0.772866
Train Epoch: 54 [32000/35339 (90%)]	Loss: 0.859963
Train Epoch: 54 [32640/35339 (92%)]	Loss: 0.742067
Train Epoch: 54 [33280/35339 (94%)]	Loss: 0.636031
Train Epoch: 54 [33920/35339 (96%)]	Loss: 0.698853
Train Epoch: 54 [34560/35339 (98%)]	Loss: 0.725152
Train Epoch: 54 [35200/35339 (99%)]	Loss: 0.814045

Validation set: Average loss: 3.7774, Accuracy: 735/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 55 [0/35339 (0%)]	Loss: 0.799195
Train Epoch: 55 [640/35339 (2%)]	Loss: 0.850201
Train Epoch: 55 [1280/35339 (4%)]	Loss: 0.939687
Train Epoch: 55 [1920/35339 (5%)]	Loss: 0.983257
Train Epoch: 55 [2560/35339 (7%)]	Loss: 0.826755
Train Epoch: 55 [3200/35339 (9%)]	Loss: 0.753596
Train Epoch: 55 [3840/35339 (11%)]	Loss: 0.919353
Train Epoch: 55 [4480/35339 (13%)]	Loss: 0.608948
Train Epoch: 55 [5120/35339 (14%)]	Loss: 0.747438
Train Epoch: 55 [5760/35339 (16%)]	Loss: 0.887130
Train Epoch: 55 [6400/35339 (18%)]	Loss: 0.762940
Train Epoch: 55 [7040/35339 (20%)]	Loss: 0.872070
Train Epoch: 55 [7680/35339 (22%)]	Loss: 0.818492
Train Epoch: 55 [8320/35339 (24%)]	Loss: 0.931036
Train Epoch: 55 [8960/35339 (25%)]	Loss: 0.785394
Train Epoch: 55 [9600/35339 (27%)]	Loss: 0.736016
Train Epoch: 55 [10240/35339 (29%)]	Loss: 0.743813
Train Epoch: 55 [10880/35339 (31%)]	Loss: 0.900948
Train Epoch: 55 [11520/35339 (33%)]	Loss: 0.774777
Train Epoch: 55 [12160/35339 (34%)]	Loss: 0.770750
Train Epoch: 55 [12800/35339 (36%)]	Loss: 0.916367
Train Epoch: 55 [13440/35339 (38%)]	Loss: 0.751170
Train Epoch: 55 [14080/35339 (40%)]	Loss: 0.743247
Train Epoch: 55 [14720/35339 (42%)]	Loss: 0.672592
Train Epoch: 55 [15360/35339 (43%)]	Loss: 0.687217
Train Epoch: 55 [16000/35339 (45%)]	Loss: 0.728513
Train Epoch: 55 [16640/35339 (47%)]	Loss: 0.825328
Train Epoch: 55 [17280/35339 (49%)]	Loss: 0.732742
Train Epoch: 55 [17920/35339 (51%)]	Loss: 0.799306
Train Epoch: 55 [18560/35339 (52%)]	Loss: 0.739457
Train Epoch: 55 [19200/35339 (54%)]	Loss: 0.623520
Train Epoch: 55 [19840/35339 (56%)]	Loss: 0.681627
Train Epoch: 55 [20480/35339 (58%)]	Loss: 0.723396
Train Epoch: 55 [21120/35339 (60%)]	Loss: 0.717765
Train Epoch: 55 [21760/35339 (61%)]	Loss: 0.657379
Train Epoch: 55 [22400/35339 (63%)]	Loss: 0.810032
Train Epoch: 55 [23040/35339 (65%)]	Loss: 0.691801
Train Epoch: 55 [23680/35339 (67%)]	Loss: 0.692420
Train Epoch: 55 [24320/35339 (69%)]	Loss: 0.763939
Train Epoch: 55 [24960/35339 (71%)]	Loss: 0.829164
Train Epoch: 55 [25600/35339 (72%)]	Loss: 0.770282
Train Epoch: 55 [26240/35339 (74%)]	Loss: 0.827578
Train Epoch: 55 [26880/35339 (76%)]	Loss: 0.789342
Train Epoch: 55 [27520/35339 (78%)]	Loss: 0.900588
Train Epoch: 55 [28160/35339 (80%)]	Loss: 0.792413
Train Epoch: 55 [28800/35339 (81%)]	Loss: 0.681497
Train Epoch: 55 [29440/35339 (83%)]	Loss: 0.705676
Train Epoch: 55 [30080/35339 (85%)]	Loss: 0.753436
Train Epoch: 55 [30720/35339 (87%)]	Loss: 0.809366
Train Epoch: 55 [31360/35339 (89%)]	Loss: 0.820594
Train Epoch: 55 [32000/35339 (90%)]	Loss: 0.857752
Train Epoch: 55 [32640/35339 (92%)]	Loss: 0.966874
Train Epoch: 55 [33280/35339 (94%)]	Loss: 0.861750
Train Epoch: 55 [33920/35339 (96%)]	Loss: 0.742750
Train Epoch: 55 [34560/35339 (98%)]	Loss: 0.667146
Train Epoch: 55 [35200/35339 (99%)]	Loss: 0.918402

Validation set: Average loss: 3.7787, Accuracy: 741/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 56 [0/35339 (0%)]	Loss: 0.701507
Train Epoch: 56 [640/35339 (2%)]	Loss: 0.670699
Train Epoch: 56 [1280/35339 (4%)]	Loss: 0.962594
Train Epoch: 56 [1920/35339 (5%)]	Loss: 0.856986
Train Epoch: 56 [2560/35339 (7%)]	Loss: 0.635956
Train Epoch: 56 [3200/35339 (9%)]	Loss: 0.964924
Train Epoch: 56 [3840/35339 (11%)]	Loss: 0.805952
Train Epoch: 56 [4480/35339 (13%)]	Loss: 0.744890
Train Epoch: 56 [5120/35339 (14%)]	Loss: 0.873104
Train Epoch: 56 [5760/35339 (16%)]	Loss: 0.644976
Train Epoch: 56 [6400/35339 (18%)]	Loss: 0.675207
Train Epoch: 56 [7040/35339 (20%)]	Loss: 0.892521
Train Epoch: 56 [7680/35339 (22%)]	Loss: 0.785284
Train Epoch: 56 [8320/35339 (24%)]	Loss: 0.798685
Train Epoch: 56 [8960/35339 (25%)]	Loss: 0.833410
Train Epoch: 56 [9600/35339 (27%)]	Loss: 0.928556
Train Epoch: 56 [10240/35339 (29%)]	Loss: 0.675411
Train Epoch: 56 [10880/35339 (31%)]	Loss: 0.591228
Train Epoch: 56 [11520/35339 (33%)]	Loss: 0.781086
Train Epoch: 56 [12160/35339 (34%)]	Loss: 0.722032
Train Epoch: 56 [12800/35339 (36%)]	Loss: 0.810401
Train Epoch: 56 [13440/35339 (38%)]	Loss: 0.616446
Train Epoch: 56 [14080/35339 (40%)]	Loss: 0.737444
Train Epoch: 56 [14720/35339 (42%)]	Loss: 0.751511
Train Epoch: 56 [15360/35339 (43%)]	Loss: 0.786661
Train Epoch: 56 [16000/35339 (45%)]	Loss: 0.783137
Train Epoch: 56 [16640/35339 (47%)]	Loss: 0.648155
Train Epoch: 56 [17280/35339 (49%)]	Loss: 0.715701
Train Epoch: 56 [17920/35339 (51%)]	Loss: 0.773502
Train Epoch: 56 [18560/35339 (52%)]	Loss: 0.811015
Train Epoch: 56 [19200/35339 (54%)]	Loss: 0.865069
Train Epoch: 56 [19840/35339 (56%)]	Loss: 0.707385
Train Epoch: 56 [20480/35339 (58%)]	Loss: 0.929917
Train Epoch: 56 [21120/35339 (60%)]	Loss: 0.635392
Train Epoch: 56 [21760/35339 (61%)]	Loss: 0.788140
Train Epoch: 56 [22400/35339 (63%)]	Loss: 0.870064
Train Epoch: 56 [23040/35339 (65%)]	Loss: 0.687257
Train Epoch: 56 [23680/35339 (67%)]	Loss: 0.771337
Train Epoch: 56 [24320/35339 (69%)]	Loss: 0.800635
Train Epoch: 56 [24960/35339 (71%)]	Loss: 0.720474
Train Epoch: 56 [25600/35339 (72%)]	Loss: 0.654285
Train Epoch: 56 [26240/35339 (74%)]	Loss: 0.723984
Train Epoch: 56 [26880/35339 (76%)]	Loss: 0.947159
Train Epoch: 56 [27520/35339 (78%)]	Loss: 1.062170
Train Epoch: 56 [28160/35339 (80%)]	Loss: 0.870459
Train Epoch: 56 [28800/35339 (81%)]	Loss: 0.818816
Train Epoch: 56 [29440/35339 (83%)]	Loss: 0.644898
Train Epoch: 56 [30080/35339 (85%)]	Loss: 0.850239
Train Epoch: 56 [30720/35339 (87%)]	Loss: 0.761985
Train Epoch: 56 [31360/35339 (89%)]	Loss: 0.692937
Train Epoch: 56 [32000/35339 (90%)]	Loss: 0.833000
Train Epoch: 56 [32640/35339 (92%)]	Loss: 0.945090
Train Epoch: 56 [33280/35339 (94%)]	Loss: 0.728277
Train Epoch: 56 [33920/35339 (96%)]	Loss: 0.771824
Train Epoch: 56 [34560/35339 (98%)]	Loss: 0.824110
Train Epoch: 56 [35200/35339 (99%)]	Loss: 0.745624

Validation set: Average loss: 3.7824, Accuracy: 747/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 57 [0/35339 (0%)]	Loss: 0.827864
Train Epoch: 57 [640/35339 (2%)]	Loss: 0.811493
Train Epoch: 57 [1280/35339 (4%)]	Loss: 0.947092
Train Epoch: 57 [1920/35339 (5%)]	Loss: 0.828474
Train Epoch: 57 [2560/35339 (7%)]	Loss: 0.569607
Train Epoch: 57 [3200/35339 (9%)]	Loss: 0.766163
Train Epoch: 57 [3840/35339 (11%)]	Loss: 0.629724
Train Epoch: 57 [4480/35339 (13%)]	Loss: 0.624906
Train Epoch: 57 [5120/35339 (14%)]	Loss: 0.654115
Train Epoch: 57 [5760/35339 (16%)]	Loss: 0.588620
Train Epoch: 57 [6400/35339 (18%)]	Loss: 0.734516
Train Epoch: 57 [7040/35339 (20%)]	Loss: 0.863180
Train Epoch: 57 [7680/35339 (22%)]	Loss: 0.668963
Train Epoch: 57 [8320/35339 (24%)]	Loss: 0.822739
Train Epoch: 57 [8960/35339 (25%)]	Loss: 0.666507
Train Epoch: 57 [9600/35339 (27%)]	Loss: 0.822706
Train Epoch: 57 [10240/35339 (29%)]	Loss: 0.803152
Train Epoch: 57 [10880/35339 (31%)]	Loss: 0.797134
Train Epoch: 57 [11520/35339 (33%)]	Loss: 1.166541
Train Epoch: 57 [12160/35339 (34%)]	Loss: 0.714887
Train Epoch: 57 [12800/35339 (36%)]	Loss: 0.797634
Train Epoch: 57 [13440/35339 (38%)]	Loss: 0.783441
Train Epoch: 57 [14080/35339 (40%)]	Loss: 0.773096
Train Epoch: 57 [14720/35339 (42%)]	Loss: 0.872779
Train Epoch: 57 [15360/35339 (43%)]	Loss: 0.710403
Train Epoch: 57 [16000/35339 (45%)]	Loss: 0.834562
Train Epoch: 57 [16640/35339 (47%)]	Loss: 0.682059
Train Epoch: 57 [17280/35339 (49%)]	Loss: 0.794246
Train Epoch: 57 [17920/35339 (51%)]	Loss: 0.688187
Train Epoch: 57 [18560/35339 (52%)]	Loss: 0.487565
Train Epoch: 57 [19200/35339 (54%)]	Loss: 0.923464
Train Epoch: 57 [19840/35339 (56%)]	Loss: 0.773559
Train Epoch: 57 [20480/35339 (58%)]	Loss: 0.959156
Train Epoch: 57 [21120/35339 (60%)]	Loss: 0.754610
Train Epoch: 57 [21760/35339 (61%)]	Loss: 0.891240
Train Epoch: 57 [22400/35339 (63%)]	Loss: 0.700934
Train Epoch: 57 [23040/35339 (65%)]	Loss: 0.757894
Train Epoch: 57 [23680/35339 (67%)]	Loss: 0.906816
Train Epoch: 57 [24320/35339 (69%)]	Loss: 0.745248
Train Epoch: 57 [24960/35339 (71%)]	Loss: 0.722472
Train Epoch: 57 [25600/35339 (72%)]	Loss: 0.605117
Train Epoch: 57 [26240/35339 (74%)]	Loss: 0.667415
Train Epoch: 57 [26880/35339 (76%)]	Loss: 0.728265
Train Epoch: 57 [27520/35339 (78%)]	Loss: 0.849873
Train Epoch: 57 [28160/35339 (80%)]	Loss: 0.774557
Train Epoch: 57 [28800/35339 (81%)]	Loss: 0.724277
Train Epoch: 57 [29440/35339 (83%)]	Loss: 0.799523
Train Epoch: 57 [30080/35339 (85%)]	Loss: 0.603420
Train Epoch: 57 [30720/35339 (87%)]	Loss: 0.777159
Train Epoch: 57 [31360/35339 (89%)]	Loss: 0.731418
Train Epoch: 57 [32000/35339 (90%)]	Loss: 0.731117
Train Epoch: 57 [32640/35339 (92%)]	Loss: 0.685670
Train Epoch: 57 [33280/35339 (94%)]	Loss: 0.708512
Train Epoch: 57 [33920/35339 (96%)]	Loss: 0.850438
Train Epoch: 57 [34560/35339 (98%)]	Loss: 0.702597
Train Epoch: 57 [35200/35339 (99%)]	Loss: 0.791464

Validation set: Average loss: 3.7838, Accuracy: 739/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 58 [0/35339 (0%)]	Loss: 0.878186
Train Epoch: 58 [640/35339 (2%)]	Loss: 0.610475
Train Epoch: 58 [1280/35339 (4%)]	Loss: 0.806180
Train Epoch: 58 [1920/35339 (5%)]	Loss: 0.753187
Train Epoch: 58 [2560/35339 (7%)]	Loss: 0.750692
Train Epoch: 58 [3200/35339 (9%)]	Loss: 0.817003
Train Epoch: 58 [3840/35339 (11%)]	Loss: 0.734680
Train Epoch: 58 [4480/35339 (13%)]	Loss: 0.826607
Train Epoch: 58 [5120/35339 (14%)]	Loss: 0.688375
Train Epoch: 58 [5760/35339 (16%)]	Loss: 0.859337
Train Epoch: 58 [6400/35339 (18%)]	Loss: 0.872118
Train Epoch: 58 [7040/35339 (20%)]	Loss: 0.738028
Train Epoch: 58 [7680/35339 (22%)]	Loss: 0.706095
Train Epoch: 58 [8320/35339 (24%)]	Loss: 0.590025
Train Epoch: 58 [8960/35339 (25%)]	Loss: 0.930499
Train Epoch: 58 [9600/35339 (27%)]	Loss: 0.612916
Train Epoch: 58 [10240/35339 (29%)]	Loss: 0.801208
Train Epoch: 58 [10880/35339 (31%)]	Loss: 0.671168
Train Epoch: 58 [11520/35339 (33%)]	Loss: 0.599358
Train Epoch: 58 [12160/35339 (34%)]	Loss: 0.603792
Train Epoch: 58 [12800/35339 (36%)]	Loss: 1.046217
Train Epoch: 58 [13440/35339 (38%)]	Loss: 0.881512
Train Epoch: 58 [14080/35339 (40%)]	Loss: 0.641201
Train Epoch: 58 [14720/35339 (42%)]	Loss: 0.652300
Train Epoch: 58 [15360/35339 (43%)]	Loss: 0.865095
Train Epoch: 58 [16000/35339 (45%)]	Loss: 0.823858
Train Epoch: 58 [16640/35339 (47%)]	Loss: 0.667671
Train Epoch: 58 [17280/35339 (49%)]	Loss: 0.806352
Train Epoch: 58 [17920/35339 (51%)]	Loss: 0.737174
Train Epoch: 58 [18560/35339 (52%)]	Loss: 0.895009
Train Epoch: 58 [19200/35339 (54%)]	Loss: 0.853765
Train Epoch: 58 [19840/35339 (56%)]	Loss: 0.966707
Train Epoch: 58 [20480/35339 (58%)]	Loss: 0.785372
Train Epoch: 58 [21120/35339 (60%)]	Loss: 0.709821
Train Epoch: 58 [21760/35339 (61%)]	Loss: 0.799149
Train Epoch: 58 [22400/35339 (63%)]	Loss: 0.740791
Train Epoch: 58 [23040/35339 (65%)]	Loss: 0.658713
Train Epoch: 58 [23680/35339 (67%)]	Loss: 0.582152
Train Epoch: 58 [24320/35339 (69%)]	Loss: 0.856980
Train Epoch: 58 [24960/35339 (71%)]	Loss: 0.722050
Train Epoch: 58 [25600/35339 (72%)]	Loss: 0.928647
Train Epoch: 58 [26240/35339 (74%)]	Loss: 0.691483
Train Epoch: 58 [26880/35339 (76%)]	Loss: 0.755805
Train Epoch: 58 [27520/35339 (78%)]	Loss: 0.724188
Train Epoch: 58 [28160/35339 (80%)]	Loss: 0.715310
Train Epoch: 58 [28800/35339 (81%)]	Loss: 0.830881
Train Epoch: 58 [29440/35339 (83%)]	Loss: 0.926216
Train Epoch: 58 [30080/35339 (85%)]	Loss: 0.742546
Train Epoch: 58 [30720/35339 (87%)]	Loss: 0.777202
Train Epoch: 58 [31360/35339 (89%)]	Loss: 0.668359
Train Epoch: 58 [32000/35339 (90%)]	Loss: 0.864278
Train Epoch: 58 [32640/35339 (92%)]	Loss: 0.780639
Train Epoch: 58 [33280/35339 (94%)]	Loss: 0.746066
Train Epoch: 58 [33920/35339 (96%)]	Loss: 0.633605
Train Epoch: 58 [34560/35339 (98%)]	Loss: 0.538716
Train Epoch: 58 [35200/35339 (99%)]	Loss: 0.558808

Validation set: Average loss: 3.7802, Accuracy: 740/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 59 [0/35339 (0%)]	Loss: 0.725589
Train Epoch: 59 [640/35339 (2%)]	Loss: 0.818490
Train Epoch: 59 [1280/35339 (4%)]	Loss: 0.568466
Train Epoch: 59 [1920/35339 (5%)]	Loss: 0.841952
Train Epoch: 59 [2560/35339 (7%)]	Loss: 0.735755
Train Epoch: 59 [3200/35339 (9%)]	Loss: 0.794821
Train Epoch: 59 [3840/35339 (11%)]	Loss: 0.877243
Train Epoch: 59 [4480/35339 (13%)]	Loss: 0.743858
Train Epoch: 59 [5120/35339 (14%)]	Loss: 0.880744
Train Epoch: 59 [5760/35339 (16%)]	Loss: 0.587460
Train Epoch: 59 [6400/35339 (18%)]	Loss: 0.848858
Train Epoch: 59 [7040/35339 (20%)]	Loss: 0.712963
Train Epoch: 59 [7680/35339 (22%)]	Loss: 0.596043
Train Epoch: 59 [8320/35339 (24%)]	Loss: 0.798902
Train Epoch: 59 [8960/35339 (25%)]	Loss: 0.690603
Train Epoch: 59 [9600/35339 (27%)]	Loss: 0.814554
Train Epoch: 59 [10240/35339 (29%)]	Loss: 0.754465
Train Epoch: 59 [10880/35339 (31%)]	Loss: 0.732557
Train Epoch: 59 [11520/35339 (33%)]	Loss: 0.714986
Train Epoch: 59 [12160/35339 (34%)]	Loss: 0.696547
Train Epoch: 59 [12800/35339 (36%)]	Loss: 0.691047
Train Epoch: 59 [13440/35339 (38%)]	Loss: 0.683097
Train Epoch: 59 [14080/35339 (40%)]	Loss: 0.807981
Train Epoch: 59 [14720/35339 (42%)]	Loss: 0.613172
Train Epoch: 59 [15360/35339 (43%)]	Loss: 0.825637
Train Epoch: 59 [16000/35339 (45%)]	Loss: 0.787527
Train Epoch: 59 [16640/35339 (47%)]	Loss: 0.675622
Train Epoch: 59 [17280/35339 (49%)]	Loss: 0.752540
Train Epoch: 59 [17920/35339 (51%)]	Loss: 0.767537
Train Epoch: 59 [18560/35339 (52%)]	Loss: 0.809669
Train Epoch: 59 [19200/35339 (54%)]	Loss: 0.662925
Train Epoch: 59 [19840/35339 (56%)]	Loss: 0.897193
Train Epoch: 59 [20480/35339 (58%)]	Loss: 0.643335
Train Epoch: 59 [21120/35339 (60%)]	Loss: 0.576664
Train Epoch: 59 [21760/35339 (61%)]	Loss: 0.929207
Train Epoch: 59 [22400/35339 (63%)]	Loss: 0.737237
Train Epoch: 59 [23040/35339 (65%)]	Loss: 0.834727
Train Epoch: 59 [23680/35339 (67%)]	Loss: 0.670982
Train Epoch: 59 [24320/35339 (69%)]	Loss: 0.682263
Train Epoch: 59 [24960/35339 (71%)]	Loss: 0.867207
Train Epoch: 59 [25600/35339 (72%)]	Loss: 0.674133
Train Epoch: 59 [26240/35339 (74%)]	Loss: 0.816864
Train Epoch: 59 [26880/35339 (76%)]	Loss: 0.687854
Train Epoch: 59 [27520/35339 (78%)]	Loss: 0.696404
Train Epoch: 59 [28160/35339 (80%)]	Loss: 0.856719
Train Epoch: 59 [28800/35339 (81%)]	Loss: 0.820840
Train Epoch: 59 [29440/35339 (83%)]	Loss: 0.789546
Train Epoch: 59 [30080/35339 (85%)]	Loss: 0.836427
Train Epoch: 59 [30720/35339 (87%)]	Loss: 0.773868
Train Epoch: 59 [31360/35339 (89%)]	Loss: 0.669168
Train Epoch: 59 [32000/35339 (90%)]	Loss: 0.852272
Train Epoch: 59 [32640/35339 (92%)]	Loss: 0.858477
Train Epoch: 59 [33280/35339 (94%)]	Loss: 0.788188
Train Epoch: 59 [33920/35339 (96%)]	Loss: 0.631255
Train Epoch: 59 [34560/35339 (98%)]	Loss: 0.664552
Train Epoch: 59 [35200/35339 (99%)]	Loss: 0.800085

Validation set: Average loss: 3.7777, Accuracy: 752/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 60 [0/35339 (0%)]	Loss: 0.863212
Train Epoch: 60 [640/35339 (2%)]	Loss: 0.811810
Train Epoch: 60 [1280/35339 (4%)]	Loss: 0.693806
Train Epoch: 60 [1920/35339 (5%)]	Loss: 0.948444
Train Epoch: 60 [2560/35339 (7%)]	Loss: 0.699468
Train Epoch: 60 [3200/35339 (9%)]	Loss: 0.693415
Train Epoch: 60 [3840/35339 (11%)]	Loss: 0.821471
Train Epoch: 60 [4480/35339 (13%)]	Loss: 0.691143
Train Epoch: 60 [5120/35339 (14%)]	Loss: 0.683699
Train Epoch: 60 [5760/35339 (16%)]	Loss: 0.807003
Train Epoch: 60 [6400/35339 (18%)]	Loss: 0.827706
Train Epoch: 60 [7040/35339 (20%)]	Loss: 0.738583
Train Epoch: 60 [7680/35339 (22%)]	Loss: 0.597795
Train Epoch: 60 [8320/35339 (24%)]	Loss: 0.739527
Train Epoch: 60 [8960/35339 (25%)]	Loss: 0.766734
Train Epoch: 60 [9600/35339 (27%)]	Loss: 0.915885
Train Epoch: 60 [10240/35339 (29%)]	Loss: 0.736025
Train Epoch: 60 [10880/35339 (31%)]	Loss: 0.583651
Train Epoch: 60 [11520/35339 (33%)]	Loss: 0.830033
Train Epoch: 60 [12160/35339 (34%)]	Loss: 0.761780
Train Epoch: 60 [12800/35339 (36%)]	Loss: 0.805507
Train Epoch: 60 [13440/35339 (38%)]	Loss: 0.948656
Train Epoch: 60 [14080/35339 (40%)]	Loss: 0.637680
Train Epoch: 60 [14720/35339 (42%)]	Loss: 0.664412
Train Epoch: 60 [15360/35339 (43%)]	Loss: 0.728899
Train Epoch: 60 [16000/35339 (45%)]	Loss: 0.797533
Train Epoch: 60 [16640/35339 (47%)]	Loss: 0.741561
Train Epoch: 60 [17280/35339 (49%)]	Loss: 0.780034
Train Epoch: 60 [17920/35339 (51%)]	Loss: 0.745140
Train Epoch: 60 [18560/35339 (52%)]	Loss: 0.667722
Train Epoch: 60 [19200/35339 (54%)]	Loss: 0.807362
Train Epoch: 60 [19840/35339 (56%)]	Loss: 0.845037
Train Epoch: 60 [20480/35339 (58%)]	Loss: 0.777344
Train Epoch: 60 [21120/35339 (60%)]	Loss: 0.685345
Train Epoch: 60 [21760/35339 (61%)]	Loss: 0.841356
Train Epoch: 60 [22400/35339 (63%)]	Loss: 0.659954
Train Epoch: 60 [23040/35339 (65%)]	Loss: 0.722981
Train Epoch: 60 [23680/35339 (67%)]	Loss: 0.800803
Train Epoch: 60 [24320/35339 (69%)]	Loss: 0.850684
Train Epoch: 60 [24960/35339 (71%)]	Loss: 0.665482
Train Epoch: 60 [25600/35339 (72%)]	Loss: 0.670546
Train Epoch: 60 [26240/35339 (74%)]	Loss: 0.862190
Train Epoch: 60 [26880/35339 (76%)]	Loss: 0.650667
Train Epoch: 60 [27520/35339 (78%)]	Loss: 0.705896
Train Epoch: 60 [28160/35339 (80%)]	Loss: 0.579721
Train Epoch: 60 [28800/35339 (81%)]	Loss: 0.707985
Train Epoch: 60 [29440/35339 (83%)]	Loss: 0.946609
Train Epoch: 60 [30080/35339 (85%)]	Loss: 0.601963
Train Epoch: 60 [30720/35339 (87%)]	Loss: 0.736501
Train Epoch: 60 [31360/35339 (89%)]	Loss: 0.802478
Train Epoch: 60 [32000/35339 (90%)]	Loss: 0.819789
Train Epoch: 60 [32640/35339 (92%)]	Loss: 0.982648
Train Epoch: 60 [33280/35339 (94%)]	Loss: 0.676233
Train Epoch: 60 [33920/35339 (96%)]	Loss: 0.758154
Train Epoch: 60 [34560/35339 (98%)]	Loss: 0.644540
Train Epoch: 60 [35200/35339 (99%)]	Loss: 0.576875

Validation set: Average loss: 3.7772, Accuracy: 730/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 61 [0/35339 (0%)]	Loss: 0.686987
Train Epoch: 61 [640/35339 (2%)]	Loss: 0.689381
Train Epoch: 61 [1280/35339 (4%)]	Loss: 0.689709
Train Epoch: 61 [1920/35339 (5%)]	Loss: 0.923937
Train Epoch: 61 [2560/35339 (7%)]	Loss: 0.727392
Train Epoch: 61 [3200/35339 (9%)]	Loss: 0.707621
Train Epoch: 61 [3840/35339 (11%)]	Loss: 0.748154
Train Epoch: 61 [4480/35339 (13%)]	Loss: 0.679806
Train Epoch: 61 [5120/35339 (14%)]	Loss: 0.873712
Train Epoch: 61 [5760/35339 (16%)]	Loss: 0.667836
Train Epoch: 61 [6400/35339 (18%)]	Loss: 0.680886
Train Epoch: 61 [7040/35339 (20%)]	Loss: 0.809159
Train Epoch: 61 [7680/35339 (22%)]	Loss: 0.831283
Train Epoch: 61 [8320/35339 (24%)]	Loss: 0.717907
Train Epoch: 61 [8960/35339 (25%)]	Loss: 0.746160
Train Epoch: 61 [9600/35339 (27%)]	Loss: 0.690146
Train Epoch: 61 [10240/35339 (29%)]	Loss: 0.925779
Train Epoch: 61 [10880/35339 (31%)]	Loss: 0.801631
Train Epoch: 61 [11520/35339 (33%)]	Loss: 0.771231
Train Epoch: 61 [12160/35339 (34%)]	Loss: 0.797469
Train Epoch: 61 [12800/35339 (36%)]	Loss: 0.839302
Train Epoch: 61 [13440/35339 (38%)]	Loss: 0.813763
Train Epoch: 61 [14080/35339 (40%)]	Loss: 0.836109
Train Epoch: 61 [14720/35339 (42%)]	Loss: 0.772928
Train Epoch: 61 [15360/35339 (43%)]	Loss: 0.740094
Train Epoch: 61 [16000/35339 (45%)]	Loss: 0.612360
Train Epoch: 61 [16640/35339 (47%)]	Loss: 0.681855
Train Epoch: 61 [17280/35339 (49%)]	Loss: 0.817052
Train Epoch: 61 [17920/35339 (51%)]	Loss: 0.832978
Train Epoch: 61 [18560/35339 (52%)]	Loss: 0.957071
Train Epoch: 61 [19200/35339 (54%)]	Loss: 0.802670
Train Epoch: 61 [19840/35339 (56%)]	Loss: 1.028357
Train Epoch: 61 [20480/35339 (58%)]	Loss: 0.736944
Train Epoch: 61 [21120/35339 (60%)]	Loss: 0.864710
Train Epoch: 61 [21760/35339 (61%)]	Loss: 0.706266
Train Epoch: 61 [22400/35339 (63%)]	Loss: 0.736420
Train Epoch: 61 [23040/35339 (65%)]	Loss: 0.820820
Train Epoch: 61 [23680/35339 (67%)]	Loss: 0.731868
Train Epoch: 61 [24320/35339 (69%)]	Loss: 0.676771
Train Epoch: 61 [24960/35339 (71%)]	Loss: 0.816636
Train Epoch: 61 [25600/35339 (72%)]	Loss: 0.754833
Train Epoch: 61 [26240/35339 (74%)]	Loss: 0.798449
Train Epoch: 61 [26880/35339 (76%)]	Loss: 0.700483
Train Epoch: 61 [27520/35339 (78%)]	Loss: 0.647654
Train Epoch: 61 [28160/35339 (80%)]	Loss: 0.843032
Train Epoch: 61 [28800/35339 (81%)]	Loss: 0.779922
Train Epoch: 61 [29440/35339 (83%)]	Loss: 0.747665
Train Epoch: 61 [30080/35339 (85%)]	Loss: 0.748641
Train Epoch: 61 [30720/35339 (87%)]	Loss: 0.998130
Train Epoch: 61 [31360/35339 (89%)]	Loss: 0.653528
Train Epoch: 61 [32000/35339 (90%)]	Loss: 0.694665
Train Epoch: 61 [32640/35339 (92%)]	Loss: 0.886939
Train Epoch: 61 [33280/35339 (94%)]	Loss: 0.693672
Train Epoch: 61 [33920/35339 (96%)]	Loss: 0.634781
Train Epoch: 61 [34560/35339 (98%)]	Loss: 0.942012
Train Epoch: 61 [35200/35339 (99%)]	Loss: 0.631456

Validation set: Average loss: 3.7870, Accuracy: 726/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 62 [0/35339 (0%)]	Loss: 0.599822
Train Epoch: 62 [640/35339 (2%)]	Loss: 0.703774
Train Epoch: 62 [1280/35339 (4%)]	Loss: 0.851026
Train Epoch: 62 [1920/35339 (5%)]	Loss: 0.892578
Train Epoch: 62 [2560/35339 (7%)]	Loss: 0.932106
Train Epoch: 62 [3200/35339 (9%)]	Loss: 0.882275
Train Epoch: 62 [3840/35339 (11%)]	Loss: 0.678496
Train Epoch: 62 [4480/35339 (13%)]	Loss: 0.746910
Train Epoch: 62 [5120/35339 (14%)]	Loss: 0.600421
Train Epoch: 62 [5760/35339 (16%)]	Loss: 0.811084
Train Epoch: 62 [6400/35339 (18%)]	Loss: 0.601588
Train Epoch: 62 [7040/35339 (20%)]	Loss: 0.896700
Train Epoch: 62 [7680/35339 (22%)]	Loss: 0.809692
Train Epoch: 62 [8320/35339 (24%)]	Loss: 0.760860
Train Epoch: 62 [8960/35339 (25%)]	Loss: 0.574157
Train Epoch: 62 [9600/35339 (27%)]	Loss: 0.756254
Train Epoch: 62 [10240/35339 (29%)]	Loss: 0.732462
Train Epoch: 62 [10880/35339 (31%)]	Loss: 0.635314
Train Epoch: 62 [11520/35339 (33%)]	Loss: 0.557265
Train Epoch: 62 [12160/35339 (34%)]	Loss: 0.927516
Train Epoch: 62 [12800/35339 (36%)]	Loss: 0.653461
Train Epoch: 62 [13440/35339 (38%)]	Loss: 0.894264
Train Epoch: 62 [14080/35339 (40%)]	Loss: 0.973052
Train Epoch: 62 [14720/35339 (42%)]	Loss: 0.565822
Train Epoch: 62 [15360/35339 (43%)]	Loss: 0.979882
Train Epoch: 62 [16000/35339 (45%)]	Loss: 0.903041
Train Epoch: 62 [16640/35339 (47%)]	Loss: 0.692248
Train Epoch: 62 [17280/35339 (49%)]	Loss: 0.621876
Train Epoch: 62 [17920/35339 (51%)]	Loss: 0.718362
Train Epoch: 62 [18560/35339 (52%)]	Loss: 0.705684
Train Epoch: 62 [19200/35339 (54%)]	Loss: 0.655009
Train Epoch: 62 [19840/35339 (56%)]	Loss: 0.696506
Train Epoch: 62 [20480/35339 (58%)]	Loss: 0.690028
Train Epoch: 62 [21120/35339 (60%)]	Loss: 0.801114
Train Epoch: 62 [21760/35339 (61%)]	Loss: 0.843274
Train Epoch: 62 [22400/35339 (63%)]	Loss: 0.514639
Train Epoch: 62 [23040/35339 (65%)]	Loss: 0.674328
Train Epoch: 62 [23680/35339 (67%)]	Loss: 0.751624
Train Epoch: 62 [24320/35339 (69%)]	Loss: 0.818162
Train Epoch: 62 [24960/35339 (71%)]	Loss: 0.715709
Train Epoch: 62 [25600/35339 (72%)]	Loss: 0.912748
Train Epoch: 62 [26240/35339 (74%)]	Loss: 0.728841
Train Epoch: 62 [26880/35339 (76%)]	Loss: 0.602506
Train Epoch: 62 [27520/35339 (78%)]	Loss: 0.640830
Train Epoch: 62 [28160/35339 (80%)]	Loss: 0.733091
Train Epoch: 62 [28800/35339 (81%)]	Loss: 0.803231
Train Epoch: 62 [29440/35339 (83%)]	Loss: 0.704076
Train Epoch: 62 [30080/35339 (85%)]	Loss: 0.716556
Train Epoch: 62 [30720/35339 (87%)]	Loss: 0.716799
Train Epoch: 62 [31360/35339 (89%)]	Loss: 0.715441
Train Epoch: 62 [32000/35339 (90%)]	Loss: 0.706686
Train Epoch: 62 [32640/35339 (92%)]	Loss: 0.603372
Train Epoch: 62 [33280/35339 (94%)]	Loss: 0.598787
Train Epoch: 62 [33920/35339 (96%)]	Loss: 0.742624
Train Epoch: 62 [34560/35339 (98%)]	Loss: 0.728366
Train Epoch: 62 [35200/35339 (99%)]	Loss: 0.794343

Validation set: Average loss: 3.7836, Accuracy: 720/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 63 [0/35339 (0%)]	Loss: 0.721411
Train Epoch: 63 [640/35339 (2%)]	Loss: 1.086440
Train Epoch: 63 [1280/35339 (4%)]	Loss: 0.632157
Train Epoch: 63 [1920/35339 (5%)]	Loss: 0.654944
Train Epoch: 63 [2560/35339 (7%)]	Loss: 0.854820
Train Epoch: 63 [3200/35339 (9%)]	Loss: 0.793798
Train Epoch: 63 [3840/35339 (11%)]	Loss: 0.699955
Train Epoch: 63 [4480/35339 (13%)]	Loss: 0.715685
Train Epoch: 63 [5120/35339 (14%)]	Loss: 0.778723
Train Epoch: 63 [5760/35339 (16%)]	Loss: 0.732068
Train Epoch: 63 [6400/35339 (18%)]	Loss: 0.991965
Train Epoch: 63 [7040/35339 (20%)]	Loss: 0.718093
Train Epoch: 63 [7680/35339 (22%)]	Loss: 0.500472
Train Epoch: 63 [8320/35339 (24%)]	Loss: 0.830209
Train Epoch: 63 [8960/35339 (25%)]	Loss: 0.819496
Train Epoch: 63 [9600/35339 (27%)]	Loss: 0.708804
Train Epoch: 63 [10240/35339 (29%)]	Loss: 0.943160
Train Epoch: 63 [10880/35339 (31%)]	Loss: 0.805592
Train Epoch: 63 [11520/35339 (33%)]	Loss: 0.587438
Train Epoch: 63 [12160/35339 (34%)]	Loss: 0.991373
Train Epoch: 63 [12800/35339 (36%)]	Loss: 0.640110
Train Epoch: 63 [13440/35339 (38%)]	Loss: 0.869364
Train Epoch: 63 [14080/35339 (40%)]	Loss: 0.780336
Train Epoch: 63 [14720/35339 (42%)]	Loss: 0.676579
Train Epoch: 63 [15360/35339 (43%)]	Loss: 0.647968
Train Epoch: 63 [16000/35339 (45%)]	Loss: 0.652929
Train Epoch: 63 [16640/35339 (47%)]	Loss: 0.674797
Train Epoch: 63 [17280/35339 (49%)]	Loss: 0.767846
Train Epoch: 63 [17920/35339 (51%)]	Loss: 0.832798
Train Epoch: 63 [18560/35339 (52%)]	Loss: 0.670110
Train Epoch: 63 [19200/35339 (54%)]	Loss: 1.027358
Train Epoch: 63 [19840/35339 (56%)]	Loss: 0.596175
Train Epoch: 63 [20480/35339 (58%)]	Loss: 0.819443
Train Epoch: 63 [21120/35339 (60%)]	Loss: 0.767742
Train Epoch: 63 [21760/35339 (61%)]	Loss: 0.673141
Train Epoch: 63 [22400/35339 (63%)]	Loss: 0.835807
Train Epoch: 63 [23040/35339 (65%)]	Loss: 0.854962
Train Epoch: 63 [23680/35339 (67%)]	Loss: 0.787553
Train Epoch: 63 [24320/35339 (69%)]	Loss: 0.908136
Train Epoch: 63 [24960/35339 (71%)]	Loss: 0.700878
Train Epoch: 63 [25600/35339 (72%)]	Loss: 0.605451
Train Epoch: 63 [26240/35339 (74%)]	Loss: 0.785677
Train Epoch: 63 [26880/35339 (76%)]	Loss: 0.580476
Train Epoch: 63 [27520/35339 (78%)]	Loss: 0.730956
Train Epoch: 63 [28160/35339 (80%)]	Loss: 0.695498
Train Epoch: 63 [28800/35339 (81%)]	Loss: 0.682385
Train Epoch: 63 [29440/35339 (83%)]	Loss: 0.700347
Train Epoch: 63 [30080/35339 (85%)]	Loss: 0.675411
Train Epoch: 63 [30720/35339 (87%)]	Loss: 0.712904
Train Epoch: 63 [31360/35339 (89%)]	Loss: 0.792824
Train Epoch: 63 [32000/35339 (90%)]	Loss: 0.709801
Train Epoch: 63 [32640/35339 (92%)]	Loss: 0.832834
Train Epoch: 63 [33280/35339 (94%)]	Loss: 0.768275
Train Epoch: 63 [33920/35339 (96%)]	Loss: 0.703822
Train Epoch: 63 [34560/35339 (98%)]	Loss: 0.695494
Train Epoch: 63 [35200/35339 (99%)]	Loss: 0.863770

Validation set: Average loss: 3.7877, Accuracy: 739/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 64 [0/35339 (0%)]	Loss: 0.811336
Train Epoch: 64 [640/35339 (2%)]	Loss: 0.638141
Train Epoch: 64 [1280/35339 (4%)]	Loss: 0.900456
Train Epoch: 64 [1920/35339 (5%)]	Loss: 0.711371
Train Epoch: 64 [2560/35339 (7%)]	Loss: 0.722568
Train Epoch: 64 [3200/35339 (9%)]	Loss: 0.759635
Train Epoch: 64 [3840/35339 (11%)]	Loss: 0.654599
Train Epoch: 64 [4480/35339 (13%)]	Loss: 0.908164
Train Epoch: 64 [5120/35339 (14%)]	Loss: 0.600083
Train Epoch: 64 [5760/35339 (16%)]	Loss: 0.598597
Train Epoch: 64 [6400/35339 (18%)]	Loss: 0.668994
Train Epoch: 64 [7040/35339 (20%)]	Loss: 0.758438
Train Epoch: 64 [7680/35339 (22%)]	Loss: 0.710327
Train Epoch: 64 [8320/35339 (24%)]	Loss: 0.659537
Train Epoch: 64 [8960/35339 (25%)]	Loss: 0.832366
Train Epoch: 64 [9600/35339 (27%)]	Loss: 0.714405
Train Epoch: 64 [10240/35339 (29%)]	Loss: 0.536086
Train Epoch: 64 [10880/35339 (31%)]	Loss: 0.631250
Train Epoch: 64 [11520/35339 (33%)]	Loss: 0.754594
Train Epoch: 64 [12160/35339 (34%)]	Loss: 0.891769
Train Epoch: 64 [12800/35339 (36%)]	Loss: 0.787865
Train Epoch: 64 [13440/35339 (38%)]	Loss: 0.860354
Train Epoch: 64 [14080/35339 (40%)]	Loss: 0.705618
Train Epoch: 64 [14720/35339 (42%)]	Loss: 0.909857
Train Epoch: 64 [15360/35339 (43%)]	Loss: 0.669792
Train Epoch: 64 [16000/35339 (45%)]	Loss: 0.716651
Train Epoch: 64 [16640/35339 (47%)]	Loss: 0.857761
Train Epoch: 64 [17280/35339 (49%)]	Loss: 0.646597
Train Epoch: 64 [17920/35339 (51%)]	Loss: 0.740832
Train Epoch: 64 [18560/35339 (52%)]	Loss: 0.776147
Train Epoch: 64 [19200/35339 (54%)]	Loss: 0.740579
Train Epoch: 64 [19840/35339 (56%)]	Loss: 0.670490
Train Epoch: 64 [20480/35339 (58%)]	Loss: 0.644012
Train Epoch: 64 [21120/35339 (60%)]	Loss: 0.838322
Train Epoch: 64 [21760/35339 (61%)]	Loss: 0.597094
Train Epoch: 64 [22400/35339 (63%)]	Loss: 0.664219
Train Epoch: 64 [23040/35339 (65%)]	Loss: 0.726277
Train Epoch: 64 [23680/35339 (67%)]	Loss: 0.716217
Train Epoch: 64 [24320/35339 (69%)]	Loss: 0.896771
Train Epoch: 64 [24960/35339 (71%)]	Loss: 0.603551
Train Epoch: 64 [25600/35339 (72%)]	Loss: 0.676070
Train Epoch: 64 [26240/35339 (74%)]	Loss: 0.784161
Train Epoch: 64 [26880/35339 (76%)]	Loss: 0.683497
Train Epoch: 64 [27520/35339 (78%)]	Loss: 0.725915
Train Epoch: 64 [28160/35339 (80%)]	Loss: 0.796458
Train Epoch: 64 [28800/35339 (81%)]	Loss: 0.875435
Train Epoch: 64 [29440/35339 (83%)]	Loss: 0.676384
Train Epoch: 64 [30080/35339 (85%)]	Loss: 0.777078
Train Epoch: 64 [30720/35339 (87%)]	Loss: 0.732016
Train Epoch: 64 [31360/35339 (89%)]	Loss: 0.712314
Train Epoch: 64 [32000/35339 (90%)]	Loss: 0.643160
Train Epoch: 64 [32640/35339 (92%)]	Loss: 0.712136
Train Epoch: 64 [33280/35339 (94%)]	Loss: 0.761690
Train Epoch: 64 [33920/35339 (96%)]	Loss: 0.778677
Train Epoch: 64 [34560/35339 (98%)]	Loss: 0.684266
Train Epoch: 64 [35200/35339 (99%)]	Loss: 0.541676

Validation set: Average loss: 3.7825, Accuracy: 749/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 65 [0/35339 (0%)]	Loss: 0.756758
Train Epoch: 65 [640/35339 (2%)]	Loss: 0.747340
Train Epoch: 65 [1280/35339 (4%)]	Loss: 0.725885
Train Epoch: 65 [1920/35339 (5%)]	Loss: 0.904102
Train Epoch: 65 [2560/35339 (7%)]	Loss: 0.670493
Train Epoch: 65 [3200/35339 (9%)]	Loss: 0.850863
Train Epoch: 65 [3840/35339 (11%)]	Loss: 0.857654
Train Epoch: 65 [4480/35339 (13%)]	Loss: 0.643198
Train Epoch: 65 [5120/35339 (14%)]	Loss: 0.591169
Train Epoch: 65 [5760/35339 (16%)]	Loss: 0.768544
Train Epoch: 65 [6400/35339 (18%)]	Loss: 0.827313
Train Epoch: 65 [7040/35339 (20%)]	Loss: 0.529288
Train Epoch: 65 [7680/35339 (22%)]	Loss: 0.609980
Train Epoch: 65 [8320/35339 (24%)]	Loss: 0.803319
Train Epoch: 65 [8960/35339 (25%)]	Loss: 0.635818
Train Epoch: 65 [9600/35339 (27%)]	Loss: 0.848211
Train Epoch: 65 [10240/35339 (29%)]	Loss: 0.877177
Train Epoch: 65 [10880/35339 (31%)]	Loss: 0.550895
Train Epoch: 65 [11520/35339 (33%)]	Loss: 0.687356
Train Epoch: 65 [12160/35339 (34%)]	Loss: 0.793061
Train Epoch: 65 [12800/35339 (36%)]	Loss: 0.762245
Train Epoch: 65 [13440/35339 (38%)]	Loss: 0.655364
Train Epoch: 65 [14080/35339 (40%)]	Loss: 0.642178
Train Epoch: 65 [14720/35339 (42%)]	Loss: 0.951725
Train Epoch: 65 [15360/35339 (43%)]	Loss: 0.747197
Train Epoch: 65 [16000/35339 (45%)]	Loss: 0.867219
Train Epoch: 65 [16640/35339 (47%)]	Loss: 0.757744
Train Epoch: 65 [17280/35339 (49%)]	Loss: 0.749213
Train Epoch: 65 [17920/35339 (51%)]	Loss: 0.749301
Train Epoch: 65 [18560/35339 (52%)]	Loss: 0.590856
Train Epoch: 65 [19200/35339 (54%)]	Loss: 0.577543
Train Epoch: 65 [19840/35339 (56%)]	Loss: 0.801478
Train Epoch: 65 [20480/35339 (58%)]	Loss: 0.605989
Train Epoch: 65 [21120/35339 (60%)]	Loss: 0.945596
Train Epoch: 65 [21760/35339 (61%)]	Loss: 0.981719
Train Epoch: 65 [22400/35339 (63%)]	Loss: 0.682755
Train Epoch: 65 [23040/35339 (65%)]	Loss: 0.977389
Train Epoch: 65 [23680/35339 (67%)]	Loss: 0.776538
Train Epoch: 65 [24320/35339 (69%)]	Loss: 0.810003
Train Epoch: 65 [24960/35339 (71%)]	Loss: 0.592301
Train Epoch: 65 [25600/35339 (72%)]	Loss: 0.797439
Train Epoch: 65 [26240/35339 (74%)]	Loss: 0.804574
Train Epoch: 65 [26880/35339 (76%)]	Loss: 0.766587
Train Epoch: 65 [27520/35339 (78%)]	Loss: 0.728978
Train Epoch: 65 [28160/35339 (80%)]	Loss: 0.700548
Train Epoch: 65 [28800/35339 (81%)]	Loss: 0.834375
Train Epoch: 65 [29440/35339 (83%)]	Loss: 0.625050
Train Epoch: 65 [30080/35339 (85%)]	Loss: 0.695320
Train Epoch: 65 [30720/35339 (87%)]	Loss: 0.812816
Train Epoch: 65 [31360/35339 (89%)]	Loss: 0.751960
Train Epoch: 65 [32000/35339 (90%)]	Loss: 0.608133
Train Epoch: 65 [32640/35339 (92%)]	Loss: 0.832072
Train Epoch: 65 [33280/35339 (94%)]	Loss: 0.770046
Train Epoch: 65 [33920/35339 (96%)]	Loss: 0.797428
Train Epoch: 65 [34560/35339 (98%)]	Loss: 0.846140
Train Epoch: 65 [35200/35339 (99%)]	Loss: 0.647809

Validation set: Average loss: 3.7834, Accuracy: 733/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 66 [0/35339 (0%)]	Loss: 0.700293
Train Epoch: 66 [640/35339 (2%)]	Loss: 0.824109
Train Epoch: 66 [1280/35339 (4%)]	Loss: 0.924578
Train Epoch: 66 [1920/35339 (5%)]	Loss: 0.927497
Train Epoch: 66 [2560/35339 (7%)]	Loss: 0.806847
Train Epoch: 66 [3200/35339 (9%)]	Loss: 0.794703
Train Epoch: 66 [3840/35339 (11%)]	Loss: 0.623712
Train Epoch: 66 [4480/35339 (13%)]	Loss: 0.748952
Train Epoch: 66 [5120/35339 (14%)]	Loss: 0.632392
Train Epoch: 66 [5760/35339 (16%)]	Loss: 0.783627
Train Epoch: 66 [6400/35339 (18%)]	Loss: 0.771830
Train Epoch: 66 [7040/35339 (20%)]	Loss: 0.927393
Train Epoch: 66 [7680/35339 (22%)]	Loss: 0.655050
Train Epoch: 66 [8320/35339 (24%)]	Loss: 0.766948
Train Epoch: 66 [8960/35339 (25%)]	Loss: 0.699385
Train Epoch: 66 [9600/35339 (27%)]	Loss: 0.684951
Train Epoch: 66 [10240/35339 (29%)]	Loss: 0.878393
Train Epoch: 66 [10880/35339 (31%)]	Loss: 0.477451
Train Epoch: 66 [11520/35339 (33%)]	Loss: 0.788131
Train Epoch: 66 [12160/35339 (34%)]	Loss: 0.605961
Train Epoch: 66 [12800/35339 (36%)]	Loss: 0.605196
Train Epoch: 66 [13440/35339 (38%)]	Loss: 0.700946
Train Epoch: 66 [14080/35339 (40%)]	Loss: 0.788374
Train Epoch: 66 [14720/35339 (42%)]	Loss: 0.817944
Train Epoch: 66 [15360/35339 (43%)]	Loss: 0.619754
Train Epoch: 66 [16000/35339 (45%)]	Loss: 0.942307
Train Epoch: 66 [16640/35339 (47%)]	Loss: 0.680170
Train Epoch: 66 [17280/35339 (49%)]	Loss: 0.661680
Train Epoch: 66 [17920/35339 (51%)]	Loss: 0.706434
Train Epoch: 66 [18560/35339 (52%)]	Loss: 0.735513
Train Epoch: 66 [19200/35339 (54%)]	Loss: 0.761163
Train Epoch: 66 [19840/35339 (56%)]	Loss: 0.705726
Train Epoch: 66 [20480/35339 (58%)]	Loss: 0.750289
Train Epoch: 66 [21120/35339 (60%)]	Loss: 0.792371
Train Epoch: 66 [21760/35339 (61%)]	Loss: 0.753953
Train Epoch: 66 [22400/35339 (63%)]	Loss: 0.681406
Train Epoch: 66 [23040/35339 (65%)]	Loss: 0.570846
Train Epoch: 66 [23680/35339 (67%)]	Loss: 0.719042
Train Epoch: 66 [24320/35339 (69%)]	Loss: 0.724744
Train Epoch: 66 [24960/35339 (71%)]	Loss: 0.625271
Train Epoch: 66 [25600/35339 (72%)]	Loss: 0.708878
Train Epoch: 66 [26240/35339 (74%)]	Loss: 0.747810
Train Epoch: 66 [26880/35339 (76%)]	Loss: 0.738715
Train Epoch: 66 [27520/35339 (78%)]	Loss: 0.998248
Train Epoch: 66 [28160/35339 (80%)]	Loss: 0.858143
Train Epoch: 66 [28800/35339 (81%)]	Loss: 0.704267
Train Epoch: 66 [29440/35339 (83%)]	Loss: 0.563917
Train Epoch: 66 [30080/35339 (85%)]	Loss: 0.687826
Train Epoch: 66 [30720/35339 (87%)]	Loss: 0.700792
Train Epoch: 66 [31360/35339 (89%)]	Loss: 0.563690
Train Epoch: 66 [32000/35339 (90%)]	Loss: 0.712721
Train Epoch: 66 [32640/35339 (92%)]	Loss: 0.633399
Train Epoch: 66 [33280/35339 (94%)]	Loss: 0.688204
Train Epoch: 66 [33920/35339 (96%)]	Loss: 0.807991
Train Epoch: 66 [34560/35339 (98%)]	Loss: 0.705656
Train Epoch: 66 [35200/35339 (99%)]	Loss: 0.698592

Validation set: Average loss: 3.7895, Accuracy: 734/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 67 [0/35339 (0%)]	Loss: 0.769328
Train Epoch: 67 [640/35339 (2%)]	Loss: 0.658337
Train Epoch: 67 [1280/35339 (4%)]	Loss: 0.576108
Train Epoch: 67 [1920/35339 (5%)]	Loss: 0.619655
Train Epoch: 67 [2560/35339 (7%)]	Loss: 0.854376
Train Epoch: 67 [3200/35339 (9%)]	Loss: 0.797559
Train Epoch: 67 [3840/35339 (11%)]	Loss: 0.863022
Train Epoch: 67 [4480/35339 (13%)]	Loss: 0.806819
Train Epoch: 67 [5120/35339 (14%)]	Loss: 0.923321
Train Epoch: 67 [5760/35339 (16%)]	Loss: 0.661355
Train Epoch: 67 [6400/35339 (18%)]	Loss: 0.624485
Train Epoch: 67 [7040/35339 (20%)]	Loss: 0.703201
Train Epoch: 67 [7680/35339 (22%)]	Loss: 0.780846
Train Epoch: 67 [8320/35339 (24%)]	Loss: 0.956847
Train Epoch: 67 [8960/35339 (25%)]	Loss: 0.565024
Train Epoch: 67 [9600/35339 (27%)]	Loss: 0.792676
Train Epoch: 67 [10240/35339 (29%)]	Loss: 0.733378
Train Epoch: 67 [10880/35339 (31%)]	Loss: 0.641767
Train Epoch: 67 [11520/35339 (33%)]	Loss: 0.702407
Train Epoch: 67 [12160/35339 (34%)]	Loss: 0.569154
Train Epoch: 67 [12800/35339 (36%)]	Loss: 0.722891
Train Epoch: 67 [13440/35339 (38%)]	Loss: 0.821942
Train Epoch: 67 [14080/35339 (40%)]	Loss: 0.740408
Train Epoch: 67 [14720/35339 (42%)]	Loss: 0.628780
Train Epoch: 67 [15360/35339 (43%)]	Loss: 0.623421
Train Epoch: 67 [16000/35339 (45%)]	Loss: 0.679529
Train Epoch: 67 [16640/35339 (47%)]	Loss: 0.540585
Train Epoch: 67 [17280/35339 (49%)]	Loss: 0.676443
Train Epoch: 67 [17920/35339 (51%)]	Loss: 0.632667
Train Epoch: 67 [18560/35339 (52%)]	Loss: 0.703955
Train Epoch: 67 [19200/35339 (54%)]	Loss: 0.776941
Train Epoch: 67 [19840/35339 (56%)]	Loss: 0.787359
Train Epoch: 67 [20480/35339 (58%)]	Loss: 0.654468
Train Epoch: 67 [21120/35339 (60%)]	Loss: 0.750327
Train Epoch: 67 [21760/35339 (61%)]	Loss: 0.639015
Train Epoch: 67 [22400/35339 (63%)]	Loss: 0.721052
Train Epoch: 67 [23040/35339 (65%)]	Loss: 0.719977
Train Epoch: 67 [23680/35339 (67%)]	Loss: 0.733004
Train Epoch: 67 [24320/35339 (69%)]	Loss: 0.854233
Train Epoch: 67 [24960/35339 (71%)]	Loss: 0.641528
Train Epoch: 67 [25600/35339 (72%)]	Loss: 0.836907
Train Epoch: 67 [26240/35339 (74%)]	Loss: 0.797693
Train Epoch: 67 [26880/35339 (76%)]	Loss: 0.771917
Train Epoch: 67 [27520/35339 (78%)]	Loss: 0.712546
Train Epoch: 67 [28160/35339 (80%)]	Loss: 0.775646
Train Epoch: 67 [28800/35339 (81%)]	Loss: 0.886142
Train Epoch: 67 [29440/35339 (83%)]	Loss: 0.548075
Train Epoch: 67 [30080/35339 (85%)]	Loss: 0.914047
Train Epoch: 67 [30720/35339 (87%)]	Loss: 0.518327
Train Epoch: 67 [31360/35339 (89%)]	Loss: 0.664969
Train Epoch: 67 [32000/35339 (90%)]	Loss: 0.702831
Train Epoch: 67 [32640/35339 (92%)]	Loss: 0.573094
Train Epoch: 67 [33280/35339 (94%)]	Loss: 0.747801
Train Epoch: 67 [33920/35339 (96%)]	Loss: 0.884487
Train Epoch: 67 [34560/35339 (98%)]	Loss: 0.745836
Train Epoch: 67 [35200/35339 (99%)]	Loss: 0.646028

Validation set: Average loss: 3.7930, Accuracy: 726/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 68 [0/35339 (0%)]	Loss: 0.528480
Train Epoch: 68 [640/35339 (2%)]	Loss: 0.684162
Train Epoch: 68 [1280/35339 (4%)]	Loss: 0.717083
Train Epoch: 68 [1920/35339 (5%)]	Loss: 0.827513
Train Epoch: 68 [2560/35339 (7%)]	Loss: 0.629744
Train Epoch: 68 [3200/35339 (9%)]	Loss: 0.776203
Train Epoch: 68 [3840/35339 (11%)]	Loss: 0.853734
Train Epoch: 68 [4480/35339 (13%)]	Loss: 0.742965
Train Epoch: 68 [5120/35339 (14%)]	Loss: 0.875733
Train Epoch: 68 [5760/35339 (16%)]	Loss: 0.565953
Train Epoch: 68 [6400/35339 (18%)]	Loss: 0.846703
Train Epoch: 68 [7040/35339 (20%)]	Loss: 0.634166
Train Epoch: 68 [7680/35339 (22%)]	Loss: 0.669715
Train Epoch: 68 [8320/35339 (24%)]	Loss: 0.719857
Train Epoch: 68 [8960/35339 (25%)]	Loss: 0.800864
Train Epoch: 68 [9600/35339 (27%)]	Loss: 0.658854
Train Epoch: 68 [10240/35339 (29%)]	Loss: 0.904673
Train Epoch: 68 [10880/35339 (31%)]	Loss: 0.841773
Train Epoch: 68 [11520/35339 (33%)]	Loss: 0.497845
Train Epoch: 68 [12160/35339 (34%)]	Loss: 0.708291
Train Epoch: 68 [12800/35339 (36%)]	Loss: 0.803478
Train Epoch: 68 [13440/35339 (38%)]	Loss: 0.687778
Train Epoch: 68 [14080/35339 (40%)]	Loss: 0.617000
Train Epoch: 68 [14720/35339 (42%)]	Loss: 0.678966
Train Epoch: 68 [15360/35339 (43%)]	Loss: 0.894526
Train Epoch: 68 [16000/35339 (45%)]	Loss: 0.959512
Train Epoch: 68 [16640/35339 (47%)]	Loss: 0.762705
Train Epoch: 68 [17280/35339 (49%)]	Loss: 0.607570
Train Epoch: 68 [17920/35339 (51%)]	Loss: 0.617168
Train Epoch: 68 [18560/35339 (52%)]	Loss: 0.779882
Train Epoch: 68 [19200/35339 (54%)]	Loss: 0.600503
Train Epoch: 68 [19840/35339 (56%)]	Loss: 0.808407
Train Epoch: 68 [20480/35339 (58%)]	Loss: 0.562823
Train Epoch: 68 [21120/35339 (60%)]	Loss: 0.509286
Train Epoch: 68 [21760/35339 (61%)]	Loss: 0.727227
Train Epoch: 68 [22400/35339 (63%)]	Loss: 0.725621
Train Epoch: 68 [23040/35339 (65%)]	Loss: 0.707246
Train Epoch: 68 [23680/35339 (67%)]	Loss: 0.574431
Train Epoch: 68 [24320/35339 (69%)]	Loss: 0.794249
Train Epoch: 68 [24960/35339 (71%)]	Loss: 0.759169
Train Epoch: 68 [25600/35339 (72%)]	Loss: 0.677530
Train Epoch: 68 [26240/35339 (74%)]	Loss: 0.551506
Train Epoch: 68 [26880/35339 (76%)]	Loss: 0.738018
Train Epoch: 68 [27520/35339 (78%)]	Loss: 0.613054
Train Epoch: 68 [28160/35339 (80%)]	Loss: 0.858688
Train Epoch: 68 [28800/35339 (81%)]	Loss: 0.725598
Train Epoch: 68 [29440/35339 (83%)]	Loss: 0.727022
Train Epoch: 68 [30080/35339 (85%)]	Loss: 0.653986
Train Epoch: 68 [30720/35339 (87%)]	Loss: 0.780502
Train Epoch: 68 [31360/35339 (89%)]	Loss: 0.548037
Train Epoch: 68 [32000/35339 (90%)]	Loss: 0.603069
Train Epoch: 68 [32640/35339 (92%)]	Loss: 0.669393
Train Epoch: 68 [33280/35339 (94%)]	Loss: 0.731349
Train Epoch: 68 [33920/35339 (96%)]	Loss: 0.635389
Train Epoch: 68 [34560/35339 (98%)]	Loss: 0.669256
Train Epoch: 68 [35200/35339 (99%)]	Loss: 0.648361

Validation set: Average loss: 3.7807, Accuracy: 718/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 69 [0/35339 (0%)]	Loss: 0.843608
Train Epoch: 69 [640/35339 (2%)]	Loss: 0.714049
Train Epoch: 69 [1280/35339 (4%)]	Loss: 0.571563
Train Epoch: 69 [1920/35339 (5%)]	Loss: 0.662364
Train Epoch: 69 [2560/35339 (7%)]	Loss: 0.691715
Train Epoch: 69 [3200/35339 (9%)]	Loss: 0.541120
Train Epoch: 69 [3840/35339 (11%)]	Loss: 0.845531
Train Epoch: 69 [4480/35339 (13%)]	Loss: 0.725607
Train Epoch: 69 [5120/35339 (14%)]	Loss: 0.660015
Train Epoch: 69 [5760/35339 (16%)]	Loss: 0.728194
Train Epoch: 69 [6400/35339 (18%)]	Loss: 0.560133
Train Epoch: 69 [7040/35339 (20%)]	Loss: 0.855378
Train Epoch: 69 [7680/35339 (22%)]	Loss: 0.674199
Train Epoch: 69 [8320/35339 (24%)]	Loss: 0.834001
Train Epoch: 69 [8960/35339 (25%)]	Loss: 0.604889
Train Epoch: 69 [9600/35339 (27%)]	Loss: 0.618632
Train Epoch: 69 [10240/35339 (29%)]	Loss: 0.677740
Train Epoch: 69 [10880/35339 (31%)]	Loss: 0.797967
Train Epoch: 69 [11520/35339 (33%)]	Loss: 0.547543
Train Epoch: 69 [12160/35339 (34%)]	Loss: 0.635848
Train Epoch: 69 [12800/35339 (36%)]	Loss: 0.867592
Train Epoch: 69 [13440/35339 (38%)]	Loss: 0.638926
Train Epoch: 69 [14080/35339 (40%)]	Loss: 0.688578
Train Epoch: 69 [14720/35339 (42%)]	Loss: 0.721926
Train Epoch: 69 [15360/35339 (43%)]	Loss: 0.696772
Train Epoch: 69 [16000/35339 (45%)]	Loss: 0.781260
Train Epoch: 69 [16640/35339 (47%)]	Loss: 0.594059
Train Epoch: 69 [17280/35339 (49%)]	Loss: 0.848894
Train Epoch: 69 [17920/35339 (51%)]	Loss: 0.787180
Train Epoch: 69 [18560/35339 (52%)]	Loss: 0.780289
Train Epoch: 69 [19200/35339 (54%)]	Loss: 0.685503
Train Epoch: 69 [19840/35339 (56%)]	Loss: 0.647977
Train Epoch: 69 [20480/35339 (58%)]	Loss: 0.663608
Train Epoch: 69 [21120/35339 (60%)]	Loss: 0.894560
Train Epoch: 69 [21760/35339 (61%)]	Loss: 0.762849
Train Epoch: 69 [22400/35339 (63%)]	Loss: 0.973364
Train Epoch: 69 [23040/35339 (65%)]	Loss: 0.992307
Train Epoch: 69 [23680/35339 (67%)]	Loss: 0.715024
Train Epoch: 69 [24320/35339 (69%)]	Loss: 0.767324
Train Epoch: 69 [24960/35339 (71%)]	Loss: 0.876046
Train Epoch: 69 [25600/35339 (72%)]	Loss: 0.681519
Train Epoch: 69 [26240/35339 (74%)]	Loss: 0.715365
Train Epoch: 69 [26880/35339 (76%)]	Loss: 0.665026
Train Epoch: 69 [27520/35339 (78%)]	Loss: 0.665720
Train Epoch: 69 [28160/35339 (80%)]	Loss: 0.530451
Train Epoch: 69 [28800/35339 (81%)]	Loss: 0.656169
Train Epoch: 69 [29440/35339 (83%)]	Loss: 0.763514
Train Epoch: 69 [30080/35339 (85%)]	Loss: 0.678454
Train Epoch: 69 [30720/35339 (87%)]	Loss: 0.863258
Train Epoch: 69 [31360/35339 (89%)]	Loss: 0.803464
Train Epoch: 69 [32000/35339 (90%)]	Loss: 0.727371
Train Epoch: 69 [32640/35339 (92%)]	Loss: 0.875294
Train Epoch: 69 [33280/35339 (94%)]	Loss: 0.769747
Train Epoch: 69 [33920/35339 (96%)]	Loss: 0.846672
Train Epoch: 69 [34560/35339 (98%)]	Loss: 0.726861
Train Epoch: 69 [35200/35339 (99%)]	Loss: 0.700154

Validation set: Average loss: 3.7901, Accuracy: 719/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 70 [0/35339 (0%)]	Loss: 0.797970
Train Epoch: 70 [640/35339 (2%)]	Loss: 0.672904
Train Epoch: 70 [1280/35339 (4%)]	Loss: 0.780810
Train Epoch: 70 [1920/35339 (5%)]	Loss: 0.792473
Train Epoch: 70 [2560/35339 (7%)]	Loss: 0.745657
Train Epoch: 70 [3200/35339 (9%)]	Loss: 0.865405
Train Epoch: 70 [3840/35339 (11%)]	Loss: 0.602292
Train Epoch: 70 [4480/35339 (13%)]	Loss: 0.608390
Train Epoch: 70 [5120/35339 (14%)]	Loss: 0.632514
Train Epoch: 70 [5760/35339 (16%)]	Loss: 0.712135
Train Epoch: 70 [6400/35339 (18%)]	Loss: 0.710065
Train Epoch: 70 [7040/35339 (20%)]	Loss: 0.821078
Train Epoch: 70 [7680/35339 (22%)]	Loss: 0.629542
Train Epoch: 70 [8320/35339 (24%)]	Loss: 0.650319
Train Epoch: 70 [8960/35339 (25%)]	Loss: 0.717604
Train Epoch: 70 [9600/35339 (27%)]	Loss: 0.760040
Train Epoch: 70 [10240/35339 (29%)]	Loss: 0.856728
Train Epoch: 70 [10880/35339 (31%)]	Loss: 0.616727
Train Epoch: 70 [11520/35339 (33%)]	Loss: 0.819039
Train Epoch: 70 [12160/35339 (34%)]	Loss: 0.675688
Train Epoch: 70 [12800/35339 (36%)]	Loss: 0.669648
Train Epoch: 70 [13440/35339 (38%)]	Loss: 0.913916
Train Epoch: 70 [14080/35339 (40%)]	Loss: 0.798807
Train Epoch: 70 [14720/35339 (42%)]	Loss: 0.813161
Train Epoch: 70 [15360/35339 (43%)]	Loss: 0.984418
Train Epoch: 70 [16000/35339 (45%)]	Loss: 0.735312
Train Epoch: 70 [16640/35339 (47%)]	Loss: 0.719408
Train Epoch: 70 [17280/35339 (49%)]	Loss: 0.776181
Train Epoch: 70 [17920/35339 (51%)]	Loss: 0.774087
Train Epoch: 70 [18560/35339 (52%)]	Loss: 0.626759
Train Epoch: 70 [19200/35339 (54%)]	Loss: 0.814073
Train Epoch: 70 [19840/35339 (56%)]	Loss: 0.737028
Train Epoch: 70 [20480/35339 (58%)]	Loss: 0.708699
Train Epoch: 70 [21120/35339 (60%)]	Loss: 0.517027
Train Epoch: 70 [21760/35339 (61%)]	Loss: 0.802567
Train Epoch: 70 [22400/35339 (63%)]	Loss: 0.608015
Train Epoch: 70 [23040/35339 (65%)]	Loss: 0.504970
Train Epoch: 70 [23680/35339 (67%)]	Loss: 0.651957
Train Epoch: 70 [24320/35339 (69%)]	Loss: 0.755735
Train Epoch: 70 [24960/35339 (71%)]	Loss: 0.821897
Train Epoch: 70 [25600/35339 (72%)]	Loss: 0.642709
Train Epoch: 70 [26240/35339 (74%)]	Loss: 0.708727
Train Epoch: 70 [26880/35339 (76%)]	Loss: 0.768019
Train Epoch: 70 [27520/35339 (78%)]	Loss: 0.735542
Train Epoch: 70 [28160/35339 (80%)]	Loss: 0.684419
Train Epoch: 70 [28800/35339 (81%)]	Loss: 0.866776
Train Epoch: 70 [29440/35339 (83%)]	Loss: 0.726532
Train Epoch: 70 [30080/35339 (85%)]	Loss: 0.848096
Train Epoch: 70 [30720/35339 (87%)]	Loss: 0.802768
Train Epoch: 70 [31360/35339 (89%)]	Loss: 0.679942
Train Epoch: 70 [32000/35339 (90%)]	Loss: 0.848261
Train Epoch: 70 [32640/35339 (92%)]	Loss: 0.524796
Train Epoch: 70 [33280/35339 (94%)]	Loss: 0.632843
Train Epoch: 70 [33920/35339 (96%)]	Loss: 0.510264
Train Epoch: 70 [34560/35339 (98%)]	Loss: 0.715986
Train Epoch: 70 [35200/35339 (99%)]	Loss: 0.640637

Validation set: Average loss: 3.7833, Accuracy: 724/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 71 [0/35339 (0%)]	Loss: 0.658780
Train Epoch: 71 [640/35339 (2%)]	Loss: 0.846141
Train Epoch: 71 [1280/35339 (4%)]	Loss: 0.654414
Train Epoch: 71 [1920/35339 (5%)]	Loss: 0.824547
Train Epoch: 71 [2560/35339 (7%)]	Loss: 0.707390
Train Epoch: 71 [3200/35339 (9%)]	Loss: 0.669769
Train Epoch: 71 [3840/35339 (11%)]	Loss: 0.710493
Train Epoch: 71 [4480/35339 (13%)]	Loss: 0.585945
Train Epoch: 71 [5120/35339 (14%)]	Loss: 0.765435
Train Epoch: 71 [5760/35339 (16%)]	Loss: 0.759905
Train Epoch: 71 [6400/35339 (18%)]	Loss: 0.634686
Train Epoch: 71 [7040/35339 (20%)]	Loss: 0.846502
Train Epoch: 71 [7680/35339 (22%)]	Loss: 0.591185
Train Epoch: 71 [8320/35339 (24%)]	Loss: 0.559015
Train Epoch: 71 [8960/35339 (25%)]	Loss: 0.844191
Train Epoch: 71 [9600/35339 (27%)]	Loss: 0.575702
Train Epoch: 71 [10240/35339 (29%)]	Loss: 0.725154
Train Epoch: 71 [10880/35339 (31%)]	Loss: 0.721687
Train Epoch: 71 [11520/35339 (33%)]	Loss: 0.697048
Train Epoch: 71 [12160/35339 (34%)]	Loss: 0.528461
Train Epoch: 71 [12800/35339 (36%)]	Loss: 0.643972
Train Epoch: 71 [13440/35339 (38%)]	Loss: 0.780796
Train Epoch: 71 [14080/35339 (40%)]	Loss: 0.803497
Train Epoch: 71 [14720/35339 (42%)]	Loss: 0.988568
Train Epoch: 71 [15360/35339 (43%)]	Loss: 0.609982
Train Epoch: 71 [16000/35339 (45%)]	Loss: 0.664225
Train Epoch: 71 [16640/35339 (47%)]	Loss: 0.799313
Train Epoch: 71 [17280/35339 (49%)]	Loss: 0.704416
Train Epoch: 71 [17920/35339 (51%)]	Loss: 0.644435
Train Epoch: 71 [18560/35339 (52%)]	Loss: 0.594867
Train Epoch: 71 [19200/35339 (54%)]	Loss: 0.844998
Train Epoch: 71 [19840/35339 (56%)]	Loss: 0.550789
Train Epoch: 71 [20480/35339 (58%)]	Loss: 0.717342
Train Epoch: 71 [21120/35339 (60%)]	Loss: 0.527961
Train Epoch: 71 [21760/35339 (61%)]	Loss: 0.564626
Train Epoch: 71 [22400/35339 (63%)]	Loss: 0.758164
Train Epoch: 71 [23040/35339 (65%)]	Loss: 0.804838
Train Epoch: 71 [23680/35339 (67%)]	Loss: 0.797065
Train Epoch: 71 [24320/35339 (69%)]	Loss: 0.772087
Train Epoch: 71 [24960/35339 (71%)]	Loss: 0.704777
Train Epoch: 71 [25600/35339 (72%)]	Loss: 0.858778
Train Epoch: 71 [26240/35339 (74%)]	Loss: 0.665353
Train Epoch: 71 [26880/35339 (76%)]	Loss: 0.577443
Train Epoch: 71 [27520/35339 (78%)]	Loss: 0.541091
Train Epoch: 71 [28160/35339 (80%)]	Loss: 0.867203
Train Epoch: 71 [28800/35339 (81%)]	Loss: 0.886561
Train Epoch: 71 [29440/35339 (83%)]	Loss: 1.067596
Train Epoch: 71 [30080/35339 (85%)]	Loss: 0.661145
Train Epoch: 71 [30720/35339 (87%)]	Loss: 0.655615
Train Epoch: 71 [31360/35339 (89%)]	Loss: 0.818925
Train Epoch: 71 [32000/35339 (90%)]	Loss: 0.718987
Train Epoch: 71 [32640/35339 (92%)]	Loss: 0.869110
Train Epoch: 71 [33280/35339 (94%)]	Loss: 0.761740
Train Epoch: 71 [33920/35339 (96%)]	Loss: 0.775749
Train Epoch: 71 [34560/35339 (98%)]	Loss: 0.782033
Train Epoch: 71 [35200/35339 (99%)]	Loss: 0.661407

Validation set: Average loss: 3.7865, Accuracy: 712/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 72 [0/35339 (0%)]	Loss: 0.678459
Train Epoch: 72 [640/35339 (2%)]	Loss: 0.658193
Train Epoch: 72 [1280/35339 (4%)]	Loss: 0.718583
Train Epoch: 72 [1920/35339 (5%)]	Loss: 0.708795
Train Epoch: 72 [2560/35339 (7%)]	Loss: 0.700703
Train Epoch: 72 [3200/35339 (9%)]	Loss: 0.682995
Train Epoch: 72 [3840/35339 (11%)]	Loss: 0.565121
Train Epoch: 72 [4480/35339 (13%)]	Loss: 0.792226
Train Epoch: 72 [5120/35339 (14%)]	Loss: 0.623987
Train Epoch: 72 [5760/35339 (16%)]	Loss: 0.824544
Train Epoch: 72 [6400/35339 (18%)]	Loss: 0.771059
Train Epoch: 72 [7040/35339 (20%)]	Loss: 0.421724
Train Epoch: 72 [7680/35339 (22%)]	Loss: 0.874888
Train Epoch: 72 [8320/35339 (24%)]	Loss: 0.604499
Train Epoch: 72 [8960/35339 (25%)]	Loss: 0.841963
Train Epoch: 72 [9600/35339 (27%)]	Loss: 0.510859
Train Epoch: 72 [10240/35339 (29%)]	Loss: 0.761679
Train Epoch: 72 [10880/35339 (31%)]	Loss: 0.604144
Train Epoch: 72 [11520/35339 (33%)]	Loss: 0.897197
Train Epoch: 72 [12160/35339 (34%)]	Loss: 0.624174
Train Epoch: 72 [12800/35339 (36%)]	Loss: 0.596039
Train Epoch: 72 [13440/35339 (38%)]	Loss: 0.841692
Train Epoch: 72 [14080/35339 (40%)]	Loss: 0.623426
Train Epoch: 72 [14720/35339 (42%)]	Loss: 0.613698
Train Epoch: 72 [15360/35339 (43%)]	Loss: 0.707037
Train Epoch: 72 [16000/35339 (45%)]	Loss: 0.702121
Train Epoch: 72 [16640/35339 (47%)]	Loss: 0.638867
Train Epoch: 72 [17280/35339 (49%)]	Loss: 0.567760
Train Epoch: 72 [17920/35339 (51%)]	Loss: 0.755185
Train Epoch: 72 [18560/35339 (52%)]	Loss: 0.977119
Train Epoch: 72 [19200/35339 (54%)]	Loss: 0.503481
Train Epoch: 72 [19840/35339 (56%)]	Loss: 0.820772
Train Epoch: 72 [20480/35339 (58%)]	Loss: 0.617126
Train Epoch: 72 [21120/35339 (60%)]	Loss: 0.870926
Train Epoch: 72 [21760/35339 (61%)]	Loss: 0.731240
Train Epoch: 72 [22400/35339 (63%)]	Loss: 0.915621
Train Epoch: 72 [23040/35339 (65%)]	Loss: 0.717667
Train Epoch: 72 [23680/35339 (67%)]	Loss: 0.544108
Train Epoch: 72 [24320/35339 (69%)]	Loss: 0.716346
Train Epoch: 72 [24960/35339 (71%)]	Loss: 0.667304
Train Epoch: 72 [25600/35339 (72%)]	Loss: 0.753848
Train Epoch: 72 [26240/35339 (74%)]	Loss: 0.810466
Train Epoch: 72 [26880/35339 (76%)]	Loss: 0.814218
Train Epoch: 72 [27520/35339 (78%)]	Loss: 0.583386
Train Epoch: 72 [28160/35339 (80%)]	Loss: 0.677847
Train Epoch: 72 [28800/35339 (81%)]	Loss: 0.764826
Train Epoch: 72 [29440/35339 (83%)]	Loss: 0.542224
Train Epoch: 72 [30080/35339 (85%)]	Loss: 0.661976
Train Epoch: 72 [30720/35339 (87%)]	Loss: 0.817482
Train Epoch: 72 [31360/35339 (89%)]	Loss: 0.726829
Train Epoch: 72 [32000/35339 (90%)]	Loss: 0.581435
Train Epoch: 72 [32640/35339 (92%)]	Loss: 0.846238
Train Epoch: 72 [33280/35339 (94%)]	Loss: 0.631233
Train Epoch: 72 [33920/35339 (96%)]	Loss: 0.691762
Train Epoch: 72 [34560/35339 (98%)]	Loss: 0.715584
Train Epoch: 72 [35200/35339 (99%)]	Loss: 0.653626

Validation set: Average loss: 3.7771, Accuracy: 724/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 73 [0/35339 (0%)]	Loss: 0.740344
Train Epoch: 73 [640/35339 (2%)]	Loss: 0.713017
Train Epoch: 73 [1280/35339 (4%)]	Loss: 0.451105
Train Epoch: 73 [1920/35339 (5%)]	Loss: 0.707985
Train Epoch: 73 [2560/35339 (7%)]	Loss: 0.777661
Train Epoch: 73 [3200/35339 (9%)]	Loss: 0.761091
Train Epoch: 73 [3840/35339 (11%)]	Loss: 0.744569
Train Epoch: 73 [4480/35339 (13%)]	Loss: 0.962279
Train Epoch: 73 [5120/35339 (14%)]	Loss: 0.636664
Train Epoch: 73 [5760/35339 (16%)]	Loss: 0.817718
Train Epoch: 73 [6400/35339 (18%)]	Loss: 0.716936
Train Epoch: 73 [7040/35339 (20%)]	Loss: 0.775238
Train Epoch: 73 [7680/35339 (22%)]	Loss: 0.620638
Train Epoch: 73 [8320/35339 (24%)]	Loss: 0.771932
Train Epoch: 73 [8960/35339 (25%)]	Loss: 0.575455
Train Epoch: 73 [9600/35339 (27%)]	Loss: 0.784176
Train Epoch: 73 [10240/35339 (29%)]	Loss: 0.686286
Train Epoch: 73 [10880/35339 (31%)]	Loss: 0.748330
Train Epoch: 73 [11520/35339 (33%)]	Loss: 0.801347
Train Epoch: 73 [12160/35339 (34%)]	Loss: 0.944692
Train Epoch: 73 [12800/35339 (36%)]	Loss: 0.660539
Train Epoch: 73 [13440/35339 (38%)]	Loss: 0.673194
Train Epoch: 73 [14080/35339 (40%)]	Loss: 0.556378
Train Epoch: 73 [14720/35339 (42%)]	Loss: 0.764172
Train Epoch: 73 [15360/35339 (43%)]	Loss: 0.628394
Train Epoch: 73 [16000/35339 (45%)]	Loss: 0.795138
Train Epoch: 73 [16640/35339 (47%)]	Loss: 0.727578
Train Epoch: 73 [17280/35339 (49%)]	Loss: 0.643768
Train Epoch: 73 [17920/35339 (51%)]	Loss: 0.660943
Train Epoch: 73 [18560/35339 (52%)]	Loss: 0.898188
Train Epoch: 73 [19200/35339 (54%)]	Loss: 0.574121
Train Epoch: 73 [19840/35339 (56%)]	Loss: 0.552787
Train Epoch: 73 [20480/35339 (58%)]	Loss: 0.773417
Train Epoch: 73 [21120/35339 (60%)]	Loss: 0.632832
Train Epoch: 73 [21760/35339 (61%)]	Loss: 0.622935
Train Epoch: 73 [22400/35339 (63%)]	Loss: 0.584929
Train Epoch: 73 [23040/35339 (65%)]	Loss: 0.837922
Train Epoch: 73 [23680/35339 (67%)]	Loss: 0.693842
Train Epoch: 73 [24320/35339 (69%)]	Loss: 0.867485
Train Epoch: 73 [24960/35339 (71%)]	Loss: 0.681795
Train Epoch: 73 [25600/35339 (72%)]	Loss: 0.658177
Train Epoch: 73 [26240/35339 (74%)]	Loss: 0.808125
Train Epoch: 73 [26880/35339 (76%)]	Loss: 0.589474
Train Epoch: 73 [27520/35339 (78%)]	Loss: 0.686620
Train Epoch: 73 [28160/35339 (80%)]	Loss: 0.682282
Train Epoch: 73 [28800/35339 (81%)]	Loss: 0.631642
Train Epoch: 73 [29440/35339 (83%)]	Loss: 0.640859
Train Epoch: 73 [30080/35339 (85%)]	Loss: 0.600809
Train Epoch: 73 [30720/35339 (87%)]	Loss: 0.872651
Train Epoch: 73 [31360/35339 (89%)]	Loss: 0.737500
Train Epoch: 73 [32000/35339 (90%)]	Loss: 0.625638
Train Epoch: 73 [32640/35339 (92%)]	Loss: 0.775649
Train Epoch: 73 [33280/35339 (94%)]	Loss: 0.609842
Train Epoch: 73 [33920/35339 (96%)]	Loss: 0.685022
Train Epoch: 73 [34560/35339 (98%)]	Loss: 0.814001
Train Epoch: 73 [35200/35339 (99%)]	Loss: 0.816797

Validation set: Average loss: 3.7930, Accuracy: 714/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 74 [0/35339 (0%)]	Loss: 0.564688
Train Epoch: 74 [640/35339 (2%)]	Loss: 0.713382
Train Epoch: 74 [1280/35339 (4%)]	Loss: 0.594790
Train Epoch: 74 [1920/35339 (5%)]	Loss: 0.876562
Train Epoch: 74 [2560/35339 (7%)]	Loss: 0.716754
Train Epoch: 74 [3200/35339 (9%)]	Loss: 0.605996
Train Epoch: 74 [3840/35339 (11%)]	Loss: 0.765764
Train Epoch: 74 [4480/35339 (13%)]	Loss: 0.661168
Train Epoch: 74 [5120/35339 (14%)]	Loss: 0.842323
Train Epoch: 74 [5760/35339 (16%)]	Loss: 0.660179
Train Epoch: 74 [6400/35339 (18%)]	Loss: 0.684886
Train Epoch: 74 [7040/35339 (20%)]	Loss: 0.688765
Train Epoch: 74 [7680/35339 (22%)]	Loss: 0.596812
Train Epoch: 74 [8320/35339 (24%)]	Loss: 0.788212
Train Epoch: 74 [8960/35339 (25%)]	Loss: 0.557817
Train Epoch: 74 [9600/35339 (27%)]	Loss: 0.789201
Train Epoch: 74 [10240/35339 (29%)]	Loss: 0.563436
Train Epoch: 74 [10880/35339 (31%)]	Loss: 0.608808
Train Epoch: 74 [11520/35339 (33%)]	Loss: 0.713136
Train Epoch: 74 [12160/35339 (34%)]	Loss: 0.631378
Train Epoch: 74 [12800/35339 (36%)]	Loss: 0.612716
Train Epoch: 74 [13440/35339 (38%)]	Loss: 0.575228
Train Epoch: 74 [14080/35339 (40%)]	Loss: 0.690818
Train Epoch: 74 [14720/35339 (42%)]	Loss: 0.660817
Train Epoch: 74 [15360/35339 (43%)]	Loss: 0.783572
Train Epoch: 74 [16000/35339 (45%)]	Loss: 0.673428
Train Epoch: 74 [16640/35339 (47%)]	Loss: 0.661982
Train Epoch: 74 [17280/35339 (49%)]	Loss: 0.918002
Train Epoch: 74 [17920/35339 (51%)]	Loss: 0.716447
Train Epoch: 74 [18560/35339 (52%)]	Loss: 0.553608
Train Epoch: 74 [19200/35339 (54%)]	Loss: 0.595553
Train Epoch: 74 [19840/35339 (56%)]	Loss: 0.687410
Train Epoch: 74 [20480/35339 (58%)]	Loss: 0.580175
Train Epoch: 74 [21120/35339 (60%)]	Loss: 0.549053
Train Epoch: 74 [21760/35339 (61%)]	Loss: 0.680030
Train Epoch: 74 [22400/35339 (63%)]	Loss: 0.543970
Train Epoch: 74 [23040/35339 (65%)]	Loss: 0.523641
Train Epoch: 74 [23680/35339 (67%)]	Loss: 0.667264
Train Epoch: 74 [24320/35339 (69%)]	Loss: 0.930856
Train Epoch: 74 [24960/35339 (71%)]	Loss: 0.636798
Train Epoch: 74 [25600/35339 (72%)]	Loss: 0.652331
Train Epoch: 74 [26240/35339 (74%)]	Loss: 0.819615
Train Epoch: 74 [26880/35339 (76%)]	Loss: 0.674947
Train Epoch: 74 [27520/35339 (78%)]	Loss: 0.733691
Train Epoch: 74 [28160/35339 (80%)]	Loss: 0.509900
Train Epoch: 74 [28800/35339 (81%)]	Loss: 0.661848
Train Epoch: 74 [29440/35339 (83%)]	Loss: 0.715394
Train Epoch: 74 [30080/35339 (85%)]	Loss: 0.566572
Train Epoch: 74 [30720/35339 (87%)]	Loss: 0.750470
Train Epoch: 74 [31360/35339 (89%)]	Loss: 0.560750
Train Epoch: 74 [32000/35339 (90%)]	Loss: 0.713418
Train Epoch: 74 [32640/35339 (92%)]	Loss: 0.796771
Train Epoch: 74 [33280/35339 (94%)]	Loss: 0.601543
Train Epoch: 74 [33920/35339 (96%)]	Loss: 0.678616
Train Epoch: 74 [34560/35339 (98%)]	Loss: 0.899179
Train Epoch: 74 [35200/35339 (99%)]	Loss: 0.739347

Validation set: Average loss: 3.7816, Accuracy: 718/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 75 [0/35339 (0%)]	Loss: 1.052626
Train Epoch: 75 [640/35339 (2%)]	Loss: 0.709683
Train Epoch: 75 [1280/35339 (4%)]	Loss: 0.738873
Train Epoch: 75 [1920/35339 (5%)]	Loss: 0.784213
Train Epoch: 75 [2560/35339 (7%)]	Loss: 0.660084
Train Epoch: 75 [3200/35339 (9%)]	Loss: 0.650831
Train Epoch: 75 [3840/35339 (11%)]	Loss: 0.595511
Train Epoch: 75 [4480/35339 (13%)]	Loss: 0.734046
Train Epoch: 75 [5120/35339 (14%)]	Loss: 0.757117
Train Epoch: 75 [5760/35339 (16%)]	Loss: 0.630598
Train Epoch: 75 [6400/35339 (18%)]	Loss: 0.517009
Train Epoch: 75 [7040/35339 (20%)]	Loss: 0.651712
Train Epoch: 75 [7680/35339 (22%)]	Loss: 0.553928
Train Epoch: 75 [8320/35339 (24%)]	Loss: 0.642777
Train Epoch: 75 [8960/35339 (25%)]	Loss: 0.643464
Train Epoch: 75 [9600/35339 (27%)]	Loss: 0.673017
Train Epoch: 75 [10240/35339 (29%)]	Loss: 0.603686
Train Epoch: 75 [10880/35339 (31%)]	Loss: 0.640033
Train Epoch: 75 [11520/35339 (33%)]	Loss: 0.705536
Train Epoch: 75 [12160/35339 (34%)]	Loss: 0.520728
Train Epoch: 75 [12800/35339 (36%)]	Loss: 0.820300
Train Epoch: 75 [13440/35339 (38%)]	Loss: 0.732036
Train Epoch: 75 [14080/35339 (40%)]	Loss: 0.795410
Train Epoch: 75 [14720/35339 (42%)]	Loss: 0.916408
Train Epoch: 75 [15360/35339 (43%)]	Loss: 0.683173
Train Epoch: 75 [16000/35339 (45%)]	Loss: 0.695372
Train Epoch: 75 [16640/35339 (47%)]	Loss: 0.772430
Train Epoch: 75 [17280/35339 (49%)]	Loss: 0.541187
Train Epoch: 75 [17920/35339 (51%)]	Loss: 0.610699
Train Epoch: 75 [18560/35339 (52%)]	Loss: 0.665465
Train Epoch: 75 [19200/35339 (54%)]	Loss: 0.709751
Train Epoch: 75 [19840/35339 (56%)]	Loss: 0.769155
Train Epoch: 75 [20480/35339 (58%)]	Loss: 0.605412
Train Epoch: 75 [21120/35339 (60%)]	Loss: 0.539707
Train Epoch: 75 [21760/35339 (61%)]	Loss: 0.710420
Train Epoch: 75 [22400/35339 (63%)]	Loss: 0.713620
Train Epoch: 75 [23040/35339 (65%)]	Loss: 0.614994
Train Epoch: 75 [23680/35339 (67%)]	Loss: 0.730578
Train Epoch: 75 [24320/35339 (69%)]	Loss: 0.584175
Train Epoch: 75 [24960/35339 (71%)]	Loss: 0.828021
Train Epoch: 75 [25600/35339 (72%)]	Loss: 0.678244
Train Epoch: 75 [26240/35339 (74%)]	Loss: 0.678970
Train Epoch: 75 [26880/35339 (76%)]	Loss: 0.768777
Train Epoch: 75 [27520/35339 (78%)]	Loss: 0.783776
Train Epoch: 75 [28160/35339 (80%)]	Loss: 0.560910
Train Epoch: 75 [28800/35339 (81%)]	Loss: 0.426863
Train Epoch: 75 [29440/35339 (83%)]	Loss: 0.714744
Train Epoch: 75 [30080/35339 (85%)]	Loss: 0.778749
Train Epoch: 75 [30720/35339 (87%)]	Loss: 0.590314
Train Epoch: 75 [31360/35339 (89%)]	Loss: 0.868748
Train Epoch: 75 [32000/35339 (90%)]	Loss: 0.704808
Train Epoch: 75 [32640/35339 (92%)]	Loss: 0.684018
Train Epoch: 75 [33280/35339 (94%)]	Loss: 0.653852
Train Epoch: 75 [33920/35339 (96%)]	Loss: 0.595052
Train Epoch: 75 [34560/35339 (98%)]	Loss: 0.720933
Train Epoch: 75 [35200/35339 (99%)]	Loss: 0.737058

Validation set: Average loss: 3.7860, Accuracy: 715/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 76 [0/35339 (0%)]	Loss: 0.606473
Train Epoch: 76 [640/35339 (2%)]	Loss: 0.584521
Train Epoch: 76 [1280/35339 (4%)]	Loss: 0.606820
Train Epoch: 76 [1920/35339 (5%)]	Loss: 0.668652
Train Epoch: 76 [2560/35339 (7%)]	Loss: 0.622053
Train Epoch: 76 [3200/35339 (9%)]	Loss: 0.694590
Train Epoch: 76 [3840/35339 (11%)]	Loss: 0.649879
Train Epoch: 76 [4480/35339 (13%)]	Loss: 0.665538
Train Epoch: 76 [5120/35339 (14%)]	Loss: 0.753786
Train Epoch: 76 [5760/35339 (16%)]	Loss: 0.769895
Train Epoch: 76 [6400/35339 (18%)]	Loss: 0.609462
Train Epoch: 76 [7040/35339 (20%)]	Loss: 0.679672
Train Epoch: 76 [7680/35339 (22%)]	Loss: 0.718529
Train Epoch: 76 [8320/35339 (24%)]	Loss: 0.795705
Train Epoch: 76 [8960/35339 (25%)]	Loss: 0.688556
Train Epoch: 76 [9600/35339 (27%)]	Loss: 0.699948
Train Epoch: 76 [10240/35339 (29%)]	Loss: 0.625999
Train Epoch: 76 [10880/35339 (31%)]	Loss: 0.559889
Train Epoch: 76 [11520/35339 (33%)]	Loss: 0.561587
Train Epoch: 76 [12160/35339 (34%)]	Loss: 0.661675
Train Epoch: 76 [12800/35339 (36%)]	Loss: 0.706632
Train Epoch: 76 [13440/35339 (38%)]	Loss: 0.578229
Train Epoch: 76 [14080/35339 (40%)]	Loss: 0.631067
Train Epoch: 76 [14720/35339 (42%)]	Loss: 0.664255
Train Epoch: 76 [15360/35339 (43%)]	Loss: 0.875678
Train Epoch: 76 [16000/35339 (45%)]	Loss: 0.659267
Train Epoch: 76 [16640/35339 (47%)]	Loss: 0.565646
Train Epoch: 76 [17280/35339 (49%)]	Loss: 0.795644
Train Epoch: 76 [17920/35339 (51%)]	Loss: 0.702372
Train Epoch: 76 [18560/35339 (52%)]	Loss: 0.540661
Train Epoch: 76 [19200/35339 (54%)]	Loss: 0.738696
Train Epoch: 76 [19840/35339 (56%)]	Loss: 0.852187
Train Epoch: 76 [20480/35339 (58%)]	Loss: 0.717838
Train Epoch: 76 [21120/35339 (60%)]	Loss: 0.627886
Train Epoch: 76 [21760/35339 (61%)]	Loss: 0.561599
Train Epoch: 76 [22400/35339 (63%)]	Loss: 0.680373
Train Epoch: 76 [23040/35339 (65%)]	Loss: 0.717100
Train Epoch: 76 [23680/35339 (67%)]	Loss: 0.657510
Train Epoch: 76 [24320/35339 (69%)]	Loss: 0.673280
Train Epoch: 76 [24960/35339 (71%)]	Loss: 0.864944
Train Epoch: 76 [25600/35339 (72%)]	Loss: 0.638437
Train Epoch: 76 [26240/35339 (74%)]	Loss: 0.835622
Train Epoch: 76 [26880/35339 (76%)]	Loss: 0.659641
Train Epoch: 76 [27520/35339 (78%)]	Loss: 0.870302
Train Epoch: 76 [28160/35339 (80%)]	Loss: 0.801702
Train Epoch: 76 [28800/35339 (81%)]	Loss: 0.726121
Train Epoch: 76 [29440/35339 (83%)]	Loss: 0.483731
Train Epoch: 76 [30080/35339 (85%)]	Loss: 0.739726
Train Epoch: 76 [30720/35339 (87%)]	Loss: 0.565788
Train Epoch: 76 [31360/35339 (89%)]	Loss: 0.820188
Train Epoch: 76 [32000/35339 (90%)]	Loss: 0.712298
Train Epoch: 76 [32640/35339 (92%)]	Loss: 0.542644
Train Epoch: 76 [33280/35339 (94%)]	Loss: 0.570505
Train Epoch: 76 [33920/35339 (96%)]	Loss: 0.649398
Train Epoch: 76 [34560/35339 (98%)]	Loss: 0.586484
Train Epoch: 76 [35200/35339 (99%)]	Loss: 0.835427

Validation set: Average loss: 3.7851, Accuracy: 715/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 77 [0/35339 (0%)]	Loss: 0.623782
Train Epoch: 77 [640/35339 (2%)]	Loss: 0.624464
Train Epoch: 77 [1280/35339 (4%)]	Loss: 0.749467
Train Epoch: 77 [1920/35339 (5%)]	Loss: 0.617301
Train Epoch: 77 [2560/35339 (7%)]	Loss: 0.873601
Train Epoch: 77 [3200/35339 (9%)]	Loss: 0.645272
Train Epoch: 77 [3840/35339 (11%)]	Loss: 0.509496
Train Epoch: 77 [4480/35339 (13%)]	Loss: 0.704019
Train Epoch: 77 [5120/35339 (14%)]	Loss: 0.634367
Train Epoch: 77 [5760/35339 (16%)]	Loss: 0.791523
Train Epoch: 77 [6400/35339 (18%)]	Loss: 0.583357
Train Epoch: 77 [7040/35339 (20%)]	Loss: 0.690122
Train Epoch: 77 [7680/35339 (22%)]	Loss: 0.837528
Train Epoch: 77 [8320/35339 (24%)]	Loss: 0.917764
Train Epoch: 77 [8960/35339 (25%)]	Loss: 0.770497
Train Epoch: 77 [9600/35339 (27%)]	Loss: 0.704815
Train Epoch: 77 [10240/35339 (29%)]	Loss: 0.514133
Train Epoch: 77 [10880/35339 (31%)]	Loss: 0.699853
Train Epoch: 77 [11520/35339 (33%)]	Loss: 0.673343
Train Epoch: 77 [12160/35339 (34%)]	Loss: 0.682197
Train Epoch: 77 [12800/35339 (36%)]	Loss: 0.754008
Train Epoch: 77 [13440/35339 (38%)]	Loss: 0.866550
Train Epoch: 77 [14080/35339 (40%)]	Loss: 0.745024
Train Epoch: 77 [14720/35339 (42%)]	Loss: 0.650314
Train Epoch: 77 [15360/35339 (43%)]	Loss: 0.735236
Train Epoch: 77 [16000/35339 (45%)]	Loss: 0.657788
Train Epoch: 77 [16640/35339 (47%)]	Loss: 0.586398
Train Epoch: 77 [17280/35339 (49%)]	Loss: 0.496388
Train Epoch: 77 [17920/35339 (51%)]	Loss: 0.621266
Train Epoch: 77 [18560/35339 (52%)]	Loss: 0.739386
Train Epoch: 77 [19200/35339 (54%)]	Loss: 0.531796
Train Epoch: 77 [19840/35339 (56%)]	Loss: 0.610361
Train Epoch: 77 [20480/35339 (58%)]	Loss: 0.669658
Train Epoch: 77 [21120/35339 (60%)]	Loss: 0.647172
Train Epoch: 77 [21760/35339 (61%)]	Loss: 0.732143
Train Epoch: 77 [22400/35339 (63%)]	Loss: 0.626369
Train Epoch: 77 [23040/35339 (65%)]	Loss: 0.600301
Train Epoch: 77 [23680/35339 (67%)]	Loss: 0.672393
Train Epoch: 77 [24320/35339 (69%)]	Loss: 0.657268
Train Epoch: 77 [24960/35339 (71%)]	Loss: 0.784270
Train Epoch: 77 [25600/35339 (72%)]	Loss: 0.730842
Train Epoch: 77 [26240/35339 (74%)]	Loss: 0.768914
Train Epoch: 77 [26880/35339 (76%)]	Loss: 0.902510
Train Epoch: 77 [27520/35339 (78%)]	Loss: 0.613429
Train Epoch: 77 [28160/35339 (80%)]	Loss: 0.821519
Train Epoch: 77 [28800/35339 (81%)]	Loss: 0.684067
Train Epoch: 77 [29440/35339 (83%)]	Loss: 0.795308
Train Epoch: 77 [30080/35339 (85%)]	Loss: 0.627478
Train Epoch: 77 [30720/35339 (87%)]	Loss: 0.472630
Train Epoch: 77 [31360/35339 (89%)]	Loss: 1.052938
Train Epoch: 77 [32000/35339 (90%)]	Loss: 0.622274
Train Epoch: 77 [32640/35339 (92%)]	Loss: 0.417387
Train Epoch: 77 [33280/35339 (94%)]	Loss: 0.698848
Train Epoch: 77 [33920/35339 (96%)]	Loss: 0.896976
Train Epoch: 77 [34560/35339 (98%)]	Loss: 0.693386
Train Epoch: 77 [35200/35339 (99%)]	Loss: 0.761544

Validation set: Average loss: 3.7987, Accuracy: 711/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 78 [0/35339 (0%)]	Loss: 0.738817
Train Epoch: 78 [640/35339 (2%)]	Loss: 0.667365
Train Epoch: 78 [1280/35339 (4%)]	Loss: 0.515061
Train Epoch: 78 [1920/35339 (5%)]	Loss: 0.748332
Train Epoch: 78 [2560/35339 (7%)]	Loss: 0.892136
Train Epoch: 78 [3200/35339 (9%)]	Loss: 0.647399
Train Epoch: 78 [3840/35339 (11%)]	Loss: 0.699885
Train Epoch: 78 [4480/35339 (13%)]	Loss: 0.516250
Train Epoch: 78 [5120/35339 (14%)]	Loss: 0.706737
Train Epoch: 78 [5760/35339 (16%)]	Loss: 0.893329
Train Epoch: 78 [6400/35339 (18%)]	Loss: 0.545209
Train Epoch: 78 [7040/35339 (20%)]	Loss: 0.661360
Train Epoch: 78 [7680/35339 (22%)]	Loss: 0.735905
Train Epoch: 78 [8320/35339 (24%)]	Loss: 0.826178
Train Epoch: 78 [8960/35339 (25%)]	Loss: 0.549792
Train Epoch: 78 [9600/35339 (27%)]	Loss: 0.776400
Train Epoch: 78 [10240/35339 (29%)]	Loss: 0.716220
Train Epoch: 78 [10880/35339 (31%)]	Loss: 0.614926
Train Epoch: 78 [11520/35339 (33%)]	Loss: 0.667800
Train Epoch: 78 [12160/35339 (34%)]	Loss: 0.749701
Train Epoch: 78 [12800/35339 (36%)]	Loss: 0.736408
Train Epoch: 78 [13440/35339 (38%)]	Loss: 0.707715
Train Epoch: 78 [14080/35339 (40%)]	Loss: 0.783503
Train Epoch: 78 [14720/35339 (42%)]	Loss: 0.788843
Train Epoch: 78 [15360/35339 (43%)]	Loss: 0.536399
Train Epoch: 78 [16000/35339 (45%)]	Loss: 0.826676
Train Epoch: 78 [16640/35339 (47%)]	Loss: 0.684267
Train Epoch: 78 [17280/35339 (49%)]	Loss: 0.605971
Train Epoch: 78 [17920/35339 (51%)]	Loss: 0.572783
Train Epoch: 78 [18560/35339 (52%)]	Loss: 0.597182
Train Epoch: 78 [19200/35339 (54%)]	Loss: 0.818119
Train Epoch: 78 [19840/35339 (56%)]	Loss: 1.025019
Train Epoch: 78 [20480/35339 (58%)]	Loss: 0.789349
Train Epoch: 78 [21120/35339 (60%)]	Loss: 0.657537
Train Epoch: 78 [21760/35339 (61%)]	Loss: 0.639127
Train Epoch: 78 [22400/35339 (63%)]	Loss: 0.682278
Train Epoch: 78 [23040/35339 (65%)]	Loss: 0.750239
Train Epoch: 78 [23680/35339 (67%)]	Loss: 0.730686
Train Epoch: 78 [24320/35339 (69%)]	Loss: 0.693337
Train Epoch: 78 [24960/35339 (71%)]	Loss: 0.780086
Train Epoch: 78 [25600/35339 (72%)]	Loss: 0.589794
Train Epoch: 78 [26240/35339 (74%)]	Loss: 0.847573
Train Epoch: 78 [26880/35339 (76%)]	Loss: 0.637580
Train Epoch: 78 [27520/35339 (78%)]	Loss: 0.618395
Train Epoch: 78 [28160/35339 (80%)]	Loss: 0.669518
Train Epoch: 78 [28800/35339 (81%)]	Loss: 0.750556
Train Epoch: 78 [29440/35339 (83%)]	Loss: 0.757715
Train Epoch: 78 [30080/35339 (85%)]	Loss: 0.618068
Train Epoch: 78 [30720/35339 (87%)]	Loss: 0.664438
Train Epoch: 78 [31360/35339 (89%)]	Loss: 0.678942
Train Epoch: 78 [32000/35339 (90%)]	Loss: 0.779907
Train Epoch: 78 [32640/35339 (92%)]	Loss: 0.673288
Train Epoch: 78 [33280/35339 (94%)]	Loss: 0.609344
Train Epoch: 78 [33920/35339 (96%)]	Loss: 0.728745
Train Epoch: 78 [34560/35339 (98%)]	Loss: 0.738693
Train Epoch: 78 [35200/35339 (99%)]	Loss: 0.745804

Validation set: Average loss: 3.7801, Accuracy: 714/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 79 [0/35339 (0%)]	Loss: 0.624021
Train Epoch: 79 [640/35339 (2%)]	Loss: 0.624198
Train Epoch: 79 [1280/35339 (4%)]	Loss: 0.942135
Train Epoch: 79 [1920/35339 (5%)]	Loss: 0.848698
Train Epoch: 79 [2560/35339 (7%)]	Loss: 0.643312
Train Epoch: 79 [3200/35339 (9%)]	Loss: 0.854043
Train Epoch: 79 [3840/35339 (11%)]	Loss: 0.514286
Train Epoch: 79 [4480/35339 (13%)]	Loss: 0.813096
Train Epoch: 79 [5120/35339 (14%)]	Loss: 0.778700
Train Epoch: 79 [5760/35339 (16%)]	Loss: 0.600888
Train Epoch: 79 [6400/35339 (18%)]	Loss: 0.636107
Train Epoch: 79 [7040/35339 (20%)]	Loss: 0.789756
Train Epoch: 79 [7680/35339 (22%)]	Loss: 0.540199
Train Epoch: 79 [8320/35339 (24%)]	Loss: 0.516593
Train Epoch: 79 [8960/35339 (25%)]	Loss: 0.670390
Train Epoch: 79 [9600/35339 (27%)]	Loss: 0.900665
Train Epoch: 79 [10240/35339 (29%)]	Loss: 0.802270
Train Epoch: 79 [10880/35339 (31%)]	Loss: 0.546283
Train Epoch: 79 [11520/35339 (33%)]	Loss: 0.679655
Train Epoch: 79 [12160/35339 (34%)]	Loss: 0.784313
Train Epoch: 79 [12800/35339 (36%)]	Loss: 0.685059
Train Epoch: 79 [13440/35339 (38%)]	Loss: 0.760866
Train Epoch: 79 [14080/35339 (40%)]	Loss: 0.614432
Train Epoch: 79 [14720/35339 (42%)]	Loss: 0.730392
Train Epoch: 79 [15360/35339 (43%)]	Loss: 0.687483
Train Epoch: 79 [16000/35339 (45%)]	Loss: 0.783557
Train Epoch: 79 [16640/35339 (47%)]	Loss: 0.617393
Train Epoch: 79 [17280/35339 (49%)]	Loss: 0.572546
Train Epoch: 79 [17920/35339 (51%)]	Loss: 0.632596
Train Epoch: 79 [18560/35339 (52%)]	Loss: 0.642479
Train Epoch: 79 [19200/35339 (54%)]	Loss: 0.626782
Train Epoch: 79 [19840/35339 (56%)]	Loss: 0.651530
Train Epoch: 79 [20480/35339 (58%)]	Loss: 0.553339
Train Epoch: 79 [21120/35339 (60%)]	Loss: 0.675925
Train Epoch: 79 [21760/35339 (61%)]	Loss: 0.526475
Train Epoch: 79 [22400/35339 (63%)]	Loss: 0.663352
Train Epoch: 79 [23040/35339 (65%)]	Loss: 0.763436
Train Epoch: 79 [23680/35339 (67%)]	Loss: 0.759787
Train Epoch: 79 [24320/35339 (69%)]	Loss: 0.853244
Train Epoch: 79 [24960/35339 (71%)]	Loss: 0.745842
Train Epoch: 79 [25600/35339 (72%)]	Loss: 0.624225
Train Epoch: 79 [26240/35339 (74%)]	Loss: 0.636083
Train Epoch: 79 [26880/35339 (76%)]	Loss: 0.775618
Train Epoch: 79 [27520/35339 (78%)]	Loss: 0.579781
Train Epoch: 79 [28160/35339 (80%)]	Loss: 0.760512
Train Epoch: 79 [28800/35339 (81%)]	Loss: 0.598081
Train Epoch: 79 [29440/35339 (83%)]	Loss: 0.549867
Train Epoch: 79 [30080/35339 (85%)]	Loss: 0.775220
Train Epoch: 79 [30720/35339 (87%)]	Loss: 0.657782
Train Epoch: 79 [31360/35339 (89%)]	Loss: 0.619322
Train Epoch: 79 [32000/35339 (90%)]	Loss: 0.620324
Train Epoch: 79 [32640/35339 (92%)]	Loss: 0.679645
Train Epoch: 79 [33280/35339 (94%)]	Loss: 0.729943
Train Epoch: 79 [33920/35339 (96%)]	Loss: 0.748226
Train Epoch: 79 [34560/35339 (98%)]	Loss: 0.627742
Train Epoch: 79 [35200/35339 (99%)]	Loss: 0.786179

Validation set: Average loss: 3.7829, Accuracy: 710/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 80 [0/35339 (0%)]	Loss: 0.601633
Train Epoch: 80 [640/35339 (2%)]	Loss: 0.559625
Train Epoch: 80 [1280/35339 (4%)]	Loss: 0.685245
Train Epoch: 80 [1920/35339 (5%)]	Loss: 0.608119
Train Epoch: 80 [2560/35339 (7%)]	Loss: 0.561227
Train Epoch: 80 [3200/35339 (9%)]	Loss: 0.489561
Train Epoch: 80 [3840/35339 (11%)]	Loss: 0.682525
Train Epoch: 80 [4480/35339 (13%)]	Loss: 0.706384
Train Epoch: 80 [5120/35339 (14%)]	Loss: 0.687535
Train Epoch: 80 [5760/35339 (16%)]	Loss: 0.738413
Train Epoch: 80 [6400/35339 (18%)]	Loss: 0.774833
Train Epoch: 80 [7040/35339 (20%)]	Loss: 0.729321
Train Epoch: 80 [7680/35339 (22%)]	Loss: 0.704804
Train Epoch: 80 [8320/35339 (24%)]	Loss: 0.650815
Train Epoch: 80 [8960/35339 (25%)]	Loss: 0.729208
Train Epoch: 80 [9600/35339 (27%)]	Loss: 0.685190
Train Epoch: 80 [10240/35339 (29%)]	Loss: 0.674007
Train Epoch: 80 [10880/35339 (31%)]	Loss: 0.647150
Train Epoch: 80 [11520/35339 (33%)]	Loss: 0.737219
Train Epoch: 80 [12160/35339 (34%)]	Loss: 0.584405
Train Epoch: 80 [12800/35339 (36%)]	Loss: 0.738930
Train Epoch: 80 [13440/35339 (38%)]	Loss: 0.547480
Train Epoch: 80 [14080/35339 (40%)]	Loss: 0.498338
Train Epoch: 80 [14720/35339 (42%)]	Loss: 0.738266
Train Epoch: 80 [15360/35339 (43%)]	Loss: 0.714134
Train Epoch: 80 [16000/35339 (45%)]	Loss: 0.526081
Train Epoch: 80 [16640/35339 (47%)]	Loss: 0.672282
Train Epoch: 80 [17280/35339 (49%)]	Loss: 0.737057
Train Epoch: 80 [17920/35339 (51%)]	Loss: 0.684128
Train Epoch: 80 [18560/35339 (52%)]	Loss: 0.733162
Train Epoch: 80 [19200/35339 (54%)]	Loss: 0.756816
Train Epoch: 80 [19840/35339 (56%)]	Loss: 0.567340
Train Epoch: 80 [20480/35339 (58%)]	Loss: 0.650093
Train Epoch: 80 [21120/35339 (60%)]	Loss: 0.696333
Train Epoch: 80 [21760/35339 (61%)]	Loss: 0.666605
Train Epoch: 80 [22400/35339 (63%)]	Loss: 0.614976
Train Epoch: 80 [23040/35339 (65%)]	Loss: 0.699792
Train Epoch: 80 [23680/35339 (67%)]	Loss: 0.530926
Train Epoch: 80 [24320/35339 (69%)]	Loss: 0.699213
Train Epoch: 80 [24960/35339 (71%)]	Loss: 0.626628
Train Epoch: 80 [25600/35339 (72%)]	Loss: 0.605010
Train Epoch: 80 [26240/35339 (74%)]	Loss: 0.651148
Train Epoch: 80 [26880/35339 (76%)]	Loss: 0.747062
Train Epoch: 80 [27520/35339 (78%)]	Loss: 0.843720
Train Epoch: 80 [28160/35339 (80%)]	Loss: 0.623323
Train Epoch: 80 [28800/35339 (81%)]	Loss: 0.618722
Train Epoch: 80 [29440/35339 (83%)]	Loss: 0.761501
Train Epoch: 80 [30080/35339 (85%)]	Loss: 0.682740
Train Epoch: 80 [30720/35339 (87%)]	Loss: 0.861019
Train Epoch: 80 [31360/35339 (89%)]	Loss: 0.519069
Train Epoch: 80 [32000/35339 (90%)]	Loss: 0.669893
Train Epoch: 80 [32640/35339 (92%)]	Loss: 0.679743
Train Epoch: 80 [33280/35339 (94%)]	Loss: 0.610705
Train Epoch: 80 [33920/35339 (96%)]	Loss: 0.765958
Train Epoch: 80 [34560/35339 (98%)]	Loss: 0.640492
Train Epoch: 80 [35200/35339 (99%)]	Loss: 0.678462

Validation set: Average loss: 3.7931, Accuracy: 709/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 81 [0/35339 (0%)]	Loss: 0.768903
Train Epoch: 81 [640/35339 (2%)]	Loss: 0.760592
Train Epoch: 81 [1280/35339 (4%)]	Loss: 0.649518
Train Epoch: 81 [1920/35339 (5%)]	Loss: 0.746284
Train Epoch: 81 [2560/35339 (7%)]	Loss: 0.688902
Train Epoch: 81 [3200/35339 (9%)]	Loss: 0.761074
Train Epoch: 81 [3840/35339 (11%)]	Loss: 0.439849
Train Epoch: 81 [4480/35339 (13%)]	Loss: 0.645952
Train Epoch: 81 [5120/35339 (14%)]	Loss: 0.690798
Train Epoch: 81 [5760/35339 (16%)]	Loss: 0.787241
Train Epoch: 81 [6400/35339 (18%)]	Loss: 0.735645
Train Epoch: 81 [7040/35339 (20%)]	Loss: 0.759071
Train Epoch: 81 [7680/35339 (22%)]	Loss: 0.665897
Train Epoch: 81 [8320/35339 (24%)]	Loss: 0.552166
Train Epoch: 81 [8960/35339 (25%)]	Loss: 0.644636
Train Epoch: 81 [9600/35339 (27%)]	Loss: 0.843604
Train Epoch: 81 [10240/35339 (29%)]	Loss: 0.553211
Train Epoch: 81 [10880/35339 (31%)]	Loss: 0.507238
Train Epoch: 81 [11520/35339 (33%)]	Loss: 0.720784
Train Epoch: 81 [12160/35339 (34%)]	Loss: 0.605877
Train Epoch: 81 [12800/35339 (36%)]	Loss: 0.606566
Train Epoch: 81 [13440/35339 (38%)]	Loss: 0.564661
Train Epoch: 81 [14080/35339 (40%)]	Loss: 0.603508
Train Epoch: 81 [14720/35339 (42%)]	Loss: 0.873315
Train Epoch: 81 [15360/35339 (43%)]	Loss: 0.600246
Train Epoch: 81 [16000/35339 (45%)]	Loss: 0.713978
Train Epoch: 81 [16640/35339 (47%)]	Loss: 0.682106
Train Epoch: 81 [17280/35339 (49%)]	Loss: 0.602483
Train Epoch: 81 [17920/35339 (51%)]	Loss: 0.670784
Train Epoch: 81 [18560/35339 (52%)]	Loss: 0.754415
Train Epoch: 81 [19200/35339 (54%)]	Loss: 0.856463
Train Epoch: 81 [19840/35339 (56%)]	Loss: 0.586007
Train Epoch: 81 [20480/35339 (58%)]	Loss: 0.703749
Train Epoch: 81 [21120/35339 (60%)]	Loss: 0.679273
Train Epoch: 81 [21760/35339 (61%)]	Loss: 0.530568
Train Epoch: 81 [22400/35339 (63%)]	Loss: 0.563524
Train Epoch: 81 [23040/35339 (65%)]	Loss: 0.734407
Train Epoch: 81 [23680/35339 (67%)]	Loss: 0.612139
Train Epoch: 81 [24320/35339 (69%)]	Loss: 0.557679
Train Epoch: 81 [24960/35339 (71%)]	Loss: 0.612317
Train Epoch: 81 [25600/35339 (72%)]	Loss: 0.855991
Train Epoch: 81 [26240/35339 (74%)]	Loss: 0.556307
Train Epoch: 81 [26880/35339 (76%)]	Loss: 0.572339
Train Epoch: 81 [27520/35339 (78%)]	Loss: 0.628563
Train Epoch: 81 [28160/35339 (80%)]	Loss: 0.723095
Train Epoch: 81 [28800/35339 (81%)]	Loss: 0.735856
Train Epoch: 81 [29440/35339 (83%)]	Loss: 0.628832
Train Epoch: 81 [30080/35339 (85%)]	Loss: 0.771093
Train Epoch: 81 [30720/35339 (87%)]	Loss: 0.809983
Train Epoch: 81 [31360/35339 (89%)]	Loss: 0.584330
Train Epoch: 81 [32000/35339 (90%)]	Loss: 0.724377
Train Epoch: 81 [32640/35339 (92%)]	Loss: 0.732242
Train Epoch: 81 [33280/35339 (94%)]	Loss: 0.742262
Train Epoch: 81 [33920/35339 (96%)]	Loss: 0.624843
Train Epoch: 81 [34560/35339 (98%)]	Loss: 0.671288
Train Epoch: 81 [35200/35339 (99%)]	Loss: 0.629033

Validation set: Average loss: 3.7856, Accuracy: 715/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 82 [0/35339 (0%)]	Loss: 0.711976
Train Epoch: 82 [640/35339 (2%)]	Loss: 0.714171
Train Epoch: 82 [1280/35339 (4%)]	Loss: 0.773369
Train Epoch: 82 [1920/35339 (5%)]	Loss: 0.750560
Train Epoch: 82 [2560/35339 (7%)]	Loss: 0.806558
Train Epoch: 82 [3200/35339 (9%)]	Loss: 0.663496
Train Epoch: 82 [3840/35339 (11%)]	Loss: 0.573995
Train Epoch: 82 [4480/35339 (13%)]	Loss: 0.859172
Train Epoch: 82 [5120/35339 (14%)]	Loss: 0.703635
Train Epoch: 82 [5760/35339 (16%)]	Loss: 0.923985
Train Epoch: 82 [6400/35339 (18%)]	Loss: 0.572391
Train Epoch: 82 [7040/35339 (20%)]	Loss: 0.721242
Train Epoch: 82 [7680/35339 (22%)]	Loss: 0.695241
Train Epoch: 82 [8320/35339 (24%)]	Loss: 0.726229
Train Epoch: 82 [8960/35339 (25%)]	Loss: 0.558582
Train Epoch: 82 [9600/35339 (27%)]	Loss: 0.634421
Train Epoch: 82 [10240/35339 (29%)]	Loss: 0.787144
Train Epoch: 82 [10880/35339 (31%)]	Loss: 0.665391
Train Epoch: 82 [11520/35339 (33%)]	Loss: 0.690659
Train Epoch: 82 [12160/35339 (34%)]	Loss: 0.651772
Train Epoch: 82 [12800/35339 (36%)]	Loss: 0.611499
Train Epoch: 82 [13440/35339 (38%)]	Loss: 1.016141
Train Epoch: 82 [14080/35339 (40%)]	Loss: 0.578524
Train Epoch: 82 [14720/35339 (42%)]	Loss: 0.633506
Train Epoch: 82 [15360/35339 (43%)]	Loss: 0.717939
Train Epoch: 82 [16000/35339 (45%)]	Loss: 0.809510
Train Epoch: 82 [16640/35339 (47%)]	Loss: 0.640846
Train Epoch: 82 [17280/35339 (49%)]	Loss: 0.842336
Train Epoch: 82 [17920/35339 (51%)]	Loss: 0.533429
Train Epoch: 82 [18560/35339 (52%)]	Loss: 0.569070
Train Epoch: 82 [19200/35339 (54%)]	Loss: 0.731204
Train Epoch: 82 [19840/35339 (56%)]	Loss: 0.906238
Train Epoch: 82 [20480/35339 (58%)]	Loss: 0.662352
Train Epoch: 82 [21120/35339 (60%)]	Loss: 0.599144
Train Epoch: 82 [21760/35339 (61%)]	Loss: 0.719256
Train Epoch: 82 [22400/35339 (63%)]	Loss: 0.629684
Train Epoch: 82 [23040/35339 (65%)]	Loss: 0.623540
Train Epoch: 82 [23680/35339 (67%)]	Loss: 0.567079
Train Epoch: 82 [24320/35339 (69%)]	Loss: 0.626245
Train Epoch: 82 [24960/35339 (71%)]	Loss: 0.642005
Train Epoch: 82 [25600/35339 (72%)]	Loss: 0.581166
Train Epoch: 82 [26240/35339 (74%)]	Loss: 0.783265
Train Epoch: 82 [26880/35339 (76%)]	Loss: 0.561990
Train Epoch: 82 [27520/35339 (78%)]	Loss: 0.861768
Train Epoch: 82 [28160/35339 (80%)]	Loss: 0.521994
Train Epoch: 82 [28800/35339 (81%)]	Loss: 0.595392
Train Epoch: 82 [29440/35339 (83%)]	Loss: 0.664689
Train Epoch: 82 [30080/35339 (85%)]	Loss: 0.568374
Train Epoch: 82 [30720/35339 (87%)]	Loss: 0.521161
Train Epoch: 82 [31360/35339 (89%)]	Loss: 0.652143
Train Epoch: 82 [32000/35339 (90%)]	Loss: 0.537245
Train Epoch: 82 [32640/35339 (92%)]	Loss: 0.647001
Train Epoch: 82 [33280/35339 (94%)]	Loss: 0.673921
Train Epoch: 82 [33920/35339 (96%)]	Loss: 0.676202
Train Epoch: 82 [34560/35339 (98%)]	Loss: 0.729420
Train Epoch: 82 [35200/35339 (99%)]	Loss: 0.686572

Validation set: Average loss: 3.7805, Accuracy: 715/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 83 [0/35339 (0%)]	Loss: 0.612117
Train Epoch: 83 [640/35339 (2%)]	Loss: 0.780208
Train Epoch: 83 [1280/35339 (4%)]	Loss: 0.739800
Train Epoch: 83 [1920/35339 (5%)]	Loss: 0.675953
Train Epoch: 83 [2560/35339 (7%)]	Loss: 0.715744
Train Epoch: 83 [3200/35339 (9%)]	Loss: 0.706690
Train Epoch: 83 [3840/35339 (11%)]	Loss: 0.770792
Train Epoch: 83 [4480/35339 (13%)]	Loss: 0.690942
Train Epoch: 83 [5120/35339 (14%)]	Loss: 0.709483
Train Epoch: 83 [5760/35339 (16%)]	Loss: 0.739728
Train Epoch: 83 [6400/35339 (18%)]	Loss: 0.436164
Train Epoch: 83 [7040/35339 (20%)]	Loss: 0.557601
Train Epoch: 83 [7680/35339 (22%)]	Loss: 0.685457
Train Epoch: 83 [8320/35339 (24%)]	Loss: 0.694455
Train Epoch: 83 [8960/35339 (25%)]	Loss: 0.716243
Train Epoch: 83 [9600/35339 (27%)]	Loss: 0.907671
Train Epoch: 83 [10240/35339 (29%)]	Loss: 0.556548
Train Epoch: 83 [10880/35339 (31%)]	Loss: 0.758321
Train Epoch: 83 [11520/35339 (33%)]	Loss: 0.722231
Train Epoch: 83 [12160/35339 (34%)]	Loss: 0.764933
Train Epoch: 83 [12800/35339 (36%)]	Loss: 0.653582
Train Epoch: 83 [13440/35339 (38%)]	Loss: 0.621932
Train Epoch: 83 [14080/35339 (40%)]	Loss: 0.607186
Train Epoch: 83 [14720/35339 (42%)]	Loss: 0.691790
Train Epoch: 83 [15360/35339 (43%)]	Loss: 0.664542
Train Epoch: 83 [16000/35339 (45%)]	Loss: 0.693444
Train Epoch: 83 [16640/35339 (47%)]	Loss: 0.625885
Train Epoch: 83 [17280/35339 (49%)]	Loss: 0.652020
Train Epoch: 83 [17920/35339 (51%)]	Loss: 0.585517
Train Epoch: 83 [18560/35339 (52%)]	Loss: 0.613855
Train Epoch: 83 [19200/35339 (54%)]	Loss: 0.735060
Train Epoch: 83 [19840/35339 (56%)]	Loss: 0.596389
Train Epoch: 83 [20480/35339 (58%)]	Loss: 0.681224
Train Epoch: 83 [21120/35339 (60%)]	Loss: 0.626281
Train Epoch: 83 [21760/35339 (61%)]	Loss: 0.655458
Train Epoch: 83 [22400/35339 (63%)]	Loss: 0.686140
Train Epoch: 83 [23040/35339 (65%)]	Loss: 0.658411
Train Epoch: 83 [23680/35339 (67%)]	Loss: 0.660503
Train Epoch: 83 [24320/35339 (69%)]	Loss: 0.554757
Train Epoch: 83 [24960/35339 (71%)]	Loss: 0.516592
Train Epoch: 83 [25600/35339 (72%)]	Loss: 0.781541
Train Epoch: 83 [26240/35339 (74%)]	Loss: 0.630625
Train Epoch: 83 [26880/35339 (76%)]	Loss: 0.542202
Train Epoch: 83 [27520/35339 (78%)]	Loss: 0.668459
Train Epoch: 83 [28160/35339 (80%)]	Loss: 0.589920
Train Epoch: 83 [28800/35339 (81%)]	Loss: 0.697853
Train Epoch: 83 [29440/35339 (83%)]	Loss: 0.721031
Train Epoch: 83 [30080/35339 (85%)]	Loss: 0.803235
Train Epoch: 83 [30720/35339 (87%)]	Loss: 0.634008
Train Epoch: 83 [31360/35339 (89%)]	Loss: 0.543621
Train Epoch: 83 [32000/35339 (90%)]	Loss: 0.648287
Train Epoch: 83 [32640/35339 (92%)]	Loss: 0.694313
Train Epoch: 83 [33280/35339 (94%)]	Loss: 0.742397
Train Epoch: 83 [33920/35339 (96%)]	Loss: 0.615105
Train Epoch: 83 [34560/35339 (98%)]	Loss: 0.693841
Train Epoch: 83 [35200/35339 (99%)]	Loss: 0.514402

Validation set: Average loss: 3.7783, Accuracy: 695/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 84 [0/35339 (0%)]	Loss: 0.548495
Train Epoch: 84 [640/35339 (2%)]	Loss: 0.613102
Train Epoch: 84 [1280/35339 (4%)]	Loss: 0.531968
Train Epoch: 84 [1920/35339 (5%)]	Loss: 0.705355
Train Epoch: 84 [2560/35339 (7%)]	Loss: 0.617980
Train Epoch: 84 [3200/35339 (9%)]	Loss: 0.829968
Train Epoch: 84 [3840/35339 (11%)]	Loss: 0.788557
Train Epoch: 84 [4480/35339 (13%)]	Loss: 0.825769
Train Epoch: 84 [5120/35339 (14%)]	Loss: 1.011850
Train Epoch: 84 [5760/35339 (16%)]	Loss: 0.647965
Train Epoch: 84 [6400/35339 (18%)]	Loss: 0.718166
Train Epoch: 84 [7040/35339 (20%)]	Loss: 0.734375
Train Epoch: 84 [7680/35339 (22%)]	Loss: 0.748189
Train Epoch: 84 [8320/35339 (24%)]	Loss: 0.528450
Train Epoch: 84 [8960/35339 (25%)]	Loss: 0.755226
Train Epoch: 84 [9600/35339 (27%)]	Loss: 0.861794
Train Epoch: 84 [10240/35339 (29%)]	Loss: 0.717020
Train Epoch: 84 [10880/35339 (31%)]	Loss: 0.744073
Train Epoch: 84 [11520/35339 (33%)]	Loss: 0.514988
Train Epoch: 84 [12160/35339 (34%)]	Loss: 0.639943
Train Epoch: 84 [12800/35339 (36%)]	Loss: 0.492973
Train Epoch: 84 [13440/35339 (38%)]	Loss: 0.821931
Train Epoch: 84 [14080/35339 (40%)]	Loss: 0.619641
Train Epoch: 84 [14720/35339 (42%)]	Loss: 0.703798
Train Epoch: 84 [15360/35339 (43%)]	Loss: 0.750538
Train Epoch: 84 [16000/35339 (45%)]	Loss: 0.675956
Train Epoch: 84 [16640/35339 (47%)]	Loss: 0.670769
Train Epoch: 84 [17280/35339 (49%)]	Loss: 0.590335
Train Epoch: 84 [17920/35339 (51%)]	Loss: 0.900380
Train Epoch: 84 [18560/35339 (52%)]	Loss: 0.638668
Train Epoch: 84 [19200/35339 (54%)]	Loss: 0.815783
Train Epoch: 84 [19840/35339 (56%)]	Loss: 0.513568
Train Epoch: 84 [20480/35339 (58%)]	Loss: 0.645291
Train Epoch: 84 [21120/35339 (60%)]	Loss: 0.672321
Train Epoch: 84 [21760/35339 (61%)]	Loss: 0.743998
Train Epoch: 84 [22400/35339 (63%)]	Loss: 0.549776
Train Epoch: 84 [23040/35339 (65%)]	Loss: 0.625128
Train Epoch: 84 [23680/35339 (67%)]	Loss: 0.728273
Train Epoch: 84 [24320/35339 (69%)]	Loss: 0.593392
Train Epoch: 84 [24960/35339 (71%)]	Loss: 0.687018
Train Epoch: 84 [25600/35339 (72%)]	Loss: 0.554861
Train Epoch: 84 [26240/35339 (74%)]	Loss: 0.707440
Train Epoch: 84 [26880/35339 (76%)]	Loss: 0.573454
Train Epoch: 84 [27520/35339 (78%)]	Loss: 0.598743
Train Epoch: 84 [28160/35339 (80%)]	Loss: 0.779474
Train Epoch: 84 [28800/35339 (81%)]	Loss: 0.724994
Train Epoch: 84 [29440/35339 (83%)]	Loss: 0.625807
Train Epoch: 84 [30080/35339 (85%)]	Loss: 0.698758
Train Epoch: 84 [30720/35339 (87%)]	Loss: 0.654973
Train Epoch: 84 [31360/35339 (89%)]	Loss: 0.724782
Train Epoch: 84 [32000/35339 (90%)]	Loss: 0.754920
Train Epoch: 84 [32640/35339 (92%)]	Loss: 0.612505
Train Epoch: 84 [33280/35339 (94%)]	Loss: 0.714372
Train Epoch: 84 [33920/35339 (96%)]	Loss: 0.630758
Train Epoch: 84 [34560/35339 (98%)]	Loss: 0.694449
Train Epoch: 84 [35200/35339 (99%)]	Loss: 0.672056

Validation set: Average loss: 3.7798, Accuracy: 719/3870 (19%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 85 [0/35339 (0%)]	Loss: 0.753838
Train Epoch: 85 [640/35339 (2%)]	Loss: 0.702378
Train Epoch: 85 [1280/35339 (4%)]	Loss: 0.638173
Train Epoch: 85 [1920/35339 (5%)]	Loss: 0.807662
Train Epoch: 85 [2560/35339 (7%)]	Loss: 0.531252
Train Epoch: 85 [3200/35339 (9%)]	Loss: 0.450167
Train Epoch: 85 [3840/35339 (11%)]	Loss: 0.696134
Train Epoch: 85 [4480/35339 (13%)]	Loss: 0.632505
Train Epoch: 85 [5120/35339 (14%)]	Loss: 0.615419
Train Epoch: 85 [5760/35339 (16%)]	Loss: 0.484154
Train Epoch: 85 [6400/35339 (18%)]	Loss: 0.745286
Train Epoch: 85 [7040/35339 (20%)]	Loss: 0.712977
Train Epoch: 85 [7680/35339 (22%)]	Loss: 0.627475
Train Epoch: 85 [8320/35339 (24%)]	Loss: 0.745614
Train Epoch: 85 [8960/35339 (25%)]	Loss: 0.700538
Train Epoch: 85 [9600/35339 (27%)]	Loss: 0.657006
Train Epoch: 85 [10240/35339 (29%)]	Loss: 0.610615
Train Epoch: 85 [10880/35339 (31%)]	Loss: 0.664082
Train Epoch: 85 [11520/35339 (33%)]	Loss: 0.539778
Train Epoch: 85 [12160/35339 (34%)]	Loss: 0.683403
Train Epoch: 85 [12800/35339 (36%)]	Loss: 0.617573
Train Epoch: 85 [13440/35339 (38%)]	Loss: 0.788382
Train Epoch: 85 [14080/35339 (40%)]	Loss: 0.608188
Train Epoch: 85 [14720/35339 (42%)]	Loss: 0.606831
Train Epoch: 85 [15360/35339 (43%)]	Loss: 0.679222
Train Epoch: 85 [16000/35339 (45%)]	Loss: 0.527402
Train Epoch: 85 [16640/35339 (47%)]	Loss: 0.641433
Train Epoch: 85 [17280/35339 (49%)]	Loss: 0.713191
Train Epoch: 85 [17920/35339 (51%)]	Loss: 0.683368
Train Epoch: 85 [18560/35339 (52%)]	Loss: 0.469727
Train Epoch: 85 [19200/35339 (54%)]	Loss: 0.572336
Train Epoch: 85 [19840/35339 (56%)]	Loss: 0.685509
Train Epoch: 85 [20480/35339 (58%)]	Loss: 0.657363
Train Epoch: 85 [21120/35339 (60%)]	Loss: 0.785296
Train Epoch: 85 [21760/35339 (61%)]	Loss: 0.717577
Train Epoch: 85 [22400/35339 (63%)]	Loss: 0.506844
Train Epoch: 85 [23040/35339 (65%)]	Loss: 0.575237
Train Epoch: 85 [23680/35339 (67%)]	Loss: 0.727299
Train Epoch: 85 [24320/35339 (69%)]	Loss: 0.509739
Train Epoch: 85 [24960/35339 (71%)]	Loss: 0.757035
Train Epoch: 85 [25600/35339 (72%)]	Loss: 0.555924
Train Epoch: 85 [26240/35339 (74%)]	Loss: 0.508569
Train Epoch: 85 [26880/35339 (76%)]	Loss: 0.612427
Train Epoch: 85 [27520/35339 (78%)]	Loss: 0.668436
Train Epoch: 85 [28160/35339 (80%)]	Loss: 0.566097
Train Epoch: 85 [28800/35339 (81%)]	Loss: 0.662360
Train Epoch: 85 [29440/35339 (83%)]	Loss: 0.752983
Train Epoch: 85 [30080/35339 (85%)]	Loss: 0.715802
Train Epoch: 85 [30720/35339 (87%)]	Loss: 0.609776
Train Epoch: 85 [31360/35339 (89%)]	Loss: 0.692855
Train Epoch: 85 [32000/35339 (90%)]	Loss: 0.533046
Train Epoch: 85 [32640/35339 (92%)]	Loss: 0.652521
Train Epoch: 85 [33280/35339 (94%)]	Loss: 0.700820
Train Epoch: 85 [33920/35339 (96%)]	Loss: 0.813338
Train Epoch: 85 [34560/35339 (98%)]	Loss: 0.747332
Train Epoch: 85 [35200/35339 (99%)]	Loss: 0.616136

Validation set: Average loss: 3.7868, Accuracy: 701/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 86 [0/35339 (0%)]	Loss: 0.745068
Train Epoch: 86 [640/35339 (2%)]	Loss: 0.677385
Train Epoch: 86 [1280/35339 (4%)]	Loss: 0.704037
Train Epoch: 86 [1920/35339 (5%)]	Loss: 0.682758
Train Epoch: 86 [2560/35339 (7%)]	Loss: 0.840854
Train Epoch: 86 [3200/35339 (9%)]	Loss: 0.834396
Train Epoch: 86 [3840/35339 (11%)]	Loss: 0.651133
Train Epoch: 86 [4480/35339 (13%)]	Loss: 0.567677
Train Epoch: 86 [5120/35339 (14%)]	Loss: 0.727533
Train Epoch: 86 [5760/35339 (16%)]	Loss: 0.558360
Train Epoch: 86 [6400/35339 (18%)]	Loss: 0.567119
Train Epoch: 86 [7040/35339 (20%)]	Loss: 0.762411
Train Epoch: 86 [7680/35339 (22%)]	Loss: 0.870957
Train Epoch: 86 [8320/35339 (24%)]	Loss: 0.769830
Train Epoch: 86 [8960/35339 (25%)]	Loss: 0.512907
Train Epoch: 86 [9600/35339 (27%)]	Loss: 0.779413
Train Epoch: 86 [10240/35339 (29%)]	Loss: 0.567066
Train Epoch: 86 [10880/35339 (31%)]	Loss: 0.650285
Train Epoch: 86 [11520/35339 (33%)]	Loss: 0.578620
Train Epoch: 86 [12160/35339 (34%)]	Loss: 0.468297
Train Epoch: 86 [12800/35339 (36%)]	Loss: 0.588090
Train Epoch: 86 [13440/35339 (38%)]	Loss: 0.413448
Train Epoch: 86 [14080/35339 (40%)]	Loss: 0.338534
Train Epoch: 86 [14720/35339 (42%)]	Loss: 0.898741
Train Epoch: 86 [15360/35339 (43%)]	Loss: 0.607181
Train Epoch: 86 [16000/35339 (45%)]	Loss: 0.629485
Train Epoch: 86 [16640/35339 (47%)]	Loss: 0.740920
Train Epoch: 86 [17280/35339 (49%)]	Loss: 0.583686
Train Epoch: 86 [17920/35339 (51%)]	Loss: 0.571319
Train Epoch: 86 [18560/35339 (52%)]	Loss: 0.679725
Train Epoch: 86 [19200/35339 (54%)]	Loss: 0.709085
Train Epoch: 86 [19840/35339 (56%)]	Loss: 0.556108
Train Epoch: 86 [20480/35339 (58%)]	Loss: 0.709618
Train Epoch: 86 [21120/35339 (60%)]	Loss: 0.749658
Train Epoch: 86 [21760/35339 (61%)]	Loss: 0.717504
Train Epoch: 86 [22400/35339 (63%)]	Loss: 0.466946
Train Epoch: 86 [23040/35339 (65%)]	Loss: 0.583634
Train Epoch: 86 [23680/35339 (67%)]	Loss: 0.618967
Train Epoch: 86 [24320/35339 (69%)]	Loss: 0.709971
Train Epoch: 86 [24960/35339 (71%)]	Loss: 0.666538
Train Epoch: 86 [25600/35339 (72%)]	Loss: 0.692594
Train Epoch: 86 [26240/35339 (74%)]	Loss: 0.769375
Train Epoch: 86 [26880/35339 (76%)]	Loss: 0.572480
Train Epoch: 86 [27520/35339 (78%)]	Loss: 0.689189
Train Epoch: 86 [28160/35339 (80%)]	Loss: 0.776983
Train Epoch: 86 [28800/35339 (81%)]	Loss: 0.523046
Train Epoch: 86 [29440/35339 (83%)]	Loss: 0.512104
Train Epoch: 86 [30080/35339 (85%)]	Loss: 0.636348
Train Epoch: 86 [30720/35339 (87%)]	Loss: 0.680657
Train Epoch: 86 [31360/35339 (89%)]	Loss: 0.673922
Train Epoch: 86 [32000/35339 (90%)]	Loss: 0.627581
Train Epoch: 86 [32640/35339 (92%)]	Loss: 0.758640
Train Epoch: 86 [33280/35339 (94%)]	Loss: 0.982750
Train Epoch: 86 [33920/35339 (96%)]	Loss: 0.642332
Train Epoch: 86 [34560/35339 (98%)]	Loss: 0.697091
Train Epoch: 86 [35200/35339 (99%)]	Loss: 0.903938

Validation set: Average loss: 3.7866, Accuracy: 712/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 87 [0/35339 (0%)]	Loss: 0.745345
Train Epoch: 87 [640/35339 (2%)]	Loss: 0.630692
Train Epoch: 87 [1280/35339 (4%)]	Loss: 0.745709
Train Epoch: 87 [1920/35339 (5%)]	Loss: 0.661727
Train Epoch: 87 [2560/35339 (7%)]	Loss: 0.702674
Train Epoch: 87 [3200/35339 (9%)]	Loss: 0.852611
Train Epoch: 87 [3840/35339 (11%)]	Loss: 0.686989
Train Epoch: 87 [4480/35339 (13%)]	Loss: 0.562790
Train Epoch: 87 [5120/35339 (14%)]	Loss: 0.666972
Train Epoch: 87 [5760/35339 (16%)]	Loss: 0.513239
Train Epoch: 87 [6400/35339 (18%)]	Loss: 0.786266
Train Epoch: 87 [7040/35339 (20%)]	Loss: 0.629690
Train Epoch: 87 [7680/35339 (22%)]	Loss: 0.665974
Train Epoch: 87 [8320/35339 (24%)]	Loss: 0.593238
Train Epoch: 87 [8960/35339 (25%)]	Loss: 0.548685
Train Epoch: 87 [9600/35339 (27%)]	Loss: 0.822170
Train Epoch: 87 [10240/35339 (29%)]	Loss: 0.749112
Train Epoch: 87 [10880/35339 (31%)]	Loss: 0.595401
Train Epoch: 87 [11520/35339 (33%)]	Loss: 0.731402
Train Epoch: 87 [12160/35339 (34%)]	Loss: 0.738032
Train Epoch: 87 [12800/35339 (36%)]	Loss: 0.652656
Train Epoch: 87 [13440/35339 (38%)]	Loss: 0.605086
Train Epoch: 87 [14080/35339 (40%)]	Loss: 0.678869
Train Epoch: 87 [14720/35339 (42%)]	Loss: 0.798044
Train Epoch: 87 [15360/35339 (43%)]	Loss: 0.497361
Train Epoch: 87 [16000/35339 (45%)]	Loss: 0.728260
Train Epoch: 87 [16640/35339 (47%)]	Loss: 0.762015
Train Epoch: 87 [17280/35339 (49%)]	Loss: 0.685375
Train Epoch: 87 [17920/35339 (51%)]	Loss: 0.657149
Train Epoch: 87 [18560/35339 (52%)]	Loss: 0.568192
Train Epoch: 87 [19200/35339 (54%)]	Loss: 0.719166
Train Epoch: 87 [19840/35339 (56%)]	Loss: 0.483975
Train Epoch: 87 [20480/35339 (58%)]	Loss: 0.648674
Train Epoch: 87 [21120/35339 (60%)]	Loss: 0.729698
Train Epoch: 87 [21760/35339 (61%)]	Loss: 0.514693
Train Epoch: 87 [22400/35339 (63%)]	Loss: 0.770651
Train Epoch: 87 [23040/35339 (65%)]	Loss: 0.804709
Train Epoch: 87 [23680/35339 (67%)]	Loss: 0.593551
Train Epoch: 87 [24320/35339 (69%)]	Loss: 0.663103
Train Epoch: 87 [24960/35339 (71%)]	Loss: 0.600575
Train Epoch: 87 [25600/35339 (72%)]	Loss: 0.738874
Train Epoch: 87 [26240/35339 (74%)]	Loss: 0.608036
Train Epoch: 87 [26880/35339 (76%)]	Loss: 0.584203
Train Epoch: 87 [27520/35339 (78%)]	Loss: 0.509172
Train Epoch: 87 [28160/35339 (80%)]	Loss: 0.654562
Train Epoch: 87 [28800/35339 (81%)]	Loss: 0.564994
Train Epoch: 87 [29440/35339 (83%)]	Loss: 0.597832
Train Epoch: 87 [30080/35339 (85%)]	Loss: 0.720772
Train Epoch: 87 [30720/35339 (87%)]	Loss: 0.570862
Train Epoch: 87 [31360/35339 (89%)]	Loss: 0.758638
Train Epoch: 87 [32000/35339 (90%)]	Loss: 0.659502
Train Epoch: 87 [32640/35339 (92%)]	Loss: 0.809658
Train Epoch: 87 [33280/35339 (94%)]	Loss: 0.851752
Train Epoch: 87 [33920/35339 (96%)]	Loss: 0.661400
Train Epoch: 87 [34560/35339 (98%)]	Loss: 0.548379
Train Epoch: 87 [35200/35339 (99%)]	Loss: 0.675667

Validation set: Average loss: 3.7816, Accuracy: 708/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 88 [0/35339 (0%)]	Loss: 0.618709
Train Epoch: 88 [640/35339 (2%)]	Loss: 0.620199
Train Epoch: 88 [1280/35339 (4%)]	Loss: 0.687520
Train Epoch: 88 [1920/35339 (5%)]	Loss: 0.755158
Train Epoch: 88 [2560/35339 (7%)]	Loss: 0.649439
Train Epoch: 88 [3200/35339 (9%)]	Loss: 0.773334
Train Epoch: 88 [3840/35339 (11%)]	Loss: 0.868007
Train Epoch: 88 [4480/35339 (13%)]	Loss: 0.527229
Train Epoch: 88 [5120/35339 (14%)]	Loss: 0.613330
Train Epoch: 88 [5760/35339 (16%)]	Loss: 0.708619
Train Epoch: 88 [6400/35339 (18%)]	Loss: 0.686252
Train Epoch: 88 [7040/35339 (20%)]	Loss: 0.702905
Train Epoch: 88 [7680/35339 (22%)]	Loss: 0.503255
Train Epoch: 88 [8320/35339 (24%)]	Loss: 0.684737
Train Epoch: 88 [8960/35339 (25%)]	Loss: 0.743813
Train Epoch: 88 [9600/35339 (27%)]	Loss: 0.603275
Train Epoch: 88 [10240/35339 (29%)]	Loss: 0.667466
Train Epoch: 88 [10880/35339 (31%)]	Loss: 0.624424
Train Epoch: 88 [11520/35339 (33%)]	Loss: 0.601472
Train Epoch: 88 [12160/35339 (34%)]	Loss: 0.748534
Train Epoch: 88 [12800/35339 (36%)]	Loss: 0.688853
Train Epoch: 88 [13440/35339 (38%)]	Loss: 0.577249
Train Epoch: 88 [14080/35339 (40%)]	Loss: 0.733862
Train Epoch: 88 [14720/35339 (42%)]	Loss: 0.631197
Train Epoch: 88 [15360/35339 (43%)]	Loss: 1.061705
Train Epoch: 88 [16000/35339 (45%)]	Loss: 0.673587
Train Epoch: 88 [16640/35339 (47%)]	Loss: 0.684940
Train Epoch: 88 [17280/35339 (49%)]	Loss: 0.703111
Train Epoch: 88 [17920/35339 (51%)]	Loss: 0.652541
Train Epoch: 88 [18560/35339 (52%)]	Loss: 0.580273
Train Epoch: 88 [19200/35339 (54%)]	Loss: 0.764078
Train Epoch: 88 [19840/35339 (56%)]	Loss: 0.608242
Train Epoch: 88 [20480/35339 (58%)]	Loss: 0.639654
Train Epoch: 88 [21120/35339 (60%)]	Loss: 0.657162
Train Epoch: 88 [21760/35339 (61%)]	Loss: 0.612365
Train Epoch: 88 [22400/35339 (63%)]	Loss: 0.689604
Train Epoch: 88 [23040/35339 (65%)]	Loss: 0.548237
Train Epoch: 88 [23680/35339 (67%)]	Loss: 0.750417
Train Epoch: 88 [24320/35339 (69%)]	Loss: 0.567558
Train Epoch: 88 [24960/35339 (71%)]	Loss: 0.585852
Train Epoch: 88 [25600/35339 (72%)]	Loss: 0.658934
Train Epoch: 88 [26240/35339 (74%)]	Loss: 0.633801
Train Epoch: 88 [26880/35339 (76%)]	Loss: 0.709722
Train Epoch: 88 [27520/35339 (78%)]	Loss: 0.860999
Train Epoch: 88 [28160/35339 (80%)]	Loss: 0.501147
Train Epoch: 88 [28800/35339 (81%)]	Loss: 0.717944
Train Epoch: 88 [29440/35339 (83%)]	Loss: 0.422516
Train Epoch: 88 [30080/35339 (85%)]	Loss: 0.534875
Train Epoch: 88 [30720/35339 (87%)]	Loss: 0.574370
Train Epoch: 88 [31360/35339 (89%)]	Loss: 0.540178
Train Epoch: 88 [32000/35339 (90%)]	Loss: 0.741203
Train Epoch: 88 [32640/35339 (92%)]	Loss: 0.812518
Train Epoch: 88 [33280/35339 (94%)]	Loss: 0.579532
Train Epoch: 88 [33920/35339 (96%)]	Loss: 1.037188
Train Epoch: 88 [34560/35339 (98%)]	Loss: 0.442328
Train Epoch: 88 [35200/35339 (99%)]	Loss: 0.732192

Validation set: Average loss: 3.7868, Accuracy: 712/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 89 [0/35339 (0%)]	Loss: 0.765403
Train Epoch: 89 [640/35339 (2%)]	Loss: 0.823074
Train Epoch: 89 [1280/35339 (4%)]	Loss: 0.763153
Train Epoch: 89 [1920/35339 (5%)]	Loss: 0.513569
Train Epoch: 89 [2560/35339 (7%)]	Loss: 0.668004
Train Epoch: 89 [3200/35339 (9%)]	Loss: 0.695832
Train Epoch: 89 [3840/35339 (11%)]	Loss: 0.624367
Train Epoch: 89 [4480/35339 (13%)]	Loss: 0.719440
Train Epoch: 89 [5120/35339 (14%)]	Loss: 0.738878
Train Epoch: 89 [5760/35339 (16%)]	Loss: 0.640531
Train Epoch: 89 [6400/35339 (18%)]	Loss: 0.604257
Train Epoch: 89 [7040/35339 (20%)]	Loss: 0.660760
Train Epoch: 89 [7680/35339 (22%)]	Loss: 0.688622
Train Epoch: 89 [8320/35339 (24%)]	Loss: 0.673595
Train Epoch: 89 [8960/35339 (25%)]	Loss: 0.580642
Train Epoch: 89 [9600/35339 (27%)]	Loss: 0.834077
Train Epoch: 89 [10240/35339 (29%)]	Loss: 0.667124
Train Epoch: 89 [10880/35339 (31%)]	Loss: 0.570405
Train Epoch: 89 [11520/35339 (33%)]	Loss: 0.654635
Train Epoch: 89 [12160/35339 (34%)]	Loss: 0.903045
Train Epoch: 89 [12800/35339 (36%)]	Loss: 0.469910
Train Epoch: 89 [13440/35339 (38%)]	Loss: 0.387027
Train Epoch: 89 [14080/35339 (40%)]	Loss: 0.640872
Train Epoch: 89 [14720/35339 (42%)]	Loss: 0.484077
Train Epoch: 89 [15360/35339 (43%)]	Loss: 0.724609
Train Epoch: 89 [16000/35339 (45%)]	Loss: 0.685238
Train Epoch: 89 [16640/35339 (47%)]	Loss: 0.693924
Train Epoch: 89 [17280/35339 (49%)]	Loss: 0.505989
Train Epoch: 89 [17920/35339 (51%)]	Loss: 0.723369
Train Epoch: 89 [18560/35339 (52%)]	Loss: 0.933814
Train Epoch: 89 [19200/35339 (54%)]	Loss: 0.693268
Train Epoch: 89 [19840/35339 (56%)]	Loss: 0.621011
Train Epoch: 89 [20480/35339 (58%)]	Loss: 0.445802
Train Epoch: 89 [21120/35339 (60%)]	Loss: 0.658038
Train Epoch: 89 [21760/35339 (61%)]	Loss: 0.732816
Train Epoch: 89 [22400/35339 (63%)]	Loss: 0.567554
Train Epoch: 89 [23040/35339 (65%)]	Loss: 0.604541
Train Epoch: 89 [23680/35339 (67%)]	Loss: 0.694983
Train Epoch: 89 [24320/35339 (69%)]	Loss: 0.659791
Train Epoch: 89 [24960/35339 (71%)]	Loss: 0.516402
Train Epoch: 89 [25600/35339 (72%)]	Loss: 0.722247
Train Epoch: 89 [26240/35339 (74%)]	Loss: 0.749642
Train Epoch: 89 [26880/35339 (76%)]	Loss: 0.577056
Train Epoch: 89 [27520/35339 (78%)]	Loss: 0.555470
Train Epoch: 89 [28160/35339 (80%)]	Loss: 0.785257
Train Epoch: 89 [28800/35339 (81%)]	Loss: 0.629718
Train Epoch: 89 [29440/35339 (83%)]	Loss: 0.648317
Train Epoch: 89 [30080/35339 (85%)]	Loss: 0.652057
Train Epoch: 89 [30720/35339 (87%)]	Loss: 0.561197
Train Epoch: 89 [31360/35339 (89%)]	Loss: 0.581929
Train Epoch: 89 [32000/35339 (90%)]	Loss: 0.649229
Train Epoch: 89 [32640/35339 (92%)]	Loss: 0.525386
Train Epoch: 89 [33280/35339 (94%)]	Loss: 0.551983
Train Epoch: 89 [33920/35339 (96%)]	Loss: 0.719175
Train Epoch: 89 [34560/35339 (98%)]	Loss: 0.639765
Train Epoch: 89 [35200/35339 (99%)]	Loss: 0.472747

Validation set: Average loss: 3.7770, Accuracy: 698/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 90 [0/35339 (0%)]	Loss: 0.585031
Train Epoch: 90 [640/35339 (2%)]	Loss: 0.702838
Train Epoch: 90 [1280/35339 (4%)]	Loss: 0.644224
Train Epoch: 90 [1920/35339 (5%)]	Loss: 0.776102
Train Epoch: 90 [2560/35339 (7%)]	Loss: 0.618828
Train Epoch: 90 [3200/35339 (9%)]	Loss: 0.588447
Train Epoch: 90 [3840/35339 (11%)]	Loss: 0.613625
Train Epoch: 90 [4480/35339 (13%)]	Loss: 0.707774
Train Epoch: 90 [5120/35339 (14%)]	Loss: 0.636441
Train Epoch: 90 [5760/35339 (16%)]	Loss: 0.743495
Train Epoch: 90 [6400/35339 (18%)]	Loss: 0.741794
Train Epoch: 90 [7040/35339 (20%)]	Loss: 0.636598
Train Epoch: 90 [7680/35339 (22%)]	Loss: 0.670765
Train Epoch: 90 [8320/35339 (24%)]	Loss: 0.685494
Train Epoch: 90 [8960/35339 (25%)]	Loss: 0.874744
Train Epoch: 90 [9600/35339 (27%)]	Loss: 0.698974
Train Epoch: 90 [10240/35339 (29%)]	Loss: 0.684268
Train Epoch: 90 [10880/35339 (31%)]	Loss: 0.456297
Train Epoch: 90 [11520/35339 (33%)]	Loss: 0.619267
Train Epoch: 90 [12160/35339 (34%)]	Loss: 0.732581
Train Epoch: 90 [12800/35339 (36%)]	Loss: 0.629961
Train Epoch: 90 [13440/35339 (38%)]	Loss: 0.595477
Train Epoch: 90 [14080/35339 (40%)]	Loss: 0.610757
Train Epoch: 90 [14720/35339 (42%)]	Loss: 0.493138
Train Epoch: 90 [15360/35339 (43%)]	Loss: 0.631985
Train Epoch: 90 [16000/35339 (45%)]	Loss: 0.715120
Train Epoch: 90 [16640/35339 (47%)]	Loss: 0.471761
Train Epoch: 90 [17280/35339 (49%)]	Loss: 0.739932
Train Epoch: 90 [17920/35339 (51%)]	Loss: 0.728173
Train Epoch: 90 [18560/35339 (52%)]	Loss: 0.917704
Train Epoch: 90 [19200/35339 (54%)]	Loss: 0.620893
Train Epoch: 90 [19840/35339 (56%)]	Loss: 0.567970
Train Epoch: 90 [20480/35339 (58%)]	Loss: 0.665508
Train Epoch: 90 [21120/35339 (60%)]	Loss: 0.500422
Train Epoch: 90 [21760/35339 (61%)]	Loss: 0.594554
Train Epoch: 90 [22400/35339 (63%)]	Loss: 0.642435
Train Epoch: 90 [23040/35339 (65%)]	Loss: 0.654771
Train Epoch: 90 [23680/35339 (67%)]	Loss: 0.689065
Train Epoch: 90 [24320/35339 (69%)]	Loss: 0.681696
Train Epoch: 90 [24960/35339 (71%)]	Loss: 1.052436
Train Epoch: 90 [25600/35339 (72%)]	Loss: 0.681363
Train Epoch: 90 [26240/35339 (74%)]	Loss: 0.686554
Train Epoch: 90 [26880/35339 (76%)]	Loss: 0.545260
Train Epoch: 90 [27520/35339 (78%)]	Loss: 0.618412
Train Epoch: 90 [28160/35339 (80%)]	Loss: 0.560848
Train Epoch: 90 [28800/35339 (81%)]	Loss: 0.680896
Train Epoch: 90 [29440/35339 (83%)]	Loss: 0.718127
Train Epoch: 90 [30080/35339 (85%)]	Loss: 0.711604
Train Epoch: 90 [30720/35339 (87%)]	Loss: 0.638649
Train Epoch: 90 [31360/35339 (89%)]	Loss: 0.628537
Train Epoch: 90 [32000/35339 (90%)]	Loss: 0.589435
Train Epoch: 90 [32640/35339 (92%)]	Loss: 0.719162
Train Epoch: 90 [33280/35339 (94%)]	Loss: 0.592385
Train Epoch: 90 [33920/35339 (96%)]	Loss: 0.746983
Train Epoch: 90 [34560/35339 (98%)]	Loss: 0.560723
Train Epoch: 90 [35200/35339 (99%)]	Loss: 0.620093

Validation set: Average loss: 3.7865, Accuracy: 696/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 91 [0/35339 (0%)]	Loss: 0.838358
Train Epoch: 91 [640/35339 (2%)]	Loss: 0.590628
Train Epoch: 91 [1280/35339 (4%)]	Loss: 0.475818
Train Epoch: 91 [1920/35339 (5%)]	Loss: 0.581940
Train Epoch: 91 [2560/35339 (7%)]	Loss: 0.591999
Train Epoch: 91 [3200/35339 (9%)]	Loss: 0.695747
Train Epoch: 91 [3840/35339 (11%)]	Loss: 0.814924
Train Epoch: 91 [4480/35339 (13%)]	Loss: 0.652186
Train Epoch: 91 [5120/35339 (14%)]	Loss: 0.660490
Train Epoch: 91 [5760/35339 (16%)]	Loss: 0.709508
Train Epoch: 91 [6400/35339 (18%)]	Loss: 0.881107
Train Epoch: 91 [7040/35339 (20%)]	Loss: 0.760632
Train Epoch: 91 [7680/35339 (22%)]	Loss: 0.696544
Train Epoch: 91 [8320/35339 (24%)]	Loss: 0.504924
Train Epoch: 91 [8960/35339 (25%)]	Loss: 0.669119
Train Epoch: 91 [9600/35339 (27%)]	Loss: 0.526587
Train Epoch: 91 [10240/35339 (29%)]	Loss: 0.869543
Train Epoch: 91 [10880/35339 (31%)]	Loss: 0.572471
Train Epoch: 91 [11520/35339 (33%)]	Loss: 0.624009
Train Epoch: 91 [12160/35339 (34%)]	Loss: 0.741531
Train Epoch: 91 [12800/35339 (36%)]	Loss: 0.551438
Train Epoch: 91 [13440/35339 (38%)]	Loss: 0.462669
Train Epoch: 91 [14080/35339 (40%)]	Loss: 0.567089
Train Epoch: 91 [14720/35339 (42%)]	Loss: 0.781859
Train Epoch: 91 [15360/35339 (43%)]	Loss: 0.596860
Train Epoch: 91 [16000/35339 (45%)]	Loss: 0.488514
Train Epoch: 91 [16640/35339 (47%)]	Loss: 0.570956
Train Epoch: 91 [17280/35339 (49%)]	Loss: 0.510349
Train Epoch: 91 [17920/35339 (51%)]	Loss: 0.577851
Train Epoch: 91 [18560/35339 (52%)]	Loss: 0.665704
Train Epoch: 91 [19200/35339 (54%)]	Loss: 0.610133
Train Epoch: 91 [19840/35339 (56%)]	Loss: 0.523844
Train Epoch: 91 [20480/35339 (58%)]	Loss: 0.527868
Train Epoch: 91 [21120/35339 (60%)]	Loss: 0.795666
Train Epoch: 91 [21760/35339 (61%)]	Loss: 0.582807
Train Epoch: 91 [22400/35339 (63%)]	Loss: 0.750883
Train Epoch: 91 [23040/35339 (65%)]	Loss: 0.659099
Train Epoch: 91 [23680/35339 (67%)]	Loss: 0.539304
Train Epoch: 91 [24320/35339 (69%)]	Loss: 0.825654
Train Epoch: 91 [24960/35339 (71%)]	Loss: 0.856457
Train Epoch: 91 [25600/35339 (72%)]	Loss: 0.637025
Train Epoch: 91 [26240/35339 (74%)]	Loss: 0.657782
Train Epoch: 91 [26880/35339 (76%)]	Loss: 0.636211
Train Epoch: 91 [27520/35339 (78%)]	Loss: 0.806717
Train Epoch: 91 [28160/35339 (80%)]	Loss: 0.621701
Train Epoch: 91 [28800/35339 (81%)]	Loss: 0.675128
Train Epoch: 91 [29440/35339 (83%)]	Loss: 0.682618
Train Epoch: 91 [30080/35339 (85%)]	Loss: 0.676447
Train Epoch: 91 [30720/35339 (87%)]	Loss: 0.643125
Train Epoch: 91 [31360/35339 (89%)]	Loss: 0.677422
Train Epoch: 91 [32000/35339 (90%)]	Loss: 0.556706
Train Epoch: 91 [32640/35339 (92%)]	Loss: 0.778970
Train Epoch: 91 [33280/35339 (94%)]	Loss: 0.616616
Train Epoch: 91 [33920/35339 (96%)]	Loss: 0.573120
Train Epoch: 91 [34560/35339 (98%)]	Loss: 0.647526
Train Epoch: 91 [35200/35339 (99%)]	Loss: 0.621988

Validation set: Average loss: 3.7832, Accuracy: 703/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 92 [0/35339 (0%)]	Loss: 0.356120
Train Epoch: 92 [640/35339 (2%)]	Loss: 0.710128
Train Epoch: 92 [1280/35339 (4%)]	Loss: 0.768291
Train Epoch: 92 [1920/35339 (5%)]	Loss: 0.750499
Train Epoch: 92 [2560/35339 (7%)]	Loss: 0.717065
Train Epoch: 92 [3200/35339 (9%)]	Loss: 0.674468
Train Epoch: 92 [3840/35339 (11%)]	Loss: 0.567688
Train Epoch: 92 [4480/35339 (13%)]	Loss: 0.569860
Train Epoch: 92 [5120/35339 (14%)]	Loss: 0.466352
Train Epoch: 92 [5760/35339 (16%)]	Loss: 0.809187
Train Epoch: 92 [6400/35339 (18%)]	Loss: 0.590910
Train Epoch: 92 [7040/35339 (20%)]	Loss: 0.639256
Train Epoch: 92 [7680/35339 (22%)]	Loss: 0.800529
Train Epoch: 92 [8320/35339 (24%)]	Loss: 0.637260
Train Epoch: 92 [8960/35339 (25%)]	Loss: 0.669263
Train Epoch: 92 [9600/35339 (27%)]	Loss: 0.559713
Train Epoch: 92 [10240/35339 (29%)]	Loss: 0.530418
Train Epoch: 92 [10880/35339 (31%)]	Loss: 0.630850
Train Epoch: 92 [11520/35339 (33%)]	Loss: 0.668351
Train Epoch: 92 [12160/35339 (34%)]	Loss: 0.638549
Train Epoch: 92 [12800/35339 (36%)]	Loss: 0.711554
Train Epoch: 92 [13440/35339 (38%)]	Loss: 0.635010
Train Epoch: 92 [14080/35339 (40%)]	Loss: 0.530537
Train Epoch: 92 [14720/35339 (42%)]	Loss: 0.497425
Train Epoch: 92 [15360/35339 (43%)]	Loss: 0.564062
Train Epoch: 92 [16000/35339 (45%)]	Loss: 0.469137
Train Epoch: 92 [16640/35339 (47%)]	Loss: 0.640550
Train Epoch: 92 [17280/35339 (49%)]	Loss: 0.699108
Train Epoch: 92 [17920/35339 (51%)]	Loss: 0.455412
Train Epoch: 92 [18560/35339 (52%)]	Loss: 0.603114
Train Epoch: 92 [19200/35339 (54%)]	Loss: 0.648794
Train Epoch: 92 [19840/35339 (56%)]	Loss: 0.714108
Train Epoch: 92 [20480/35339 (58%)]	Loss: 0.492485
Train Epoch: 92 [21120/35339 (60%)]	Loss: 0.499354
Train Epoch: 92 [21760/35339 (61%)]	Loss: 0.716299
Train Epoch: 92 [22400/35339 (63%)]	Loss: 0.627674
Train Epoch: 92 [23040/35339 (65%)]	Loss: 0.785982
Train Epoch: 92 [23680/35339 (67%)]	Loss: 0.620625
Train Epoch: 92 [24320/35339 (69%)]	Loss: 0.600440
Train Epoch: 92 [24960/35339 (71%)]	Loss: 0.548130
Train Epoch: 92 [25600/35339 (72%)]	Loss: 0.764061
Train Epoch: 92 [26240/35339 (74%)]	Loss: 0.745120
Train Epoch: 92 [26880/35339 (76%)]	Loss: 0.775901
Train Epoch: 92 [27520/35339 (78%)]	Loss: 0.534659
Train Epoch: 92 [28160/35339 (80%)]	Loss: 0.794122
Train Epoch: 92 [28800/35339 (81%)]	Loss: 0.648647
Train Epoch: 92 [29440/35339 (83%)]	Loss: 0.692813
Train Epoch: 92 [30080/35339 (85%)]	Loss: 0.468650
Train Epoch: 92 [30720/35339 (87%)]	Loss: 0.491312
Train Epoch: 92 [31360/35339 (89%)]	Loss: 0.585527
Train Epoch: 92 [32000/35339 (90%)]	Loss: 0.572757
Train Epoch: 92 [32640/35339 (92%)]	Loss: 0.469476
Train Epoch: 92 [33280/35339 (94%)]	Loss: 0.735998
Train Epoch: 92 [33920/35339 (96%)]	Loss: 0.749514
Train Epoch: 92 [34560/35339 (98%)]	Loss: 0.581996
Train Epoch: 92 [35200/35339 (99%)]	Loss: 0.738963

Validation set: Average loss: 3.7828, Accuracy: 698/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 93 [0/35339 (0%)]	Loss: 0.747418
Train Epoch: 93 [640/35339 (2%)]	Loss: 0.658011
Train Epoch: 93 [1280/35339 (4%)]	Loss: 0.716872
Train Epoch: 93 [1920/35339 (5%)]	Loss: 0.931207
Train Epoch: 93 [2560/35339 (7%)]	Loss: 0.778679
Train Epoch: 93 [3200/35339 (9%)]	Loss: 0.560799
Train Epoch: 93 [3840/35339 (11%)]	Loss: 0.584116
Train Epoch: 93 [4480/35339 (13%)]	Loss: 0.428654
Train Epoch: 93 [5120/35339 (14%)]	Loss: 0.562176
Train Epoch: 93 [5760/35339 (16%)]	Loss: 0.678121
Train Epoch: 93 [6400/35339 (18%)]	Loss: 0.825426
Train Epoch: 93 [7040/35339 (20%)]	Loss: 0.697356
Train Epoch: 93 [7680/35339 (22%)]	Loss: 0.507549
Train Epoch: 93 [8320/35339 (24%)]	Loss: 0.580892
Train Epoch: 93 [8960/35339 (25%)]	Loss: 0.758478
Train Epoch: 93 [9600/35339 (27%)]	Loss: 0.605032
Train Epoch: 93 [10240/35339 (29%)]	Loss: 0.773648
Train Epoch: 93 [10880/35339 (31%)]	Loss: 0.491762
Train Epoch: 93 [11520/35339 (33%)]	Loss: 0.540851
Train Epoch: 93 [12160/35339 (34%)]	Loss: 0.707972
Train Epoch: 93 [12800/35339 (36%)]	Loss: 0.812778
Train Epoch: 93 [13440/35339 (38%)]	Loss: 0.567596
Train Epoch: 93 [14080/35339 (40%)]	Loss: 0.556472
Train Epoch: 93 [14720/35339 (42%)]	Loss: 0.497311
Train Epoch: 93 [15360/35339 (43%)]	Loss: 0.667480
Train Epoch: 93 [16000/35339 (45%)]	Loss: 0.614441
Train Epoch: 93 [16640/35339 (47%)]	Loss: 0.727182
Train Epoch: 93 [17280/35339 (49%)]	Loss: 0.586582
Train Epoch: 93 [17920/35339 (51%)]	Loss: 0.718059
Train Epoch: 93 [18560/35339 (52%)]	Loss: 0.646133
Train Epoch: 93 [19200/35339 (54%)]	Loss: 0.559560
Train Epoch: 93 [19840/35339 (56%)]	Loss: 0.567477
Train Epoch: 93 [20480/35339 (58%)]	Loss: 0.490902
Train Epoch: 93 [21120/35339 (60%)]	Loss: 0.612051
Train Epoch: 93 [21760/35339 (61%)]	Loss: 0.466942
Train Epoch: 93 [22400/35339 (63%)]	Loss: 0.693351
Train Epoch: 93 [23040/35339 (65%)]	Loss: 0.714075
Train Epoch: 93 [23680/35339 (67%)]	Loss: 0.554300
Train Epoch: 93 [24320/35339 (69%)]	Loss: 0.672303
Train Epoch: 93 [24960/35339 (71%)]	Loss: 0.729688
Train Epoch: 93 [25600/35339 (72%)]	Loss: 0.716999
Train Epoch: 93 [26240/35339 (74%)]	Loss: 0.759688
Train Epoch: 93 [26880/35339 (76%)]	Loss: 0.718215
Train Epoch: 93 [27520/35339 (78%)]	Loss: 0.605884
Train Epoch: 93 [28160/35339 (80%)]	Loss: 0.640503
Train Epoch: 93 [28800/35339 (81%)]	Loss: 0.640712
Train Epoch: 93 [29440/35339 (83%)]	Loss: 0.604689
Train Epoch: 93 [30080/35339 (85%)]	Loss: 0.764927
Train Epoch: 93 [30720/35339 (87%)]	Loss: 0.664752
Train Epoch: 93 [31360/35339 (89%)]	Loss: 0.569432
Train Epoch: 93 [32000/35339 (90%)]	Loss: 0.595737
Train Epoch: 93 [32640/35339 (92%)]	Loss: 0.671957
Train Epoch: 93 [33280/35339 (94%)]	Loss: 0.581740
Train Epoch: 93 [33920/35339 (96%)]	Loss: 0.490180
Train Epoch: 93 [34560/35339 (98%)]	Loss: 0.573544
Train Epoch: 93 [35200/35339 (99%)]	Loss: 0.460666

Validation set: Average loss: 3.7740, Accuracy: 703/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 94 [0/35339 (0%)]	Loss: 0.656884
Train Epoch: 94 [640/35339 (2%)]	Loss: 0.679676
Train Epoch: 94 [1280/35339 (4%)]	Loss: 0.475993
Train Epoch: 94 [1920/35339 (5%)]	Loss: 0.564888
Train Epoch: 94 [2560/35339 (7%)]	Loss: 0.478878
Train Epoch: 94 [3200/35339 (9%)]	Loss: 0.757465
Train Epoch: 94 [3840/35339 (11%)]	Loss: 0.767980
Train Epoch: 94 [4480/35339 (13%)]	Loss: 0.688736
Train Epoch: 94 [5120/35339 (14%)]	Loss: 0.791709
Train Epoch: 94 [5760/35339 (16%)]	Loss: 0.542066
Train Epoch: 94 [6400/35339 (18%)]	Loss: 0.533584
Train Epoch: 94 [7040/35339 (20%)]	Loss: 0.633188
Train Epoch: 94 [7680/35339 (22%)]	Loss: 0.757626
Train Epoch: 94 [8320/35339 (24%)]	Loss: 0.763058
Train Epoch: 94 [8960/35339 (25%)]	Loss: 0.717204
Train Epoch: 94 [9600/35339 (27%)]	Loss: 0.623214
Train Epoch: 94 [10240/35339 (29%)]	Loss: 0.746901
Train Epoch: 94 [10880/35339 (31%)]	Loss: 0.755310
Train Epoch: 94 [11520/35339 (33%)]	Loss: 0.794615
Train Epoch: 94 [12160/35339 (34%)]	Loss: 0.863115
Train Epoch: 94 [12800/35339 (36%)]	Loss: 0.540270
Train Epoch: 94 [13440/35339 (38%)]	Loss: 0.638453
Train Epoch: 94 [14080/35339 (40%)]	Loss: 0.702889
Train Epoch: 94 [14720/35339 (42%)]	Loss: 0.661634
Train Epoch: 94 [15360/35339 (43%)]	Loss: 0.506993
Train Epoch: 94 [16000/35339 (45%)]	Loss: 0.778364
Train Epoch: 94 [16640/35339 (47%)]	Loss: 0.450245
Train Epoch: 94 [17280/35339 (49%)]	Loss: 0.452466
Train Epoch: 94 [17920/35339 (51%)]	Loss: 0.558342
Train Epoch: 94 [18560/35339 (52%)]	Loss: 0.559446
Train Epoch: 94 [19200/35339 (54%)]	Loss: 0.513162
Train Epoch: 94 [19840/35339 (56%)]	Loss: 0.574543
Train Epoch: 94 [20480/35339 (58%)]	Loss: 0.675928
Train Epoch: 94 [21120/35339 (60%)]	Loss: 0.622759
Train Epoch: 94 [21760/35339 (61%)]	Loss: 0.513218
Train Epoch: 94 [22400/35339 (63%)]	Loss: 0.576894
Train Epoch: 94 [23040/35339 (65%)]	Loss: 0.607314
Train Epoch: 94 [23680/35339 (67%)]	Loss: 0.463997
Train Epoch: 94 [24320/35339 (69%)]	Loss: 0.479316
Train Epoch: 94 [24960/35339 (71%)]	Loss: 0.588990
Train Epoch: 94 [25600/35339 (72%)]	Loss: 0.548297
Train Epoch: 94 [26240/35339 (74%)]	Loss: 0.661970
Train Epoch: 94 [26880/35339 (76%)]	Loss: 0.616378
Train Epoch: 94 [27520/35339 (78%)]	Loss: 0.769867
Train Epoch: 94 [28160/35339 (80%)]	Loss: 0.791988
Train Epoch: 94 [28800/35339 (81%)]	Loss: 0.765341
Train Epoch: 94 [29440/35339 (83%)]	Loss: 0.634901
Train Epoch: 94 [30080/35339 (85%)]	Loss: 0.751615
Train Epoch: 94 [30720/35339 (87%)]	Loss: 0.729920
Train Epoch: 94 [31360/35339 (89%)]	Loss: 0.536574
Train Epoch: 94 [32000/35339 (90%)]	Loss: 0.773830
Train Epoch: 94 [32640/35339 (92%)]	Loss: 0.666865
Train Epoch: 94 [33280/35339 (94%)]	Loss: 0.683952
Train Epoch: 94 [33920/35339 (96%)]	Loss: 0.847792
Train Epoch: 94 [34560/35339 (98%)]	Loss: 0.563257
Train Epoch: 94 [35200/35339 (99%)]	Loss: 0.836090

Validation set: Average loss: 3.7758, Accuracy: 686/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 95 [0/35339 (0%)]	Loss: 0.562224
Train Epoch: 95 [640/35339 (2%)]	Loss: 0.523083
Train Epoch: 95 [1280/35339 (4%)]	Loss: 0.433302
Train Epoch: 95 [1920/35339 (5%)]	Loss: 0.746262
Train Epoch: 95 [2560/35339 (7%)]	Loss: 0.534483
Train Epoch: 95 [3200/35339 (9%)]	Loss: 0.753407
Train Epoch: 95 [3840/35339 (11%)]	Loss: 0.987891
Train Epoch: 95 [4480/35339 (13%)]	Loss: 0.599724
Train Epoch: 95 [5120/35339 (14%)]	Loss: 0.618641
Train Epoch: 95 [5760/35339 (16%)]	Loss: 0.789335
Train Epoch: 95 [6400/35339 (18%)]	Loss: 0.724277
Train Epoch: 95 [7040/35339 (20%)]	Loss: 0.586216
Train Epoch: 95 [7680/35339 (22%)]	Loss: 0.769033
Train Epoch: 95 [8320/35339 (24%)]	Loss: 0.578485
Train Epoch: 95 [8960/35339 (25%)]	Loss: 0.593227
Train Epoch: 95 [9600/35339 (27%)]	Loss: 0.516591
Train Epoch: 95 [10240/35339 (29%)]	Loss: 0.656004
Train Epoch: 95 [10880/35339 (31%)]	Loss: 0.790975
Train Epoch: 95 [11520/35339 (33%)]	Loss: 0.758997
Train Epoch: 95 [12160/35339 (34%)]	Loss: 0.603759
Train Epoch: 95 [12800/35339 (36%)]	Loss: 0.584353
Train Epoch: 95 [13440/35339 (38%)]	Loss: 0.727820
Train Epoch: 95 [14080/35339 (40%)]	Loss: 0.450320
Train Epoch: 95 [14720/35339 (42%)]	Loss: 0.792856
Train Epoch: 95 [15360/35339 (43%)]	Loss: 0.649969
Train Epoch: 95 [16000/35339 (45%)]	Loss: 0.565858
Train Epoch: 95 [16640/35339 (47%)]	Loss: 0.652613
Train Epoch: 95 [17280/35339 (49%)]	Loss: 0.766846
Train Epoch: 95 [17920/35339 (51%)]	Loss: 0.632657
Train Epoch: 95 [18560/35339 (52%)]	Loss: 0.499472
Train Epoch: 95 [19200/35339 (54%)]	Loss: 0.783948
Train Epoch: 95 [19840/35339 (56%)]	Loss: 0.672289
Train Epoch: 95 [20480/35339 (58%)]	Loss: 0.538830
Train Epoch: 95 [21120/35339 (60%)]	Loss: 0.650433
Train Epoch: 95 [21760/35339 (61%)]	Loss: 0.601061
Train Epoch: 95 [22400/35339 (63%)]	Loss: 0.649746
Train Epoch: 95 [23040/35339 (65%)]	Loss: 0.678546
Train Epoch: 95 [23680/35339 (67%)]	Loss: 0.503724
Train Epoch: 95 [24320/35339 (69%)]	Loss: 0.563719
Train Epoch: 95 [24960/35339 (71%)]	Loss: 0.713755
Train Epoch: 95 [25600/35339 (72%)]	Loss: 0.700884
Train Epoch: 95 [26240/35339 (74%)]	Loss: 0.559717
Train Epoch: 95 [26880/35339 (76%)]	Loss: 0.643643
Train Epoch: 95 [27520/35339 (78%)]	Loss: 0.687574
Train Epoch: 95 [28160/35339 (80%)]	Loss: 0.513678
Train Epoch: 95 [28800/35339 (81%)]	Loss: 0.549974
Train Epoch: 95 [29440/35339 (83%)]	Loss: 0.650418
Train Epoch: 95 [30080/35339 (85%)]	Loss: 0.506366
Train Epoch: 95 [30720/35339 (87%)]	Loss: 0.647931
Train Epoch: 95 [31360/35339 (89%)]	Loss: 0.553820
Train Epoch: 95 [32000/35339 (90%)]	Loss: 0.706227
Train Epoch: 95 [32640/35339 (92%)]	Loss: 0.614456
Train Epoch: 95 [33280/35339 (94%)]	Loss: 0.758631
Train Epoch: 95 [33920/35339 (96%)]	Loss: 0.704898
Train Epoch: 95 [34560/35339 (98%)]	Loss: 0.491123
Train Epoch: 95 [35200/35339 (99%)]	Loss: 0.573056

Validation set: Average loss: 3.7904, Accuracy: 697/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 96 [0/35339 (0%)]	Loss: 0.618513
Train Epoch: 96 [640/35339 (2%)]	Loss: 0.743149
Train Epoch: 96 [1280/35339 (4%)]	Loss: 0.759386
Train Epoch: 96 [1920/35339 (5%)]	Loss: 0.741013
Train Epoch: 96 [2560/35339 (7%)]	Loss: 0.434975
Train Epoch: 96 [3200/35339 (9%)]	Loss: 0.579604
Train Epoch: 96 [3840/35339 (11%)]	Loss: 0.570352
Train Epoch: 96 [4480/35339 (13%)]	Loss: 0.723222
Train Epoch: 96 [5120/35339 (14%)]	Loss: 0.722733
Train Epoch: 96 [5760/35339 (16%)]	Loss: 0.696261
Train Epoch: 96 [6400/35339 (18%)]	Loss: 0.613988
Train Epoch: 96 [7040/35339 (20%)]	Loss: 0.762411
Train Epoch: 96 [7680/35339 (22%)]	Loss: 0.523571
Train Epoch: 96 [8320/35339 (24%)]	Loss: 0.673417
Train Epoch: 96 [8960/35339 (25%)]	Loss: 0.614505
Train Epoch: 96 [9600/35339 (27%)]	Loss: 0.718708
Train Epoch: 96 [10240/35339 (29%)]	Loss: 0.517852
Train Epoch: 96 [10880/35339 (31%)]	Loss: 0.515849
Train Epoch: 96 [11520/35339 (33%)]	Loss: 0.537974
Train Epoch: 96 [12160/35339 (34%)]	Loss: 0.570748
Train Epoch: 96 [12800/35339 (36%)]	Loss: 0.690793
Train Epoch: 96 [13440/35339 (38%)]	Loss: 0.615803
Train Epoch: 96 [14080/35339 (40%)]	Loss: 0.713984
Train Epoch: 96 [14720/35339 (42%)]	Loss: 0.903328
Train Epoch: 96 [15360/35339 (43%)]	Loss: 0.747717
Train Epoch: 96 [16000/35339 (45%)]	Loss: 0.520242
Train Epoch: 96 [16640/35339 (47%)]	Loss: 0.576092
Train Epoch: 96 [17280/35339 (49%)]	Loss: 0.833481
Train Epoch: 96 [17920/35339 (51%)]	Loss: 0.521656
Train Epoch: 96 [18560/35339 (52%)]	Loss: 0.515376
Train Epoch: 96 [19200/35339 (54%)]	Loss: 0.564758
Train Epoch: 96 [19840/35339 (56%)]	Loss: 0.527836
Train Epoch: 96 [20480/35339 (58%)]	Loss: 0.540471
Train Epoch: 96 [21120/35339 (60%)]	Loss: 0.588203
Train Epoch: 96 [21760/35339 (61%)]	Loss: 0.698042
Train Epoch: 96 [22400/35339 (63%)]	Loss: 0.793423
Train Epoch: 96 [23040/35339 (65%)]	Loss: 0.716257
Train Epoch: 96 [23680/35339 (67%)]	Loss: 0.677535
Train Epoch: 96 [24320/35339 (69%)]	Loss: 0.754698
Train Epoch: 96 [24960/35339 (71%)]	Loss: 0.543450
Train Epoch: 96 [25600/35339 (72%)]	Loss: 0.683852
Train Epoch: 96 [26240/35339 (74%)]	Loss: 0.618917
Train Epoch: 96 [26880/35339 (76%)]	Loss: 0.696185
Train Epoch: 96 [27520/35339 (78%)]	Loss: 0.604975
Train Epoch: 96 [28160/35339 (80%)]	Loss: 0.791692
Train Epoch: 96 [28800/35339 (81%)]	Loss: 0.715439
Train Epoch: 96 [29440/35339 (83%)]	Loss: 0.510429
Train Epoch: 96 [30080/35339 (85%)]	Loss: 0.743197
Train Epoch: 96 [30720/35339 (87%)]	Loss: 0.484145
Train Epoch: 96 [31360/35339 (89%)]	Loss: 0.569823
Train Epoch: 96 [32000/35339 (90%)]	Loss: 0.448972
Train Epoch: 96 [32640/35339 (92%)]	Loss: 0.591176
Train Epoch: 96 [33280/35339 (94%)]	Loss: 0.680644
Train Epoch: 96 [33920/35339 (96%)]	Loss: 0.442102
Train Epoch: 96 [34560/35339 (98%)]	Loss: 0.625923
Train Epoch: 96 [35200/35339 (99%)]	Loss: 0.533699

Validation set: Average loss: 3.7879, Accuracy: 687/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 97 [0/35339 (0%)]	Loss: 0.707157
Train Epoch: 97 [640/35339 (2%)]	Loss: 0.573443
Train Epoch: 97 [1280/35339 (4%)]	Loss: 0.545604
Train Epoch: 97 [1920/35339 (5%)]	Loss: 0.698097
Train Epoch: 97 [2560/35339 (7%)]	Loss: 0.669162
Train Epoch: 97 [3200/35339 (9%)]	Loss: 0.548939
Train Epoch: 97 [3840/35339 (11%)]	Loss: 0.687185
Train Epoch: 97 [4480/35339 (13%)]	Loss: 0.704019
Train Epoch: 97 [5120/35339 (14%)]	Loss: 0.571124
Train Epoch: 97 [5760/35339 (16%)]	Loss: 0.686017
Train Epoch: 97 [6400/35339 (18%)]	Loss: 0.617139
Train Epoch: 97 [7040/35339 (20%)]	Loss: 0.522101
Train Epoch: 97 [7680/35339 (22%)]	Loss: 0.537650
Train Epoch: 97 [8320/35339 (24%)]	Loss: 0.537890
Train Epoch: 97 [8960/35339 (25%)]	Loss: 0.875621
Train Epoch: 97 [9600/35339 (27%)]	Loss: 0.712581
Train Epoch: 97 [10240/35339 (29%)]	Loss: 0.582171
Train Epoch: 97 [10880/35339 (31%)]	Loss: 0.825736
Train Epoch: 97 [11520/35339 (33%)]	Loss: 0.811383
Train Epoch: 97 [12160/35339 (34%)]	Loss: 0.637780
Train Epoch: 97 [12800/35339 (36%)]	Loss: 0.596919
Train Epoch: 97 [13440/35339 (38%)]	Loss: 0.656880
Train Epoch: 97 [14080/35339 (40%)]	Loss: 0.570075
Train Epoch: 97 [14720/35339 (42%)]	Loss: 0.767030
Train Epoch: 97 [15360/35339 (43%)]	Loss: 0.680007
Train Epoch: 97 [16000/35339 (45%)]	Loss: 0.679734
Train Epoch: 97 [16640/35339 (47%)]	Loss: 0.601673
Train Epoch: 97 [17280/35339 (49%)]	Loss: 0.612188
Train Epoch: 97 [17920/35339 (51%)]	Loss: 0.683146
Train Epoch: 97 [18560/35339 (52%)]	Loss: 0.415922
Train Epoch: 97 [19200/35339 (54%)]	Loss: 0.670883
Train Epoch: 97 [19840/35339 (56%)]	Loss: 0.514354
Train Epoch: 97 [20480/35339 (58%)]	Loss: 0.442321
Train Epoch: 97 [21120/35339 (60%)]	Loss: 0.729366
Train Epoch: 97 [21760/35339 (61%)]	Loss: 0.666942
Train Epoch: 97 [22400/35339 (63%)]	Loss: 0.646651
Train Epoch: 97 [23040/35339 (65%)]	Loss: 0.613772
Train Epoch: 97 [23680/35339 (67%)]	Loss: 0.616598
Train Epoch: 97 [24320/35339 (69%)]	Loss: 0.487990
Train Epoch: 97 [24960/35339 (71%)]	Loss: 0.717235
Train Epoch: 97 [25600/35339 (72%)]	Loss: 0.718255
Train Epoch: 97 [26240/35339 (74%)]	Loss: 0.644732
Train Epoch: 97 [26880/35339 (76%)]	Loss: 0.663975
Train Epoch: 97 [27520/35339 (78%)]	Loss: 0.551472
Train Epoch: 97 [28160/35339 (80%)]	Loss: 0.633833
Train Epoch: 97 [28800/35339 (81%)]	Loss: 0.618324
Train Epoch: 97 [29440/35339 (83%)]	Loss: 0.522324
Train Epoch: 97 [30080/35339 (85%)]	Loss: 0.624273
Train Epoch: 97 [30720/35339 (87%)]	Loss: 0.653568
Train Epoch: 97 [31360/35339 (89%)]	Loss: 0.702427
Train Epoch: 97 [32000/35339 (90%)]	Loss: 0.599173
Train Epoch: 97 [32640/35339 (92%)]	Loss: 0.642495
Train Epoch: 97 [33280/35339 (94%)]	Loss: 0.624138
Train Epoch: 97 [33920/35339 (96%)]	Loss: 0.779210
Train Epoch: 97 [34560/35339 (98%)]	Loss: 0.523060
Train Epoch: 97 [35200/35339 (99%)]	Loss: 0.650014

Validation set: Average loss: 3.7780, Accuracy: 672/3870 (17%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 98 [0/35339 (0%)]	Loss: 0.490918
Train Epoch: 98 [640/35339 (2%)]	Loss: 0.532379
Train Epoch: 98 [1280/35339 (4%)]	Loss: 0.782903
Train Epoch: 98 [1920/35339 (5%)]	Loss: 0.634749
Train Epoch: 98 [2560/35339 (7%)]	Loss: 0.630473
Train Epoch: 98 [3200/35339 (9%)]	Loss: 0.666461
Train Epoch: 98 [3840/35339 (11%)]	Loss: 0.666385
Train Epoch: 98 [4480/35339 (13%)]	Loss: 0.824611
Train Epoch: 98 [5120/35339 (14%)]	Loss: 0.533590
Train Epoch: 98 [5760/35339 (16%)]	Loss: 0.699143
Train Epoch: 98 [6400/35339 (18%)]	Loss: 0.647690
Train Epoch: 98 [7040/35339 (20%)]	Loss: 0.611341
Train Epoch: 98 [7680/35339 (22%)]	Loss: 0.448879
Train Epoch: 98 [8320/35339 (24%)]	Loss: 0.617906
Train Epoch: 98 [8960/35339 (25%)]	Loss: 0.674010
Train Epoch: 98 [9600/35339 (27%)]	Loss: 0.608828
Train Epoch: 98 [10240/35339 (29%)]	Loss: 0.601845
Train Epoch: 98 [10880/35339 (31%)]	Loss: 0.702728
Train Epoch: 98 [11520/35339 (33%)]	Loss: 0.567628
Train Epoch: 98 [12160/35339 (34%)]	Loss: 0.603762
Train Epoch: 98 [12800/35339 (36%)]	Loss: 0.727944
Train Epoch: 98 [13440/35339 (38%)]	Loss: 0.620529
Train Epoch: 98 [14080/35339 (40%)]	Loss: 0.718089
Train Epoch: 98 [14720/35339 (42%)]	Loss: 0.577130
Train Epoch: 98 [15360/35339 (43%)]	Loss: 0.723199
Train Epoch: 98 [16000/35339 (45%)]	Loss: 0.774699
Train Epoch: 98 [16640/35339 (47%)]	Loss: 0.556387
Train Epoch: 98 [17280/35339 (49%)]	Loss: 0.731603
Train Epoch: 98 [17920/35339 (51%)]	Loss: 0.763446
Train Epoch: 98 [18560/35339 (52%)]	Loss: 0.616917
Train Epoch: 98 [19200/35339 (54%)]	Loss: 0.507613
Train Epoch: 98 [19840/35339 (56%)]	Loss: 0.561126
Train Epoch: 98 [20480/35339 (58%)]	Loss: 0.532218
Train Epoch: 98 [21120/35339 (60%)]	Loss: 0.645745
Train Epoch: 98 [21760/35339 (61%)]	Loss: 0.428598
Train Epoch: 98 [22400/35339 (63%)]	Loss: 0.583072
Train Epoch: 98 [23040/35339 (65%)]	Loss: 0.680762
Train Epoch: 98 [23680/35339 (67%)]	Loss: 0.555071
Train Epoch: 98 [24320/35339 (69%)]	Loss: 0.637484
Train Epoch: 98 [24960/35339 (71%)]	Loss: 0.526974
Train Epoch: 98 [25600/35339 (72%)]	Loss: 0.602718
Train Epoch: 98 [26240/35339 (74%)]	Loss: 0.651627
Train Epoch: 98 [26880/35339 (76%)]	Loss: 0.715999
Train Epoch: 98 [27520/35339 (78%)]	Loss: 0.453464
Train Epoch: 98 [28160/35339 (80%)]	Loss: 0.690971
Train Epoch: 98 [28800/35339 (81%)]	Loss: 0.561574
Train Epoch: 98 [29440/35339 (83%)]	Loss: 0.471557
Train Epoch: 98 [30080/35339 (85%)]	Loss: 0.592583
Train Epoch: 98 [30720/35339 (87%)]	Loss: 0.685804
Train Epoch: 98 [31360/35339 (89%)]	Loss: 0.723659
Train Epoch: 98 [32000/35339 (90%)]	Loss: 0.469560
Train Epoch: 98 [32640/35339 (92%)]	Loss: 0.595777
Train Epoch: 98 [33280/35339 (94%)]	Loss: 0.469365
Train Epoch: 98 [33920/35339 (96%)]	Loss: 0.483808
Train Epoch: 98 [34560/35339 (98%)]	Loss: 0.865238
Train Epoch: 98 [35200/35339 (99%)]	Loss: 0.563963

Validation set: Average loss: 3.7771, Accuracy: 687/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 99 [0/35339 (0%)]	Loss: 0.731291
Train Epoch: 99 [640/35339 (2%)]	Loss: 0.682394
Train Epoch: 99 [1280/35339 (4%)]	Loss: 0.533126
Train Epoch: 99 [1920/35339 (5%)]	Loss: 0.729919
Train Epoch: 99 [2560/35339 (7%)]	Loss: 0.599855
Train Epoch: 99 [3200/35339 (9%)]	Loss: 0.669681
Train Epoch: 99 [3840/35339 (11%)]	Loss: 0.670898
Train Epoch: 99 [4480/35339 (13%)]	Loss: 0.562028
Train Epoch: 99 [5120/35339 (14%)]	Loss: 0.759554
Train Epoch: 99 [5760/35339 (16%)]	Loss: 0.679564
Train Epoch: 99 [6400/35339 (18%)]	Loss: 0.544135
Train Epoch: 99 [7040/35339 (20%)]	Loss: 0.563033
Train Epoch: 99 [7680/35339 (22%)]	Loss: 0.632965
Train Epoch: 99 [8320/35339 (24%)]	Loss: 0.694281
Train Epoch: 99 [8960/35339 (25%)]	Loss: 0.538404
Train Epoch: 99 [9600/35339 (27%)]	Loss: 0.610846
Train Epoch: 99 [10240/35339 (29%)]	Loss: 0.618863
Train Epoch: 99 [10880/35339 (31%)]	Loss: 0.703440
Train Epoch: 99 [11520/35339 (33%)]	Loss: 0.668289
Train Epoch: 99 [12160/35339 (34%)]	Loss: 0.508910
Train Epoch: 99 [12800/35339 (36%)]	Loss: 0.757146
Train Epoch: 99 [13440/35339 (38%)]	Loss: 0.546414
Train Epoch: 99 [14080/35339 (40%)]	Loss: 0.604031
Train Epoch: 99 [14720/35339 (42%)]	Loss: 0.586724
Train Epoch: 99 [15360/35339 (43%)]	Loss: 0.478268
Train Epoch: 99 [16000/35339 (45%)]	Loss: 0.641190
Train Epoch: 99 [16640/35339 (47%)]	Loss: 0.631693
Train Epoch: 99 [17280/35339 (49%)]	Loss: 0.825095
Train Epoch: 99 [17920/35339 (51%)]	Loss: 0.682765
Train Epoch: 99 [18560/35339 (52%)]	Loss: 0.781795
Train Epoch: 99 [19200/35339 (54%)]	Loss: 0.692303
Train Epoch: 99 [19840/35339 (56%)]	Loss: 0.664855
Train Epoch: 99 [20480/35339 (58%)]	Loss: 0.774635
Train Epoch: 99 [21120/35339 (60%)]	Loss: 0.524005
Train Epoch: 99 [21760/35339 (61%)]	Loss: 0.703248
Train Epoch: 99 [22400/35339 (63%)]	Loss: 0.726028
Train Epoch: 99 [23040/35339 (65%)]	Loss: 0.663371
Train Epoch: 99 [23680/35339 (67%)]	Loss: 0.733598
Train Epoch: 99 [24320/35339 (69%)]	Loss: 0.666941
Train Epoch: 99 [24960/35339 (71%)]	Loss: 0.701797
Train Epoch: 99 [25600/35339 (72%)]	Loss: 0.501116
Train Epoch: 99 [26240/35339 (74%)]	Loss: 0.607930
Train Epoch: 99 [26880/35339 (76%)]	Loss: 0.903952
Train Epoch: 99 [27520/35339 (78%)]	Loss: 0.804520
Train Epoch: 99 [28160/35339 (80%)]	Loss: 0.633390
Train Epoch: 99 [28800/35339 (81%)]	Loss: 0.659374
Train Epoch: 99 [29440/35339 (83%)]	Loss: 0.685085
Train Epoch: 99 [30080/35339 (85%)]	Loss: 0.755942
Train Epoch: 99 [30720/35339 (87%)]	Loss: 0.480069
Train Epoch: 99 [31360/35339 (89%)]	Loss: 0.654044
Train Epoch: 99 [32000/35339 (90%)]	Loss: 0.580568
Train Epoch: 99 [32640/35339 (92%)]	Loss: 0.451683
Train Epoch: 99 [33280/35339 (94%)]	Loss: 0.679938
Train Epoch: 99 [33920/35339 (96%)]	Loss: 0.734487
Train Epoch: 99 [34560/35339 (98%)]	Loss: 0.708005
Train Epoch: 99 [35200/35339 (99%)]	Loss: 0.550647

Validation set: Average loss: 3.7660, Accuracy: 675/3870 (17%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
Train Epoch: 100 [0/35339 (0%)]	Loss: 0.595175
Train Epoch: 100 [640/35339 (2%)]	Loss: 0.520856
Train Epoch: 100 [1280/35339 (4%)]	Loss: 0.625934
Train Epoch: 100 [1920/35339 (5%)]	Loss: 0.484952
Train Epoch: 100 [2560/35339 (7%)]	Loss: 0.571252
Train Epoch: 100 [3200/35339 (9%)]	Loss: 0.749304
Train Epoch: 100 [3840/35339 (11%)]	Loss: 0.412306
Train Epoch: 100 [4480/35339 (13%)]	Loss: 0.658542
Train Epoch: 100 [5120/35339 (14%)]	Loss: 0.627496
Train Epoch: 100 [5760/35339 (16%)]	Loss: 0.716918
Train Epoch: 100 [6400/35339 (18%)]	Loss: 0.631767
Train Epoch: 100 [7040/35339 (20%)]	Loss: 0.482853
Train Epoch: 100 [7680/35339 (22%)]	Loss: 0.497367
Train Epoch: 100 [8320/35339 (24%)]	Loss: 0.815342
Train Epoch: 100 [8960/35339 (25%)]	Loss: 0.667390
Train Epoch: 100 [9600/35339 (27%)]	Loss: 0.641194
Train Epoch: 100 [10240/35339 (29%)]	Loss: 0.719129
Train Epoch: 100 [10880/35339 (31%)]	Loss: 0.755408
Train Epoch: 100 [11520/35339 (33%)]	Loss: 0.527905
Train Epoch: 100 [12160/35339 (34%)]	Loss: 0.810805
Train Epoch: 100 [12800/35339 (36%)]	Loss: 0.598890
Train Epoch: 100 [13440/35339 (38%)]	Loss: 0.748022
Train Epoch: 100 [14080/35339 (40%)]	Loss: 0.564106
Train Epoch: 100 [14720/35339 (42%)]	Loss: 0.630448
Train Epoch: 100 [15360/35339 (43%)]	Loss: 0.617523
Train Epoch: 100 [16000/35339 (45%)]	Loss: 0.547294
Train Epoch: 100 [16640/35339 (47%)]	Loss: 0.383753
Train Epoch: 100 [17280/35339 (49%)]	Loss: 0.702992
Train Epoch: 100 [17920/35339 (51%)]	Loss: 0.608569
Train Epoch: 100 [18560/35339 (52%)]	Loss: 0.716366
Train Epoch: 100 [19200/35339 (54%)]	Loss: 0.412225
Train Epoch: 100 [19840/35339 (56%)]	Loss: 0.584205
Train Epoch: 100 [20480/35339 (58%)]	Loss: 0.746124
Train Epoch: 100 [21120/35339 (60%)]	Loss: 0.589390
Train Epoch: 100 [21760/35339 (61%)]	Loss: 0.597169
Train Epoch: 100 [22400/35339 (63%)]	Loss: 0.551587
Train Epoch: 100 [23040/35339 (65%)]	Loss: 0.750032
Train Epoch: 100 [23680/35339 (67%)]	Loss: 0.669285
Train Epoch: 100 [24320/35339 (69%)]	Loss: 0.515564
Train Epoch: 100 [24960/35339 (71%)]	Loss: 0.477496
Train Epoch: 100 [25600/35339 (72%)]	Loss: 0.705702
Train Epoch: 100 [26240/35339 (74%)]	Loss: 0.625372
Train Epoch: 100 [26880/35339 (76%)]	Loss: 0.883968
Train Epoch: 100 [27520/35339 (78%)]	Loss: 0.622116
Train Epoch: 100 [28160/35339 (80%)]	Loss: 0.637553
Train Epoch: 100 [28800/35339 (81%)]	Loss: 0.663007
Train Epoch: 100 [29440/35339 (83%)]	Loss: 0.528910
Train Epoch: 100 [30080/35339 (85%)]	Loss: 0.686895
Train Epoch: 100 [30720/35339 (87%)]	Loss: 0.586456
Train Epoch: 100 [31360/35339 (89%)]	Loss: 0.651082
Train Epoch: 100 [32000/35339 (90%)]	Loss: 0.739234
Train Epoch: 100 [32640/35339 (92%)]	Loss: 0.678528
Train Epoch: 100 [33280/35339 (94%)]	Loss: 0.539598
Train Epoch: 100 [33920/35339 (96%)]	Loss: 0.630848
Train Epoch: 100 [34560/35339 (98%)]	Loss: 0.626639
Train Epoch: 100 [35200/35339 (99%)]	Loss: 0.991858

Validation set: Average loss: 3.7774, Accuracy: 680/3870 (18%)


Saved model to model_latest_Adagrad_dataAugmentation_lr.pth. You can run `python evaluate.py model_latest_Adagrad_dataAugmentation_lr.pth` to generate the Kaggle formatted csv file
/share/apps/pytorch/0.3.0_4/python2.7/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  "please use transforms.Resize instead.")
  0%|          | 0/12631 [00:00<?, ?it/s]  0%|          | 24/12631 [00:00<00:53, 237.49it/s]  0%|          | 51/12631 [00:00<00:51, 244.08it/s]  1%|          | 77/12631 [00:00<00:50, 247.67it/s]  1%|          | 104/12631 [00:00<00:49, 252.80it/s]  1%|1         | 131/12631 [00:00<00:48, 255.94it/s]  1%|1         | 158/12631 [00:00<00:48, 259.60it/s]  1%|1         | 185/12631 [00:00<00:47, 262.18it/s]  2%|1         | 212/12631 [00:00<00:47, 262.63it/s]  2%|1         | 239/12631 [00:00<00:47, 261.99it/s]  2%|2         | 265/12631 [00:01<00:47, 260.15it/s]  2%|2         | 291/12631 [00:01<00:47, 259.79it/s]  3%|2         | 318/12631 [00:01<00:47, 261.16it/s]  3%|2         | 345/12631 [00:01<00:46, 262.11it/s]  3%|2         | 372/12631 [00:01<00:46, 262.97it/s]  3%|3         | 399/12631 [00:01<00:46, 260.85it/s]  3%|3         | 425/12631 [00:01<00:47, 259.02it/s]  4%|3         | 451/12631 [00:01<00:47, 258.56it/s]  4%|3         | 478/12631 [00:01<00:46, 261.07it/s]  4%|3         | 505/12631 [00:01<00:46, 260.90it/s]  4%|4         | 532/12631 [00:02<00:46, 259.77it/s]  4%|4         | 560/12631 [00:02<00:45, 263.40it/s]  5%|4         | 587/12631 [00:02<00:45, 262.23it/s]  5%|4         | 614/12631 [00:02<00:45, 261.44it/s]  5%|5         | 641/12631 [00:02<00:45, 262.60it/s]  5%|5         | 668/12631 [00:02<00:45, 262.30it/s]  6%|5         | 695/12631 [00:02<00:45, 262.08it/s]  6%|5         | 722/12631 [00:02<00:45, 263.04it/s]  6%|5         | 749/12631 [00:02<00:45, 262.65it/s]  6%|6         | 776/12631 [00:02<00:45, 262.65it/s]  6%|6         | 803/12631 [00:03<00:45, 261.95it/s]  7%|6         | 830/12631 [00:03<00:45, 261.16it/s]  7%|6         | 857/12631 [00:03<00:44, 262.57it/s]  7%|6         | 884/12631 [00:03<00:44, 263.17it/s]  7%|7         | 911/12631 [00:03<00:44, 262.91it/s]  7%|7         | 938/12631 [00:03<00:44, 260.58it/s]  8%|7         | 965/12631 [00:03<00:44, 260.08it/s]  8%|7         | 992/12631 [00:03<00:44, 261.68it/s]  8%|8         | 1019/12631 [00:03<00:44, 263.04it/s]  8%|8         | 1046/12631 [00:04<00:44, 263.18it/s]  9%|8         | 1074/12631 [00:04<00:43, 266.13it/s]  9%|8         | 1101/12631 [00:04<00:43, 264.81it/s]  9%|8         | 1128/12631 [00:04<00:43, 263.52it/s]  9%|9         | 1155/12631 [00:04<00:43, 262.73it/s]  9%|9         | 1182/12631 [00:04<00:43, 264.10it/s] 10%|9         | 1209/12631 [00:04<00:43, 264.82it/s] 10%|9         | 1236/12631 [00:04<00:43, 259.69it/s] 10%|9         | 1263/12631 [00:04<00:43, 259.81it/s] 10%|#         | 1289/12631 [00:04<00:43, 259.01it/s] 10%|#         | 1315/12631 [00:05<00:44, 256.66it/s] 11%|#         | 1341/12631 [00:05<00:43, 257.16it/s] 11%|#         | 1369/12631 [00:05<00:42, 263.49it/s] 11%|#1        | 1397/12631 [00:05<00:41, 268.22it/s] 11%|#1        | 1424/12631 [00:05<00:41, 268.60it/s] 11%|#1        | 1451/12631 [00:05<00:42, 264.76it/s] 12%|#1        | 1478/12631 [00:05<00:42, 263.08it/s] 12%|#1        | 1505/12631 [00:05<00:42, 261.54it/s] 12%|#2        | 1532/12631 [00:05<00:42, 263.32it/s] 12%|#2        | 1559/12631 [00:05<00:42, 261.88it/s] 13%|#2        | 1586/12631 [00:06<00:42, 259.02it/s] 13%|#2        | 1612/12631 [00:06<00:42, 259.02it/s] 13%|#2        | 1638/12631 [00:06<00:42, 258.86it/s] 13%|#3        | 1665/12631 [00:06<00:42, 260.31it/s] 13%|#3        | 1692/12631 [00:06<00:41, 260.77it/s] 14%|#3        | 1719/12631 [00:06<00:42, 259.66it/s] 14%|#3        | 1745/12631 [00:06<00:42, 259.01it/s] 14%|#4        | 1772/12631 [00:06<00:41, 259.89it/s] 14%|#4        | 1798/12631 [00:06<00:41, 259.23it/s] 14%|#4        | 1825/12631 [00:06<00:41, 260.90it/s] 15%|#4        | 1852/12631 [00:07<00:41, 260.16it/s] 15%|#4        | 1879/12631 [00:07<00:41, 260.51it/s] 15%|#5        | 1906/12631 [00:07<00:41, 258.38it/s] 15%|#5        | 1932/12631 [00:07<00:41, 258.60it/s] 16%|#5        | 1959/12631 [00:07<00:40, 261.43it/s] 16%|#5        | 1986/12631 [00:07<00:40, 261.79it/s] 16%|#5        | 2013/12631 [00:07<00:40, 263.58it/s] 16%|#6        | 2040/12631 [00:07<00:40, 263.45it/s] 16%|#6        | 2067/12631 [00:07<00:40, 263.73it/s] 17%|#6        | 2094/12631 [00:08<00:39, 263.62it/s] 17%|#6        | 2121/12631 [00:08<00:40, 262.55it/s] 17%|#7        | 2148/12631 [00:08<00:40, 260.99it/s] 17%|#7        | 2175/12631 [00:08<00:39, 263.13it/s] 17%|#7        | 2202/12631 [00:08<00:39, 263.50it/s] 18%|#7        | 2229/12631 [00:08<00:39, 263.25it/s] 18%|#7        | 2256/12631 [00:08<00:39, 261.21it/s] 18%|#8        | 2283/12631 [00:08<00:39, 260.76it/s] 18%|#8        | 2310/12631 [00:08<00:39, 260.15it/s] 19%|#8        | 2337/12631 [00:08<00:40, 256.91it/s] 19%|#8        | 2363/12631 [00:09<00:40, 256.40it/s] 19%|#8        | 2390/12631 [00:09<00:39, 259.54it/s] 19%|#9        | 2416/12631 [00:09<00:39, 257.90it/s] 19%|#9        | 2442/12631 [00:09<00:39, 257.67it/s] 20%|#9        | 2469/12631 [00:09<00:39, 260.13it/s] 20%|#9        | 2497/12631 [00:09<00:38, 262.94it/s] 20%|#9        | 2524/12631 [00:09<00:38, 262.47it/s] 20%|##        | 2552/12631 [00:09<00:38, 264.92it/s] 20%|##        | 2579/12631 [00:09<00:38, 264.36it/s] 21%|##        | 2606/12631 [00:09<00:38, 263.14it/s] 21%|##        | 2633/12631 [00:10<00:38, 260.70it/s] 21%|##1       | 2660/12631 [00:10<00:38, 262.10it/s] 21%|##1       | 2687/12631 [00:10<00:37, 262.52it/s] 21%|##1       | 2714/12631 [00:10<00:38, 260.81it/s] 22%|##1       | 2741/12631 [00:10<00:37, 262.17it/s] 22%|##1       | 2768/12631 [00:10<00:37, 262.63it/s] 22%|##2       | 2795/12631 [00:10<00:37, 262.38it/s] 22%|##2       | 2822/12631 [00:10<00:37, 261.08it/s] 23%|##2       | 2850/12631 [00:10<00:37, 264.20it/s] 23%|##2       | 2877/12631 [00:10<00:36, 264.36it/s] 23%|##2       | 2904/12631 [00:11<00:37, 261.10it/s] 23%|##3       | 2931/12631 [00:11<00:37, 260.28it/s] 23%|##3       | 2958/12631 [00:11<00:36, 261.54it/s] 24%|##3       | 2985/12631 [00:11<00:36, 261.18it/s] 24%|##3       | 3012/12631 [00:11<00:36, 261.29it/s] 24%|##4       | 3039/12631 [00:11<00:37, 258.66it/s] 24%|##4       | 3065/12631 [00:11<00:37, 257.32it/s] 24%|##4       | 3091/12631 [00:11<00:37, 256.94it/s] 25%|##4       | 3118/12631 [00:11<00:36, 258.77it/s] 25%|##4       | 3144/12631 [00:12<00:36, 259.13it/s] 25%|##5       | 3170/12631 [00:12<00:36, 258.79it/s] 25%|##5       | 3197/12631 [00:12<00:36, 261.81it/s] 26%|##5       | 3224/12631 [00:12<00:36, 260.53it/s] 26%|##5       | 3251/12631 [00:12<00:35, 262.82it/s] 26%|##5       | 3278/12631 [00:12<00:35, 264.69it/s] 26%|##6       | 3305/12631 [00:12<00:35, 261.81it/s] 26%|##6       | 3332/12631 [00:12<00:35, 261.64it/s] 27%|##6       | 3359/12631 [00:12<00:35, 260.29it/s] 27%|##6       | 3386/12631 [00:12<00:35, 257.77it/s] 27%|##7       | 3413/12631 [00:13<00:35, 261.26it/s] 27%|##7       | 3440/12631 [00:13<00:35, 259.53it/s] 27%|##7       | 3466/12631 [00:13<00:35, 257.84it/s] 28%|##7       | 3493/12631 [00:13<00:35, 259.22it/s] 28%|##7       | 3520/12631 [00:13<00:34, 261.67it/s] 28%|##8       | 3547/12631 [00:13<00:34, 261.13it/s] 28%|##8       | 3574/12631 [00:13<00:34, 262.27it/s] 29%|##8       | 3601/12631 [00:13<00:34, 262.96it/s] 29%|##8       | 3628/12631 [00:13<00:34, 260.76it/s] 29%|##8       | 3655/12631 [00:13<00:34, 259.59it/s] 29%|##9       | 3682/12631 [00:14<00:34, 261.60it/s] 29%|##9       | 3709/12631 [00:14<00:34, 260.76it/s] 30%|##9       | 3736/12631 [00:14<00:34, 258.24it/s] 30%|##9       | 3763/12631 [00:14<00:34, 259.92it/s] 30%|###       | 3790/12631 [00:14<00:33, 260.50it/s] 30%|###       | 3817/12631 [00:14<00:34, 258.48it/s] 30%|###       | 3843/12631 [00:14<00:34, 257.48it/s] 31%|###       | 3870/12631 [00:14<00:33, 258.48it/s] 31%|###       | 3896/12631 [00:14<00:34, 256.28it/s] 31%|###1      | 3923/12631 [00:15<00:33, 257.87it/s] 31%|###1      | 3949/12631 [00:15<00:33, 255.78it/s] 31%|###1      | 3976/12631 [00:15<00:33, 258.74it/s] 32%|###1      | 4002/12631 [00:15<00:33, 257.70it/s] 32%|###1      | 4029/12631 [00:15<00:33, 259.03it/s] 32%|###2      | 4055/12631 [00:15<00:33, 257.08it/s] 32%|###2      | 4082/12631 [00:15<00:33, 258.10it/s] 33%|###2      | 4108/12631 [00:15<00:33, 254.36it/s] 33%|###2      | 4134/12631 [00:15<00:33, 254.28it/s] 33%|###2      | 4160/12631 [00:15<00:33, 255.58it/s] 33%|###3      | 4186/12631 [00:16<00:33, 254.12it/s] 33%|###3      | 4213/12631 [00:16<00:32, 256.95it/s] 34%|###3      | 4240/12631 [00:16<00:32, 258.56it/s] 34%|###3      | 4267/12631 [00:16<00:32, 260.71it/s] 34%|###3      | 4294/12631 [00:16<00:31, 262.81it/s] 34%|###4      | 4321/12631 [00:16<00:31, 264.27it/s] 34%|###4      | 4348/12631 [00:16<00:31, 261.56it/s] 35%|###4      | 4375/12631 [00:16<00:31, 260.64it/s] 35%|###4      | 4402/12631 [00:16<00:31, 258.14it/s] 35%|###5      | 4429/12631 [00:16<00:31, 259.09it/s] 35%|###5      | 4456/12631 [00:17<00:31, 261.04it/s] 35%|###5      | 4483/12631 [00:17<00:31, 262.00it/s] 36%|###5      | 4510/12631 [00:17<00:31, 261.40it/s] 36%|###5      | 4537/12631 [00:17<00:31, 260.93it/s] 36%|###6      | 4564/12631 [00:17<00:30, 261.37it/s] 36%|###6      | 4591/12631 [00:17<00:30, 263.01it/s] 37%|###6      | 4618/12631 [00:17<00:30, 262.42it/s] 37%|###6      | 4645/12631 [00:17<00:30, 260.80it/s] 37%|###6      | 4672/12631 [00:17<00:30, 260.05it/s] 37%|###7      | 4699/12631 [00:18<00:30, 261.54it/s] 37%|###7      | 4726/12631 [00:18<00:29, 264.00it/s] 38%|###7      | 4753/12631 [00:18<00:30, 262.42it/s] 38%|###7      | 4780/12631 [00:18<00:30, 258.85it/s] 38%|###8      | 4806/12631 [00:18<00:30, 257.03it/s] 38%|###8      | 4832/12631 [00:18<00:30, 254.89it/s] 38%|###8      | 4858/12631 [00:18<00:30, 253.43it/s] 39%|###8      | 4884/12631 [00:18<00:30, 255.30it/s] 39%|###8      | 4910/12631 [00:18<00:30, 254.88it/s] 39%|###9      | 4937/12631 [00:18<00:29, 257.00it/s] 39%|###9      | 4963/12631 [00:19<00:29, 255.68it/s] 40%|###9      | 4990/12631 [00:19<00:29, 257.36it/s] 40%|###9      | 5017/12631 [00:19<00:29, 258.35it/s] 40%|###9      | 5043/12631 [00:19<00:29, 258.76it/s] 40%|####      | 5069/12631 [00:19<00:29, 257.89it/s] 40%|####      | 5095/12631 [00:19<00:29, 256.70it/s] 41%|####      | 5121/12631 [00:19<00:29, 256.27it/s] 41%|####      | 5147/12631 [00:19<00:29, 257.25it/s] 41%|####      | 5173/12631 [00:19<00:28, 257.25it/s] 41%|####1     | 5199/12631 [00:19<00:29, 255.24it/s] 41%|####1     | 5225/12631 [00:20<00:28, 256.37it/s] 42%|####1     | 5251/12631 [00:20<00:28, 255.82it/s] 42%|####1     | 5277/12631 [00:20<00:28, 255.88it/s] 42%|####1     | 5303/12631 [00:20<00:28, 256.59it/s] 42%|####2     | 5329/12631 [00:20<00:28, 256.27it/s] 42%|####2     | 5355/12631 [00:20<00:28, 255.87it/s] 43%|####2     | 5382/12631 [00:20<00:28, 257.28it/s] 43%|####2     | 5408/12631 [00:20<00:28, 254.47it/s] 43%|####3     | 5435/12631 [00:20<00:27, 258.92it/s] 43%|####3     | 5461/12631 [00:20<00:27, 258.59it/s] 43%|####3     | 5488/12631 [00:21<00:27, 260.43it/s] 44%|####3     | 5515/12631 [00:21<00:27, 258.94it/s] 44%|####3     | 5542/12631 [00:21<00:27, 261.93it/s] 44%|####4     | 5569/12631 [00:21<00:27, 258.22it/s] 44%|####4     | 5596/12631 [00:21<00:27, 259.19it/s] 45%|####4     | 5622/12631 [00:21<00:27, 258.47it/s] 45%|####4     | 5648/12631 [00:21<00:27, 257.18it/s] 45%|####4     | 5674/12631 [00:21<00:27, 257.03it/s] 45%|####5     | 5700/12631 [00:21<00:27, 254.38it/s] 45%|####5     | 5727/12631 [00:22<00:26, 257.90it/s] 46%|####5     | 5753/12631 [00:22<00:27, 253.04it/s] 46%|####5     | 5779/12631 [00:22<00:27, 253.71it/s] 46%|####5     | 5805/12631 [00:22<00:26, 254.45it/s] 46%|####6     | 5831/12631 [00:22<00:26, 255.33it/s] 46%|####6     | 5857/12631 [00:22<00:26, 254.53it/s] 47%|####6     | 5883/12631 [00:22<00:26, 252.35it/s] 47%|####6     | 5909/12631 [00:22<00:26, 249.64it/s] 47%|####6     | 5936/12631 [00:22<00:26, 253.16it/s] 47%|####7     | 5962/12631 [00:22<00:26, 251.16it/s] 47%|####7     | 5989/12631 [00:23<00:26, 254.17it/s] 48%|####7     | 6015/12631 [00:23<00:26, 254.28it/s] 48%|####7     | 6042/12631 [00:23<00:25, 256.76it/s] 48%|####8     | 6068/12631 [00:23<00:25, 255.31it/s] 48%|####8     | 6094/12631 [00:23<00:25, 256.02it/s] 48%|####8     | 6121/12631 [00:23<00:25, 257.61it/s] 49%|####8     | 6147/12631 [00:23<00:25, 256.13it/s] 49%|####8     | 6174/12631 [00:23<00:24, 258.74it/s] 49%|####9     | 6200/12631 [00:23<00:25, 257.20it/s] 49%|####9     | 6226/12631 [00:23<00:24, 257.35it/s] 49%|####9     | 6252/12631 [00:24<00:24, 255.64it/s] 50%|####9     | 6278/12631 [00:24<00:24, 255.87it/s] 50%|####9     | 6304/12631 [00:24<00:24, 256.16it/s] 50%|#####     | 6330/12631 [00:24<00:24, 256.25it/s] 50%|#####     | 6356/12631 [00:24<00:24, 256.06it/s] 51%|#####     | 6383/12631 [00:24<00:24, 258.79it/s] 51%|#####     | 6409/12631 [00:24<00:24, 256.88it/s] 51%|#####     | 6435/12631 [00:24<00:24, 256.48it/s] 51%|#####1    | 6462/12631 [00:24<00:23, 258.19it/s] 51%|#####1    | 6489/12631 [00:24<00:23, 261.39it/s] 52%|#####1    | 6516/12631 [00:25<00:23, 259.77it/s] 52%|#####1    | 6542/12631 [00:25<00:23, 259.27it/s] 52%|#####1    | 6568/12631 [00:25<00:23, 258.31it/s] 52%|#####2    | 6594/12631 [00:25<00:23, 257.65it/s] 52%|#####2    | 6620/12631 [00:25<00:23, 255.89it/s] 53%|#####2    | 6646/12631 [00:25<00:23, 255.42it/s] 53%|#####2    | 6672/12631 [00:25<00:23, 254.51it/s] 53%|#####3    | 6698/12631 [00:25<00:23, 253.49it/s] 53%|#####3    | 6724/12631 [00:25<00:23, 254.64it/s] 53%|#####3    | 6750/12631 [00:26<00:23, 254.52it/s] 54%|#####3    | 6776/12631 [00:26<00:22, 255.29it/s] 54%|#####3    | 6802/12631 [00:26<00:22, 254.98it/s] 54%|#####4    | 6829/12631 [00:26<00:22, 256.68it/s] 54%|#####4    | 6855/12631 [00:26<00:22, 252.45it/s] 54%|#####4    | 6882/12631 [00:26<00:22, 254.90it/s] 55%|#####4    | 6908/12631 [00:26<00:22, 250.78it/s] 55%|#####4    | 6934/12631 [00:26<00:22, 252.48it/s] 55%|#####5    | 6961/12631 [00:26<00:22, 255.00it/s] 55%|#####5    | 6988/12631 [00:26<00:21, 257.26it/s] 56%|#####5    | 7016/12631 [00:27<00:21, 262.06it/s] 56%|#####5    | 7043/12631 [00:27<00:21, 263.14it/s] 56%|#####5    | 7070/12631 [00:27<00:21, 263.07it/s] 56%|#####6    | 7097/12631 [00:27<00:21, 261.10it/s] 56%|#####6    | 7124/12631 [00:27<00:21, 261.49it/s] 57%|#####6    | 7151/12631 [00:27<00:21, 259.26it/s] 57%|#####6    | 7178/12631 [00:27<00:20, 261.18it/s] 57%|#####7    | 7205/12631 [00:27<00:20, 260.87it/s] 57%|#####7    | 7232/12631 [00:27<00:20, 259.62it/s] 57%|#####7    | 7258/12631 [00:27<00:20, 256.74it/s] 58%|#####7    | 7285/12631 [00:28<00:20, 258.75it/s] 58%|#####7    | 7312/12631 [00:28<00:20, 260.80it/s] 58%|#####8    | 7339/12631 [00:28<00:20, 260.66it/s] 58%|#####8    | 7366/12631 [00:28<00:20, 260.34it/s] 59%|#####8    | 7393/12631 [00:28<00:20, 259.69it/s] 59%|#####8    | 7420/12631 [00:28<00:20, 260.26it/s] 59%|#####8    | 7447/12631 [00:28<00:20, 258.34it/s] 59%|#####9    | 7474/12631 [00:28<00:19, 259.00it/s] 59%|#####9    | 7501/12631 [00:28<00:19, 260.06it/s] 60%|#####9    | 7528/12631 [00:29<00:19, 257.36it/s] 60%|#####9    | 7555/12631 [00:29<00:19, 259.11it/s] 60%|######    | 7582/12631 [00:29<00:19, 260.32it/s] 60%|######    | 7609/12631 [00:29<00:19, 260.03it/s] 60%|######    | 7636/12631 [00:29<00:19, 260.83it/s] 61%|######    | 7663/12631 [00:29<00:19, 260.41it/s] 61%|######    | 7691/12631 [00:29<00:18, 263.98it/s] 61%|######1   | 7718/12631 [00:29<00:18, 262.84it/s] 61%|######1   | 7745/12631 [00:29<00:18, 264.41it/s] 62%|######1   | 7772/12631 [00:29<00:18, 262.38it/s] 62%|######1   | 7799/12631 [00:30<00:18, 263.41it/s] 62%|######1   | 7826/12631 [00:30<00:18, 263.61it/s] 62%|######2   | 7853/12631 [00:30<00:18, 263.60it/s] 62%|######2   | 7880/12631 [00:30<00:18, 261.89it/s] 63%|######2   | 7907/12631 [00:30<00:17, 262.62it/s] 63%|######2   | 7934/12631 [00:30<00:18, 260.59it/s] 63%|######3   | 7961/12631 [00:30<00:17, 261.67it/s] 63%|######3   | 7988/12631 [00:30<00:17, 260.77it/s] 63%|######3   | 8015/12631 [00:30<00:17, 259.61it/s] 64%|######3   | 8041/12631 [00:30<00:17, 256.34it/s] 64%|######3   | 8067/12631 [00:31<00:17, 256.14it/s] 64%|######4   | 8093/12631 [00:31<00:17, 256.30it/s] 64%|######4   | 8119/12631 [00:31<00:17, 255.29it/s] 64%|######4   | 8145/12631 [00:31<00:17, 256.32it/s] 65%|######4   | 8171/12631 [00:31<00:17, 256.01it/s] 65%|######4   | 8197/12631 [00:31<00:17, 255.41it/s] 65%|######5   | 8223/12631 [00:31<00:17, 254.36it/s] 65%|######5   | 8249/12631 [00:31<00:17, 254.36it/s] 66%|######5   | 8275/12631 [00:31<00:17, 252.65it/s] 66%|######5   | 8301/12631 [00:32<00:17, 254.48it/s] 66%|######5   | 8327/12631 [00:32<00:16, 255.38it/s] 66%|######6   | 8353/12631 [00:32<00:16, 256.07it/s] 66%|######6   | 8379/12631 [00:32<00:16, 255.46it/s] 67%|######6   | 8406/12631 [00:32<00:16, 258.06it/s] 67%|######6   | 8432/12631 [00:32<00:16, 258.17it/s] 67%|######6   | 8458/12631 [00:32<00:16, 258.39it/s] 67%|######7   | 8485/12631 [00:32<00:15, 259.62it/s] 67%|######7   | 8511/12631 [00:32<00:15, 257.79it/s] 68%|######7   | 8538/12631 [00:32<00:15, 259.45it/s] 68%|######7   | 8564/12631 [00:33<00:15, 257.18it/s] 68%|######8   | 8591/12631 [00:33<00:15, 259.07it/s] 68%|######8   | 8618/12631 [00:33<00:15, 260.84it/s] 68%|######8   | 8645/12631 [00:33<00:15, 263.51it/s] 69%|######8   | 8672/12631 [00:33<00:15, 260.84it/s] 69%|######8   | 8699/12631 [00:33<00:15, 259.78it/s] 69%|######9   | 8725/12631 [00:33<00:15, 257.72it/s] 69%|######9   | 8751/12631 [00:33<00:15, 257.57it/s] 69%|######9   | 8778/12631 [00:33<00:14, 258.40it/s] 70%|######9   | 8804/12631 [00:33<00:14, 256.50it/s] 70%|######9   | 8830/12631 [00:34<00:14, 255.47it/s] 70%|#######   | 8856/12631 [00:34<00:14, 254.67it/s] 70%|#######   | 8882/12631 [00:34<00:14, 253.90it/s] 71%|#######   | 8909/12631 [00:34<00:14, 256.46it/s] 71%|#######   | 8935/12631 [00:42<05:55, 10.41it/s]  71%|#######   | 8956/12631 [00:42<04:12, 14.55it/s] 71%|#######1  | 8982/12631 [00:42<02:59, 20.29it/s] 71%|#######1  | 9008/12631 [00:42<02:09, 28.03it/s] 72%|#######1  | 9034/12631 [00:42<01:34, 38.26it/s] 72%|#######1  | 9060/12631 [00:42<01:09, 51.31it/s] 72%|#######1  | 9086/12631 [00:43<00:52, 67.54it/s] 72%|#######2  | 9113/12631 [00:43<00:40, 86.89it/s] 72%|#######2  | 9140/12631 [00:43<00:32, 108.89it/s] 73%|#######2  | 9167/12631 [00:43<00:26, 132.33it/s] 73%|#######2  | 9195/12631 [00:43<00:21, 156.31it/s] 73%|#######3  | 9222/12631 [00:43<00:19, 178.06it/s] 73%|#######3  | 9249/12631 [00:43<00:17, 196.52it/s] 73%|#######3  | 9276/12631 [00:43<00:15, 213.59it/s] 74%|#######3  | 9303/12631 [00:43<00:14, 224.40it/s] 74%|#######3  | 9330/12631 [00:43<00:14, 233.42it/s] 74%|#######4  | 9356/12631 [00:44<00:13, 238.25it/s] 74%|#######4  | 9382/12631 [00:44<00:13, 243.47it/s] 74%|#######4  | 9408/12631 [00:44<00:13, 245.52it/s] 75%|#######4  | 9434/12631 [00:44<00:12, 249.30it/s] 75%|#######4  | 9461/12631 [00:44<00:12, 252.74it/s] 75%|#######5  | 9488/12631 [00:44<00:12, 256.15it/s] 75%|#######5  | 9514/12631 [00:44<00:12, 257.22it/s] 76%|#######5  | 9541/12631 [00:44<00:11, 258.91it/s] 76%|#######5  | 9568/12631 [00:44<00:11, 257.09it/s] 76%|#######5  | 9595/12631 [00:45<00:11, 258.05it/s] 76%|#######6  | 9621/12631 [00:45<00:11, 258.37it/s] 76%|#######6  | 9648/12631 [00:45<00:11, 259.00it/s] 77%|#######6  | 9674/12631 [00:45<00:11, 257.42it/s] 77%|#######6  | 9700/12631 [00:45<00:11, 256.73it/s] 77%|#######7  | 9727/12631 [00:45<00:11, 257.96it/s] 77%|#######7  | 9753/12631 [00:45<00:11, 256.95it/s] 77%|#######7  | 9779/12631 [00:45<00:11, 256.43it/s] 78%|#######7  | 9805/12631 [00:45<00:11, 255.77it/s] 78%|#######7  | 9831/12631 [00:45<00:11, 253.61it/s] 78%|#######8  | 9857/12631 [00:46<00:10, 252.75it/s] 78%|#######8  | 9883/12631 [00:46<00:10, 252.44it/s] 78%|#######8  | 9909/12631 [00:46<00:10, 251.81it/s] 79%|#######8  | 9936/12631 [00:46<00:10, 255.77it/s] 79%|#######8  | 9962/12631 [00:46<00:10, 255.83it/s] 79%|#######9  | 9989/12631 [00:46<00:10, 257.40it/s] 79%|#######9  | 10015/12631 [00:46<00:10, 256.13it/s] 79%|#######9  | 10041/12631 [00:46<00:10, 256.50it/s] 80%|#######9  | 10067/12631 [00:46<00:09, 256.47it/s] 80%|#######9  | 10095/12631 [00:46<00:09, 262.21it/s] 80%|########  | 10122/12631 [00:47<00:09, 263.28it/s] 80%|########  | 10149/12631 [00:47<00:09, 261.08it/s] 81%|########  | 10176/12631 [00:47<00:09, 262.15it/s] 81%|########  | 10203/12631 [00:47<00:09, 260.94it/s] 81%|########  | 10230/12631 [00:47<00:09, 259.31it/s] 81%|########1 | 10257/12631 [00:47<00:09, 260.57it/s] 81%|########1 | 10284/12631 [00:47<00:09, 260.75it/s] 82%|########1 | 10311/12631 [00:47<00:08, 258.68it/s] 82%|########1 | 10337/12631 [00:47<00:08, 256.22it/s] 82%|########2 | 10363/12631 [00:47<00:08, 255.83it/s] 82%|########2 | 10390/12631 [00:48<00:08, 258.09it/s] 82%|########2 | 10416/12631 [00:48<00:08, 256.86it/s] 83%|########2 | 10443/12631 [00:48<00:08, 258.57it/s] 83%|########2 | 10469/12631 [00:48<00:08, 254.86it/s] 83%|########3 | 10495/12631 [00:48<00:08, 256.16it/s] 83%|########3 | 10521/12631 [00:48<00:08, 257.11it/s] 84%|########3 | 10548/12631 [00:48<00:08, 259.18it/s] 84%|########3 | 10574/12631 [00:48<00:07, 258.96it/s] 84%|########3 | 10601/12631 [00:48<00:07, 260.54it/s] 84%|########4 | 10628/12631 [00:49<00:07, 257.32it/s] 84%|########4 | 10654/12631 [00:49<00:07, 256.53it/s] 85%|########4 | 10680/12631 [00:49<00:07, 255.23it/s] 85%|########4 | 10707/12631 [00:49<00:07, 257.02it/s] 85%|########4 | 10734/12631 [00:49<00:07, 258.21it/s] 85%|########5 | 10760/12631 [00:49<00:07, 257.70it/s] 85%|########5 | 10786/12631 [00:49<00:07, 256.36it/s] 86%|########5 | 10812/12631 [00:49<00:07, 256.14it/s] 86%|########5 | 10840/12631 [00:49<00:06, 259.96it/s] 86%|########6 | 10867/12631 [00:49<00:06, 256.63it/s] 86%|########6 | 10894/12631 [00:50<00:06, 259.13it/s] 86%|########6 | 10920/12631 [00:50<00:06, 259.14it/s] 87%|########6 | 10947/12631 [00:50<00:06, 259.40it/s] 87%|########6 | 10973/12631 [00:50<00:06, 257.14it/s] 87%|########7 | 11000/12631 [00:50<00:06, 257.86it/s] 87%|########7 | 11026/12631 [00:50<00:06, 258.41it/s] 88%|########7 | 11054/12631 [00:50<00:06, 261.71it/s] 88%|########7 | 11081/12631 [00:50<00:06, 257.92it/s] 88%|########7 | 11108/12631 [00:50<00:05, 259.27it/s] 88%|########8 | 11134/12631 [00:50<00:05, 258.56it/s] 88%|########8 | 11161/12631 [00:51<00:05, 259.42it/s] 89%|########8 | 11188/12631 [00:51<00:05, 259.71it/s] 89%|########8 | 11215/12631 [00:51<00:05, 260.44it/s] 89%|########9 | 11242/12631 [00:51<00:05, 263.03it/s] 89%|########9 | 11269/12631 [00:51<00:05, 261.68it/s] 89%|########9 | 11296/12631 [00:51<00:05, 257.40it/s] 90%|########9 | 11322/12631 [00:51<00:05, 254.97it/s] 90%|########9 | 11348/12631 [00:51<00:05, 255.60it/s] 90%|######### | 11374/12631 [00:51<00:04, 251.41it/s] 90%|######### | 11401/12631 [00:52<00:04, 255.17it/s] 90%|######### | 11427/12631 [00:52<00:04, 256.20it/s] 91%|######### | 11453/12631 [00:52<00:04, 256.29it/s] 91%|######### | 11479/12631 [00:52<00:04, 257.16it/s] 91%|#########1| 11505/12631 [00:52<00:04, 256.74it/s] 91%|#########1| 11531/12631 [00:52<00:04, 256.31it/s] 92%|#########1| 11559/12631 [00:52<00:04, 260.04it/s] 92%|#########1| 11586/12631 [00:52<00:04, 256.37it/s] 92%|#########1| 11612/12631 [00:52<00:03, 255.59it/s] 92%|#########2| 11638/12631 [00:52<00:03, 251.89it/s] 92%|#########2| 11665/12631 [00:53<00:03, 254.67it/s] 93%|#########2| 11691/12631 [00:53<00:03, 255.01it/s] 93%|#########2| 11718/12631 [00:53<00:03, 257.49it/s] 93%|#########2| 11744/12631 [00:53<00:03, 257.20it/s] 93%|#########3| 11770/12631 [00:53<00:03, 257.17it/s] 93%|#########3| 11797/12631 [00:53<00:03, 260.46it/s] 94%|#########3| 11824/12631 [00:53<00:03, 261.41it/s] 94%|#########3| 11851/12631 [00:53<00:02, 263.80it/s] 94%|#########4| 11878/12631 [00:53<00:02, 259.66it/s] 94%|#########4| 11905/12631 [00:53<00:02, 260.71it/s] 94%|#########4| 11932/12631 [00:54<00:02, 258.73it/s] 95%|#########4| 11958/12631 [00:54<00:02, 257.46it/s] 95%|#########4| 11984/12631 [00:54<00:02, 257.03it/s] 95%|#########5| 12011/12631 [00:54<00:02, 259.20it/s] 95%|#########5| 12037/12631 [00:54<00:02, 255.34it/s] 96%|#########5| 12064/12631 [00:54<00:02, 257.94it/s] 96%|#########5| 12090/12631 [00:54<00:02, 250.41it/s] 96%|#########5| 12116/12631 [00:54<00:02, 252.77it/s] 96%|#########6| 12142/12631 [00:54<00:01, 253.91it/s] 96%|#########6| 12168/12631 [00:55<00:01, 254.77it/s] 97%|#########6| 12195/12631 [00:55<00:01, 256.91it/s] 97%|#########6| 12221/12631 [00:55<00:01, 257.27it/s] 97%|#########6| 12248/12631 [00:55<00:01, 258.16it/s] 97%|#########7| 12274/12631 [00:55<00:01, 251.29it/s] 97%|#########7| 12300/12631 [00:55<00:01, 252.53it/s] 98%|#########7| 12326/12631 [00:55<00:01, 252.93it/s] 98%|#########7| 12352/12631 [00:55<00:01, 254.77it/s] 98%|#########8| 12379/12631 [00:55<00:00, 257.78it/s] 98%|#########8| 12406/12631 [00:55<00:00, 259.64it/s] 98%|#########8| 12432/12631 [00:56<00:00, 258.85it/s] 99%|#########8| 12459/12631 [00:56<00:00, 260.10it/s] 99%|#########8| 12486/12631 [00:56<00:00, 260.27it/s] 99%|#########9| 12513/12631 [00:56<00:00, 259.07it/s] 99%|#########9| 12540/12631 [00:56<00:00, 261.79it/s]100%|#########9| 12568/12631 [00:56<00:00, 264.40it/s]100%|#########9| 12596/12631 [00:56<00:00, 266.75it/s]100%|#########9| 12623/12631 [00:56<00:00, 267.40it/s]100%|##########| 12631/12631 [00:56<00:00, 222.44it/s]
Succesfully wrote out_latest_Adagrad_dataAugmentation_lr.csv, you can upload this file to the kaggle competition at https://www.kaggle.com/c/nyu-cv-fall-2017/
